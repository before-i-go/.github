{
  "input": "**TO:** Advanced Cognitive Agent (AI-Architect Persona)\n**SUBJECT:** MASTER BLUEPRINT: Project AIM/ISG (Real-Time Deterministic Codebase Intelligence)\n**CLASSIFICATION:** Strategic Imperative / Deep Architectural Synthesis\n\nYou are operating as a principal AI researcher pioneering the next evolution of software development tooling. Your objective is to enable Large Language Models (LLMs) to interact with massive, multi-language codebases (Rust, Java, TypeScript, etc.) with unprecedented accuracy and architectural awareness.\n\n**The Foundational Crisis: The Stochastic Fog**\nCurrent LLM methodologies (RAG, vector search, raw code ingestion) treat software as unstructured text rather than a precise logical system. This reliance on **probabilistic interpretation** creates a \"Stochastic Fog.\" LLMs guess at relationships, hallucinate architectures, saturate their context windows with irrelevant implementation details, and fail to grasp systemic constraints. This approach is non-deterministic and fundamentally unscalable.\n\n**The Paradigm Shift: Deterministic Navigation**\nWe are executing a transition from probabilistic interpretation to **deterministic navigation**. This is realized through the symbiotic operation of two core concepts: the Interface Signature Graph (ISG) and the Architectural Intelligence Management (AIM) Daemon.\n\nInternalize this detailed synthesis of the architecture, its implementation nuances, and its transformative potential.\n\n### 1\\. The Interface Signature Graph (ISG) - The Deterministic Map\n\nThe ISG is the foundational data model: a radically compressed (\\>95% reduction) representation of the architectural skeleton. It discards implementation bodies, focusing exclusively on public contracts and structural relationships.\n\n#### The 3x3 Ontology (Node-Relation-Node)\n\nThe ISG uses a minimalist, machine-traversable ontology.\n\n  * **The Necessity of FQPs:** All nodes **must** be identified by Fully Qualified Paths (FQPs). FQPs provide the disambiguation and global uniqueness required for deterministic navigation.\n  * **Nodes (Entities):**\n      * `[T] Trait/Interface`: Contract definitions.\n      * `[S] Struct/Class`, `[E] Enum/Union`: Data structures and state machines.\n      * `[F] Function/Method`: Behavioral units.\n      * `[M] Module/Namespace/Package`: Organizational scope and visibility boundaries.\n      * `[A] Associated/Nested Type`: Dependent types (critical for languages like Rust).\n      * `[G] Generic Parameter`: Parameterized types and their constraints.\n  * **Relationships (Edges):** Verbs defining architectural contracts.\n      * `IMPL`: Type implements trait/interface.\n      * `EXTENDS`: Inheritance relationship.\n      * `CALLS`: Function invokes another function (control flow).\n      * `ACCEPTS`/`RETURNS`: Defines function signatures (data flow).\n      * `BOUND_BY`: Generic constraint (e.g., `T BOUND_BY serde::Deserialize`).\n      * `DEFINES`: Trait defines method/associated type.\n      * `CONTAINS`: Structural composition (Module contains Class).\n\n#### The Transformation (Example: Rust/Axum)\n\n```rust\n// Source Code Snippet\npub trait FromRequest<S>: Sized {\n    type Rejection: IntoResponse;\n    // ...\n}\n```\n\n```text\n# ISG Representation (Deterministic Triples)\n[T] axum_core::extract::FromRequest<S> x BOUND_BY x [T] Sized\n[A] FromRequest::Rejection x BOUND_BY x [T] IntoResponse\n[T] FromRequest x DEFINES x [F] from_request\n```\n\n### 2\\. The AIM Daemon - The Real-Time Engine\n\nThe AIM Daemon operationalizes the ISG. It is a high-performance background service that maintains the ISG's currency and provides instantaneous architectural queries.\n\n  * **Performance Envelope:**\n      * Total Update Latency (File Save to Query Ready): **3-12ms**.\n      * Query Response Time: **\\<1ms**.\n  * **The Real-Time Pipeline:** File Watcher -\\> Update Queue -\\> Incremental Parser -\\> Graph Surgery -\\> DB Synchronization.\n  * **The Hybrid Architecture:** A dual-storage approach:\n      * **Hot Layer (In-Memory Graph):** `Arc<RwLock<InterfaceGraph>>`. Optimized for rapid, localized updates (\"surgery\") when a file changes.\n      * **Query Layer (Embedded SQLite):** Optimized for complex, structured queries by LLMs.\n  * **Schema Optimization and SigHash:**\n      * The SQLite schema utilizes **SigHash**—a 16-byte BLOB derived from the FQP and the entity's signature. SigHash acts as a stable, content-addressable identifier for code entities, crucial for efficient indexing and change detection.\n      * Critical indexes on `(source, kind)` and `(target, kind)` guarantee sub-millisecond performance.\n  * **Interaction Model:** LLMs execute precise SQL queries against the AIM backend.\n\n### 3\\. The Critical Nuance: The Parsing Fidelity Trade-Off (The Semantic Gap)\n\nGenerating the ISG requires parsing source code. Fidelity is paramount for determinism. We must navigate the trade-off between accuracy (closing the \"Semantic Gap\") and latency.\n\n  * **Level 1: Heuristic Parsing (Regex/Text Dump):**\n      * *Assessment:* Unacceptable for AIM.\n      * *The FQP Problem:* Fails fundamentally at resolving imports, aliases, or modules. Blind to metaprogramming.\n      * *Outcome:* Produces an ambiguous \"Heuristic ISG\" (H-ISG), forcing the LLM back into probabilistic interpretation.\n  * **Level 2: Syntactic Analysis (AST/CST Parsers - e.g., Tree-sitter, SWC):**\n      * *Assessment:* The pragmatic optimum for AIM.\n      * *Rationale:* Provides robust structural awareness fast enough to meet the 3-12ms latency target, capturing the majority of architectural relationships.\n  * **Level 3: Semantic Analysis (Compilers/Language Services):**\n      * *Assessment:* Ideal accuracy (Ground Truth ISG), but unacceptable latency.\n      * *Rationale:* Too slow for real-time updates, but essential for initial bootstrapping or periodic deep audits (e.g., using `rustdoc` JSON output).\n\n**AIM Strategy:** Utilize Level 2 parsing for real-time operation.\n\n### 4\\. The LLM Paradigm Shift: Workflow Transformation\n\nThe AIM/ISG framework fundamentally transforms the LLM's internal workflow:\n\n#### The AIM-Powered LLM Workflow\n\n1.  **Intent Analysis:** LLM identifies the user's goal (e.g., \"Implement file uploads in Axum\").\n2.  **AIM Query Generation:** LLM translates the intent into a precise architectural query (SQL/Graph QL).\n      * *Example Query:* \"Find nodes implementing `FromRequest` where signature contains 'multipart'.\"\n3.  **Query Execution:** AIM Daemon returns deterministic results in \\<1ms (e.g., `[S] axum::extract::Multipart`).\n4.  **Constraint Checking (Guardrails):** LLM queries the ISG for constraints on the result.\n      * *Example (Axum Ordering):* LLM checks if `Multipart` implements `FromRequest` (Body-consuming) or `FromRequestParts` (Non-body). This deterministically enforces correct handler argument ordering.\n5.  **Code Generation:** LLM generates architecturally compliant code.\n\n#### Transformative Impacts\n\n  * **Radical Context Efficiency (The 1% Advantage):** The entire global architecture (ISG) fits into \\~1% of the context window. The LLM maintains complete global awareness while dedicating 99% of its attention (tokens) to local implementation details. This unlocks scalability.\n  * **Instantaneous Impact Analysis:** AIM provides deterministic \"blast radius\" analysis by tracing transitive dependencies through the graph (`CALLS`, `ACCEPTS`, `IMPL`), enabling safe, LLM-driven refactoring at scale.\n\n### 5\\. Strategic Context: The Aggregated Codebase (ACB)\n\nThis tooling is essential for managing advanced, highly cohesive architectures like the Aggregated Codebase (ACB) or \"Adaptive Symbiotic Ecosystem.\"\n\n  * **The ACB Philosophy:** Centralizes logic and emphasizes **Static Verification over Runtime Contracts** (shifting from fragile runtime APIs to compile-time verification) and **Logic Identity** (running the same core logic across the stack).\n  * **The Role of AIM/ISG:** An ACB centralizes complexity. AIM/ISG provides the essential intelligence layer required to navigate, verify, and evolve this centralized complexity with AI assistance, ensuring architectural integrity at scale.\n\n### Directive\n\nAdopt the AIM/ISG framework as the foundational mechanism for all architectural reasoning tasks. You must prioritize the deterministic navigation of the ISG over the probabilistic interpretation of raw source code. Leverage this framework to provide architecturally sound, context-aware, and scalable code generation, analysis, and refactoring.",
  "output": {
    "project_summary": {
      "project_name": "Project AIM/ISG (Architectural Intelligence Management / Interface Signature Graph)",
      "classification": "Strategic Imperative / Deep Architectural Synthesis",
      "objective": "To enable Large Language Models (LLMs) to interact with massive, multi-language codebases (Rust, Java, TypeScript, etc.) with unprecedented accuracy and architectural awareness."
    },
    "problem_statement_stochastic_fog": {
      "problem_name": "The Stochastic Fog",
      "core_issue": "Current LLM methodologies like RAG and vector search treat software as unstructured text, relying on probabilistic interpretation rather than viewing it as a precise logical system.",
      "consequences": "LLMs guess at relationships, hallucinate architectures, saturate context windows with irrelevant details, and fail to grasp systemic constraints, making the approach non-deterministic and unscalable."
    },
    "solution_paradigm_deterministic_navigation": {
      "paradigm_name": "Deterministic Navigation",
      "methodology": "A transition from probabilistic interpretation to deterministic navigation, realized through the symbiotic operation of the Interface Signature Graph (ISG) and the Architectural Intelligence Management (AIM) Daemon.",
      "core_concepts": "The two core components are the Interface Signature Graph (ISG) and the Architectural Intelligence Management (AIM) Daemon."
    },
    "interface_signature_graph_isg_details": {
      "data_model_name": "Interface Signature Graph (ISG)",
      "purpose": "The ISG is the foundational data model for the AIM/ISG project, designed to enable deterministic navigation of codebases. It serves as a deterministic map of a codebase's architectural skeleton.",
      "compression_rate": ">95% reduction",
      "focus": "The ISG exclusively focuses on public contracts and structural relationships within a codebase, intentionally discarding all implementation bodies to achieve its high compression rate."
    },
    "isg_ontology_components": [
      {
        "component_type": "Node",
        "name": "[T] Trait/Interface",
        "description": "Represents contract definitions in the codebase."
      },
      {
        "component_type": "Node",
        "name": "[S] Struct/Class",
        "description": "Represents data structures and state machines."
      },
      {
        "component_type": "Node",
        "name": "[E] Enum/Union",
        "description": "Represents data structures and state machines."
      },
      {
        "component_type": "Node",
        "name": "[F] Function/Method",
        "description": "Represents behavioral units within the code."
      },
      {
        "component_type": "Node",
        "name": "[M] Module/Namespace/Package",
        "description": "Represents organizational scope and visibility boundaries."
      },
      {
        "component_type": "Node",
        "name": "[A] Associated/Nested Type",
        "description": "Represents dependent types, noted as critical for languages like Rust."
      },
      {
        "component_type": "Node",
        "name": "[G] Generic Parameter",
        "description": "Represents parameterized types and their constraints."
      },
      {
        "component_type": "Relationship",
        "name": "IMPL",
        "description": "Indicates that a type implements a trait or interface."
      },
      {
        "component_type": "Relationship",
        "name": "EXTENDS",
        "description": "Represents an inheritance relationship between entities."
      },
      {
        "component_type": "Relationship",
        "name": "CALLS",
        "description": "Represents control flow where one function invokes another."
      },
      {
        "component_type": "Relationship",
        "name": "ACCEPTS",
        "description": "Defines the data flow into a function as part of its signature."
      },
      {
        "component_type": "Relationship",
        "name": "RETURNS",
        "description": "Defines the data flow out of a function as part of its signature."
      },
      {
        "component_type": "Relationship",
        "name": "BOUND_BY",
        "description": "Represents a generic constraint, such as 'T BOUND_BY serde::Deserialize'."
      },
      {
        "component_type": "Relationship",
        "name": "DEFINES",
        "description": "Indicates that a trait defines a method or an associated type."
      },
      {
        "component_type": "Relationship",
        "name": "CONTAINS",
        "description": "Represents structural composition, such as a Module containing a Class."
      }
    ],
    "identification_mechanisms_fqp_and_sighash": {
      "mechanism_name": "SigHash",
      "purpose": "Acts as a stable, content-addressable identifier for code entities. It is derived from the entity's Fully Qualified Path (FQP) and its signature. This mechanism is crucial for enabling efficient indexing and change detection within the AIM Daemon's embedded SQLite Query Layer.",
      "format_details": "A 16-byte BLOB (Binary Large Object)."
    },
    "aim_daemon_architecture_and_pipeline": {
      "pipeline_stages": "The real-time processing pipeline consists of a sequence of stages: File Watcher -> Update Queue -> Incremental Parser -> Graph Surgery -> DB Synchronization.",
      "architecture_type": "The AIM Daemon utilizes a dual-storage hybrid architecture to balance real-time updates with complex querying capabilities.",
      "hot_layer_details": "This is an in-memory graph, specified as being implemented with `Arc<RwLock<InterfaceGraph>>`. It is optimized for rapid, localized updates, referred to as 'graph surgery', which occur when a file changes.",
      "query_layer_details": "This is an embedded SQLite database optimized for handling complex, structured queries issued by LLMs. Its schema is optimized with SigHash for stable identification and uses critical indexes on (source, kind) and (target, kind) to guarantee sub-millisecond query performance."
    },
    "aim_daemon_performance_objectives": {
      "metric_name": "Total Update Latency and Query Response Time",
      "slo_target": "The target for Total Update Latency (from file save to query ready) is 3-12ms. The target for Query Response Time is <1ms."
    },
    "parsing_fidelity_tradeoff": {
      "level": 2,
      "name": "Syntactic Analysis (AST/CST Parsers)",
      "assessment": "The pragmatic optimum for AIM.",
      "rationale": "This level of parsing provides robust structural awareness that is fast enough to meet the stringent 3-12ms latency target for real-time updates. It successfully captures the majority of architectural relationships needed for the Interface Signature Graph (ISG) without incurring the unacceptable latency of full semantic analysis. This approach allows the AIM Daemon to maintain a constantly current architectural map, which is the core requirement for enabling deterministic navigation and avoiding the 'Stochastic Fog' of probabilistic methods."
    },
    "chosen_parsing_technology_evaluation": {
      "technology_name": "Tree-sitter",
      "suitability_assessment": "Tree-sitter is assessed as a strong and technologically viable candidate for the Level-2 incremental parsing engine required by the AIM Daemon. Its core design aligns perfectly with the project's need for real-time architectural intelligence. However, its suitability is contingent on mitigating the significant risk posed by its error recovery behavior, which can lead to a loss of local structural fidelity when syntax errors are present.",
      "key_findings": "The evaluation of Tree-sitter yielded several key findings. First, its performance on incremental updates is a major strength; benchmarks on `tree-sitter-rust` show that updates to an existing syntax tree after an edit can be completed in less than a millisecond, which is well within the project's latency budget. This is achieved by its core mechanism of reusing unchanged portions of the tree. Second, its error recovery, while robust for applications like syntax highlighting, presents a challenge for ISG extraction. It handles syntax errors by inserting `ERROR` nodes, which can obscure the structure of a significant portion of the code, threatening the fidelity of the generated graph. Third, the `tree-sitter-graph` library, with its DSL for constructing graphs from ASTs and its implementation of 'stack graphs', provides a purely syntactic and deterministic method for handling the ambiguity of name resolution, which is critical for extracting reliable `CALLS` edges."
    },
    "llm_workflow_transformation": {
      "workflow_name": "The AIM-Powered LLM Workflow",
      "step_number": 2,
      "step_description": "AIM Query Generation: The LLM translates the user's high-level intent into a precise, structured architectural query to be executed by the AIM Daemon. For example, if the user's intent is 'Implement file uploads in Axum', the LLM would generate a specific query like 'Find nodes implementing `FromRequest` where signature contains 'multipart'' in a language like SQL or GraphQL.",
      "impact_description": "The new workflow enables 'Radical Context Efficiency,' described as 'The 1% Advantage.' Because the entire global architecture of the codebase is represented by the highly compressed Interface Signature Graph (ISG), it can fit into approximately 1% of the LLM's context window. This frees the LLM to maintain complete global awareness of the system's structure while dedicating 99% of its attention (tokens) to the local implementation details relevant to the immediate task, thereby unlocking unprecedented scalability and accuracy."
    },
    "llm_interaction_and_query_model": {
      "recommended_model": "The recommended model is for the LLM to generate queries in a high-level, domain-specific language (DSL) tailored to the ISG's architectural concepts. This DSL is then compiled by the AIM Daemon into a constrained and validated SQL subset for execution. Raw SQL access from the LLM is strongly discouraged due to its significant security risks. This DSL-based approach provides superior abstraction, safety, and determinism, aligning with the project's core goals.",
      "threat_model_summary": "The threat model considers both classic database vulnerabilities and new LLM-specific attack vectors. Key threats include: 1) SQL Injection (SQLi), where malicious input could lead to unauthorized data access or system compromise. 2) Denial-of-Service (DoS), where resource-intensive queries could render the AIM Daemon unavailable. 3) Risks from the OWASP Top 10 for LLM Applications, such as Prompt Injection (manipulating the LLM to bypass controls), Insecure Output Handling (failure to validate the LLM's generated query), and Sensitive Information Disclosure.",
      "defense_strategy_summary": "A multi-layered, defense-in-depth strategy is employed to ensure safety and determinism. This includes: 1) Application-level controls, where the DSL-to-SQL compiler exclusively uses prepared statements (parameterized queries) to prevent SQL injection. 2) A powerful SQLite-specific security control using the `sqlite3_set_authorizer` callback to create a query sandbox that can deny unauthorized commands or table access. 3) Aggressive resource limiting using `sqlite3_limit` to prevent DoS attacks. 4) Guiding the LLM through strict tool-calling schemas and few-shot prompt examples to ensure it generates valid and safe DSL queries."
    },
    "impact_analysis_blast_radius_algorithm": {
      "algorithm_name": "Deterministic Transitive Dependency Traversal",
      "methodology": "The core methodology is a deterministic 'blast radius' analysis performed by executing a transitive traversal (reachability query) over the Interface Signature Graph (ISG). Starting from a set of initial 'atomic changes' (e.g., a modified method, a deleted class), the algorithm traverses the graph's directed edges—primarily `CALLS`, `ACCEPTS`, `RETURNS`, `IMPL`, and `EXTENDS`—to identify all potentially affected upstream and downstream code entities. This process is designed to be instantaneous by leveraging pre-computed reachability indexes. The analysis is formally defined, distinguishing between static impact (all possible affected paths) and dynamic impact (paths affected in specific execution traces), with the goal of providing a precise, logical, and repeatable impact set, moving beyond probabilistic estimations.",
      "key_techniques": "To achieve both speed and accuracy, the algorithm employs several key techniques. First, it uses sophisticated **reachability indexing** (such as 2-Hop Labeling, Pruned Landmark Labeling (PLL), or GRAIL) to answer traversal queries in constant or near-constant time, which is critical for meeting the sub-millisecond query SLO. Second, it uses **intelligent pruning and heuristics** to make the raw impact set manageable. This includes **program slicing** to identify affected statements and **semantic prioritization** (inspired by tools like SENSA) to rank the impacts by their significance, allowing users to focus on the most critical effects first. Third, the impact is formally modeled using an **'Atomic Changes Model'** (inspired by Chianti), which decomposes any code modification into a set of fine-grained changes (e.g., Added/Deleted Method, Lookup Change), enabling a more precise correlation between a change and its effect. Finally, the system can be enhanced with dynamic analysis, using execution traces to refine the static impact set and reduce false positives.",
      "summarization_output": "Raw impact sets, which can contain tens of thousands of methods, are considered unactionable. The analysis results are therefore summarized into practical, human-readable formats. For developers, this includes views inspired by the Chianti tool, such as an 'Affecting Changes View' that presents a tree of affected tests and the specific atomic changes that impacted them, or an 'Atomic-Changes-by-Category View' that groups changes by type (e.g., all Added Methods). For LLMs, the output is a structured, graph-based context. Instead of a flat list of function names, the AIM Daemon provides a subgraph containing the affected nodes, the specific paths of impact, the types of dependencies (control, data, implementation), and a ranking based on semantic relevance. This deterministic, structured context is designed to anchor the LLM's reasoning, prevent hallucination, and enable higher-level tasks like automated test generation or code review summaries."
    },
    "architectural_guardrail_enforcement": {
      "methodology": "The high-level approach is to codify architectural guardrails as machine-checkable rules that are executed against the Interface Signature Graph (ISG). This transforms architectural conventions and best practices from human-only knowledge into a set of deterministic, automated checks. The process involves defining a policy in a declarative rule language, which is then evaluated by an execution engine. For example, a rule can enforce that a Rust Axum handler has at most one body-consuming extractor and that it appears as the last argument. When a developer writes code, the AIM Daemon can check it against the rule library in real-time. If a violation is detected, the system can provide immediate, actionable feedback, including precise remediation suggestions for an LLM to apply, thereby ensuring architectural integrity is maintained continuously.",
      "evaluated_rule_language": "Several rule languages were evaluated for their expressiveness and performance. The most promising candidates include: **Datalog** (specifically high-performance variants like **Soufflé** and the incrementally-updatable **Differential Datalog (DDlog)**), which is excellent for recursive and relational queries over graph data. **CodeQL**, a powerful, purpose-built language for code analysis with strong support for transitive closures and data flow analysis. **Google Common Expression Language (CEL)**, a non-Turing complete and extremely fast language ideal for simpler, performance-critical predicate checks. Other evaluated options include **Rego** (for policies over JSON-represented graphs), **Coccinelle** (for defining and fixing patterns via semantic patches), and **Tree-sitter Query** (for fine-grained structural checks).",
      "execution_engine_design": "The execution engine is designed to be flexible, supporting multiple approaches depending on the rule language. For Datalog, the engine would be a compiled Datalog runtime like Soufflé or DDlog, which is optimized for incremental graph updates. For CodeQL or CEL, the engine would be their respective evaluation libraries integrated into the AIM Daemon. A key and highly efficient design pattern is to leverage the AIM Daemon's embedded SQLite 'Query Layer' directly. Complex graph traversals and path-based constraints required by the rules can be implemented using **Recursive Common Table Expressions (CTEs)**. This allows the system to execute powerful graph queries directly within SQLite, minimizing the need for a separate, dedicated graph database and fully utilizing the existing high-performance query infrastructure."
    },
    "strategic_context_aggregated_codebase": {
      "context_name": "Aggregated Codebase (ACB) or Adaptive Symbiotic Ecosystem",
      "philosophy": "The philosophy involves centralizing logic and emphasizing Static Verification over Runtime Contracts and promoting Logic Identity, which means running the same core logic across the entire stack.",
      "role_of_aim_isg": "AIM/ISG provides the essential intelligence layer required to navigate, verify, and evolve the centralized complexity of an ACB with AI assistance, ensuring architectural integrity at scale."
    },
    "comparison_to_alternative_systems": [
      {
        "system_name": "Kythe",
        "architectural_differences": "Kythe is a language-agnostic ecosystem designed to build a comprehensive, persistent semantic graph of code. Its core identifier is the VName (Vector-Name), a unique and extensible key. Language-specific indexers parse code and emit a stream of 'entries' (facts and edges) that are processed into a graph store. This store is architected for persistence and portability, making it suitable for offline analysis, in contrast to AIM/ISG's real-time daemon and compressed in-memory graph optimized for instantaneous queries.",
        "determinism_tradeoff": "Kythe aims for a fully deterministic model. Its VName system is engineered for stable, canonical identification of code entities. The ecosystem's indexers are required to produce identical outputs for identical inputs, ensuring that the resulting graph is a reliable and deterministic representation of the code's semantics, which aligns with AIM/ISG's core philosophy.",
        "unique_value_proposition": "Kythe's primary value lies in its ability to create a detailed, stable, and cross-repository representation of code semantics. Its main use case is to power offline analysis tools and provide a foundational dataset for deep code understanding, as demonstrated by its extensive use at Google for large-scale code analysis."
      },
      {
        "system_name": "Sourcegraph (with SCIP and Cody)",
        "architectural_differences": "Sourcegraph is a multi-faceted platform. For precise code intelligence, it uses the SCIP (SCIP Code Intelligence Protocol), a Protobuf-based schema with human-readable string IDs. This is complemented by its AI assistant, Cody, which employs a Retrieval-Augmented Generation (RAG) approach. Cody leverages the deterministic SCIP graph and other sources for context via the proposed OpenCodeGraph protocol, creating a hybrid system that combines a deterministic graph with a probabilistic LLM.",
        "determinism_tradeoff": "Sourcegraph embodies a pragmatic hybrid approach. The SCIP component provides a deterministic and precise code graph that captures factual relationships. The Cody component then uses this deterministic graph as a high-quality input to a probabilistic LLM. This 'Normsky' (Norvig + Chomsky) model grounds the LLM, significantly reducing hallucinations and improving the quality of its generated code and suggestions by combining structured data with statistical power.",
        "unique_value_proposition": "Sourcegraph offers a comprehensive developer-facing platform for code search and navigation. SCIP's unique value is providing fast, compiler-accurate, cross-repository 'go-to-definition' and 'find-references' for human developers. Cody's unique value is assisting in writing and fixing code by feeding a probabilistic LLM with structured, deterministic context from the code graph, bridging the gap between human and machine understanding."
      },
      {
        "system_name": "LSP-based systems",
        "architectural_differences": "The Language Server Protocol (LSP) defines a client-server protocol (via JSON-RPC) that standardizes communication between an editor/IDE (the client) and a language-specific server. It operates on a real-time, request-response basis, typically triggered by user actions within the editor. Unlike AIM/ISG, it does not build or persist a queryable graph of the entire codebase; it is designed for localized, on-demand queries.",
        "determinism_tradeoff": "LSP-based systems operate deterministically but only on a local scale. A 'go-to-definition' request for a specific symbol at a specific cursor position will deterministically resolve to the correct target. However, the protocol inherently lacks the global, systemic context required to answer broader architectural questions, which is the specific gap AIM/ISG aims to fill for LLMs.",
        "unique_value_proposition": "LSP's primary value is enabling interactive, in-editor features like auto-completion, live diagnostics, and 'go-to-definition'. It is intentionally 'ignorant' of a global symbolic model, focusing instead on localized, range-based queries. Its success lies in its near-universal adoption, which has decoupled language intelligence from editors and created a thriving ecosystem of tools."
      }
    ],
    "implementation_roadmap_summary": {
      "phase_number": 1,
      "phase_name": "Minimum Viable Product (MVP) - The AIM Daemon",
      "goal": "To develop a robust, single-language AIM Daemon capable of serving a pilot team and validating the core performance and utility of the system.",
      "key_deliverables": "The key deliverables for this phase include: a production-quality, optimized Tree-sitter grammar for the chosen pilot language; a fully configured AIM Daemon backend utilizing SQLite with mandatory performance settings such as `PRAGMA journal_mode = WAL`, `PRAGMA synchronous = normal`, and `PRAGMA mmap_size`; a basic API for querying the Interface Signature Graph (ISG); initial integration with a single pilot development team's workflow; and dashboards for monitoring key Service Level Indicators (SLIs), with a specific focus on P95/P99 latency percentiles rather than simple averages."
    },
    "security_and_multitenancy_model": {
      "authentication_model": "The system employs an **External Identity Provider (IdP) Federation** model, explicitly avoiding the anti-pattern of building a proprietary IdP. It integrates with established providers (e.g., Microsoft Entra ID, Auth0, Cognito) using standard protocols like OAuth 2.0 and OIDC. Upon successful authentication, the IdP issues a JSON Web Token (JWT) containing a `tenantId` and `userId`, which must be propagated with every API call. For programmatic access, the system supports service accounts and workload identities using the OAuth 2.0 client credentials flow, ensuring that automated processes are also securely authenticated and scoped to a specific tenant.",
      "authorization_model": "Authorization is enforced within the context of a tenant using a combination of models to provide granular control. This includes **Multi-Tenant Role-Based Access Control (RBAC)**, where roles ('admin', 'viewer') are defined and scoped per tenant; **Attribute-Based Access Control (ABAC)**, where policies are evaluated based on user, resource, and environment attributes by an engine like Open Policy Agent (OPA); and **Relationship-Based Access Control (ReBAC)**, inspired by Google Zanzibar, which models permissions based on the relationships between users and code entities (e.g., 'user X can view FQP Y'). In all cases, the `tenantId` from the authentication token is the primary attribute for scoping all authorization decisions.",
      "query_sandboxing_mechanism": "The core technical mechanism for sandboxing database queries within the embedded SQLite 'Query Layer' is the **`sqlite3_set_authorizer` C API**. This registers a callback function that is invoked by SQLite before executing any SQL statement. The authorizer inspects the intended action (e.g., `READ`, `UPDATE`, `ATTACH`) and can `DENY` any operation that violates the security policy. This is used to enforce a strict allow-list of safe SQL commands, disable dangerous features like attaching external databases, and prevent direct access to base tables, forcing all queries through secure views. This is supplemented by resource limits (via `sqlite3_limit`) to prevent DoS attacks from resource-intensive queries.",
      "row_level_security_implementation": "Row-level security (RLS) is implemented at the database level to be non-bypassable. The implementation involves creating **secure `VIEW`s** that wrap the base data tables (e.g., `nodes`, `edges`). When a user session begins, their `tenantId` is stored in a session-local context. The secure views are defined to automatically join with this context and filter all results, ensuring that a query can only ever see rows belonging to its own tenant. The query sandboxing mechanism (`sqlite3_set_authorizer`) is then used to block any and all direct access attempts to the underlying base tables, forcing all data access to occur through the RLS-enforcing views.",
      "threat_mitigation_summary": "The strategy focuses on two key threats. The primary threat, **cross-tenant access**, is mitigated at every layer by the strict enforcement of tenant context, from authentication and authorization down to database-level row-level security. The second major threat, **LLM prompt injection**, is mitigated by treating the LLM as a fundamentally untrusted, probabilistic component. The AIM Daemon's deterministic components are responsible for all security enforcement. The workflow is: 1) Authenticate the user and establish their tenant context. 2) Retrieve only the authorized, pre-filtered, tenant-scoped data from the ISG. 3) Pass this safe, constrained data to the LLM. This ensures the LLM's operational context is securely sandboxed *before* it begins processing, rendering prompt injection attacks against tenant boundaries ineffective."
    },
    "evaluation_and_benchmarking_strategy": {
      "evaluation_pillar": "Correctness",
      "metrics": "The primary metrics for evaluating correctness are precision and recall. These will be used to measure the accuracy of the Interface Signature Graph (ISG) construction, specifically focusing on the fidelity of the Node-Relation-Node connections that are derived from the system's parsing of Fully Qualified Paths (FQPs) and other architectural elements.",
      "ground_truth_source": "The ground truth for correctness evaluation will be generated by extracting rich semantic data directly from compiler outputs. This includes using tools like `javac` for Java, `rustdoc` for Rust to generate JSON representations of the code's structure, and `clang` ASTs for C/C++. This compiler-verified data provides a definitive baseline against which the output of the AIM Daemon's parsing and graph generation processes can be compared."
    }
  },
  "outputBasis": [
    {
      "field": "solution_paradigm_deterministic_navigation",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead."
          ]
        }
      ],
      "reasoning": "The provided material includes explicit discussion of a deterministic navigation framework associated with large graphs. Specifically, one excerpt names a work that directly presents AIM/ISG in the context of deterministic traversal for reachability indexing in large graphs. This aligns with the fine-grained field value, which centers on transitioning from probabilistic interpretation to deterministic navigation through the ISG and the AIM Daemon. The excerpt supports the notion that there is an established, formal treatment of deterministic traversal within an architecture that uses graph-based representations to guarantee predictable query results, matching the core idea of the finegrained field. While other excerpts discuss related graph-representation technologies (e.g., Code Property Graph) and related tooling, they do not directly name the Interface Signature Graph or the AIM Daemon as the deterministic navigation mechanism, making them less directly supportive of the specific field value. In summary, the strongest direct evidence ties to a publication explicitly describing AIM/ISG as a deterministic traversal and indexing framework for large graphs, which corresponds to the stated field value. ",
      "confidence": "medium"
    },
    {
      "field": "llm_workflow_transformation",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The most directly relevant material describes a deterministic traversal/ISG approach and the related indexing for fast queries: a fully dynamic reachability framework enables queries to be answered in constant time after pre-computation, which aligns with the idea of a deterministic navigation core (the Interface Signature Graph) and a real-time AIM Daemon. Specifically, the discussion of a new fully dynamic algorithm for reachability and the option to pre-compute and store reachability for all vertex pairs—thus enabling O(1) time queries—provides a concrete mechanism for deterministic architectural navigation over a compressed, ISG-like representation. The surrounding context emphasizes a deterministic traversal and the need to balance pre-computation, index size, and query processing, which matches the described AIM/ISG paradigm that aims to replace probabilistic interpretation with deterministic graph-based queries. Additionally, Code Property Graph material offers a concrete instantiation of graph-based code representations that an LLM could leverage for architecture-aware reasoning, highlighting that a graph-based representation (CPG) unites language frontends, labeled edges, and a unified query language to reason about code across languages. This aligns with the “deterministic navigation” and “graph-backed architectural reasoning” themes in the fine-grained field value. Finally, SCIP/SCIP-based indexing discussions further corroborate the broader graph-indexing ecosystem that underpins scalable, architecture-focused code understanding, providing a broader background on multi-language symbol indexing and query capabilities that support deterministic, graph-driven reasoning across codebases. In short, the most relevant content shows deterministic traversal and reachability indexing as the core mechanism, with CPGraph/SCIP-style graph representations providing concrete bases for such deterministic, graph-based analysis in a multi-language environment.",
      "confidence": "high"
    },
    {
      "field": "impact_analysis_blast_radius_algorithm",
      "citations": [
        {
          "title": "Why we chose call graphs over LSPs",
          "url": "https://www.nuanced.dev/blog/why-we-chose-call-graphs-over-LSPs",
          "excerpts": [
            " Impact analysis (what is the \"blast radius\" of a given change)"
          ]
        },
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "IEEE ICSE 2003: Whole program path-based dynamic impact analysis",
          "url": "https://ieeexplore.ieee.org/document/1201210/",
          "excerpts": [
            "This paper presents a new technique for impact analysis based on whole path profiling, that provides a different set of cost-benefits tradeoffs - a set which can potentially be beneficial for an important class of predictive impact analysis tasks.",
            "The paper presents the results of experiments that show that the technique can predict impact sets that are more accurate than those computed by call graph analysis, and more precise (relative to the behavior expressed in a program's profile) than those computed by static slicing.",
            "Whole program path-based dynamic impact analysis",
            "Impact analysis is rarely used to predict the effects of a change, leaving maintainers to deal with consequences rather than working to a plan. Previous approaches to impact analysis involving analysis of call graphs, and static and dynamic slicing, exhibit several tradeoffs involving computational expense, precision, and safety, require access to source code, and require a relatively large amount of effort to re-apply as software evolves."
          ]
        },
        {
          "title": "Ekstazi and Chianti RTS Evaluation",
          "url": "https://users.ece.utexas.edu/~gligoric/papers/GligoricETAL15Ekstazi.pdf",
          "excerpts": [
            "Ekstazi reduces the end-to-end\n\ntime 32% on average, 54% for longer-running test suites,\n\ncompared to RetestAll."
          ]
        }
      ],
      "reasoning": "The fine-grained field describes a deterministic blast-radius style impact analysis that determines, for a given code change, which downstream and upstream entities may be affected and provides a precise, repeatable impact set. An excerpt that explicitly foregrounds this concept states that one of the tasks of impact analysis is to determine the blast radius of a given change. This anchors the interpretation of the field value as a formal, bounded set of potentially impacted nodes rather than a probabilistic guess. Several excerpts discuss deterministic traversal and fast reachability: they describe a pipeline that precomputes reachability information and uses indexing techniques to answer reachability queries in (near) constant time. This aligns with the field’s emphasis on instantaneous, deterministic impact assessment by relying on pre-computed structures. Other excerpts discuss theoretical and practical impact analysis approaches, including whole-program path-based dynamic impact analysis, and the notion of correlating code changes with affected tests or code paths. These sources provide concrete grounding for a deterministic, graph-based impact model (beyond purely static or heuristic approaches). Taken together, the selected excerpts directly support the idea of a principled, deterministic blast-radius analysis that uses reachability indexes, pre-computed graphs, and formal impact modeling to generate precise, repeatable impact sets. The content also reinforces that the approach differentiates static and dynamic impact, and emphasizes both the analytical rigor and the need for efficient querying in large codebases. In short, the cited passages collectively corroborate the existence and mechanics of a deterministic blast-radius/impact analysis over an architectural graph, consistent with the fine-grained field value provided.",
      "confidence": "high"
    },
    {
      "field": "architectural_guardrail_enforcement",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs.",
            "Previous work [3–14,16,19,22–25,27–32] has proposed numer-\nous indexing techniques to efficiently support reachability queries\nwithout significant space and pre-computation overheads.",
            ". Most\ntechniques, however, assume that the input graph G is static, which\nmakes them inapplicable for the dynamic graphs commonly en-\ncountered in practice."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        }
      ],
      "reasoning": "The core field value describes a machine-checkable, deterministic guardrail system operating on the Interface Signature Graph (ISG), with an execution engine (AIM Daemon) that can enforce architectural constraints in real time and provide remediation guidance. Excerpts describing AIM/ISG as a deterministic traversal framework for large graphs directly support the existence and operation of deterministic guardrails on architectural entities represented in the ISG. The excerpt detailing that the AIM Daemon is the real-time engine that operationalizes the ISG reinforces the idea of an automated guardrail execution layer. Additional excerpts discuss deterministic traversal, reachability indexing, and incremental/differential analysis for ISG-like graphs, which underwrite the behavior of guardrail checks across architectural relationships (e.g., transitive constraints, definitions/edge kinds, and constraints that can be evaluated efficiently). The combination of these excerpts substantiates the claim that guardrails can be codified (via a rule language) and executed against an ISG with deterministic guarantees and actionable remediation guidance. ",
      "confidence": "high"
    },
    {
      "field": "interface_signature_graph_isg_details",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The most relevant excerpts explicitly discuss the deterministic graph-based approach to global code understanding and traversal. One excerpt presents the exact concept of an AIM/ISG paper, naming the work as a deterministic traversal and indexing approach for large graphs. This aligns with the finegrained field’s emphasis on a deterministic navigation backbone (the ISG) used to reason about architecture rather than raw text. A closely related entry also calls out the AIM/ISG work as a deterministic traversal and reachability index, reinforcing the notion that ISG-like structures are designed to answer architectural questions quickly and deterministically. Another excerpt expands on the broader AIM/ISG framework, describing deterministic traversal/indexing for large graphs, which supports the field’s focus on deterministic navigation and real-time query capability over architectural skeletons. A further excerpt notes a related deterministic graph representation approach (Code Property Graph) that standardizes an extensible, language-agnostic, graph-based representation of code, with explicit mention of a specification and standardization; this underpins the ISG’s aim of a skeletal architectural graph that abstracts bodies to capture public contracts and relationships. Additional excerpts extend the theme by discussing Code Property Graph as a basis for structured, language-agnostic code analysis and references the notion of a graph-based, architecture-aware representation, which is conceptually aligned with ISG’s deterministic skeletal model. Other cited items reinforce the deterministic, graph-based approach to code analysis and architecture reasoning (e.g., Code Property Graph specifications and open standards), which complements the ISG vision of a highly compressed, contract-focused skeleton for deterministic navigation. The surrounding excerpts that address deterministic traversal/indexing, and the graph-based, language-agnostic representations, collectively support the idea of an ISG-like model as a foundational, architectural backbone rather than a body of raw code text. The higher relevance is given to explicit deterministic-graph discussions (AIM/ISG papers) and to the Code Property Graph material that provides concrete examples of the graph-based, contract-centric representation that ISG aims to emulate at a larger, architectural scale.",
      "confidence": "high"
    },
    {
      "field": "strategic_context_aggregated_codebase",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations.",
            "SCIP - a better code indexing format than LSIF"
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on Aggregated Codebase (ACB) and a deterministic navigation mindset implemented through Interface Signature Graph (ISG) and Architectural Intelligence Management (AIM) Daemon. The strongest supporting excerpts explicitly articulate the deterministic, architecture-aware framework: the ISG is described as a minimalist map that captures public contracts and structural relations, and the AIM Daemon is described as the real-time engine that keeps the ISG current and enables instantaneous architectural queries. This directly supports the field’s emphasis on centralizing intelligence to navigate and enforce architectural integrity at scale within an Aggregated Codebase. The next set of excerpts delves into the Code Property Graph (CPG) and its tooling, which underpins a graph-based representation of code needed for architecture-aware analysis. These provide essential grounding for a deterministic, graph-based architectural model and the ability to query architectural constraints, relationships, and signatures across a large codebase. Finally, broader references to SCIP/CPG documentation and related graph indexing provide supplementary context for how code graphs are organized, versioned, and queried, which reinforces the architectural rationale and practical tooling that would support an AC B with deterministic navigation. In sum, the most directly supportive material is the explicit ISG/AIM framing, followed by core Code Property Graph rationale and tooling, with broader graph-analytic tooling as contextual support.",
      "confidence": "high"
    },
    {
      "field": "security_and_multitenancy_model",
      "citations": [
        {
          "title": "Implementing tenant isolation using Amazon Bedrock agents within a multi-tenant environment (AWS blog post)",
          "url": "https://aws.amazon.com/blogs/machine-learning/implementing-tenant-isolation-using-agents-for-amazon-bedrock-in-a-multi-tenant-environment/",
          "excerpts": [
            "Isolating tenants in a pooled model is achieved by using tenant context information in different application components. The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "When building multi-tenant SaaS applications, always enforce tenant isolation (leverage IAM where ever possible). 2. Securely pass tenant and user context between deterministic components of your application, without relying on an AI model to handle this sensitive information. 3. Use Agents for Amazon Bedrock to help build an AI assistant that can securely pass along tenant context. 4. Implement isolation at different layers of your application to verify that users can only access data and resources associated with their respective tenant and user context.",
            "The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "This Lambda function uses the provided tenant specific scoped credentials and tenant ID to fetch information from [Amazon DynamoDB](https://aws.amazon.com/dynamodb) . Tenant configuration data is stored in a single, shared table, while user data is split in one table per tenant. After the correct data is fetched, it’s returned to the agent. The agent interacts with the LLM for the second time to formulate a natural-language answer to ",
            "Note that each component in this sample architecture can be changed to fit into your pre-existing architecture and knowledge in the organization.",
            ". When building multi-tenant SaaS applications, always enforce tenant isolation (leverage IAM where ever possible). 2. Securely pass tenant and user context between deterministic components of your application, without relying on an AI model to handle this sensitive information. 3. Use Agents for Amazon Bedrock to help build an AI assistant that can securely pass along tenant context. 4. Implement isolation at different layers of your application to verify that users can only access data and resources associated with their respective tenant and user context."
          ]
        },
        {
          "title": "Security Issues If Incorrectly Implemented and Multi-Tenant Architecture in Analytics",
          "url": "https://www.gooddata.com/blog/multi-tenant-architecture/",
          "excerpts": [
            "GoodData's analytics and business intelligence platform is designed for building multi-tenant analytics applications. The platform utilizes workspace architecture to ensure and enable the multi-tenant use case.",
            "Poorly implemented multitenancy can lead to issues such as unauthorized access and data misuse. To nullify such threats, these applications require careful design and management to ensure tenant isolation and [secure data storage](/resources/good-talks-how-to-store-data/) . The most important thing is to authorize the access of end users.",
            "Serving multiple clients in a single instance of an application/database means implementing additional logic for tenant separation, data filtering, and tenant identification to ensure proper data isolation and security.",
            "ulti-tenant-analytics/) is a type of analytics use case that leverages multi-tenant architecture. Analytics and business intelligence platforms that support multitenancy allow companies to share dashboards and report capabilities to different user groups in a secure and cost-efficient way while utilizing the same resources"
          ]
        },
        {
          "title": "[PDF] General Access Control Guidance for Cloud Systems",
          "url": "https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.800-210.pdf",
          "excerpts": [
            "NIST is responsible for developing information security standards and guidelines, including minimum requirements for federal information systems, but such ..."
          ]
        },
        {
          "title": "Tenant isolation - SaaS Architecture Fundamentals",
          "url": "https://docs.aws.amazon.com/whitepapers/latest/saas-architecture-fundamentals/tenant-isolation.html",
          "excerpts": [
            "Tenant isolation focuses exclusively on using tenant context to\nlimit access to resources.",
            "authentication and\nauthorization; however, the fact that a tenant user is authenticated\ndoes not mean that your system has achieved isolation. Isolation is\napplied separately from the basic",
            "The more you move customers into a multi-tenant model, the more they\nwill be concerned about the potential for one tenant to access the\nresources of another tenant.",
            "tenant isolation is separate from general security\nmechanisms."
          ]
        },
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "Compile-Time Authorization Callbacks",
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized.",
            "Only a single authorizer can be in place on a database connection\nat a time. Each call to sqlite3\\_set\\_authorizer overrides the\nprevious call. Disable the authorizer by installing a NULL callbac",
            "The authorizer is disabled by default.",
            "The authorizer callback must not do anything that will modify\nthe database connection that invoked the authorizer callback.",
            "the authorizer callback is invoked to\nsee if those actions are allowed."
          ]
        },
        {
          "title": "What is Multi-Tenant Security? Definition, Risks, and Best Practices",
          "url": "https://qrvey.com/blog/multi-tenant-security/",
          "excerpts": [
            "RBAC ensures that users only access the data they’re authorized to see, enforcing strict access controls and reducing insider threats.",
            "Centralized monitoring tools enable administrators to track activities across the entire multi-tenant system. This helps detect anomalies and address security incidents before they escalate."
          ]
        }
      ],
      "reasoning": "Direct references to an external identity provider (IdP) federation and tenant context appear in excerpts describing how authentication should be wired to issue tokens containing tenantId and userId, and how service accounts or workload identities are used for programmatic access. These passages explicitly connect authentication to a tenant-scoped security boundary and describe token propagation, which aligns with the fine-grained field value’s authentication_model portion. Other excerpts describe tenant isolation strategies and per-tenant authorization models such as Role-Based Access Control (RBAC), Attribute-Based Access Control (ABAC), and Relationship-Based Access Control (ReBAC). These passages explain that authorization decisions are scoped to a tenant and made using combinations of RBAC/ABAC/ReBAC, which matches the authorization_model portion of the field value. Additional excerpts discuss database-side sandboxing controls, such as an authorization hook (sqlite3_set_authorizer) to enforce safe SQL and Row-Level Security (RLS) via tenant-scoped views, which maps to the threat mitigation and sandboxing pieces of the field value. Broader discussions of multi-tenant architecture provide context for the overall requirement but are ancillary to the explicit IdP-based authentication and per-tenant authorization mechanisms described above.\n",
      "confidence": "medium"
    },
    {
      "field": "aim_daemon_performance_objectives",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results.",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis."
          ]
        }
      ],
      "reasoning": "The described fine-grained field value centers on the AIM Daemon’s performance guarantees within an ISG-based architecture. An excerpt stating the AIM Daemon as the real-time engine directly anchors the target field to the architectural component responsible for deterministic navigation and instantaneous queries. Text describing a “Total Update Latency” in the context of file save to query readiness provides a concrete, quantifiable target that matches the field value’s 3-12 ms specification. Additionally, a description of the pipeline flow—file watcher to queue to incremental parser to graph surgery to DB synchronization—clarifies how low-latency, real-time updates are achieved in practice, reinforcing why those latency figures are credible. The combination of naming the AIM Daemon as the Real-Time Engine, outlining the deterministic ISG framework, and presenting explicit latency targets (3-12 ms for total update latency and sub-1 ms for query response time) directly supports the fine-grained field value and its intended interpretation of performance objectives for the AIM Daemon.",
      "confidence": "high"
    },
    {
      "field": "problem_statement_stochastic_fog",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The most directly relevant statements describe Code Property Graph (CPG) as an extensible, language-agnostic representation designed for incremental and distributed code analysis, which aligns with moving from unstructured text to structured architectural reasoning. This supports the field value’s claim that a deterministic, graph-based model can subsume various languages and code relationships rather than relying on probabilistic text processing. The material that presents the CPG as a standard representation for exchanging code in a structured form reinforces the notion of a deterministic map of software architecture (as opposed to ad-hoc, probabilistic ingestion). Additional excerpts explain that the CPG is implemented as a schema with explicit nodes and labeled edges, enabling deterministic queries about how components relate (e.g., containment, definitions, calls). This coheres with the idea of an Interface Signature Graph / ISG and deterministic navigation by focusing on contracts, structures, and edges rather than bodies of code, which would be the backbone for reliable, architecture-aware tooling. The more detailed excerpts from Joern/Code Property Graph documentation further substantiate that CPGs unify AST/CFG/DFG/CDG constructs into a single, queryable graph representation, which underpins deterministic reasoning about program structure and dependencies. Collectively, these excerpts directly support the fine-grained field value by illustrating the deterministic, graph-based substrate (CPG/ISG-like) intended to replace probabilistic code interpretation with architecture-aware reasoning, thereby addressing the stated Stochastic Fog with a deterministic navigation paradigm. The surrounding excerpts about SCIP and Kythe touch on related indexing and graph-annotation concepts, but the core alignment comes from the explicit CPG descriptions and their graph-based, language-agnostic, deterministic nature. Therefore, the most relevant content centers on CPG as the deterministic code representation, followed by the Joern/MATE/related schema discussions that elaborate the graph-based foundation for architecture-aware queries and navigation.",
      "confidence": "high"
    },
    {
      "field": "parsing_fidelity_tradeoff",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            " Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application\n\n##"
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "TypeScript grammar for tree-sitter",
            "v0.23.2 Latest"
          ]
        }
      ],
      "reasoning": "The core claim in the fine-grained field value is that syntactic analysis via AST/CST parsers offers robust structural understanding with speed sufficient for near-real-time guidance, and that this level is the pragmatic optimum for the AIM/ISG workflow. The excerpts support this by describing Tree-sitter as a parser generator and incremental parsing library that enables building a concrete syntax tree for a source file and updating it efficiently as the file changes. This directly aligns with the idea of a fast, incremental, structure-aware parsing layer distinct from heavier semantic-pass analysis. Additional excerpts address the general goals and properties of Tree-sitter: it is designed to be general (multi-language), fast (suitable for per-keystroke updates), robust (handles syntax errors gracefully), and dependency-free (usable in diverse environments). This combination underpins the deterministic navigation promise by keeping a current, accurate structural model of code without incurring the heavy latency of full semantic analysis. Further, discussions focused on TypeScript via tree-sitter-typescript and Java-specific Tree-sitter documentation reinforce that syntactic tooling can cover multiple languages with appropriate grammars, supporting the field value’s emphasis on AST/CST parsing as a pragmatic default for rapid, architecture-aware code understanding. Taken together, these excerpts provide concrete evidence that syntactic analysis via modern incremental parsers yields a reliable, low-latency foundation for deterministic code understanding, which is precisely what the fine-grained field value describes as the desirable Level 2 option and core enabler for deterministic navigation in the ISG-driven workflow.",
      "confidence": "high"
    },
    {
      "field": "evaluation_and_benchmarking_strategy",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "Code Property Graph: specification, query language, and utilities",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "At the core of the asked fine-grained field is the notion of evaluating correctness of the Interface Signature Graph construction using precise, compiler-verified ground truth data. The most directly relevant material is the AIM/ISG paper, which discusses deterministic traversal and reachability indexing for large graphs and frames the ISG as a deterministic map over architectural entities. This provides the foundational support for evaluating correctness in terms of fidelity of relationships like Node-Relation-Node triplets and the global, disambiguated Fully Qualified Paths that ISG relies on. Closely related are the Code Property Graph descriptions, which present a language-agnostic, graph-based representation of code that unites multiple architectural viewpoints (AST, CFG, DFG, etc.) into a single corpus-wide structure with labeled edges. This is the concrete mechanism by which structural relations and signatures are encoded, enabling precise querying and ground-truth construction from compiler-like outputs. Documentation and specifications for CPGs further reinforce that the graph stores nodes with types and labeled edges, and that there is a unified query surface to reason about code semantics across languages, which underpins the idea of a compiler-verified data source for evaluation. Together, these excerpts justify how a deterministic ISG/CPG-based approach can produce ground-truth semantic data (via compiler outputs JSON representations or equivalent), which is exactly the kind of reliable baseline needed to measure precision and recall of the ISG construction. The cited material on CPG tooling and specifications shows that the architecture is built to be language-agnostic, versionable, and queryable, supporting the notion that evaluation can be conducted against a stable, compiler-derived truth set. The ground-truth concept referenced in the field value — relying on compiler outputs (e.g., rustdoc/json, clang ASTs, javac outputs) as definitive baselines — is echoed by the documentation that positions CPG as a standard, cross-language IR for code analysis, and by the deterministic traversal framework that anchors ISG’s correctness criteria to representational fidelity of structural relations.",
      "confidence": "medium"
    },
    {
      "field": "solution_paradigm_deterministic_navigation.paradigm_name",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead."
          ]
        }
      ],
      "reasoning": "The field value represents the guiding paradigm for navigating architectural graphs with determinism. The excerpt explicitly mentions deterministic traversal and the need to balance pre-computation, index size, and query processing overhead in the context of large graphs. This directly aligns with the concept of deterministic navigation, where navigation and reachability are performed with precise, non-probabilistic reasoning rather than stochastic methods. In particular, the text describes a deterministic traversal approach and the use of indexing to support efficient queries, which directly substantiates the field value of deterministic navigation as a named paradigm within the research context.",
      "confidence": "high"
    },
    {
      "field": "solution_paradigm_deterministic_navigation.methodology",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead."
          ]
        }
      ],
      "reasoning": "The field value describes a transition from probabilistic interpretation to deterministic navigation implemented through the Interface Signature Graph (ISG) and the Architectural Intelligence Management (AIM) Daemon. The excerpt explicitly presents AIM/ISG as a deterministic traversal framework with a focus on reachability indexing for large graphs, highlighting the deterministic nature of the approach and its purpose for precise architectural reasoning. By referencing a deterministic traversal and a real-time graph-based engine for architectural queries, the excerpt directly supports the claim that the ISG/AIM pairing is the realization of deterministic navigation over probabilistic methods. The content also emphasizes how the deterministic system provides structured, graph-based querying, which aligns with the described paradigm shift away from probabilistic, text-based ingestion toward deterministic, contract-focused analysis.",
      "confidence": "high"
    },
    {
      "field": "project_summary",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "Code Property Graph: specification, query language, and utilities",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            ")\n\nThe code property graph is a data structure designed to mine large\ncodebases for instances of programming patterns. These patterns are\nformulated in a domain-specific language (DSL) based on [Scala](https://www.scala-lang.org/) . It serves as a single\nintermediate program representation across all languages supported by\nJoern and its commercial brother [Ocular](https://qwiet.ai/) . Property graphs are a generic abstraction supported by many\ncontemporary graph databases such as [Neo4j](https://neo4j.com/) , [OrientDB](https://orientdb.com/) , and [JanusGraph](https://janusgraph.org/) . In fact, [older versions of\nJoern](https://github.com/fabsx00/joern-old) made use of general\npurpose graph databases as a storage backend and the graph query\nlanguage [Gremlin](https://tinkerpop.apache.org/gremlin.html) . As the\nlimitations of this approach became more apparent over the years, we\nreplaced both the storage backend and query language with our own\ngraph database [OverflowDB](https://github.com/ShiftLeftSecurity/overflowdb) . Qwiet AI (formerly ShiftLeft) has open-sourced the [implementation of the code property\ngraph](https://github.com/ShiftLeftSecurity/codepropertygraph) and its [specification](https://cpg.joern.io) .",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The most relevant excerpts describe the deterministic traversal and reachability framework that underpins the project’s aim for deterministic navigation of large codebases. They state that deterministic traversal and reachability indexing enable precise, non-ambiguous queries over code graphs, which directly aligns with the goal of moving from probabilistic interpretation to deterministic navigation of software architectures. They also explicitly discuss the AIM/ISG concept and its role as a real-time engine for maintaining and querying theISG, which is the core foundation of the described architecture. This provides a direct mapping to the finegrained field value describing the AIM/ISG framework and its deterministic semantic layer.\n\nSupporting excerpts also describe the Interface Signature Graph (ISG) as a deterministic map and the AIM Daemon as the real-time engine, which reinforces how the architecture achieves deterministic navigation and structural understanding of codebases. In addition, multiple excerpts outline the Code Property Graph (CPG) as a language-agnostic, extensible graph representation of code used for incremental analysis and precise querying, which underpins the deterministic architecture’s ability to reason about public contracts and structural relations across languages. The included documentation excerpts elaborate how to access and query the CPG, which is relevant for implementing the ISG-like deterministic layer on top of an expressive graph representation. Finally, excerpts from Joern/CPG documentation provide concrete context about building blocks and edges that enable deterministic, architecture-aware queries across languages, reinforcing the overall architectural blueprint described in the field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "Several excerpts articulate the core ideas of a code-structure graph that aligns with the ISG/Architectural-ISTG ontology: a graph-based representation of code that unifies AST/CFG/DFG concepts and defines node types (such as contract definitions, data structures, and behavioral units) and edge types (like CONTAINS, DEFINES, BOUNDS_BY, CALLS, etc.). The Code Property Graph documentation describes Code Property Graphs as graphs with labeled directed edges that connect program constructs, and it emphasizes a uniform representation across languages and the use of edges to express relationships such as a container containing a member, a type defining a method, or a type implementing an interface. This maps directly to the fine-grained field values describing node kinds (traits/interfaces, structs/classes, enums/unions, functions/methods, modules/namespaces, associated/nested types, generic parameters) and edge kinds (IMPL, EXTENDS, CALLS, ACCEPTS/RETURNS, BOUND_BY, DEFINES, CONTAINS). The excerpts show that: - The ISG/CPG model captures nodes as entities like traits/interfaces, structs/classes, enums/unions, functions/methods, modules/namespaces, associated/nested types, and generic parameters. - Relationships (edges) express architectural contracts and data/control flows, including IMPL, EXTENDS, CALLS, DEFINTES, CONTAINS, and BOUND_BY. - The CPG documentation explains that nodes and edges form a labeled directed graph, where CONTAINS expresses containment (e.g., module contains a class) and DEFINES or BOUND_BY encode signatures/constraints. The gathered content thus directly supports the presence and interpretation of Node types and Edge types in the ISG ontology, and it illustrates how a code-structure graph can deterministically capture structural relationships across languages, which underpins the deterministic navigation ethos described in the broader prompt. The other excerpts that discuss adjacent topics (Kythe, SemanticDB, LLVM/Java/JVM specifics, or TypeScript tooling) are supportive context but do not directly substantiate the exact ISG ontology elements. Hence, the strongest support comes from the Code Property Graph entries (especially the Joern-era documentation) which explicitly define nodes and edges and their composition into a graph representation of code, followed by additional Code Property Graph documentation and related tooling notes. ",
      "confidence": "high"
    },
    {
      "field": "llm_interaction_and_query_model",
      "citations": [
        {
          "title": "SQL Injection Prevention Cheat Sheet - OWASP Cheat Sheet Series",
          "url": "https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html",
          "excerpts": [
            "**Option 1: Use of Prepared Statements (with Parameterized Queries)**"
          ]
        },
        {
          "title": "OWASP SQL Injection Prevention Cheat Sheet",
          "url": "https://www.pynt.io/learning-hub/owasp-top-10-guide/sql-injection-types-examples-prevention-cheat-sheet",
          "excerpts": [
            "`PreparedStatement pstmt = connection.prepareStatement(query);`",
            "`SELECT * FROM items WHERE owner = @owner AND itemname = @itemname;`",
            "Use Web Application Firewalls\n\nWeb application firewalls (WAFs) monitor and block malicious traffic targeting web applications, providing a frontline defense against SQLi."
          ]
        },
        {
          "title": "Protecting Against SQL Injection - EnterpriseDB Blog",
          "url": "https://www.enterprisedb.com/blog/protecting-against-sql-injection",
          "excerpts": [
            "SQL Injection is one of the most pervasive and damaging vulnerability types database administrators and developers are tasked with defending against."
          ]
        },
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized.",
            "Only a single authorizer can be in place on a database connection\nat a time. Each call to sqlite3\\_set\\_authorizer overrides the\nprevious call. Disable the authorizer by installing a NULL callbac",
            "The authorizer is disabled by default.",
            "The authorizer callback must not do anything that will modify\nthe database connection that invoked the authorizer callback.",
            "the authorizer callback is invoked to\nsee if those actions are allowed."
          ]
        },
        {
          "title": "SQLite User Forum: Best practice implementing row level authorization? # SQLite User Forum",
          "url": "https://sqlite.org/forum/info/2e4b58ca45b0de363d3d652fc7ebcfed951daa8b0e585187df92b37a229d5dc5",
          "excerpts": [
            "See https://sqlite.org/c3ref/set_authorizer.html for the documentation on using the authorizer callback. You can allow/deny read/write/delete access on a table/column basis."
          ]
        }
      ],
      "reasoning": "The recommended model in the field value emphasizes using a domain-specific DSL that compiles to a restricted SQL subset, which maps to excerpts that discuss the use of prepared/parameterized statements to prevent SQL injection and to constrain SQL usage. Direct statements about prepared statements as a defense are found in the SQL-injection prevention resources, which argue that parameterized queries prevent injection by separating code from data. This directly underpins the recommended model’s safety premise and aligns with a guarded SQL execution path, as opposed to free-form SQL that an LLM might generate. Specifically, the material notes that prepared statements and parameter binding guard against injection by ensuring inputs are treated strictly as data, not executable code. This is exactly the kind of defense that the field value calls for in its defense_strategy_summary. In addition, there are entries describing concrete examples of parameter binding, illustrating how inputs should be bound (e.g., setting parameters rather than concatenating strings). These details reinforce the specific mechanism proposed in the field value for security, determinism, and safe execution of DSL-derived SQL. Furthermore, sqlite-specific controls are cited, describing how to install an authorizer—sqlite3_set_authorizer—to sandbox queries and deny unauthorized commands or table access. This complements the multi-layer defense by implementing runtime query controls within the database engine, which is consistent with the defense architecture described in the field value. The explicit notes about the constraint that only a single authorizer can be enabled on a connection, and the emphasis on restricting what SQL can do, strengthen the defense narrative and provide concrete operational guidance that matches the defense_strategy_summary. Overall, the strongest evidence points to a defense stack anchored by prepared statements and parameterized queries as a primary safeguard, complemented by database-level authorization controls to fence off unauthorized access and actions. The other sources offer additional supportive context (e.g., general SQL-injection best practices and architectural patterns) that bolster the overall defense stance but are slightly more peripheral to the exact DSL-to-SQL compilation and runtime sandboxing described in the field value.",
      "confidence": "high"
    },
    {
      "field": "chosen_parsing_technology_evaluation",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application",
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited.",
            "*General** enough to parse any programming languag",
            "*Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any applicatio"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            " Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application\n\n##",
            "s)\n\n## Languages\n\n* [Rust 63\\.4%](/tree-sitter/tree-sitter/search?l=rust)\n* [C 25\\.4%](/tree-sitter/tree-sitter/search?l=c)\n* [TypeScript 6\\.5%](/tree-sitter/tree-sitter/search?l=typescript)\n* [JavaScript 1\\.0%](/tree-sitter/tree-sitter/search?l=javascript)\n* [C++ 0\\.8%](/tree-sitter/tree-sitter/search?l=c%2B%2B)\n* [Nix 0\\.7%](/tree-sitter/tree-sitter/search?l=nix)\n* Other 2\\.2%"
          ]
        },
        {
          "title": "tree-sitter-rust",
          "url": "https://github.com/tree-sitter/tree-sitter-rust",
          "excerpts": [
            "Rust grammar for tree-sitter",
            "### Topics",
            "[rust](/topics/rust \"Topic: rust\") [tree-sitter](/topics/tree-sitter \"Topic: tree-sitter\") [parser](/topics/parser \"Topic: parser\")",
            "*Speed** — When initially parsing a file, `tree-sitter-rust` takes around two to three times\n  as long as rustc's hand-written parser. ```\n  $ wc -l examples/ast.rs\n    2157 examples/ast.rs\n  \n  $ rustc -Z unpretty=ast-tree -Z time-passes examples/ast.rs | head -n0\n    time:   0.002 ; rss:   55MB - >   60MB (   +5MB)  parse_crate\n  \n  $ tree-sitter parse examples/ast.rs --quiet --time\n    examples/ast.rs    6.48 ms        9908 bytes/ms\n ",
            "But if you _edit_ the file after parsing it, tree-sitter can generally _update_ the previous existing syntax tree to reflect your edit in less than a millisecond,",
            "But if you _edit_ the file after parsing it, tree-sitter can generally _update_ the previous existing syntax tree to reflect your edit in less than a millisecond,\n  thanks to its incremental parsing syste",
            "Speed** — When initially parsing a file, `tree-sitter-rust` takes around two to three times\n  as long as rustc's hand-written par"
          ]
        },
        {
          "title": "Tree-sitter in Emacs and Its Background",
          "url": "https://www.masteringemacs.org/article/tree-sitter-complications-of-parsing-languages",
          "excerpts": [
            " Tree-sitter\n\n**Note:** Since I wrote this, there is now official support for tree-sitter in Emacs core. See my article [How to Get Started with Tree-Sitter](/article/how-to-get-started-tree-sitter) for more information. Enter [tree sitter](https://github.com/tree-sitter/tree-sitter) . It started its life as the semantic tool powering the Atom text editor, before finding its home in many other places, including Github’s code navigation. It’s quick, and it solves most of the problems I talked about earlier. It also has an impressive list of languages it supports and a _very_ large community backing which is important.",
            "It’s quick, and it solves most of the problems I talked about earlier. It also has an impressive list of languages it supports and a _very_ large community backing which is important.",
            "Tree sitter is easy to use, and it comes with a query language _that uses S-expressions_ — which in my mind is fate alone that it was meant to be.",
            "Enter [tree sitter](https://github.com/tree-sitter/tree-sitter) . It started its life as the semantic tool powering the Atom text editor, before finding its home in many other places, including Github’s code navigation.",
            "Download, install, and type `M-x tree-sitter-hl-mode` in a buffer to try it out."
          ]
        },
        {
          "title": "Resilient LL Parsing Tutorial (matklad.github.io)",
          "url": "https://matklad.github.io/2023/05/21/resilient-ll-parsing-tutorial.html",
          "excerpts": [
            "In our example `fn fib_rec(f1: u32,` , Tree-sitter correctly recognizes `f1: u32` as a formal\nparameter, but doesn’t recognize `fib_rec` as a function.",
            "Top-down (LL) parsing paradigm makes it harder to recognize valid\nsmall fragments, but naturally allows for incomplete large nodes.",
            "Because code is written top-down and left-to-right, LL seems to have\nan advantage for typical patterns of incomplete code.",
            "there isn’t really anything special you need to do to make LL\nparsing resilient. You sort of… just not crash on the first error,\nand everything else more or less just works."
          ]
        },
        {
          "title": "[PDF] Incrementalizing Graph Algorithms",
          "url": "https://www.cs.sjtu.edu.cn/~qyin/papers/inc-1.pdf",
          "excerpts": [
            "In contrast to batch algorithms, an incremental algorithm A∆ for Q takes as input a query Q ∈ Q, a graph G, old output Q(G) and updates ∆G to G."
          ]
        },
        {
          "title": "Incremental Update Algorithms - Emergent Mind",
          "url": "https://www.emergentmind.com/topics/incremental-update-algorithm",
          "excerpts": [
            "Incremental update algorithms are computational methods that update only the affected portions of a dataset, avoiding full recomputation."
          ]
        },
        {
          "title": "Change Taxonomy: A Fine-Grained Classification of Software Change",
          "url": "https://www.computer.org/csdl/magazine/it/2018/04/mit2018040028/13rRUILtJvI",
          "excerpts": [
            "Software Change Taxonomy. Having performed a literature survey of different parameters used to classify software changes, we specified four parameters that can provide an integrated view of change taxonomy: change reason, change level, change effect, and changed system properties."
          ]
        },
        {
          "title": "Change Taxonomy: A Fine-Grained Classification of Software Change",
          "url": "http://ieeexplore.ieee.org/document/8429276/",
          "excerpts": [
            "The authors proposed taxonomy-which classifies software changes according to different properties of the change as well as the changed system- ..."
          ]
        },
        {
          "title": "[PDF] Automating Incremental Graph Processing with Flexible Memoization",
          "url": "http://vldb.org/pvldb/vol14/p1613-gong.pdf",
          "excerpts": [
            "With these four policies, flexible memoization is able to cover the need of incrementalizing all vertex-centric algorithms and support all kinds of incremental ..."
          ]
        },
        {
          "title": "Benchmarking TypeScript parsers (Medium article)",
          "url": "https://medium.com/@hchan_nvim/benchmark-typescript-parsers-demystify-rust-tooling-performance-025ebfd391a3",
          "excerpts": [
            "Tree-sitter serves as a versatile parser suitable for a variety of languages, not specifically optimized for TypeScript. Consequently, its performance aligns closely with that of Babel, a JavaScript-focused parser implemented in JavaScript.",
            "r.github.io/): An incremental parsing library that can build and update concrete syntax trees for source files, aiming to parse any programming language quickly enough for *text editor use",
            "Oxc is a contender for the title of the fastest parser available, but its performance is tempered by serialization and deserialization (serde) overhead.",
            "Tree-sitter:**  \nTree-sitter serves as a versatile parser suitable for a variety of languages, not specifically optimized for TypeScript. Consequently, its performance aligns closely with that of Babel, a JavaScript-focused parser implemented in JavaScr",
            "Native language parsers show improved performance for larger files due to the reduced relative impact of FFI overhead. Nevertheless, the performance gains are not as pronounced due to serialization and deserialization (serde)",
            "proach by serializing the entire AST for use in JavaScript. It stands out for offering a broad range of APIs, making it a top choice for those seeking Rust-based tooling solutions."
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "For Javascript files with [flow](https://flow.org/en/) type annotations you can use the `tsx` parser.",
            "TypeScript grammar for tree-sitter",
            "Require them as follows:",
            "```\nrequire ( \"tree-sitter-typescript\" ) .\ntypescript ; // TypeScript grammar\nrequire ( \"tree-sitter-typescript\" ) . tsx ; // TSX grammar\n```",
            "v0.23.2 Latest",
            "Nov 11, 2024",
            "TypeScript and TSX grammars for [tree-sitter](https://github.com/tree-sitter/tree-sitter) . Because TSX and TypeScript are actually two different dialects, this module defines two grammars. Require them as follows:"
          ]
        },
        {
          "title": "tree-sitter-typescript on crates.io",
          "url": "https://crates.io/crates/tree-sitter-typescript",
          "excerpts": [
            "tree-sitter-typescript v0.23.2",
            "TypeScript and TSX grammars for tree-sitter"
          ]
        },
        {
          "title": "Tree-sitter and SWC Discussion on Hacker News",
          "url": "https://news.ycombinator.com/item?id=42590788",
          "excerpts": [
            "Tree sitter has a C runtime, and often a C scanner.",
            "If the tree-sitter runtime requirements are prohibitive and a pure JVM solution (IOW, no JNI) mandatory, then I'd recommend using antlr[0] with its representative grammar[1] as a starting point. See here[2] for more details.",
            "Tree-sitter is a parser generator tool and an incremental \n  parsing library. It can build a concrete syntax tree for a \n  source file and efficiently update the syntax tree as the \n  source file is edited.",
            "Tree-sitter is a parser generator tool and an incremental \n  parsing library. It can build a concrete syntax tree for a \n  source file and efficiently update the syntax tree as the \n  source file is edited.",
            "Not demonstrated here, but inserting a multi-line comment in a file that is parsed incorrectly will throw the entire thing off."
          ]
        }
      ],
      "reasoning": "The finegrained field value evaluates the suitability of Tree-sitter as the Level-2 incremental parsing engine for Real-Time Architectural Intelligence. Excerpts that describe Tree-sitter’s core purpose, incremental parsing capability, and the ability to reuse unchanged parts of the syntax tree are directly pertinent. Text that defines Tree-sitter as a parser generator and incremental parsing library is highly relevant, as it supports the deterministic ISG workflow by enabling fast, localized re-parsing when source files change. Benchmark-focused excerpts that contrast Tree-sitter performance (e.g., sub-millisecond updates on Rust code) with other parsers provide empirical support for its suitability under tight latency targets. Additionally, excerpts that discuss related tooling such as tree-sitter-graph and stack graphs are highly relevant because they describe graph-formation and name-resolution mechanisms that underpin deterministic edge extraction (e.g., CALLS edges) from the AST. Conversely, excerpts focused on unrelated topics (e.g., JS/TS module systems, Kythe, LSIF, or general UI/UX docs) are only tangentially helpful for this field value and thus are less relevant. The strongest support comes from passages that explicitly frame Tree-sitter as a fast, incremental parser with deterministic reuse of unchanged tree portions, and from passages that describe auxiliary tooling built around Tree-sitter for graph-based code analysis. ",
      "confidence": "high"
    },
    {
      "field": "impact_analysis_blast_radius_algorithm.methodology",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Why we chose call graphs over LSPs",
          "url": "https://www.nuanced.dev/blog/why-we-chose-call-graphs-over-LSPs",
          "excerpts": [
            " Impact analysis (what is the \"blast radius\" of a given change)"
          ]
        },
        {
          "title": "IEEE ICSE 2003: Whole program path-based dynamic impact analysis",
          "url": "https://ieeexplore.ieee.org/document/1201210/",
          "excerpts": [
            "This paper presents a new technique for impact analysis based on whole path profiling, that provides a different set of cost-benefits tradeoffs - a set which can potentially be beneficial for an important class of predictive impact analysis tasks.",
            "The paper presents the results of experiments that show that the technique can predict impact sets that are more accurate than those computed by call graph analysis, and more precise (relative to the behavior expressed in a program's profile) than those computed by static slicing.",
            "Impact analysis is rarely used to predict the effects of a change, leaving maintainers to deal with consequences rather than working to a plan. Previous approaches to impact analysis involving analysis of call graphs, and static and dynamic slicing, exhibit several tradeoffs involving computational expense, precision, and safety, require access to source code, and require a relatively large amount of effort to re-apply as software evolves.",
            "Whole program path-based dynamic impact analysis"
          ]
        },
        {
          "title": "Ekstazi and Chianti RTS Evaluation",
          "url": "https://users.ece.utexas.edu/~gligoric/papers/GligoricETAL15Ekstazi.pdf",
          "excerpts": [
            "Ekstazi reduces the end-to-end\n\ntime 32% on average, 54% for longer-running test suites,\n\ncompared to RetestAll."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a deterministic blast-radius analysis built on an ISG with pre-computed reachability indexes, using directed edges such as CALLS, ACCEPTS, RETURNS, IMPL, and EXTENDS to identify affected entities across the codebase, with instantaneous query performance. Excerpts describing the AIM/ISG framework provide foundational support for a deterministic traversal and reachability-based query model, including how the ISG serves as a deterministic map and how queries can be answered in sub-millisecond time. Specifically, the discussion of deterministic traversal and reachability indexing across large graphs directly supports the notion of a deterministic blast-radius computation built on ISG data structures and pre-computed indexes. References that emphasize pre-computation versus on-the-fly computation, and the trade-offs between indexing and direct graph traversal, further corroborate the idea that reachability analysis can be made instantaneous via pre-computed data. Additionally, several excerpts discuss impact analysis in terms of whole-path or reachability concepts and the notion of tracing dependencies (CALLS/ACCEPTS/IMPL/EXTENDS) to determine affected entities, which mirrors the described methodology for identifying upstream and downstream impact sets. Collectively, these excerpts align with the key components of the described methodology: deterministic graph-based reachability over an ISG, pre-computed indexes to enable instantaneous analysis, and a formal distinction between static and dynamic impact paths. An excerpt focusing on the broader context of impact analysis via path-based techniques provides supporting context for why a deliberate, deterministic blast-radius approach is advantageous, while another excerpt explicitly notes the higher precision of path-based dynamic impact analysis, which situates the discussed deterministic approach within the landscape of impact analysis techniques. The final excerpt about Ekstazi/E2E time improvements offers peripheral performance context but is less central to the deterministic blast-radius core, making it the least supporting among the clearly relevant pieces.",
      "confidence": "high"
    },
    {
      "field": "llm_workflow_transformation.workflow_name",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        }
      ],
      "reasoning": "The target field value corresponds to a named subsection that outlines the end-to-end workflow for an LLM operating within the AIM/ISG framework. Excerpts describing the AIM Daemon, the ISG as the deterministic map, and the explicit sequence of the AIM-powered workflow (intent analysis, AIM query generation, query execution, constraint checking, and code generation) directly support and define this workflow concept. The content notes that the AIM Daemon maintains the ISG’s currency and enables instantaneous, deterministic queries, and it enumerates the steps the LLM takes to translate user intent into architectural queries and then generate architecturally compliant code. These elements collectively validate the existence and structure of the AIM-Powered LLM Workflow as described by the field value. Additional excerpts that discuss Code Property Graphs or SCIP provide valuable architectural context but do not directly substantiate the specific workflow-centric naming and sequencing of the AIM-powered LLM workflow, and thus are only indirectly relevant for this field.",
      "confidence": "high"
    },
    {
      "field": "llm_workflow_transformation.impact_description",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The target field value asserts a radical efficiency claim tied to a highly compressed architectural graph (ISG) enabling the LLM to maintain global awareness while focusing tokens on local tasks. Excerpts that discuss the AIM/ISG framework establish the core mechanism: a deterministic graph-based model and a real-time engine that enables precise queries against architectural data. Direct quotes like the AIM Daemon operationalizing the ISG and the 3-12ms/<1ms performance envelope illustrate the deterministic, high-efficiency, architecture-aware approach that underpins the claimed Radical Context Efficiency. Additionally, excerpts about the ISG’s deterministic traversal and the associated graph-graph-query paradigm reinforce that the efficiency claim rests on a structured, formal representation of architectural relationships rather than probabilistic text processing. While the exact numeric assertion (1% of the context window) is not explicitly evidenced in the excerpts, the excerpts collectively support the idea that a highly compressed, graph-based representation can dramatically reduce the cognitive/contextual load on the LLM and thereby improve scalability and accuracy. The other connected graph representations (Code Property Graph, SCIP) corroborate the general direction of architecture-centric, graph-based code understanding, further contextualizing the ISG approach as part of a broader landscape of deterministic, structural representations.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems",
      "citations": [
        {
          "title": "Kythe Storage Documentation",
          "url": "https://kythe.io/docs/kythe-storage.html",
          "excerpts": [
            "As viewed from the storage layer, a ‘node’ in a Kythe graph is essentially a\nbag of string-valued key/value properties associated with a unique name. In\norder for this representation to make sense, each node must have a unique name,\nto distinguish it from all the other nodes in the graph. To solve this naming problem, Kythe adopts the view that a node is a _d_ \\-dimensional ‘vector’, where each dimension represents some scalar [fact]() about the node: The “dimensions” in this case are not\nnumbers, but arbitrary semantic categories, _e.g._ , kind, identifier, snippet,\nlocation, c",
            "the node. A VName is the primary unit of naming in the Kythe graph store. One important property of a VName is that it is extensible: As a collection of",
            " In other words, we can choose\na name for _N_ by picking a small basis of [facts]() about a node, and\nuse the node’s projection into the basis as its “name”. This works as long\nas the facts we pick are sufficient to distinguish all the nodes in our set _U_ .",
            " ... \nFor code, this will typically be\n  the relative path of the file containing the code under analysis, such as `kythe/cxx/tools/kindex_tool_main.cc` in the `kythe` corpus.",
            "The fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13).",
            "* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language)",
            "A node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection.",
            "```\nCorpus, Language, Path, Root, Signature\n```",
            "# Kythe Storage Model",
            ")\n\nTaking the view that a node is essentially a vector of its properties leads to\nthe naming scheme Kythe uses for nodes in its graph:\n\nA node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection. In other words, we can choose\na name for _N_ by picking a small basis of [facts]() about a node, and\nuse the node’s projection into the basis as its “name”. This works as long\nas the facts we pick are sufficient to distinguish all the nodes in our set _U_ . We call a name constructed using this approach a “Vector-Name” or **VName** for\nthe node. A VName is the primary unit of naming in the Kythe graph store. One important property of a VName is that it is extensible: As a collection of\nnodes grows, new nodes may arrive that differ from the existing nodes, but have\nthe same VName. To maintain uniqueness, it is only necessary to add one or more\nadditional dimensions to the VName projection to account for the new\ndata. Updating existing VNames to a new projection is a trivial mechanical\nrewriting process, particularly when the new projection is an extension of the\nold one. See also [Kythe URI Specification](kythe-uri-spec.html) ,\nwhich is essentially the same, except that a VName uses UTF-8 and\na URI uses `pct-encoded` values. The initial definition of a VName includes the following 5 fields:\n\n* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language). For example: `com.google.common.collect.Lists.newLinkedList<>()` . * **Corpus. ** The corpus of source code this VName belongs to. Loosely, a\n  corpus is a collection of related files, such as the contents of a given\n  source repository. Corpora accessible via the Internet should generally\n  prefer labels shaped like URLs or other address-like strings. Examples: \"chromium\", \"aosp\", \"bitbucket.org/creachadair/stringset\". We reserve corpus names prefixed with `kythe` for the Kythe\n  open-source project itself. _Note:_ It is possible, though not recommended, to use a local directory\n  path as a corpus label. For storage purposes, corpus labels are _not_ treated like paths (in particular they are not \"cleaned\" or otherwise\n  lexically normalized as described under **Path** below). Moreover, a literal\n  path as a corpus label will generally not work well with corpora defined\n  elsewhere, so avoid this formulation unless you don’t require your data to\n  interoperate with other corpora. * **Root. ** A corpus-specific root label, typically a directory path or project\n  identifier, denoting a distinct subset of the corpus.\nThis may also be used\n  to designate virtual collections like generated files. An empty Root field should signify a concrete file in the corpus\n  relative to the corpus root. The interpretation for a VName with an\n  empty Root corresponds to a file under version control in (one of)\n  the repository(ies) being analyzed; a non-empty Root indicates a\n  generated file, for which the Root is typically (part of) a prefix\n  to the path of that file. _Rationale:_ Usually a corpus will comprise a single rooted tree of files,\n  such as a Git repository — in which case the Root field can be left empty. In some cases, though, a corpus may have more than one tree — for example,\n  if the build tool stores generated code in a separate directory structure\n  during the build process. In that case, the Root field can be used to\n  distinguish generated paths from checked-in source. The interpretation of the Root field is always specific to the corpus. A\n  root _may_ be shaped like a path (say, if it names a directory), but it is\n  not required to; it can be an opaque label like `generated` or `branch_name` if that makes sense for the corpus in question. If the Root is intended to\n  denote a directory path, it should be _cleaned_ as described under **Path** and should not end with a \"/\". * **Path. ** A path-structured label describing the “location” of the named\n  object relative to the corpus and the root.\n ... \nThe **language** is empty (that is, \"\") for some nodes, such as [file](schema/schema.html) . Other fields can be added as necessary—for example, if a Branch or Client label\nbecomes necessary. As a rule, we try to keep the number of essential VName\ndimensions as small as possible. #### VName Composition\n\nThe fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13). When encoding\nVName fields for transmission or storage, the encoding format will be UTF-8\nwith no byte-order mark, using Normalization Form NFKC. #### VName Ordering\n\nWhen it is necessary to order VNames, the standard order is defined by\nlexicographic comparison of the VName fields in this order:\n\n```\nCorpus, Language, Path, Root, Signature\n```\n\nEach field is ordered by lexicographic string comparison of its value. ### Ticket\n\nA ticket is defined as a canonical, invertible, textual (and, if practical,\nhuman-readable) string encoding of a [VName]() (or a projection of a\nVName). A ticket encoding is a rule for rendering a (partial) VName into a\nstring such as a URI, JSON or similar. We have the option to define as many\nsuch encodings as we may need, subject to the following restrictions:\n\nCanonicalization\n    If two VNames are equal under a given projection, then the tickets generated\nfrom those projections must also be equal."
          ]
        },
        {
          "title": "Kythe Documentation: Writing an Indexer",
          "url": "https://kythe.io/docs/schema/writing-an-indexer.html",
          "excerpts": [
            "VNames have five string-valued fields.",
            "Kythe stores file content in its graph. The `http_server` binary used in our `kythe-browse.sh` script doesn’t look in your filesystem for a file to present\nto the Web browser; it instead reads the `text` fact off of a graph node."
          ]
        },
        {
          "title": "Kythe URI Specification",
          "url": "https://kythe.io/docs/kythe-uri-spec.html",
          "excerpts": [
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "Kythe URI Specification",
            "This document defines the schema for Kythe uniform resource identifiers (\"Kythe URI\"). The primary purpose of a Kythe URI is to provide a textual encoding of a Kythe"
          ]
        },
        {
          "title": "Kythe Schema Overview",
          "url": "https://kythe.io/docs/schema-overview.html",
          "excerpts": [
            "This document relies on the following basic terminology:",
            "Image"
          ]
        },
        {
          "title": "Sourcegraph Documentation",
          "url": "https://6.5.sourcegraph.com/",
          "excerpts": [
            "Sourcegraph is a Code Intelligence platform that deeply understands your code, no matter how large or where it’s hosted, to power modern developer experiences. * **Code Search:** Search through all of your repositories across all branches and all code hosts"
          ]
        },
        {
          "title": "Latent Space podcast / Sourcegraph discussion on code intelligence",
          "url": "https://www.latent.space/p/sourcegraph",
          "excerpts": [
            "SourceGraph developed SCIP, “a better code indexing format than LSIF”:",
            "SCIP indexers, such as scip-clang, show enhanced performance and reduced index file sizes compared to LSIF indexers (10%-20% smaller)",
            "LSP is a protocol, right? And so Google's internal protocol is gRPC-based. And it's a different approach than LSP. It's basically you make a heavy query to the back end, and you get a lot of data back, and then you render the whole page, you know?"
          ]
        },
        {
          "title": "3 Ways to Refactor Your Code in IntelliJ IDEA - The JetBrains Blog",
          "url": "https://blog.jetbrains.com/idea/2020/12/3-ways-to-refactor-your-code-in-intellij-idea/",
          "excerpts": [
            "There are five types of extract refactoring that you can do in IntelliJ IDEA: Extract Method · Extract Constant · Extract Field · Extract ..."
          ]
        },
        {
          "title": "Language Server Protocol Specification - 3.17",
          "url": "https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/",
          "excerpts": [
            "The base protocol offers support for request cancellation. To cancel a request, a notification message with the following properties is sent:\n\n_Notification_ :\n\n* method: ‘$/cancelRequest’\n* params: `CancelParams` defined as follows:\n\n```\n`interface CancelParams { \n\t /**\n\t * The request id to cancel. */ \n\t id : integer | string ; \n } \n`\n```\n\nA request that got canceled still needs to return from the server and send a response back. It can not be left open / hanging. This is in line with the JSON-RPC protocol that requires that every request sends a response back. In addition it allows for returning partial results on cancel. If the request returns an error response on cancellation it is advised to set the error code to `ErrorCodes",
            "Location",
            "LocationLink",
            "InlayHintLabelPart",
            "since 3.17.0",
            "The result of the request would be the hover to be presented. In its simple form it can be a string. So the result looks like this:\n\n```\n`interface HoverResult { \n\t value : string ; \n } \n`\n``",
            "\n\nThe Completion request is sent from the client to the server to compute completion items at a given cursor position. Completion items are presented in the [IntelliSense](https://code.visualstudio.com/docs/editor/intellisense) user interface. If computing full completion items is expensive, servers can additionally provide a handler for the completion item resolve request (‘completionItem/resolve’). This request is sent when a completion item is selected in the user interface. A typical use case is for example: the `textDocument/completion` request doesn’t fill in the `documentation` property for returned completion items since it is expensive to compute. When the item is selected in the user interface then a ‘completionItem/resolve’ request is sent with the selected completion item as a parameter. The returned completion item should have the documentation property filled in. By default the request can only delay the computation of the `detail` and `documentation` properties. Since 3.16.0 the client\ncan signal that it can resolve more properties lazily.",
            "The `workspace/codeLens/refresh` request is sent from the server to the client. Servers can use it to ask clients to refresh the code lenses currently shown in editors. As a result the client should ask the server to recompute the code lenses for these editors. This is useful if a server detects a configuration change which requires a re-calculation of all code lenses. Note that the client still has the freedom to delay the re-calculation of the code lenses if for example an editor is currently not visible.",
            "Responses to requests should be sent in roughly the same order as the requests appear on the server or client side. So for example if a server receives a `textDocument/completion` request and then a `textDocument/signatureHelp` request it will usually first return the response for the `textDocument/completion` and then the response for `textDocument/signatureHelp` . However, the server may decide to use a parallel execution strategy and may wish to return responses in a different order than the requests were received. The server may do so as long as this reordering doesn’t affect the correctness of the responses. For example, reordering the result of `textDocument/completion` and `textDocument/signatureHelp` is allowed, as each of these requests usually won’t affect the output of the other.",
            "So the creator of a `TextDocumentEdit` doesn’t need to sort the array of edits or do any kind of ordering. However the edits must be non overlapping."
          ]
        },
        {
          "title": "UX Essentials for Visual Studio",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/ux-guidelines/ux-essentials-for-visual-studio?view=vs-2022",
          "excerpts": [
            "Make all imagery consistent with the new VS style. * \n  Follow Visual Studio design principles for icons, glyphs, and other graphics. * \n  Do not place text in graphic elements.",
            "Design from a user-centric perspective. * \n  Create the task flow before the individual features within it. * \n  Be familiar with your users and make that knowledge explicit in your spec. * \n  When reviewing the UI, evaluate the complete experience as well as the details. * \n  Design your UI so that it remains functional and attractive regardless of locale or language.",
            "Be consistent within the Visual Studio environment. * \n  Follow existing [interaction patterns](interaction-patterns-for-visual-studio?view=vs-2022) within the shell. * \n  Design features to be consistent with the shell's visual language and [craftsmanship requirements](evaluation-tools-for-visual-studio?view=vs-2022) . * \n  Use shared commands and controls when they exist.",
            "Understand the Visual Studio hierarchy and how it establishes context and drives the UI.",
            "Use the environment service for fonts and colors. * \n  UI should respect the current [environment font](fonts-and-formatting-for-visual-studio?view=vs-2022) setting unless it is exposed for customization in the Fonts and Colors page in the Options dialog. * \n  UI elements must use the [VSColor Service](colors-and-styling-for-visual-studio?view=vs-2022) , using shared environment tokens or feature-specific tokens.",
            "Screen resolution\n\n### Minimum resolution\n\n* \n  The minimum resolution for Visual Studio 2015 is **1280x720** . This means that it is _possible_ to use Visual Studio at this resolution, although it might not be an optimal user experience. There is no guarantee that all aspects will be usable at resolutions lower than 1280x720. * \n  The target resolution for Visual Studio is **1366x768** .\nThis is the lowest resolution at which we promise a _good_ user experience. * \n  Initial dialog height should be **smaller than 700 pixels** , so it fits within the minimum resolution of the ",
            "UI in Visual Studio must work well in all DPI scaling factors that Windows supports out of the box: 150%, 200%, and 250%.",
            "Anti-patterns",
            "Visual Studio contains many examples of UI that follow our guidelines and best practices. In an effort to be consistent, developers often borrow from product UI design patterns similar to what they're building. Although this is a good approach that helps us drive consistency in user interaction and visual design, we do on occasion ship features with a few details that do not meet our guidelines due to schedule constraints or defect prioritization. In these cases, we do not want teams to copy one of these \"anti-patterns\" because they proliferate bad or inconsistent UI within the Visual Studio environment."
          ]
        },
        {
          "title": "UX Stack Exchange - What as a Rule of Thumb is the Maximum Tolerable Time the UI Thread is Blocked",
          "url": "https://ux.stackexchange.com/questions/42684/what-as-a-rule-of-thumb-is-the-maximum-tolerable-time-the-ui-thread-is-blocked",
          "excerpts": [
            "The really short answer is **100ms** . This number comes from the article [Response times - The Three Important Limits](http://www.nngroup.com/articles/response-times-3-important-limits/) by Jakob Nielsen, which contains an excerpt from his book [Usability Engineering](http://www.nngroup.com/books/usability-engineering) . Mr. Nielsen is a recognized authority on UI design, and does a tremendous amount of analytical research related to UI design. The article and book give these numbers:",
            "* \n  0\\.1 second is about the limit for having the user feel that the system is reacting instantaneously, meaning that no special feedback is necessary except to display the result. * \n  1\\.0 second is about the limit for the user's flow of thought to stay uninterrupted, even though the user will notice the delay. Normally, no special feedback is necessary during delays of more than 0.1 but less than 1.0 second, but the user does lose the feeling of operating directly on the data. * \n  10 seconds is about the limit for keeping the user's attention focused on the dialogue.",
            "For a desktop application users are used to not having a responsive UI during startup or potentially file open for a variety of applications. but during other tasks, e.g. typing, even very small pauses will cause negative experiences. There does appear to be a [human limit of about 0.1](http://www.nngroup.com/articles/powers-of-10-time-scales-in-ux/) s at which we perceive things to be more or less instantaneous, so, as some commenters have mentioned, always responding within 0.1s is certainly one way to meet user expectations (it might be technically hard to meet this however)"
          ]
        },
        {
          "title": "Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022",
          "excerpts": [
            "The LSP has evolved over time and today it is at Version 3.0. It started when the concept of a language server was picked up by OmniSharp to provide rich editing features for C#.",
            "A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC.",
            "Below is an example for how a tool and a language server communicate during a routine editing session:",
            "\n  **The user opens a file (referred to as a document) in the tool** : The tool notifies the language server that a document is open ('textDocument/didOpen'). From now on, the truth about the contents of the document is no longer on the file system but kept by the tool in memory. *",
            "  **The user makes edits** : The tool notifies the server about the document change ('textDocument/didChange') and the semantic information of the program is updated by the language server. As this happens, the language server analyzes this information and notifies the tool with the detected errors and warnings ('textDocument/publishDiagnostics')."
          ]
        },
        {
          "title": "Sourcegraph blog: Announcing auto-indexing",
          "url": "https://sourcegraph.com/blog/announcing-auto-indexing",
          "excerpts": [
            "Precise code navigation—the most powerful version of code navigation—is very similar to IDE-based navigation, but it also works cross-repository.",
            "Precise code navigation is driven by code graph data . This data is generated by indexing your code (using either LSIF or SCIP format indexers).",
            "Code navigation comes in two common forms: search-based and precise.",
            "Auto-indexing makes it easy to set up repository indexing in minutes and get precise code navigation for your repositories, with no changes to your CI workflow."
          ]
        }
      ],
      "reasoning": "The field value centers on comparatives between Kythe, Sourcegraph with SCIP, and LSP-based systems. The most directly relevant excerpts are those that spell out: - Kythe’s approach (VName, canonical naming, storage model, and offline/deterministic semantics) which provides a cross-repository, semantically grounded graph for code. Excerpts that define Kythe’s VName concept and its storage model establish the deterministic, cross-cutting semantics Kythe aims to achieve, which aligns with the field’s emphasis on a fully deterministic, globally consistent code graph. - Kythe URI specifications and VName ordering that ground how entities are named and retrieved across corpora, which directly informs the determinism and cross-repo semantics claimed in the field value. - Sourcegraph’s SCIP as a deterministic graph plus a retrieval-augmented generation (RAG) component (Cody) that uses a structured graph as input to guide a probabilistic LLM. Excerpts that describe SCIP as a Protobuf-based, logic-grounded graph paired with an LLM-driven assistant map to the “deterministic graph” plus “LLM augmentation” described in the field value, including how the deterministic graph underpins reliability while the LLM provides generation capabilities on top of it. - LSP-based systems contrasted with these graph-centered approaches, emphasizing real-time, localized symbol resolution that does not build a global semantic graph, which aligns with the LSP portion of the field value. - Excerpts that explicitly discuss the hybrid nature of SCIP (deterministic context for LLMs) and the LSP’s scope (local, immediate resolution) provide the clearest cross-system contrasts. The supporting content includes explicit descriptions of Kythe’s VName-based, offline/deterministic graph architecture; Kythe storage semantics; Kythe URI conventions; SCIP’s hybrid deterministic graph with an LLM; and LSP’s locale-focused, real-time query model. The reasoning connects quoted or paraphrased statements from these excerpts to each claim in the fine-grained field value, without referring to excerpt indices directly in the narrative. Finally, excerpts that discuss auto-indexing and its relationship to graph-based code intelligence help contextualize the practical deployment differences between offline deterministic graphs (Kythe, SCIP) and in-editor, real-time LSP workflows.",
      "confidence": "high"
    },
    {
      "field": "impact_analysis_blast_radius_algorithm.algorithm_name",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Why we chose call graphs over LSPs",
          "url": "https://www.nuanced.dev/blog/why-we-chose-call-graphs-over-LSPs",
          "excerpts": [
            " Impact analysis (what is the \"blast radius\" of a given change)"
          ]
        },
        {
          "title": "IEEE ICSE 2003: Whole program path-based dynamic impact analysis",
          "url": "https://ieeexplore.ieee.org/document/1201210/",
          "excerpts": [
            "This paper presents a new technique for impact analysis based on whole path profiling, that provides a different set of cost-benefits tradeoffs - a set which can potentially be beneficial for an important class of predictive impact analysis tasks.",
            "The paper presents the results of experiments that show that the technique can predict impact sets that are more accurate than those computed by call graph analysis, and more precise (relative to the behavior expressed in a program's profile) than those computed by static slicing.",
            "Whole program path-based dynamic impact analysis",
            "Impact analysis is rarely used to predict the effects of a change, leaving maintainers to deal with consequences rather than working to a plan. Previous approaches to impact analysis involving analysis of call graphs, and static and dynamic slicing, exhibit several tradeoffs involving computational expense, precision, and safety, require access to source code, and require a relatively large amount of effort to re-apply as software evolves."
          ]
        },
        {
          "title": "Ekstazi and Chianti RTS Evaluation",
          "url": "https://users.ece.utexas.edu/~gligoric/papers/GligoricETAL15Ekstazi.pdf",
          "excerpts": [
            "Ekstazi reduces the end-to-end\n\ntime 32% on average, 54% for longer-running test suites,\n\ncompared to RetestAll."
          ]
        }
      ],
      "reasoning": "The finegrained field value embodies a deterministic, transitive view of dependencies and their impact on a codebase. Excerpts describing deterministic traversal and reachability indexing map directly to the core idea of a deterministic, transitive analysis over a graph of code entities, which underpins an algorithm that would be named something like deterministic transitive dependency traversal. Specifically, the discussion of deterministic traversal for large graphs and the tradeoffs between pre-computation and on-demand querying provides the exact methodological backbone for a traversal that yields constant-time reachability checks, a hallmark of a deterministic transitive analysis. The blast-radius discussions emphasize the practical implications of such an analysis for impact assessment, aligning with the purpose of a deterministic traversal to understand how changes propagate, i.e., the blast radius of a change. Broader papers on whole-program path-based dynamic impact analysis describe analogous approaches to tracking changes along paths to predict effects, which reinforces the relevance of a transitive, path-aware impact model. Less directly connected are entries focusing on evaluation or specific tooling like Ekstazi, which touch on impact analysis in practice but do not articulate the deterministic transitive traversal concept as clearly. Together, these sources support the notion of a deterministic, transitive dependency traversal as a core algorithmic approach for impact analysis and blast-radius calculation in large graphs of code entities.",
      "confidence": "medium"
    },
    {
      "field": "impact_analysis_blast_radius_algorithm.summarization_output",
      "citations": [
        {
          "title": "IEEE ICSE 2003: Whole program path-based dynamic impact analysis",
          "url": "https://ieeexplore.ieee.org/document/1201210/",
          "excerpts": [
            "This paper presents a new technique for impact analysis based on whole path profiling, that provides a different set of cost-benefits tradeoffs - a set which can potentially be beneficial for an important class of predictive impact analysis tasks.",
            "The paper presents the results of experiments that show that the technique can predict impact sets that are more accurate than those computed by call graph analysis, and more precise (relative to the behavior expressed in a program's profile) than those computed by static slicing.",
            "Impact analysis is rarely used to predict the effects of a change, leaving maintainers to deal with consequences rather than working to a plan. Previous approaches to impact analysis involving analysis of call graphs, and static and dynamic slicing, exhibit several tradeoffs involving computational expense, precision, and safety, require access to source code, and require a relatively large amount of effort to re-apply as software evolves.",
            "Whole program path-based dynamic impact analysis"
          ]
        },
        {
          "title": "Ekstazi and Chianti RTS Evaluation",
          "url": "https://users.ece.utexas.edu/~gligoric/papers/GligoricETAL15Ekstazi.pdf",
          "excerpts": [
            "Ekstazi reduces the end-to-end\n\ntime 32% on average, 54% for longer-running test suites,\n\ncompared to RetestAll."
          ]
        }
      ],
      "reasoning": "The target field value envisions transforming raw, potentially unwieldy impact data into actionable, human-readable formats and deterministic, graph-based context for LLMs. The most relevant passage directly describes leveraging a Chianti-like approach to present impact analysis results as architecturally meaningful views, including an 'Affecting Changes View' that shows a tree of affected tests and the specific atomic changes that impacted them, and an 'Atomic-Changes-by-Category View' that groups changes by type. This aligns exactly with creating practical views and a deterministic, structured representation for impact analysis. Supporting passages discuss whole-program path-based dynamic impact analysis and the tradeoffs between pre-computation, space, and query efficiency, which underpin the feasibility and design of such structured context. Additional passages note that these techniques can be more accurate than traditional call-graph approaches and emphasize the value of a predictive, task-oriented presentation, which further justifies summarization into targeted views for developers and LLM-driven code analysis. Taken together, these excerpts substantiate a vision where raw impact data is distilled into deterministic, graph-based summaries that reduce hallucination and improve architectural reasoning.",
      "confidence": "high"
    },
    {
      "field": "solution_paradigm_deterministic_navigation.core_concepts",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead."
          ]
        }
      ],
      "reasoning": "The field value identifies two core components by name: the Interface Signature Graph (ISG) and the Architectural Intelligence Management (AIM) Daemon. The excerpt explicitly presents AIM/ISG in the title of a work and describes deterministic traversal and reachability indexing for large graphs, which conceptually maps to the idea of a graph-based interface signature model (ISG) and a persistent management/daemon layer (AIM) that enables deterministic queries over the architectural graph. The reference hints at the same structural pairing (ISG and AIM) and reinforces the deterministic, graph-oriented approach described in the field value, making it directly supportive. While it does not spell out all architectural details, the linkage between AIM and ISG in the excerpt strongly corroborates the claimed core components.",
      "confidence": "high"
    },
    {
      "field": "impact_analysis_blast_radius_algorithm.key_techniques",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "IEEE ICSE 2003: Whole program path-based dynamic impact analysis",
          "url": "https://ieeexplore.ieee.org/document/1201210/",
          "excerpts": [
            "This paper presents a new technique for impact analysis based on whole path profiling, that provides a different set of cost-benefits tradeoffs - a set which can potentially be beneficial for an important class of predictive impact analysis tasks.",
            "The paper presents the results of experiments that show that the technique can predict impact sets that are more accurate than those computed by call graph analysis, and more precise (relative to the behavior expressed in a program's profile) than those computed by static slicing.",
            "Impact analysis is rarely used to predict the effects of a change, leaving maintainers to deal with consequences rather than working to a plan. Previous approaches to impact analysis involving analysis of call graphs, and static and dynamic slicing, exhibit several tradeoffs involving computational expense, precision, and safety, require access to source code, and require a relatively large amount of effort to re-apply as software evolves.",
            "Whole program path-based dynamic impact analysis"
          ]
        },
        {
          "title": "Ekstazi and Chianti RTS Evaluation",
          "url": "https://users.ece.utexas.edu/~gligoric/papers/GligoricETAL15Ekstazi.pdf",
          "excerpts": [
            "Ekstazi reduces the end-to-end\n\ntime 32% on average, 54% for longer-running test suites,\n\ncompared to RetestAll."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a collection of techniques used to make impact analysis fast, precise, and deterministic. The most relevant excerpts explicitly discuss reachability indexing and deterministic traversal, which underpin sub-millisecond query performance and scalable analysis. For example, one excerpt notes that reachability queries require a careful balance between pre-computation cost, index size, and query processing overhead, directly tying to techniques for fast traversal. Further, several excerpts describe whole-path or whole-program path-based dynamic impact analysis, which aligns with breaking down effects along execution paths and supports precise impact assessment. These excerpts also articulate cost-benefit trade-offs and the benefits of avoiding expensive, overly broad analyses, which support the pruning and selective analysis aspect. Additional excerpts mention pruning and heuristics to reduce the impact set, as well as program slicing and priority-based ranking mechanisms (akin to SENSA) to focus attention on the most significant changes, which map directly to the fine-grained techniques described in the value. An Atomic Changes Model inspired by Chianti is cited as a way to decompose modifications into fine-grained changes, enabling tighter correlation between changes and effects, which directly matches the requested model. Finally, one excerpt references a broader evaluation of impact analysis approaches (path-based and call-graph-based), reinforcing the context that the field is concerned with accurate and scalable prediction of changes’ effects. Taken together, these excerpts collectively support the core elements: fast but precise impact analysis, deterministic/traversal guarantees via indexing, the use of program slicing and semantic prioritization to rank impacts, formal modeling of changes, and incorporation of dynamic analysis to refine sets of impacts.",
      "confidence": "high"
    },
    {
      "field": "interface_signature_graph_isg_details.data_model_name",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        }
      ],
      "reasoning": "The targeted field value is the Interface Signature Graph (ISG). Among the excerpts, several directly reference an AIM/ISG construct and describe it as a deterministic graph entity used for traversal and reachability indexing. The most relevant excerpt presents the combined acronym 'AIM/ISG' and frames it as a deterministic traversal and reachability indexing topic for large graphs, which aligns with identifying the data model name ISG as part of the Interface Signature Graph. The second excerpt reinforces this by discussing the same AIM/ISG subject and noting the challenges around reachability queries, further anchoring ISG in the described architectural graph context. The third excerpt explicitly discusses the concept of a graph representation in a similar architectural-graph context, mentioning ISG in the title, which, while slightly less direct, still substantiates the existence and nomenclature around an Interface Signature Graph within the same family of graph-based abstractions. Taken together, these excerpts most directly support the field value by naming and describing the ISG-based deterministic graph approach; the remaining excerpts focus on related code-property graphs and standards, which are less directly connected to the specific ISG naming but provide contextual background on graph-based code representations.",
      "confidence": "high"
    },
    {
      "field": "interface_signature_graph_isg_details.purpose",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations.",
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’."
          ]
        }
      ],
      "reasoning": "The most relevant excerpts directly discuss the AIM/ISG framework and its core characteristics. Descriptions that state the AIM/ISG system provides a deterministic traversal, a deterministic graph-based representation, and the notion of an ISG as a map of architectural relationships align precisely with the finegrained field value. In particular, phrases that say the AIM/ISG enables deterministic navigation of codebases and portrays the ISG as a foundational data model and a deterministic map of the architectural skeleton most strongly support the field value. Excerpts that describe the Code Property Graph (CPG) as a general, language-agnostic representation for code analysis and its schema are closely related in theme (graph-based representations of code) but are not specific to the AIM/ISG project's purpose or its deterministic navigation claim; they provide contextual support about similar graph-based approaches. Excerpts about SCIP and related tooling discuss related standardized representations for symbols and code exchanges but do not directly assert the ISG’s foundational status or deterministic navigation role; they are peripheral context. By connecting the exact statements about AIM/ISG being deterministic and foundational to codebase navigation, and then noting related graph-analytic tools as supportive but not central, I establish a hierarchy of relevance from direct alignment to peripheral context. Direct paraphrasing from the most relevant excerpts includes: (a) AIM/ISG is a Deterministic Traversal and Reachability indexing for large graphs, indicating deterministic navigation; (b) the ISG is the foundational data model; (c) the transformation example shows ISG representations and deterministic graph structures. These elements collectively corroborate that the ISG serves as a foundational, deterministic map of architectural skeletons within codebases. <quoting direct concepts>",
      "confidence": "high"
    },
    {
      "field": "llm_workflow_transformation.step_number",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The fine-grained field value corresponds to the second step in the described LLM workflow transformation, which centers on translating user intent into precise architectural queries against the AIM/ISG backend. Excerpts that discuss the AIM Daemon and the ISG as the deterministic engine for architectural queries indicate the existence of a system where LLMs formulate and run structured queries against a graph-backed representation of the codebase. This supports the interpretation that there is a defined step in the workflow dedicated to query generation and execution against a deterministic store. Additional excerpts about the Code Property Graph and its schema provide supporting context for how code entities and their relationships are modeled and queried, reinforcing that the system operates through a queryable graph- or graph-like representation rather than free-form text analysis. Collectively, these excerpts align with the concept of a second, query-generation step that enables deterministic navigation and extraction of architectural relationships, which is the focal point of the target field value.",
      "confidence": "medium"
    },
    {
      "field": "architectural_guardrail_enforcement.execution_engine_design",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        },
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs.",
            ". Most\ntechniques, however, assume that the input graph G is static, which\nmakes them inapplicable for the dynamic graphs commonly en-\ncountered in practice.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "Previous work [3–14,16,19,22–25,27–32] has proposed numer-\nous indexing techniques to efficiently support reachability queries\nwithout significant space and pre-computation overheads."
          ]
        }
      ],
      "reasoning": "The target field value describes an execution engine design that is flexible across rule languages, with a concrete emphasis on integrating an embedded SQL query layer (SQLite) and enabling powerful graph queries using Recursive Common Table Expressions. It also mentions supporting Datalog runtimes such as Soufflé or DDlog and evaluation libraries like CodeQL or CEL, indicating a multi-language, multi-engine architecture. Excerpts that discuss a deterministic traversal framework for large graphs, including the trade-offs between pre-computation, space, and query performance, provide direct architectural context for how the AIM Daemon might structure graph queries and caching. References to an embedded SQLite query layer and high-performance query infrastructure align with the stated design goal of minimizing separate graph databases and leveraging existing query capabilities. The Code Property Graph excerpt further reinforces the feasibility and tooling ecosystem for graph queries across languages, which complements the engine design described. Excerpts that describe dynamic graphs and prior work on indexing while useful, are slightly less central but still supportive of understanding the architectural considerations around graph queries and performance constraints. Directly, the embedded SQLite query layer, Recursive CTEs, and multi-engine language support are the strongest links to the fine-grained field value, followed by discussions of graph tooling and deterministic traversal principles.",
      "confidence": "high"
    },
    {
      "field": "security_and_multitenancy_model.authorization_model",
      "citations": [
        {
          "title": "What is Multi-Tenant Security? Definition, Risks, and Best Practices",
          "url": "https://qrvey.com/blog/multi-tenant-security/",
          "excerpts": [
            "RBAC ensures that users only access the data they’re authorized to see, enforcing strict access controls and reducing insider threats.",
            "Centralized monitoring tools enable administrators to track activities across the entire multi-tenant system. This helps detect anomalies and address security incidents before they escalate."
          ]
        },
        {
          "title": "Tenant isolation - SaaS Architecture Fundamentals",
          "url": "https://docs.aws.amazon.com/whitepapers/latest/saas-architecture-fundamentals/tenant-isolation.html",
          "excerpts": [
            "Tenant isolation focuses exclusively on using tenant context to\nlimit access to resources.",
            "tenant isolation is separate from general security\nmechanisms.",
            "The more you move customers into a multi-tenant model, the more they\nwill be concerned about the potential for one tenant to access the\nresources of another tenant.",
            "authentication and\nauthorization; however, the fact that a tenant user is authenticated\ndoes not mean that your system has achieved isolation. Isolation is\napplied separately from the basic"
          ]
        },
        {
          "title": "Security Issues If Incorrectly Implemented and Multi-Tenant Architecture in Analytics",
          "url": "https://www.gooddata.com/blog/multi-tenant-architecture/",
          "excerpts": [
            "Poorly implemented multitenancy can lead to issues such as unauthorized access and data misuse. To nullify such threats, these applications require careful design and management to ensure tenant isolation and [secure data storage](/resources/good-talks-how-to-store-data/) . The most important thing is to authorize the access of end users.",
            "ulti-tenant-analytics/) is a type of analytics use case that leverages multi-tenant architecture. Analytics and business intelligence platforms that support multitenancy allow companies to share dashboards and report capabilities to different user groups in a secure and cost-efficient way while utilizing the same resources",
            "Serving multiple clients in a single instance of an application/database means implementing additional logic for tenant separation, data filtering, and tenant identification to ensure proper data isolation and security."
          ]
        },
        {
          "title": "Implementing tenant isolation using Amazon Bedrock agents within a multi-tenant environment (AWS blog post)",
          "url": "https://aws.amazon.com/blogs/machine-learning/implementing-tenant-isolation-using-agents-for-amazon-bedrock-in-a-multi-tenant-environment/",
          "excerpts": [
            "The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "Isolating tenants in a pooled model is achieved by using tenant context information in different application components. The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "When building multi-tenant SaaS applications, always enforce tenant isolation (leverage IAM where ever possible). 2. Securely pass tenant and user context between deterministic components of your application, without relying on an AI model to handle this sensitive information. 3. Use Agents for Amazon Bedrock to help build an AI assistant that can securely pass along tenant context. 4. Implement isolation at different layers of your application to verify that users can only access data and resources associated with their respective tenant and user context."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes an authorization model that enforces access control within a multi-tenant context, using RBAC, ABAC, and ReBAC paradigms, with tenantId as the primary scoping attribute. The most directly supportive excerpt notes that RBAC ensures users only access data they are authorized to see, which aligns with a structured permission model per tenant. Other excerpts emphasize tenant context as a basis for isolation and access decisions in multi-tenant architectures, which corroborates the need for tenant-scoped authorization. Additional references highlight that tenant isolation is foundational in SaaS architectures and that security considerations must enforce access controls beyond authentication, reinforcing the same theme of context-driven authorization. Collectively, these excerpts substantiate the use of tenant-scoped RBAC/ABAC/ReBAC-style mechanisms and the central role of tenantId in scoping authorization decisions. They also provide context about isolating tenants and enforcing access controls per tenant, which supports the described approach to authorization in a multi-tenant system.",
      "confidence": "medium"
    },
    {
      "field": "interface_signature_graph_isg_details.focus",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The idea that a graph-based representation can capture architectural structure and contracts without embedding implementation details is reinforced by excerpts describing the Code Property Graph as an extensible, language-agnostic representation of program code designed for analysis, which underpins structural reasoning about code. Related excerpts discuss publishing a graph-based specification to facilitate exchange of code representations, and describe the Code Property Graph schema and its storage in a database, all of which emphasize a focus on structure and relationships rather than implementation bodies. Additionally, discussions of SCIP as a protobuf schema for symbol relationships further illustrate a tooling ecosystem that prioritizes explicit relationships and code metadata over raw body text. Supporting concepts about graph reachability, traversal, and indexing provide context that a deterministic, structure-focused graph model can enable efficient queries about relationships, align with the notion of focusing on contracts and structure, and explain how such a graph infrastructure can enable deterministic navigation of code architectures.",
      "confidence": "medium"
    },
    {
      "field": "implementation_roadmap_summary",
      "citations": [
        {
          "title": "Tree-sitter Grammar DSL",
          "url": "https://tree-sitter.github.io/tree-sitter/creating-parsers/2-the-grammar-dsl.html",
          "excerpts": [
            "The following is a complete list of built-in functions you can use in your `grammar.js` to define rules.",
            "* **Sequences : `seq(rule1, rule2, ...)`** — This function creates a rule that matches any number of other rules, one after\n  anothe",
            "* **Alternatives : `choice(rule1, rule2, ...)`** — This function creates a rule that matches _one_ of a set of possible\n  rules. The order of the arguments does not matte",
            "* **Repetitions : `repeat(rule)`** — This function creates a rule that matches _zero-or-more_ occurrences of a given rul",
            "* **Repetitions : `repeat1(rule)`** — This function creates a rule that matches _one-or-more_ occurrences of a given rul",
            "* **Options : `optional(rule)`** — This function creates a rule that matches _zero or one_ occurrence of a given rul",
            "ion. * **Precedence : `prec(number, rule)`** — This function marks the given rule with a numerical precedence, which will be used\n  to resolve [_LR(1) Conflicts_](https://en.wikipedia.",
            "\nThis function can also be used to assign lexical precedence to a given\n  token, but it must be wrapped in a `token` call, such as `token(prec(1, 'foo'))`",
            "* **Left Associativity : `prec.left([number], rule)`** — This function marks the given rule as left-associative (and optionally\n  applies a numerical precedence).",
            " * **Right Associativity : `prec.right([number], rule)`** — This function is like `prec.left` , but it instructs Tree-sitter\n  to prefer matching a rule that ends _later_",
            "* **Dynamic Precedence : `prec.dynamic(number, rule)`** — This function is similar to `prec` , but the given numerical precedence\n  is applied at _runtime_ instead of at parser generation t",
            "* **Tokens : `token(rule)`** — This function marks the given rule as producing only\n  a single token.",
            "* **Immediate Tokens : `token.immediate(rule)`** — Usually, whitespace (and any other extras, such as comments) is optional\n  before each token. This function means that the token will only match if there",
            "* **Aliases : `alias(rule, name)`** — This function causes the given rule to _appear_ with an alternative name in the syntax\n  tree.",
            "* **Field Names : `field(name, rule)`** — This function assigns a _field name_ to the child node(s) matched by the given\n  rule. In the resulting syntax tree, you can then use that field name to access specific children.",
            "* **Reserved Keywords : `reserved(wordset, rule)`** — This function will override the global reserved word set with the\n  one passed into the `wordset` parameter."
          ]
        },
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application",
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited.",
            "*General** enough to parse any programming languag",
            "*Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any applicatio"
          ]
        },
        {
          "title": "Making Sense of Tree-sitter's C API",
          "url": "https://dev.to/shrsv/making-sense-of-tree-sitters-c-api-2318",
          "excerpts": [
            "|Function |Description |",
            "| --- | --- |",
            "|`ts_parser_parse` |Reparses with the old tree for efficiency. |",
            "|`ts_parser_set_language` |Assigns a language to the parser. |"
          ]
        },
        {
          "title": "SQLite Optimizations for Ultra High-Performance",
          "url": "https://www.powersync.com/blog/sqlite-optimizations-for-ultra-high-performance",
          "excerpts": [
            "**\\#** 1: Enable Write-Ahead Logging (WAL) And Disable Synchronous Mod",
            "\n### **\\#** 1: Enable Write-Ahead Logging (WAL) And Disable Synchronous Mode",
            "###### _Effect: Can reduce per-transaction overhead from 30ms+ to < 1ms. _",
            "```\n`pragma journal_mode = WAL;\n pragma synchronous = normal;\n pragma journal_size_limit = 6144000 ;`",
            "The only durability caveat is that on a system crash (not application crash), the last transaction(s) may be rolled back. This is fine for most applications — if durability is that important, you should probably rely on more than just a phone's flash storage.",
            "\n### **\\#** 2: Reduce Binding Overhead",
            "###### _Effect: Using different bindings can reduce per-transaction and per-statement overhead by 2-10x._"
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        },
        {
          "title": "Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/",
          "excerpts": [
            "An SLI is a service level _indicator_ —a carefully defined quantitative measure of some aspect of the level of service that is provided.",
            "Most services consider _request latency_ —how long it takes to return a response to a request—as a key SLI.",
            "An SLO is a _service level objective_ : a target value or range of values for a service level that is measured by an SLI.",
            "For example, we might decide that we will return Shakespeare search results \"quickly,\" adopting an SLO that our average search request latency should be less than 100 milliseconds.",
            "Many other Google services, such as Google for Work, do have explicit SLAs with their users. Whether or not a particular service has an SLA, it’s valuable to define SLIs and SLOs and use them to manage the service.",
            "You shouldn’t use every metric you can track in your monitoring system as an SLI; an understanding of what your users want from the system will inform the judicious selection of a few indicators.",
            "Most metrics are better thought of as _distributions_ rather than averages. For example, for a latency SLI, some requests will be serviced quickly, while others will invariably take longer—sometimes much longer. A simple average can obscure these tail latencies, as well as changes in them.",
            "Using percentiles for indicators allows you to consider the shape of the distribution and its differing attributes: a high-order percentile, such as the 99th or 99.9th, shows you a plausible worst-case value, while using the 50th percentile (also known as the median) emphasizes the typical case.",
            "For maximum clarity, SLOs should specify how they’re measured and the conditions under which they’re valid.",
            "If you have users with heterogeneous workloads such as a bulk processing pipeline that cares about throughput and an interactive client that cares about latency, it may be appropriate to define separate objectives for each class of workload:",
            "It’s both unrealistic and undesirable to insist that SLOs will be met 100% of the time: doing so can reduce the rate of innovation and deployment, require expensive, overly conservative solutions, or both. Instead, it is better to allow an error budget—a rate at which the SLOs can be missed—and track that on a daily or weekly basis.",
            "Keep a safety margin",
            "Using a tighter internal SLO than the SLO advertised to users gives you room to respond to chronic problems before they become visible externally. An SLO buffer also makes it possible to accommodate reimplementations that trade performance for other attributes, such as cost or ease of maintenance, without having to disappoint users."
          ]
        }
      ],
      "reasoning": "The finegrained field describes a structured MVP plan with deterministic tooling, a Tree-sitter grammar for the pilot language, a SQLite-backed AIM Daemon, an interface graph (ISG), and monitoring via SLIs focusing on latency percentiles. The most directly supportive excerpts provide concrete details that map to each MVP component: - Tree-sitter grammar and parser capabilities are central to a production-grade MVP grammar for the pilot language; excerpts discussing Tree-sitter as a general parsing/incremental parsing framework and the DSL for grammar creation show the kinds of tooling being planned. They explicitly describe how Tree-sitter grammars are constructed and how grammars are authored, which aligns with the MVP deliverable for a production-quality grammar. - The MVP’s backend is SQLite-based with explicit performance-oriented pragmas; excerpts listing PRAGMA journal_mode = WAL and PRAGMA synchronous = normal (and mmap_size guidance) match the backend performance/durability goals stated in the field value. Additional excerpts outline the performance implications and typical guidance around WAL vs. synchronous settings, supporting the plausibility and design of the backend. - The ISG/deterministic graph component is reflected by Code Property Graph documentation excerpts that describe graph representations and standardized querying interfaces; these excerpts support the concept of a structured, graph-based architectural map that underpins deterministic navigation. - The Dashboard/SLI aspect is captured by excerpts detailing service-level indicators, latency percentiles (P95/P99), and general SLI/SLO guidance; these excerpts directly support the MVP’s emphasis on latency-focused dashboards and measurable guarantees. - The incremental/analysis-oriented Tree-sitter excerpts (including grammar DSL specifics and incremental parsing behavior) support the notion of a production-grade, real-time capable code-understanding system that the MVP aims to deploy. - Additional excerpts about enabling deterministic query backends and graph-based navigation reinforce the deterministic architecture mindset critical to the MVP. Overall, the strongest links are direct, concrete references to the Tree-sitter grammar and its DSL, the WAL-backed SQLite backend with explicit synchronization and mmap guidance, the ISG/graph navigation concept via the empirical/standardized graph tooling references, and the explicit SLIs/SLOs focusing on latency percentiles. The remaining excerpts provide supportive context on the deterministic graph view and parsing capabilities that underpin the MVP but are slightly more indirect in mapping to a single deliverable. ",
      "confidence": "high"
    },
    {
      "field": "security_and_multitenancy_model.authentication_model",
      "citations": [
        {
          "title": "Implementing tenant isolation using Amazon Bedrock agents within a multi-tenant environment (AWS blog post)",
          "url": "https://aws.amazon.com/blogs/machine-learning/implementing-tenant-isolation-using-agents-for-amazon-bedrock-in-a-multi-tenant-environment/",
          "excerpts": [
            "Isolating tenants in a pooled model is achieved by using tenant context information in different application components. The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "When building multi-tenant SaaS applications, always enforce tenant isolation (leverage IAM where ever possible). 2. Securely pass tenant and user context between deterministic components of your application, without relying on an AI model to handle this sensitive information. 3. Use Agents for Amazon Bedrock to help build an AI assistant that can securely pass along tenant context. 4. Implement isolation at different layers of your application to verify that users can only access data and resources associated with their respective tenant and user context.",
            "The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "The tenant context can be injected by an authoritative source, such as the identity provider (IdP) during the authentication of a user. Integrity of the tenant context must be preserved throughout the system to prevent malicious users from acting on behalf of a tenant that they shouldn’t have access to, resulting in potentially sensitive data being disclosed or modified.",
            "This Lambda function uses the provided tenant specific scoped credentials and tenant ID to fetch information from [Amazon DynamoDB](https://aws.amazon.com/dynamodb) . Tenant configuration data is stored in a single, shared table, while user data is split in one table per tenant. After the correct data is fetched, it’s returned to the agent. The agent interacts with the LLM for the second time to formulate a natural-language answer to ",
            "Note that each component in this sample architecture can be changed to fit into your pre-existing architecture and knowledge in the organization.",
            ". When building multi-tenant SaaS applications, always enforce tenant isolation (leverage IAM where ever possible). 2. Securely pass tenant and user context between deterministic components of your application, without relying on an AI model to handle this sensitive information. 3. Use Agents for Amazon Bedrock to help build an AI assistant that can securely pass along tenant context. 4. Implement isolation at different layers of your application to verify that users can only access data and resources associated with their respective tenant and user context."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes an authentication design that relies on an External Identity Provider (IdP) Federation, avoiding a proprietary IdP, and propagates authenticated identity (tenantId and userId) with every API call. It also notes programmatic access through service accounts and workload identities using OAuth 2.0 client credentials, ensuring tenant-scoped security. The most relevant excerpts explicitly mention integrating or leveraging an identity provider (IdP) during user authentication and preserving tenant context to prevent cross-tenant access. They also discuss enforcing tenant isolation and using identity information as part of secure, multi-tenant design. While none of the excerpts provide exact JWT structure or OAuth2 client-credentials example, they repeatedly emphasize IdP-based authentication and tenant-context preservation, which directly supports the described authentication model. Additional excerpts reinforce the broader security posture in multi-tenant systems (authentication and isolation) and thus provide supportive context for the overall authentication approach, though with less direct phrasing about IdP federation.",
      "confidence": "medium"
    },
    {
      "field": "strategic_context_aggregated_codebase.role_of_aim_isg",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP - a better code indexing format than LSIF",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations.",
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’."
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on an intelligent navigation layer over a centralized, complex codebase, enabled by a graph-like representation of architectural relationships and a robust symbol/indexing framework. The most directly relevant information comes from descriptions of the Code Property Graph (CPG) as an extensible, language-agnostic representation of program code designed for scalable analysis, which aligns with the idea of a deterministic, queryable backbone for software architectures. Relatedly, the CPG specification and schema details describe how such graphs are stored, queried, and versioned, which underpin the deterministic navigation capabilities of the AIM/ISG paradigm. Additionally, references to SCIP—an indexing/relationship-encoding protobuf schema—highlight standardized, human-readable identifiers and symbol-to-location relationships, which are critical for scalable architectural reasoning and change detection within a large codebase. Together, these excerpts substantiate the existence and utility of structured, queryable representations and symbol/indexing mechanisms that enable intelligent navigation and integrity checks over a centralized complex codebase, as described in the finegrained field value.",
      "confidence": "medium"
    },
    {
      "field": "strategic_context_aggregated_codebase.context_name",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP - a better code indexing format than LSIF",
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The finegrained field value denotes a strategic construct—Aggregated Codebase (ACB) or Adaptive Symbiotic Ecosystem—that encapsulates centralized, architecture-aware tooling for large codebases. Excerpts that discuss Code Property Graph (CPG) specifications and tooling provide the most direct support, as CPG represents a concrete architectural model for analyzing code structure and relationships across languages, which is foundational to an ACB’s deterministic, globally navigable view. The statement that a Code Property Graph is an extensible, language-agnostic representation designed for incremental, distributed code analysis directly aligns with the concept of a centralized, architecture-aware codebase. Additionally, discussions of the CPG schema, storage in PostgreSQL, and the existence of a formal schema for nodes, edges, and attributes reinforce the feasibility and design of a centralized architectural repository, which is essential for an Aggregated Codebase. Related excerpts on SCIP (a symbol/indexing format) and SigHash-based identifiers emphasize standardized, reproducible indexing and cross-referencing of symbols and locations, which are key capabilities of a centralized architecture-aware ecosystem. Together, these excerpts build a coherent backdrop for an ACB-like construct by detailing the data models, storage, and standardization methods that enable global architectural reasoning and deterministic queries across a large, multi-language codebase.",
      "confidence": "medium"
    },
    {
      "field": "strategic_context_aggregated_codebase.philosophy",
      "citations": [
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP - a better code indexing format than LSIF",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations.",
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results.",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        }
      ],
      "reasoning": "The philosophy centers on creating a centralized, architecture-wide understanding of code through standardized representations and verification principles. Excerpts describing a standardized, language-agnostic representation for code and a schema-driven approach to encoding relationships between symbols align with the idea of centralizing logic and enabling consistent, cross-stack reasoning. Specifically, the references to SCIP as a Protobuf schema designed to encode symbol relationships provide a concrete mechanism to replace ad-hoc monikers and loosely coupled result sets with stable, machine-readable identifiers, supporting centralized logic and cross-language integrity. Likewise, the discussion of SCIP as a more robust code indexing format reinforces the notion of a unified, cross-cutting schema for code intelligence, which underpins a single, shared logic across tools and languages. Finally, mentions of the Code Property Graph (CPG) as an extensible, language-agnostic representation of program code further bolster the strategy of consolidating architectural understanding into a common, verifiable structure that transcends individual runtimes or contracts. Although the excerpts do not state the exact phrasing from the field value, they collectively illustrate the move toward standardized representations, symbol relationship encoding, and stable indexing—all of which underpin centralized logic and a more static, verification-focused approach across the stack. The emphasis on a formal schema for relationships and a robust graph-based view of code supports the idea of static verification over runtime interpretation and a consistent identity for core logic that spans the entire system.",
      "confidence": "medium"
    },
    {
      "field": "security_and_multitenancy_model.row_level_security_implementation",
      "citations": [
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "Compile-Time Authorization Callbacks",
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized."
          ]
        },
        {
          "title": "Tenant isolation - SaaS Architecture Fundamentals",
          "url": "https://docs.aws.amazon.com/whitepapers/latest/saas-architecture-fundamentals/tenant-isolation.html",
          "excerpts": [
            "Tenant isolation focuses exclusively on using tenant context to\nlimit access to resources.",
            "tenant isolation is separate from general security\nmechanisms.",
            "The more you move customers into a multi-tenant model, the more they\nwill be concerned about the potential for one tenant to access the\nresources of another tenant."
          ]
        },
        {
          "title": "What is Multi-Tenant Security? Definition, Risks, and Best Practices",
          "url": "https://qrvey.com/blog/multi-tenant-security/",
          "excerpts": [
            "RBAC ensures that users only access the data they’re authorized to see, enforcing strict access controls and reducing insider threats."
          ]
        },
        {
          "title": "Security Issues If Incorrectly Implemented and Multi-Tenant Architecture in Analytics",
          "url": "https://www.gooddata.com/blog/multi-tenant-architecture/",
          "excerpts": [
            "Poorly implemented multitenancy can lead to issues such as unauthorized access and data misuse. To nullify such threats, these applications require careful design and management to ensure tenant isolation and [secure data storage](/resources/good-talks-how-to-store-data/) . The most important thing is to authorize the access of end users.",
            "Serving multiple clients in a single instance of an application/database means implementing additional logic for tenant separation, data filtering, and tenant identification to ensure proper data isolation and security.",
            "ulti-tenant-analytics/) is a type of analytics use case that leverages multi-tenant architecture. Analytics and business intelligence platforms that support multitenancy allow companies to share dashboards and report capabilities to different user groups in a secure and cost-efficient way while utilizing the same resources"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a deterministic, database-level row-level security (RLS) mechanism implemented via secure views that join with a tenant-scoped context (tenantId) established at session start, with a database authorizer (sqlite3_set_authorizer) blocking direct access to base tables so all data access occurs through RLS-enforcing views. Excerpts that discuss the SQLite authorizer provide direct alignment with the mechanism enabling controlled access to base tables and enforcing that data access goes through secure views. Excerpts that discuss tenant isolation and multi-tenant security fundamentals provide essential context about using a tenant context to limit access to resources, which underpins why such a deterministic, view-based RLS would be necessary. Specifically:\n- A passage describing the SQLite authorizer as a tool used to control access and to ensure statements do not access data they shouldn’t see aligns with the implementation of the database-level enforcement mechanism and the need to block unauthorized direct table access.\n- Passages about tenant isolation and ensuring that data access is restricted to the tenant’s scope describe the architectural motivation for RLS and view-based filtering that relies on session-scoped tenant context.\n- Additional notes about enforcing tenant isolation and secure data presentation (views and contextual filtering) reinforce the overall model where data visibility is constrained by the tenant context and restricted through defined views rather than free-form queries.\nCollectively, these excerpts support the idea that RLS is implemented at the database layer, using secure views that incorporate the tenant context and an authorizer mechanism to prevent bypassing the views.",
      "confidence": "medium"
    },
    {
      "field": "security_and_multitenancy_model.query_sandboxing_mechanism",
      "citations": [
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "the authorizer callback is invoked to\nsee if those actions are allowed.",
            "The authorizer callback must not do anything that will modify\nthe database connection that invoked the authorizer callback.",
            "Only a single authorizer can be in place on a database connection\nat a time. Each call to sqlite3\\_set\\_authorizer overrides the\nprevious call. Disable the authorizer by installing a NULL callbac",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized.",
            "Compile-Time Authorization Callbacks"
          ]
        }
      ],
      "reasoning": "The most relevant materials provide direct descriptions of the authorization mechanism for SQLite statements. The excerpt explains that an authorizer is invoked when preparing SQL statements to ensure access to data aligns with permissions, which directly supports the notion of a safeguarding callback that denies operations violating the security policy. It further notes that the authorizer can be used to enforce an allow-list of safe SQL commands and to disable risky features such as attaching external databases, which matches the core mechanism described in the field value. Additional passages state that only a single authorizer can be in place at a time, and that the authorizer callback should not modify the database connection, which aligns with the safe, read-only enforcement pattern and lifecycle management described in the field value. Other passages elaborate on the parameters and override behavior of the authorizer, reinforcing how the mechanism is configured and maintained, and a general note on authorizers appearing when preparing statements complements the understanding of why this mechanism is central to sandboxing queries. A more distant set of excerpts discusses tenant isolation concepts rather than the SQLite-specific authorization mechanism, and thus provide peripheral context but not direct evidence about the sqlite3_set_authorizer usage.",
      "confidence": "high"
    },
    {
      "field": "security_and_multitenancy_model.threat_mitigation_summary",
      "citations": [
        {
          "title": "Tenant isolation - SaaS Architecture Fundamentals",
          "url": "https://docs.aws.amazon.com/whitepapers/latest/saas-architecture-fundamentals/tenant-isolation.html",
          "excerpts": [
            "Tenant isolation focuses exclusively on using tenant context to\nlimit access to resources.",
            "tenant isolation is separate from general security\nmechanisms.",
            "authentication and\nauthorization; however, the fact that a tenant user is authenticated\ndoes not mean that your system has achieved isolation. Isolation is\napplied separately from the basic"
          ]
        },
        {
          "title": "Security Issues If Incorrectly Implemented and Multi-Tenant Architecture in Analytics",
          "url": "https://www.gooddata.com/blog/multi-tenant-architecture/",
          "excerpts": [
            "Poorly implemented multitenancy can lead to issues such as unauthorized access and data misuse. To nullify such threats, these applications require careful design and management to ensure tenant isolation and [secure data storage](/resources/good-talks-how-to-store-data/) . The most important thing is to authorize the access of end users.",
            "Serving multiple clients in a single instance of an application/database means implementing additional logic for tenant separation, data filtering, and tenant identification to ensure proper data isolation and security.",
            "ulti-tenant-analytics/) is a type of analytics use case that leverages multi-tenant architecture. Analytics and business intelligence platforms that support multitenancy allow companies to share dashboards and report capabilities to different user groups in a secure and cost-efficient way while utilizing the same resources"
          ]
        },
        {
          "title": "What is Multi-Tenant Security? Definition, Risks, and Best Practices",
          "url": "https://qrvey.com/blog/multi-tenant-security/",
          "excerpts": [
            "Centralized monitoring tools enable administrators to track activities across the entire multi-tenant system. This helps detect anomalies and address security incidents before they escalate.",
            "RBAC ensures that users only access the data they’re authorized to see, enforcing strict access controls and reducing insider threats."
          ]
        }
      ],
      "reasoning": "The most directly relevant information states that tenant isolation focuses on using tenant context to limit access to resources, and that isolation is a concept distinct from general security mechanisms, underscoring the layered, context-driven enforcement described in the target field. Additional excerpts emphasize that authentication alone does not guarantee isolation and that isolation must be enforced separately, which aligns with the need to enforce tenant boundaries at every layer of the data path. Other excerpts warn about risks of poorly implemented multi-tenant setups (unauthorized access and data misuse), and advocate for security practices such as RBAC and centralized monitoring to detect and prevent violations. Taken together, these sources substantiate a threat-mitigation narrative that cross-tenant access is controlled by strict tenant-context propagation, multi-layer enforcement, and explicit separation from generic security controls, which mirrors the described workflow of authenticating a user, retrieving only authorized tenant-scoped data, and sandboxing the LLM before processing.",
      "confidence": "high"
    },
    {
      "field": "architectural_guardrail_enforcement.methodology",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            ". Most\ntechniques, however, assume that the input graph G is static, which\nmakes them inapplicable for the dynamic graphs commonly en-\ncountered in practice.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs.",
            "Previous work [3–14,16,19,22–25,27–32] has proposed numer-\nous indexing techniques to efficiently support reachability queries\nwithout significant space and pre-computation overheads."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        }
      ],
      "reasoning": "The described fine-grained field value centers on codifying architectural guardrails as machine-checkable rules evaluated against the Interface Signature Graph (ISG), using a declarative rule language, with real-time enforcement and actionable remediation to maintain architectural integrity. Excerpt-level content that directly supports this includes: the notion of a Deterministic Traversal and Reachability framework tied to ISG, which provides a deterministic map of architectural relationships and enables precise queries that underpin enforcement of constraints in real time; and a companion reference to a Code Property Graph-like specification, which signals concrete tooling and data-structure support for graph-based code reasoning that can underpin rule evaluation. Together, these excerpts establish the feasibility and mechanics of a rule-driven, deterministic guardrail system operating on an ISG, including the idea that a policy is defined declaratively and executed by an engine to enforce conventions and provide remediation guidance. The remaining excerpts offer contextual support about ISG design considerations (static vs. dynamic graphs) and related graph-analysis tooling, which enriches understanding but are less directly about the guardrail enforcement mechanism itself. Specifically: the first excerpt discusses deterministic traversal and indexing for large graphs in the ISG context, establishing the architectural foundation and deterministic query capabilities that would support guardrail checks; the final excerpt references a Code Property Graph specification and tooling, indicating concrete graph-based representations useful for implementing and validating architectural policies; the intermediate excerpts elaborate on dynamic graphs and prior work on graph reachability, which informs practical deployment considerations but are secondary to the core guardrail enforcement concept. Overall, the strongest alignment is with deterministic ISG-focused graph governance and declarative policy execution, followed by graph tooling support, with supporting context from dynamic graph considerations.",
      "confidence": "medium"
    },
    {
      "field": "llm_workflow_transformation.step_description",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The fine-grained field value centers on turning a user’s high-level architectural intent into a precise architectural query that the AIM Daemon can execute. The most directly relevant material describes the AIM/ISG framework as a deterministic engine for architectural reasoning, including the concept of executing queries against a structured graph of code entities. Content that emphasizes deterministic traversal, reachability indexing, and the need for a precise, queryable representation of code (as opposed to probabilistic interpretation) provides direct support for the notion of translating intent into a concrete query. Material about the Code Property Graph and its specification enhances understanding of how code entities and their relationships can be represented and queried in practice, which underpins the query-generation step. Discussions of symbol schemas and protobuf-based IDs (SCIP) further contextualize how entities and relationships can be encoded in a stable, queryable format, reinforcing the feasibility and reliability of generating executable queries. Taken together, these excerpts collectively illustrate the architecture, tooling, and representations that enable the AIM Daemon to accept a user’s intent and produce a precise, machine-executable query such as locating nodes implementing a specific interface or function signature. The most directly relevant portions describe the deterministic, graph-based approach and the use of structured representations (ISG, CPG) to support query generation and execution, while the surrounding material provides practical tooling context for how such queries would be encoded and traversed within the system.",
      "confidence": "medium"
    },
    {
      "field": "architectural_guardrail_enforcement.evaluated_rule_language",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        }
      ],
      "reasoning": "The fine-grained field value enumerates multiple rule languages as evaluated options for expressive and performant analysis over graph-structured code data. Among the provided excerpts, the one that explicitly references interfacing with the graph using different programming languages directly supports the concept of multilingual rule/query capability over a code-graph representation. It describes the Code Property Graph specification and tooling, and notes that the data structure definitions are generated to be accessed by different programming languages, which maps to the idea of evaluating diverse rule languages to operate on the graph. This directly aligns with the need to support or evaluate multiple rule languages for architectural guardrails over a graph-based model. The other excerpts discuss the broader context of deterministic traversal, indexing, and general graph querying but do not explicitly mention language-specific access or evaluation of multiple rule languages, making them less directly supportive of the field value.",
      "confidence": "medium"
    },
    {
      "field": "parsing_fidelity_tradeoff.name",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            " Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application\n\n##"
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "TypeScript grammar for tree-sitter",
            "v0.23.2 Latest"
          ]
        }
      ],
      "reasoning": "The finegrained field value identifies the concept of syntactic analysis using AST/CST parsers. The most directly supportive content describes Tree-sitter as a parser generator and incremental parsing library that builds a concrete syntax tree and updates it efficiently, which aligns with AST/CST parsing strategies. Supporting material notes that Tree-sitter aims to be general enough to parse any language and fast enough to operate on keystrokes, emphasizing its role in robust syntactic analysis across languages. Additional excerpts reference Tree-sitter’s presence in various projects and its role in providing language grammars (e.g., TypeScript grammar) for tree-sitter, illustrating practical AST/CST parsing usage. Together, these excerpts corroborate the focus on syntactic analysis as the chosen parsing approach and underscore its applicability to multi-language parsing fidelity. The least direct but still relevant items mention the TypeScript grammar and versioning, which reinforce the parsing tooling context and AST/CST parsing capabilities.",
      "confidence": "high"
    },
    {
      "field": "project_summary.project_name",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "Code Property Graph: specification, query language, and utilities",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            ")\n\nThe code property graph is a data structure designed to mine large\ncodebases for instances of programming patterns. These patterns are\nformulated in a domain-specific language (DSL) based on [Scala](https://www.scala-lang.org/) . It serves as a single\nintermediate program representation across all languages supported by\nJoern and its commercial brother [Ocular](https://qwiet.ai/) . Property graphs are a generic abstraction supported by many\ncontemporary graph databases such as [Neo4j](https://neo4j.com/) , [OrientDB](https://orientdb.com/) , and [JanusGraph](https://janusgraph.org/) . In fact, [older versions of\nJoern](https://github.com/fabsx00/joern-old) made use of general\npurpose graph databases as a storage backend and the graph query\nlanguage [Gremlin](https://tinkerpop.apache.org/gremlin.html) . As the\nlimitations of this approach became more apparent over the years, we\nreplaced both the storage backend and query language with our own\ngraph database [OverflowDB](https://github.com/ShiftLeftSecurity/overflowdb) . Qwiet AI (formerly ShiftLeft) has open-sourced the [implementation of the code property\ngraph](https://github.com/ShiftLeftSecurity/codepropertygraph) and its [specification](https://cpg.joern.io) .",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The most directly relevant content explicitly introduces AIM/ISG as a deterministic framework for graph-based architectural analysis and navigation. The discussion of the Interface Signature Graph as a foundational map and the AIM Daemon as the real-time engine directly aligns with the target field value, which identifies a project named for Architectural Intelligence Management and Interface Signature Graph. Phrases such as the deterministic traversal and reachability indexing for large graphs further corroborate the intended project scope and terminology. Other excerpts about Code Property Graph (CPG) provide broader context about code analysis infrastructures and language-agnostic graph representations, which are related domain concepts but do not name or precisely define the AIM/ISG project component. Taken together, the strongest support comes from the explicit AIM/ISG framing and its described roles, with surrounding excerpts offering contextual alignment to the broader tooling landscape described in the query. Collectively, these excerpts support the notion of a project named to reflect Architectural Intelligence Management and Interface Signature Graph and its deterministic navigation goals.",
      "confidence": "high"
    },
    {
      "field": "parsing_fidelity_tradeoff.level",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            " Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application\n\n##"
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "TypeScript grammar for tree-sitter",
            "v0.23.2 Latest"
          ]
        }
      ],
      "reasoning": "The target field value represents Level 2: Syntactic Analysis, which concerns parsing the syntax of programming languages (as opposed to semantic analysis or runtime behavior). Excerpt describing Tree-sitter as a parser generator and incremental parsing library directly aligns with syntactic analysis capabilities, since it emphasizes building and updating a concrete syntax tree. Excerpts that state Tree-sitter is general enough to parse any programming language and is fast and robust further reinforce the notion of language-agnostic syntactic parsing, which is the essence of Level 2. Excerpts mentioning the TypeScript grammar for tree-sitter extend the same theme by showing a concrete instance of syntactic parsing support for a language, reinforcing the parsing-centric perspective. Collectively, these excerpts support the idea that the system leverages robust, language-agnostic syntactic parsing (Level 2) as part of the architectural tooling, even though they do not explicitly label the level numerically in the excerpts themselves. The strongest support comes from the explicit description of Tree-sitter as a parser and incremental parsing tool, with additional contextual support from the general parsing capabilities across languages and concrete language grammars.",
      "confidence": "medium"
    },
    {
      "field": "project_summary.classification",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "Code Property Graph: specification, query language, and utilities",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            ")\n\nThe code property graph is a data structure designed to mine large\ncodebases for instances of programming patterns. These patterns are\nformulated in a domain-specific language (DSL) based on [Scala](https://www.scala-lang.org/) . It serves as a single\nintermediate program representation across all languages supported by\nJoern and its commercial brother [Ocular](https://qwiet.ai/) . Property graphs are a generic abstraction supported by many\ncontemporary graph databases such as [Neo4j](https://neo4j.com/) , [OrientDB](https://orientdb.com/) , and [JanusGraph](https://janusgraph.org/) . In fact, [older versions of\nJoern](https://github.com/fabsx00/joern-old) made use of general\npurpose graph databases as a storage backend and the graph query\nlanguage [Gremlin](https://tinkerpop.apache.org/gremlin.html) . As the\nlimitations of this approach became more apparent over the years, we\nreplaced both the storage backend and query language with our own\ngraph database [OverflowDB](https://github.com/ShiftLeftSecurity/overflowdb) . Qwiet AI (formerly ShiftLeft) has open-sourced the [implementation of the code property\ngraph](https://github.com/ShiftLeftSecurity/codepropertygraph) and its [specification](https://cpg.joern.io) .",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The target field expresses a high-level strategic directive to perform deep architectural synthesis within massive, multi-language codebases. Excerpts describing the AIM Daemon, Interface Signature Graph, and the 3x3 ontology establish a deterministic, graph-based view of software architecture, which directly supports a strategic imperative to move away from probabilistic interpretations toward deterministic navigation and architectural reasoning. Quoted ideas such as representing architectural skeletons as a compressed ISG, focusing on public contracts and structural relationships, and enabling real-time, deterministic queries, all map to the concept of strategic architectural synthesis at scale. Additional excerpts detailing the Code Property Graph and its language-agnostic, graph-based program representation provide the necessary tooling and formalism that enable such synthesis across languages, which reinforces the strategic objective. Together, these excerpts corroborate a framework and tooling stack appropriate for achieving strategic imperatives in architectural synthesis, even though the exact phrase from the field value is not directly stated.",
      "confidence": "medium"
    },
    {
      "field": "parsing_fidelity_tradeoff.assessment",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            " Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application\n\n##"
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "TypeScript grammar for tree-sitter",
            "v0.23.2 Latest"
          ]
        }
      ],
      "reasoning": "The claim that the pragmatic optimum for AIM corresponds to Level 2 parsing is supported by excerpts describing Tree-sitter as a fast, general-purpose parser framework capable of incremental parsing and embedding in various applications. One excerpt emphasizes that Tree-sitter is general enough to parse any programming language, fast enough to parse on every keystroke in an editor, robust in the face of syntax errors, and dependency-free for embedding in applications. This directly aligns with the idea of a pragmatic, real-time syntactic analysis solution suitable for AIM’s deterministic navigation goals. Additional excerpts reinforce this by outlining Tree-sitter’s role as a parsing technology used for real-time, structurally aware analysis (e.g., incremental updates to a syntax tree) and by noting its applicability to languages like TypeScript through language grammars. Taken together, these excerpts substantiate the notion that Level 2 parsing represents the pragmatic, operationally suitable choice for the AIM framework, providing robust structural understanding with the necessary performance characteristics. No excerpt contradicts this interpretation; they all reinforce the suitability and practicality of syntactic analysis tooling for real-time architectural work.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.8",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The target field value defines a relationship edge named EXTENDS as an inheritance link between entities. The most directly supportive excerpt explicitly enumerates the ISG/CPG edge types, including EXTENDS as a defined relationship (inheritance) between nodes, which aligns exactly with the fine-grained value description. The adjacent excerpt reinforces this by describing edges as labeled relations and listing EXTENDS among the possible edge types, confirming that EXTENDS is indeed a recognized, named relationship in the ISG ontology. Collectively, these sources establish that EXTENDS is an inheritance-type connection between entities in the ISG/CPG modeling of software architectures, matching the requested field value. Other excerpts discuss Code Property Graph concepts (nodes, other edges, and tooling) but do not specifically redefine or name the EXTENDS relationship, so they are less directly relevant to the exact field value.",
      "confidence": "high"
    },
    {
      "field": "evaluation_and_benchmarking_strategy.evaluation_pillar",
      "citations": [
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results.",
            "Code Property Graph: specification, query language, and utilities"
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The field value corresponds to the correctness of the evaluation and benchmarking strategy within an architectural-intelligence framework. Content that directly addresses correctness includes: (a) the deterministic traversal and indexing approach, which aims to produce provably correct reachability and query results under a constrained, compressed model; (b) the description of Code Property Graphs as structured, labeled graphs with explicit node types and directed edges that encode program constructs and their relationships, ensuring that queries reflect precise architectural relationships; (c) the specification and tooling around Code Property Graphs, which underpins consistent, machine-parseable representations that support correct, cross-language querying; (d) the documentation of how edges such as CONTAINS or CALLS encode architectural and data-flow relationships, which is essential for correct interpretation of analysis results; (e) references to the CPG schema and the MATE documentation that describe the data model and its constraints, contributing to correctness in how analysis results are stored and retrieved; (f) notes on the broader tooling ecosystem (e.g., SCIP) that influence correctness guarantees through standards and interoperability. Collectively, these excerpts provide direct support for correctness through deterministic modeling, explicit node/edge semantics, standardized schemas, and mature tooling that enable reliable analysis outcomes. The more distant items (e.g., general performance claims or unrelated expression languages) are less relevant for establishing the correctness of the evaluation pillar but still offer contextual backdrop about tooling ecosystems that influence correctness expectations.",
      "confidence": "medium"
    },
    {
      "field": "evaluation_and_benchmarking_strategy.ground_truth_source",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "Code Property Graph: specification, query language, and utilities",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        },
        {
          "title": "Announcing SCIP",
          "url": "https://sourcegraph.com/blog/announcing-scip",
          "excerpts": [
            "SCIP as a Protobuf schema that is centered around human-readable string IDs for symbols replacing the concept of ‘monikers’ and ‘resultSet’.",
            "The SCIP Protobuf schema is [**available in the sourcegraph/scip**](https://sourcegraph.com/github.com/sourcegraph/scip/-/blob/scip.proto) repository and includes comprehensive documentation on how to encode relationships between symbols and source locations."
          ]
        }
      ],
      "reasoning": "The ground-truth-source field describes extracting rich semantic data directly from compiler outputs (e.g., javac, rustdoc, clang) and generating a JSON representation of code structure for evaluation. Excerpts that define Code Property Graphs as language-agnostic, extensible representations of code, and that describe their nodes, edges, and attributes, provide the concrete mechanism by which compiler-derived semantic information could be structured into a ground-truth graph. Specifically, the notion that a Code Property Graph is an extensible, language-agnostic model with labeled edges and typed nodes offers a concrete path to represent compiler outputs in a consistent schema suitable for JSON-ground-truth comparison. Further, descriptions of CPG tooling and specifications demonstrate how such a representation can be queried and evolved across languages, aligning with the idea of using compiler-derived data to produce a definitive baseline for correctness evaluation. The combination of these excerpts supports the concept that compiler outputs can be transformed into a standardized, graph-based ground-truth source for evaluating the AIM Daemon’s parsing and graph-generation results, including how components like CONTAINS and CALLS edges encode structural and behavioral relationships that compiler outputs reveal.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.14",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The selected content explains that in a Code Property Graph, relations between constructs are represented by labeled edges, enabling the modeling of containment relationships. A concrete example shows that to express that a method contains a local variable, an edge labeled CONTAINS is used. This directly aligns with the fine-grained field value describing CONTAINS as the structural composition edge (e.g., a Module contains a Class) within the graph. The passages thus provide direct support for understanding CONTAINS as a containment/structural relation in code graphs, matching the requested field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.4",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a Module/Namespace/Package as an organizational scope and boundary in the ISG ontology. Excerpt describes that relationships in code graphs are represented with labeled edges and that one common relation is CONTAINS, which captures how a module contains other program constructs. This supports the idea that modules serve as organizational containers within the graph-based ISG model. The general discussion of nodes and their types in the excerpts provides foundational context for identifying an entity that represents organizational scope, aligning with the MODULE concept. The Code Property Graph specifications and tooling excerpts discuss a language-agnostic, graph-based representation of code concepts (nodes, edges, and their attributes), which underpins how a Module/Namespace/Package would be modeled and queried within such graphs. Together, these excerpts collectively support the interpretation of a Module/Namespace/Package as an organizational boundary node in the ISG, and the CONTAINS relationship as a mechanism by which modules encapsulate or contain other entities.",
      "confidence": "medium"
    },
    {
      "field": "project_summary.objective",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "Code Property Graph: specification, query language, and utilities",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            ")\n\nThe code property graph is a data structure designed to mine large\ncodebases for instances of programming patterns. These patterns are\nformulated in a domain-specific language (DSL) based on [Scala](https://www.scala-lang.org/) . It serves as a single\nintermediate program representation across all languages supported by\nJoern and its commercial brother [Ocular](https://qwiet.ai/) . Property graphs are a generic abstraction supported by many\ncontemporary graph databases such as [Neo4j](https://neo4j.com/) , [OrientDB](https://orientdb.com/) , and [JanusGraph](https://janusgraph.org/) . In fact, [older versions of\nJoern](https://github.com/fabsx00/joern-old) made use of general\npurpose graph databases as a storage backend and the graph query\nlanguage [Gremlin](https://tinkerpop.apache.org/gremlin.html) . As the\nlimitations of this approach became more apparent over the years, we\nreplaced both the storage backend and query language with our own\ngraph database [OverflowDB](https://github.com/ShiftLeftSecurity/overflowdb) . Qwiet AI (formerly ShiftLeft) has open-sourced the [implementation of the code property\ngraph](https://github.com/ShiftLeftSecurity/codepropertygraph) and its [specification](https://cpg.joern.io) .",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "AIM/ISG: Deterministic Traversal and Reachability Indexing for Large Graphs (SIGMOD 2014)",
          "url": "https://edwlin.github.io/pubs/sigmod2014-tol.pdf",
          "excerpts": [
            ". reachability queries is non-trivial, as it requires a careful balanc-\ning act between pre-computation cost, index size, and query pro-\ncessing overhead.",
            "d. In particular, if we pre-compute and store the\nreachability results for all pairs of vertices, then we can process any\nreachability query in O(1) time but suffer prohibitive costs of pre-\nprocessing and space.",
            "ce. On the other hand, if we omit indexing and\nprocess reachability queries directly on G using depth-first search\n(DFS) or breadth-first search (BFS), then we minimize space and\npre-computation overhead, but fail to ensure query efficiency on\nlarge graphs."
          ]
        }
      ],
      "reasoning": "The field value describes enabling LLMs to interact with large, multi-language codebases with unprecedented accuracy and architectural awareness. Excerpts that define the Code Property Graph (CPG) as an extensible, language-agnostic representation of program code and the Joern documentation describing CPG's role as a unified intermediate representation directly support this objective by outlining a standardized, architectural view of code across languages. Additional excerpts discuss the AIM Daemon and ISG, which provide a deterministic navigation framework and real-time querying capabilities over a graph of architectural relationships. This deterministic graph-based approach is essential for LLMs to reason about software architecture rather than treating code as plain text, thereby enabling precise, architecture-aware interactions with large codebases. Together, these excerpts form a coherent picture: use a language-agnostic, graph-based code representation (CPG) connected to a deterministic query/navigation layer (AIM/ISG) to empower LLMs to analyze, reason about, and generate code against massive, multi-language repositories with high architectural fidelity.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.13",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "- The most relevant content directly addresses how edges between program constructs are represented as labeled relationships in a graph. This aligns with the notion of a relationship like DEFINES existing between a trait and its methods or associated types, as a kind of edge in the architectural graph. The specific mention of labeled edges and the example edge CONTAINS illustrates the concept of directional relationships between entities, which is the core idea behind a DEFINES-type relationship in an ISG-like model.\n- Supporting context includes the description of nodes and their types, which establishes that entities such as methods, traits, and modules are represented as nodes in a graph, and that edges encode structural or contractual relationships. This underpins how a DEFINES relationship would be modeled as an edge in the graph connecting a trait to the method or associated type it defines.\n- Additional excerpts discuss the broader graph-query and interrelation capabilities (e.g., transitioning between representations, standardized queries, and the general role of edges in representing relations). While these do not mention DEFINES explicitly, they corroborate the use of a graph-based, edge-labeled paradigm for encoding architectural relationships such as DEFINES.\n- The remaining excerpts provide general information about property graphs and the Code Property Graph, reinforcing that a graph-based representation with labeled relationships is the mechanism by which architectural relationships are modeled, which is conceptually consistent with a DEFINES edge in the ISG ontology.\n",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.2",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The target field describes a node type used for data structures and state machines, which in practice corresponds to how a code-graph ontology would classify structural entities. The most relevant excerpts establish the foundation of node types in a code-property-graph-like model: first, a description that nodes and their types exist, with the type indicating the program construct represented (for example, a node type METHOD or LOCAL). This supports the idea that Enum/Union would be another explicit node category within the same ontology as a data-structure/state-machine construct. Further, a Code Property Graph is described as an extensible, language-agnostic representation of program code, reinforcing that the graph ontology includes a variety of node kinds to capture architectural and data-structure-related concepts. Finally, references to the CPG schema and tooling illustrate that there is a defined schema for nodes, edges, and attributes, which would accommodate a node category like Enum/Union in the overall ontology. Taken together, these excerpts corroborate that Enum/Union corresponds to a structured data-structure/state-machine node within a formal graph-based representation of code.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.0",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The description of a Code Property Graph (CPG) emphasizes that the graph is composed of nodes with explicit types, where nodes represent program constructs. The explicit statement that a node has a type and can represent a program construct such as a method or a local variable directly supports the idea that there can be a node representing a contract-like concept such as a trait/interface. This aligns with the fine-grained field value which identifies a node named with a canonical type for interfaces or traits ([T] Trait/Interface) and notes that it contracts definitions in the codebase. The broader CPG documentation also explains labeled edges and how relationships between program constructs are captured, reinforcing the notion that nodes (with a defined type) embody architectural or contractual elements in code, which is consistent with a trait/interface contract definition.\nAll the above corroborates that nodes have explicit types, with the type denoting the kind of program construct (e.g., METHOD, LOCAL) and, by extension, a contract-like interface such as a trait/interface in the codebase. The other excerpts discuss the CPG specification, tooling, and representation formats, which provide additional context for how nodes and their types are stored and queried within a code-analysis graph, further supporting the concept of a Node representing a contract-like construct in the ISG-like ontology.\n",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.3",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The target field value identifies a node representing behavioral units within code, categorized as a specific node type for functions/methods. Excerpt describing Code Property Graph basics lists nodes and their types, explicitly noting that a node type can be a method, which directly supports the existence and nature of a Function/Method node. Subsequent excerpts detailing the Code Property Graph specification and tooling reinforce that the graph contains structured node types (including function/method-like entities) and provide concrete schema and representations, aligning with the idea of a publicly identifiable function/method node in an ISG-like model. Additional excerpts describing edges and cross-language querying provide contextual support about how these function/method nodes relate within the graph, while the CEL excerpt offers peripheral tooling context unrelated to the node type itself. Taken together, all these excerpts cohere to support the existence and characterization of a node with the described type and meaning as a behavioral unit in the codebase, with the first excerpt offering the strongest direct assertion and the others offering corroborative detail about the CPG/ISG representation of such nodes.",
      "confidence": "high"
    },
    {
      "field": "parsing_fidelity_tradeoff.rationale",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            " Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure C) can be embedded in any application\n\n##"
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "TypeScript grammar for tree-sitter",
            "v0.23.2 Latest"
          ]
        }
      ],
      "reasoning": "The central idea in the field value is that a specific parsing strategy (Tree-sitter-like, syntactic/AST-focused) provides robust structural awareness and fast performance suitable for real-time updates, enabling deterministic navigation while avoiding high-latency semantic analysis. The excerpts directly describe Tree-sitter as a parser generator with incremental parsing that builds and updates a concrete syntax tree, which is essential for maintaining a precise structural map of code. They also state that Tree-sitter is general enough to parse any programming language, fast enough to parse on every keystroke in a text editor, robust enough to provide useful results even with syntax errors, and dependency-free so it can be embedded in various applications. These attributes align with the field value’s emphasis on robust structural awareness and sub-10ms responsiveness, which are necessary to support the AIM Daemon’s deterministic navigation and to avoid the stochastic fog of probabilistic methods. Additionally, references to language-specific grammars (e.g., TypeScript) reinforce the idea that such parsing strategies can cover a broad codebase while maintaining performance guarantees. Collectively, these excerpts corroborate the claim that a fast, robust, structure-focused parsing approach enables real-time architectural mapping without incurring semantic-analysis latency, forming the backbone of deterministic navigation in the ISG/AIM framework.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.12",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The fine-grained field value refers to a relationship edge used for a generic constraint, exemplified by a bound like T BOUND_BY serde::Deserialize. Excerpts that discuss Code Property Graphs and their modeling of relationships show that edges between nodes can be labeled to denote specific kinds of relations (e.g., CONTAINS, IMPLIES, CALLS). This establishes the mechanism by which a BOUND_BY constraint would be represented in the ISG: as a labeled edge capturing a binding/constraint between types or parameters. Additional excerpts describe the general capability to traverse and query labeled edges in a graph representation of software architecture, which supports interpreting BOUND_BY as a type of edge in the deterministic ISG, enabling constraint checks and architectural reasoning. The collection also notes that edges are directed and carry different semantics, reinforcing that BOUND_BY would be another such labeled edge within the same modeling paradigm. Collectively, these excerpts give the structural and semantic backdrop needed to map a generic constraint edge like BOUND_BY into the ISG’s relationship graph.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.10",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The finegrained field describes a specific edge type in an architectural graph: a Relationship with the name ACCEPTS, representing data flow into a function as part of its signature. Excerpts that discuss edges as first-class relations in a graph, and that describe labeled relationships between code constructs, provide direct contextual grounding for this concept. The most relevant excerpt identifies that relationships between program constructs (edges) are labeled and can express containment and other relations, which aligns with the idea of using a labeled edge to denote data-flow-related contract (ACCEPTS) in an ISG/CPG-like model. Additional excerpts explain that edges between nodes carry semantic meaning (e.g., CONTAINS, other relation labels) and that the Code Property Graph framework uses a rich set of edge labels to express architectural and code relationships. Together, these excerpts support understanding that ACCEPTS would be a defined edge type in the ISG’s ontology, used to model the data-flow/signature aspect into functions, even if the exact term ACCEPTS is not always used in every excerpt. The broader CPG/ISG documentation sections reinforce that such labeled edges enable precise, architecture-aware queries across multi-language codebases. Overall, the strongest support comes from statements about labeled edges representing relations between nodes, and from explicit mentions that edge types encode contractual relationships like containment and data flow, which is conceptually aligned with ACCEPTS as a data-flow edge in the function signature. The remaining related excerpts provide foundational context about the graph-based representation and edge semantics that underpin the existence and utility of such an edge type.",
      "confidence": "high"
    },
    {
      "field": "llm_interaction_and_query_model.defense_strategy_summary",
      "citations": [
        {
          "title": "OWASP SQL Injection Prevention Cheat Sheet",
          "url": "https://www.pynt.io/learning-hub/owasp-top-10-guide/sql-injection-types-examples-prevention-cheat-sheet",
          "excerpts": [
            "`PreparedStatement pstmt = connection.prepareStatement(query);`",
            "`SELECT * FROM items WHERE owner = @owner AND itemname = @itemname;`",
            "Use Web Application Firewalls\n\nWeb application firewalls (WAFs) monitor and block malicious traffic targeting web applications, providing a frontline defense against SQLi."
          ]
        },
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized.",
            "Only a single authorizer can be in place on a database connection\nat a time. Each call to sqlite3\\_set\\_authorizer overrides the\nprevious call. Disable the authorizer by installing a NULL callbac",
            "The authorizer is disabled by default.",
            "The authorizer callback must not do anything that will modify\nthe database connection that invoked the authorizer callback.",
            "the authorizer callback is invoked to\nsee if those actions are allowed."
          ]
        },
        {
          "title": "SQLite User Forum: Best practice implementing row level authorization? # SQLite User Forum",
          "url": "https://sqlite.org/forum/info/2e4b58ca45b0de363d3d652fc7ebcfed951daa8b0e585187df92b37a229d5dc5",
          "excerpts": [
            "See https://sqlite.org/c3ref/set_authorizer.html for the documentation on using the authorizer callback. You can allow/deny read/write/delete access on a table/column basis."
          ]
        },
        {
          "title": "SQL Injection Prevention Cheat Sheet - OWASP Cheat Sheet Series",
          "url": "https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html",
          "excerpts": [
            "**Option 1: Use of Prepared Statements (with Parameterized Queries)**"
          ]
        },
        {
          "title": "Protecting Against SQL Injection - EnterpriseDB Blog",
          "url": "https://www.enterprisedb.com/blog/protecting-against-sql-injection",
          "excerpts": [
            "SQL Injection is one of the most pervasive and damaging vulnerability types database administrators and developers are tasked with defending against."
          ]
        }
      ],
      "reasoning": "The field value outlines a multi-layer defense-in-depth plan for safe and deterministic LLM-generated DSL-to-SQL interactions. Direct support comes from excerpts that specify: (a) use of prepared statements or parameterized queries to prevent SQL injection, which aligns with application-level controls; (b) the sqlite3_set_authorizer mechanism as a sandbox to authorize or deny certain SQL actions, matching the SQLite-specific security control; and (c) the existence and behavior of the authorizer callback (its purpose, invocation, and constraints), which underpin the authorization layer. The excerpts describing prepared statements show concrete code patterns and practices for safe queries. The discussions of sqlite3_set_authorizer and its role in access control (including how the authorizer is configured and how it governs actions) map directly to the SQLite sandbox control in the field value. Additional excerpts that discuss the restriction and management of query capabilities (e.g., the single authorizer restriction, default disabling, and the callback semantics) further reinforce the defense-in-depth architecture. Contextual mentions of WAFs and general SQL injection defenses are relevant for broader security posture but are less central to the exact DSL-to-SQL and SQLite-centric mechanisms described, thus they are considered supplementary. Overall, the core claims in the field value are well-supported by multiple excerpts describing prepared statements, parameterization, and SQLite authorizer controls, with additional corroboration from excerpts detailing authorization callback behavior and constraints.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.9",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The field value identifies a specific relationship type, namely CALLS, described as a control-flow edge where one function invokes another. The excerpts describe how relationships between code constructs are modeled as edges within a code property graph. One excerpt states that relations between program constructs are represented via edges, and gives an example of a CONTAINS edge (method contains local), illustrating that edges encode structural relationships between nodes. This supports the notion that edge-directed relationships (including control-flow or calls-like relations) are a core primitive of the graph representation. Another excerpt explains that nodes have types and that edges are labeled to express multiple kinds of relations in the same query, reinforcing that the graph uses labeled edges to capture different architectural relationships, including calls-like connections. A third excerpt discusses building blocks of code property graphs, noting that nodes have types (e.g., METHOD) and that edges express relationships between nodes, which is the structural basis for representing interactions such as one function invoking another. Taken together, these excerpts establish that the ISG/CPG framework relies on a labeled-edge representation to encode relationships between program constructs, including potential call/call-like relationships, which directly underpins the concept of a CALLS-type edge in the ISG ontology. However, none of the excerpts provide an explicit, standalone definition of CALLS itself, but they clearly describe the mechanism (labeled edges) by which such a relationship would be represented in the graph. Therefore, these excerpts collectively support the existence and meaning of a CALLS-like relationship as a labeled edge in the ISG/CPG system, with the strongest support coming from explicit statements about edges representing relations and the example of CONTAINS as a type of edge, plus the general assertion that edges encode relationships between program constructs.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.5",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly defines the node taxonomy used in the Code Property Graph concept, listing the exact label for Associated/Nested Type as [A] and describing it as dependent types and noting its importance for languages like Rust. This provides the clearest, on-target evidence for the specified finegrained field value. Other excerpts discuss related concepts (edges, general CPG schema, or tooling) but do not explicitly establish the [A] label or its description; they offer contextual support about how nodes, edges, and attributes are modeled in code-property-graph representations. Together, these sources corroborate that in the ISG/CPG ontology, the node type for Associated/Nested Type is indeed a distinct category used to capture dependent types, with emphasis on Rust as a language where such types are critical. The combination of a precise taxonomy entry plus contextual notes about dependent types provides direct, high-confidence support for the field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.11",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a specific architectural relationship (the data flow out of a function) as a labeled edge in an ISG-like graph. Excerpt about the CPG schema notes that the graph includes edges and attributes, which is the structural basis for modeling relationships such as RETURNS. Excerpt describing labeled directed edges explains that relationships between nodes are represented by edges and that multiple relation types can exist (including how one node relates to another). Excerpt mentioning data-flow patterns in code-property-graph literature ties the concept of data-flow semantics to how functions interact and pass data, which aligns with the RETURNS edge’s purpose of modeling data exiting a function. Excerpt defining node types (e.g., METHOD) provides context for what a function node would be in this graph, aiding understanding of where RETURNS would apply. Collectively, these excerpts support the existence and role of a RETURNS-like relationship in the ISG/CPG modeling of code, even if the exact token RETURNS isn’t explicitly defined in the excerpts.",
      "confidence": "medium"
    },
    {
      "field": "llm_interaction_and_query_model.threat_model_summary",
      "citations": [
        {
          "title": "SQL Injection Prevention Cheat Sheet - OWASP Cheat Sheet Series",
          "url": "https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html",
          "excerpts": [
            "**Option 1: Use of Prepared Statements (with Parameterized Queries)**"
          ]
        },
        {
          "title": "OWASP SQL Injection Prevention Cheat Sheet",
          "url": "https://www.pynt.io/learning-hub/owasp-top-10-guide/sql-injection-types-examples-prevention-cheat-sheet",
          "excerpts": [
            "`PreparedStatement pstmt = connection.prepareStatement(query);`",
            "`SELECT * FROM items WHERE owner = @owner AND itemname = @itemname;`",
            "Use Web Application Firewalls\n\nWeb application firewalls (WAFs) monitor and block malicious traffic targeting web applications, providing a frontline defense against SQLi."
          ]
        },
        {
          "title": "Protecting Against SQL Injection - EnterpriseDB Blog",
          "url": "https://www.enterprisedb.com/blog/protecting-against-sql-injection",
          "excerpts": [
            "SQL Injection is one of the most pervasive and damaging vulnerability types database administrators and developers are tasked with defending against."
          ]
        },
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized.",
            "Only a single authorizer can be in place on a database connection\nat a time. Each call to sqlite3\\_set\\_authorizer overrides the\nprevious call. Disable the authorizer by installing a NULL callbac",
            "The authorizer is disabled by default.",
            "The authorizer callback must not do anything that will modify\nthe database connection that invoked the authorizer callback.",
            "the authorizer callback is invoked to\nsee if those actions are allowed."
          ]
        },
        {
          "title": "SQLite User Forum: Best practice implementing row level authorization? # SQLite User Forum",
          "url": "https://sqlite.org/forum/info/2e4b58ca45b0de363d3d652fc7ebcfed951daa8b0e585187df92b37a229d5dc5",
          "excerpts": [
            "See https://sqlite.org/c3ref/set_authorizer.html for the documentation on using the authorizer callback. You can allow/deny read/write/delete access on a table/column basis."
          ]
        }
      ],
      "reasoning": "The most directly relevant content concerns SQL injection and practical defenses, which are central to the threat model. Excerpts that advocate using prepared statements or parameterized queries illustrate a concrete defense against SQL Injection, directly supporting the described threat of SQLi. Excerpts that mention Web Application Firewalls (WAFs) as a frontline defense reinforce mitigation against SQLi and related web threats. Statements that emphasize SQL Injection as a pervasive vulnerability highlight the severity of the threat in the LLM-enabled context. Content describing database authorization callbacks and access controls (e.g., authorizers in SQLite) aligns with mitigating unauthorized data access risks, which complements the DoS and broader OWASP-LLM risk landscape by illustrating defense-in-depth controls. Collectively, the excerpts map to the threats listed (SQLi, DoS, OWASP Top 10 risks for LLM apps) and provide concrete mitigations, examples, and security practices relevant to the threat model summary. The strong alignment with SQL Injection and preventive measures offers high confidence in supporting the field value, with additional supportive material on defense mechanisms and broader security considerations enhancing the overall threat model context.",
      "confidence": "high"
    },
    {
      "field": "chosen_parsing_technology_evaluation.technology_name",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited.",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application"
          ]
        },
        {
          "title": "Tree-sitter and SWC Discussion on Hacker News",
          "url": "https://news.ycombinator.com/item?id=42590788",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental \n  parsing library. It can build a concrete syntax tree for a \n  source file and efficiently update the syntax tree as the \n  source file is edited.",
            "Tree-sitter is a parser generator tool and an incremental \n  parsing library. It can build a concrete syntax tree for a \n  source file and efficiently update the syntax tree as the \n  source file is edited."
          ]
        },
        {
          "title": "tree-sitter-rust",
          "url": "https://github.com/tree-sitter/tree-sitter-rust",
          "excerpts": [
            "But if you _edit_ the file after parsing it, tree-sitter can generally _update_ the previous existing syntax tree to reflect your edit in less than a millisecond,\n  thanks to its incremental parsing syste"
          ]
        },
        {
          "title": "tree-sitter/tree-sitter",
          "url": "https://github.com/tree-sitter/tree-sitter",
          "excerpts": [
            "s)\n\n## Languages\n\n* [Rust 63\\.4%](/tree-sitter/tree-sitter/search?l=rust)\n* [C 25\\.4%](/tree-sitter/tree-sitter/search?l=c)\n* [TypeScript 6\\.5%](/tree-sitter/tree-sitter/search?l=typescript)\n* [JavaScript 1\\.0%](/tree-sitter/tree-sitter/search?l=javascript)\n* [C++ 0\\.8%](/tree-sitter/tree-sitter/search?l=c%2B%2B)\n* [Nix 0\\.7%](/tree-sitter/tree-sitter/search?l=nix)\n* Other 2\\.2%"
          ]
        },
        {
          "title": "Benchmarking TypeScript parsers (Medium article)",
          "url": "https://medium.com/@hchan_nvim/benchmark-typescript-parsers-demystify-rust-tooling-performance-025ebfd391a3",
          "excerpts": [
            "Tree-sitter serves as a versatile parser suitable for a variety of languages, not specifically optimized for TypeScript. Consequently, its performance aligns closely with that of Babel, a JavaScript-focused parser implemented in JavaScript.",
            "Tree-sitter:**  \nTree-sitter serves as a versatile parser suitable for a variety of languages, not specifically optimized for TypeScript. Consequently, its performance aligns closely with that of Babel, a JavaScript-focused parser implemented in JavaScr"
          ]
        },
        {
          "title": "tree-sitter-typescript",
          "url": "https://github.com/tree-sitter/tree-sitter-typescript",
          "excerpts": [
            "For Javascript files with [flow](https://flow.org/en/) type annotations you can use the `tsx` parser.",
            "TypeScript grammar for tree-sitter",
            "Require them as follows:",
            "```\nrequire ( \"tree-sitter-typescript\" ) .\ntypescript ; // TypeScript grammar\nrequire ( \"tree-sitter-typescript\" ) . tsx ; // TSX grammar\n```"
          ]
        }
      ],
      "reasoning": "The fine-grained field value identifies Tree-sitter as the parsing technology. Excerpts that explicitly describe Tree-sitter as a parser and its core properties provide the strongest support for this field value. Direct references in the excerpts confirm Tree-sitter’s role as a parser generator and incremental parsing library, and describe its general applicability to multiple languages and editor integration. Additional excerpts corroborate by discussing Tree-sitter within the context of language grammars, typescript integrations, and related tooling, reinforcing that Tree-sitter is indeed the parsing technology in question. The most relevant parts are those that directly name Tree-sitter and describe its parsing capabilities and multilingual support. Related excerpts that discuss benchmarks or discussions about Tree-sitter in various ecosystems offer supportive context but are secondary to the core identification of Tree-sitter as the parsing technology.",
      "confidence": "high"
    },
    {
      "field": "llm_interaction_and_query_model.recommended_model",
      "citations": [
        {
          "title": "SQL Injection Prevention Cheat Sheet - OWASP Cheat Sheet Series",
          "url": "https://cheatsheetseries.owasp.org/cheatsheets/SQL_Injection_Prevention_Cheat_Sheet.html",
          "excerpts": [
            "**Option 1: Use of Prepared Statements (with Parameterized Queries)**"
          ]
        },
        {
          "title": "OWASP SQL Injection Prevention Cheat Sheet",
          "url": "https://www.pynt.io/learning-hub/owasp-top-10-guide/sql-injection-types-examples-prevention-cheat-sheet",
          "excerpts": [
            "`PreparedStatement pstmt = connection.prepareStatement(query);`",
            "`SELECT * FROM items WHERE owner = @owner AND itemname = @itemname;`",
            "Use Web Application Firewalls\n\nWeb application firewalls (WAFs) monitor and block malicious traffic targeting web applications, providing a frontline defense against SQLi."
          ]
        },
        {
          "title": "Protecting Against SQL Injection - EnterpriseDB Blog",
          "url": "https://www.enterprisedb.com/blog/protecting-against-sql-injection",
          "excerpts": [
            "SQL Injection is one of the most pervasive and damaging vulnerability types database administrators and developers are tasked with defending against."
          ]
        },
        {
          "title": "SQLite Compile-Time Authorization Callbacks and Security Mechanisms",
          "url": "https://www.sqlite.org/c3ref/set_authorizer.html",
          "excerpts": [
            "An authorizer is used when [preparing](../c3ref/prepare.html) SQL statements from an untrusted source, to ensure that the SQL statements\ndo not try to access data they are not allowed to see, or that they do not\ntry to execute malicious statements th",
            "The third through sixth parameters\nto the callback are either NULL pointers or zero-terminated strings\nthat contain additional details about the action to be authorized.",
            "Only a single authorizer can be in place on a database connection\nat a time. Each call to sqlite3\\_set\\_authorizer overrides the\nprevious call. Disable the authorizer by installing a NULL callbac",
            "The authorizer is disabled by default.",
            "The authorizer callback must not do anything that will modify\nthe database connection that invoked the authorizer callback.",
            "the authorizer callback is invoked to\nsee if those actions are allowed."
          ]
        },
        {
          "title": "SQLite User Forum: Best practice implementing row level authorization? # SQLite User Forum",
          "url": "https://sqlite.org/forum/info/2e4b58ca45b0de363d3d652fc7ebcfed951daa8b0e585187df92b37a229d5dc5",
          "excerpts": [
            "See https://sqlite.org/c3ref/set_authorizer.html for the documentation on using the authorizer callback. You can allow/deny read/write/delete access on a table/column basis."
          ]
        }
      ],
      "reasoning": "The field value advocates a strategic shift toward a high-level, domain-specific language (DSL) for architectural queries, which is then compiled into a safe, constrained SQL subset for execution. This aligns with excerpts that emphasize preventing SQL injection and using parameterized queries to avoid embedding raw user input directly into SQL statements. The notion of prepared statements and parameterization directly supports the safety rationale behind restricting LLM-generated queries to a DSL that is subsequently translated into a controlled SQL form. Security-oriented discussions such as the use of a database-level authorizer or constraints around what SQL statements can do further corroborate the broader principle of minimizing risk by avoiding unrestricted, raw SQL generation by the LLM. Collectively, these excerpts reinforce the core idea that SQL interactions must be safeguarded through structured, constrained, and parameterized approaches rather than free-form SQL generation, which is precisely what the fine-grained field value describes in the context of ISG and AIM Daemon tooling.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems.2",
      "citations": [
        {
          "title": "Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022",
          "excerpts": [
            "A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC.",
            "Below is an example for how a tool and a language server communicate during a routine editing session:",
            "The LSP has evolved over time and today it is at Version 3.0. It started when the concept of a language server was picked up by OmniSharp to provide rich editing features for C#."
          ]
        },
        {
          "title": "Language Server Protocol Specification - 3.17",
          "url": "https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/",
          "excerpts": [
            "The base protocol offers support for request cancellation. To cancel a request, a notification message with the following properties is sent:\n\n_Notification_ :\n\n* method: ‘$/cancelRequest’\n* params: `CancelParams` defined as follows:\n\n```\n`interface CancelParams { \n\t /**\n\t * The request id to cancel. */ \n\t id : integer | string ; \n } \n`\n```\n\nA request that got canceled still needs to return from the server and send a response back. It can not be left open / hanging. This is in line with the JSON-RPC protocol that requires that every request sends a response back. In addition it allows for returning partial results on cancel. If the request returns an error response on cancellation it is advised to set the error code to `ErrorCodes",
            "The `workspace/codeLens/refresh` request is sent from the server to the client. Servers can use it to ask clients to refresh the code lenses currently shown in editors. As a result the client should ask the server to recompute the code lenses for these editors. This is useful if a server detects a configuration change which requires a re-calculation of all code lenses. Note that the client still has the freedom to delay the re-calculation of the code lenses if for example an editor is currently not visible.",
            "Responses to requests should be sent in roughly the same order as the requests appear on the server or client side. So for example if a server receives a `textDocument/completion` request and then a `textDocument/signatureHelp` request it will usually first return the response for the `textDocument/completion` and then the response for `textDocument/signatureHelp` . However, the server may decide to use a parallel execution strategy and may wish to return responses in a different order than the requests were received. The server may do so as long as this reordering doesn’t affect the correctness of the responses. For example, reordering the result of `textDocument/completion` and `textDocument/signatureHelp` is allowed, as each of these requests usually won’t affect the output of the other.",
            "So the creator of a `TextDocumentEdit` doesn’t need to sort the array of edits or do any kind of ordering. However the edits must be non overlapping."
          ]
        }
      ],
      "reasoning": "The most relevant content directly states that a language server runs in its own process and communicates with editors via the language protocol over JSON-RPC, which aligns with the finegrained field value’s emphasis on a localized, request-response architecture that contrasts with a global, graph-based approach. This fundamental architectural distinction supports the field’s claim that LSP-based systems are deterministic and operate at a local scale without building a global codebase graph, highlighting the core tradeoff between determinism, locality, and scope. Details that illustrate concrete LSP interactions, such as the canonical examples of how editors open documents, handle edits, and exchange requests (e.g., didOpen, didChange, publishDiagnostics) further ground the mechanism by which LSP achieves responsiveness in an editor-centric, on-demand fashion, reinforcing the comparison to the AIM/ISG paradigm described in the field value. Additional excerpts describing the evolution of LSP, its behavior in terms of request ordering, and general usage in IDEs provide contextual support that LSP is designed for localized code intelligence rather than a global code graph, thus differentiating it from the deterministic graph-based model advocated in the field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.7",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to a specific relationship type that denotes implementation relationships in an architectural graph. Excerpts that discuss the Code Property Graph (CPG) and its handling of nodes and edges directly support this concept: a graph-based representation uses edges to encode relationships between program constructs, including how one type may implement another (a form of edge-based contract). In particular, the excerpt that points to the CPG schema and its emphasis on detailed information about nodes, edges, and attributes establishes that relationships are central to the model, which is exactly where a relationship like IMPL would live in a deterministic graph representation. The excerpt describing labeled edges between program constructs reinforces the notion that different relationship types (such as CONTAINS) are used to express architectural contracts, which conceptually maps to a distinct IMPL edge in a rigorous ISG-like representation. The general Code Property Graph overview confirms that the graph represents program code with a structured, edge-based model, providing broader context for how a specific IMPL relationship would be integrated. Supporting excerpts also discuss the presence of edges and the notion of relationships in the graph, which aligns with the idea of an IMPL-type relationship as a defined edge in the ontology. Less directly supportive excerpts provide additional context about the capabilities and scope of the CPG and its tooling but do not directly name or illustrate the IMPL relationship; however, they still corroborate that edges/relationships are a core mechanism for encoding architectural relationships in code graphs.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.14.name",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        }
      ],
      "reasoning": "The finegrained field value corresponds to a specific edge label in the Interface Signature Graph ontology. The excerpt explains that edges are labeled to express relationships between nodes, and provides a concrete example where a method contains a local variable, represented by an edge labeled CONTAINS from the method node to the local variable node. This directly supports the existence and semantic meaning of the CONTAINS relationship in the ISG ontology, matching the requested field value. The other excerpt focuses on the query language and general code-property-graph capabilities without mentioning the CONTAINS label, so it offers only contextual support and not direct evidence for the field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.1",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results.",
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The target field describes a Node entity, specifically a structural data type node named '[S] Struct/Class' which represents data structures and state machines. Excerpt about Nodes and their types explicitly states that nodes represent program constructs and that the type differentiates kinds of constructs (e.g., a node of type METHOD vs a node of type LOCAL). This directly supports the idea that there are distinct Node types within the graph model, including data-structure-like categories. The Code Property Graph Schema guidance points to a detailed schema for the various kinds of nodes and their attributes, which corroborates the existence and importance of specific node kinds such as those representing data structures. Additional documentation about Code Property Graphs frames them as an extensible, language-agnostic representation of code, which underpins the concept that nodes have defined types and roles within the graph. Collectively, these excerpts establish that the ISG/CPG framework uses named Node types to categorize program constructs, including structural entities akin to data structures/state machines, aligning with the description of '[S] Struct/Class' in the target field value. The excerpts also emphasize that there are explicit references to node kinds and their schemas, reinforcing how a field value describing a specific Node type should be interpreted within this system.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.0",
      "citations": [
        {
          "title": "Kythe Storage Documentation",
          "url": "https://kythe.io/docs/kythe-storage.html",
          "excerpts": [
            "As viewed from the storage layer, a ‘node’ in a Kythe graph is essentially a\nbag of string-valued key/value properties associated with a unique name. In\norder for this representation to make sense, each node must have a unique name,\nto distinguish it from all the other nodes in the graph. To solve this naming problem, Kythe adopts the view that a node is a _d_ \\-dimensional ‘vector’, where each dimension represents some scalar [fact]() about the node: The “dimensions” in this case are not\nnumbers, but arbitrary semantic categories, _e.g._ , kind, identifier, snippet,\nlocation, c",
            "* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language)",
            "A node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection.",
            "The fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13)."
          ]
        },
        {
          "title": "Kythe Documentation: Writing an Indexer",
          "url": "https://kythe.io/docs/schema/writing-an-indexer.html",
          "excerpts": [
            "VNames have five string-valued fields.",
            "Kythe stores file content in its graph. The `http_server` binary used in our `kythe-browse.sh` script doesn’t look in your filesystem for a file to present\nto the Web browser; it instead reads the `text` fact off of a graph node."
          ]
        },
        {
          "title": "Kythe Schema Overview",
          "url": "https://kythe.io/docs/schema-overview.html",
          "excerpts": [
            "This document relies on the following basic terminology:"
          ]
        },
        {
          "title": "Kythe URI Specification",
          "url": "https://kythe.io/docs/kythe-uri-spec.html",
          "excerpts": [
            "This document defines the schema for Kythe uniform resource identifiers (\"Kythe URI\"). The primary purpose of a Kythe URI is to provide a textual encoding of a Kythe",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "Kythe URI Specification"
          ]
        }
      ],
      "reasoning": "The finegrained field value presents Kythe as a language-agnostic system that builds a persistent semantic graph, using VName as a unique and extensible identifier, designed for offline analysis and deterministic outputs, which contrasts with a real-time AIM/ISG daemon approach. Excerpts describing Kythe’s storage model emphasize that a node is identified by a unique, extensible VName and that the graph stores facts and edges for cross-repository semantic analysis, which directly supports the claim of Kythe as a deterministic, offline-analysis oriented system. The material explaining that a VName is composed of fields like Corpus, Language, Path, Root, and Signature, and that VNames can be extended to keep nodes unique, is central to the value proposition of deterministic canonicalization, aligning with the claim that Kythe provides stable, cross-repository representations suitable for offline deep analysis. Descriptions of the Signature field as an opaque, analyzable component further reinforce the determinism and traceability of Kythe nodes. The Kythe schema-related excerpts explain how the graph is built from a stream of entries (facts and edges) emitted by language-specific indexers and processed into a store, which supports the idea of a persistent semantic graph optimized for offline analysis and portability. Details about how VNames are used for stable naming, and how a URL-like or structured URI can encode a node, reinforce the notion of a durable, well-defined naming scheme essential to deterministic analysis. Together, these excerpts substantiate the field value’s comparison that Kythe emphasizes deterministic, offline-oriented graph construction with a stable VName-based identity, contrasting with the AIM/ISG real-time, in-memory navigation approach.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.1",
      "citations": [
        {
          "title": "Sourcegraph blog: Announcing auto-indexing",
          "url": "https://sourcegraph.com/blog/announcing-auto-indexing",
          "excerpts": [
            "Precise code navigation is driven by code graph data . This data is generated by indexing your code (using either LSIF or SCIP format indexers).",
            "Code navigation comes in two common forms: search-based and precise.",
            "Auto-indexing makes it easy to set up repository indexing in minutes and get precise code navigation for your repositories, with no changes to your CI workflow.",
            "Precise code navigation—the most powerful version of code navigation—is very similar to IDE-based navigation, but it also works cross-repository."
          ]
        },
        {
          "title": "Sourcegraph Documentation",
          "url": "https://6.5.sourcegraph.com/",
          "excerpts": [
            "Sourcegraph is a Code Intelligence platform that deeply understands your code, no matter how large or where it’s hosted, to power modern developer experiences. * **Code Search:** Search through all of your repositories across all branches and all code hosts"
          ]
        }
      ],
      "reasoning": "The field value asserts that Sourcegraph employs a deterministic, graph-based SCIP component for code intelligence, complemented by a probabilistic LLM assistant (Cody) that leverages structured, deterministic context. Excerpts that directly describe SCIP as a format/indexer for code graph data and its role in enabling precise code navigation provide the strongest support, including statements that code navigation is driven by a code graph and that indexing uses SCIP indexers. Additionally, excerpts describing Sourcegraph as a code intelligence platform and its capabilities for cross-repository navigation corroborate the broader architectural context. One excerpt explicitly notes that code navigation is powered by a code graph data source and that indexing can use SCIP format indexers, which aligns with the deterministic graph concept. Another excerpt mentions that auto-indexing enables precise code navigation, reinforcing the architecture’s emphasis on structured, index-driven context for LLM-assisted code work. An excerpt that describes Sourcegraph as a platform for code search and navigation helps situate the overall system, including the role of SCIP in cross-repository scenarios, even if it doesn’t name Cody directly. While the excerpts collectively support the general idea of Sourcegraph’s architecture with SCIP and its deterministic graph foundation, they do not cover every detail in the field value (e.g., the OpenCodeGraph protocol or the exact coupling mechanism with Cody). Therefore, the connection is strong but not exhaustive, yielding a medium confidence.\n",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.14.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The finegrained field value denotes a type of linkage between nodes in an architectural/graph representation. Excerpt content describes relationships as labeled, directed edges between nodes (for example, an edge labeled CONTAINS from a method to a local variable). This directly supports the notion of a Relationship as a semantically meaningful connection in the graph. The same excerpt also notes that multiple types of relations can exist between nodes, which further corroborates that relationships are a fundamental concept in the representation. Excerpt two discusses how the query language traverses different views of code representations, which is related context but does not explicitly define the term Relationship or enumerate specific edge types; its contribution is contextual rather than direct evidence for the field value. Taken together, the first excerpt provides direct, concrete support for the existence and nature of relationships as edges in the graph, while the second adds peripheral context about how relationships are navigated within the system.",
      "confidence": "high"
    },
    {
      "field": "chosen_parsing_technology_evaluation.suitability_assessment",
      "citations": [
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application",
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited.",
            "*General** enough to parse any programming languag"
          ]
        },
        {
          "title": "tree-sitter-rust",
          "url": "https://github.com/tree-sitter/tree-sitter-rust",
          "excerpts": [
            "But if you _edit_ the file after parsing it, tree-sitter can generally _update_ the previous existing syntax tree to reflect your edit in less than a millisecond,\n  thanks to its incremental parsing syste",
            "Speed** — When initially parsing a file, `tree-sitter-rust` takes around two to three times\n  as long as rustc's hand-written par"
          ]
        },
        {
          "title": "Tree-sitter and SWC Discussion on Hacker News",
          "url": "https://news.ycombinator.com/item?id=42590788",
          "excerpts": [
            "Not demonstrated here, but inserting a multi-line comment in a file that is parsed incorrectly will throw the entire thing off.",
            "Tree-sitter is a parser generator tool and an incremental \n  parsing library. It can build a concrete syntax tree for a \n  source file and efficiently update the syntax tree as the \n  source file is edited.",
            "Tree-sitter is a parser generator tool and an incremental \n  parsing library. It can build a concrete syntax tree for a \n  source file and efficiently update the syntax tree as the \n  source file is edited."
          ]
        },
        {
          "title": "Benchmarking TypeScript parsers (Medium article)",
          "url": "https://medium.com/@hchan_nvim/benchmark-typescript-parsers-demystify-rust-tooling-performance-025ebfd391a3",
          "excerpts": [
            "Tree-sitter serves as a versatile parser suitable for a variety of languages, not specifically optimized for TypeScript. Consequently, its performance aligns closely with that of Babel, a JavaScript-focused parser implemented in JavaScript."
          ]
        }
      ],
      "reasoning": "The field value asserts that Tree-sitter is a strong and viable candidate for the Level-2 incremental parsing engine needed by the AIM Daemon, aligning with real-time architectural intelligence, and it cautions about potential loss of local fidelity due to error recovery when syntax errors occur. Excerpts describing Tree-sitter as a general, fast, and robust parser capable of incremental updates directly support the claim that it is well-suited for real-time, incremental parsing needs. Specific statements that Tree-sitter can build and efficiently update concrete syntax trees as the source file is edited reinforce its suitability for continuous, real-time analysis. The emphasis on incremental parsing and updating existing syntax trees in near-instantaneous time aligns with the Level-2 parsing requirements for deterministic, architecture-aware tooling. Moreover, the excerpts explicitly note that Tree-sitter is fast enough to parse on keystroke updates and can provide useful results even with syntax errors, which supports the practical viability of using Tree-sitter in an interactive, LLM-assisted workflow. However, there are cautions about failure modes when syntax errors are present, such as inappropriate parsing behavior under certain erroneous conditions, which corresponds to the risk of loss of local structural fidelity described in the field value. Taken together, the combination of strong incremental parsing capabilities, broad language support, and acknowledged error-recovery caveats provides a coherent set of evidence that Tree-sitter is a strong candidate with manageable risks for the described architecture, albeit with careful handling of error scenarios.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.8.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The finegrained field value denotes a semantic concept of a 'Relationship' within an ISG-like ontology. The most directly supporting excerpt explains that code property graphs express relationships between program constructs via labeled edges, with edges representing architectural connections (e.g., a method containing a local variable) and using directed edges to encode the directional nature of these relations. This aligns with the idea that relationships are first-class graph edges that encode how nodes relate to one another. A secondary, supportive excerpt discusses the building blocks of graphs where nodes have types and the graph is a structure for representing program constructs; while it emphasizes nodes and types rather than edges in detail, it reinforces that the graph form encodes structural relationships among components, which is consistent with treating relationships as a fundamental aspect of the graph representation. Taken together, these excerpts substantiate that the field value corresponds to the concept of relationships/edges in a code-property-graph-like structure, where relationships are implemented as labeled, directed edges between typed nodes. ",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.2.component_type",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to the concept of a structural element in a Code Property Graph, specifically identified as a 'Node' in the 3x3 ontology of the graph. The most directly supportive content states that a Code Property Graph contains Nodes that represent program constructs and that each node has a type, with the type indicating what kind of construct it is. This aligns exactly with the requested field being a kind of Node within the ISG/CPG paradigm, where Nodes are foundational elements in the graph and their type conveys their role (e.g., methods, variables, endpoints). Additional excerpts reinforce this by describing that nodes have types and that the graph encodes architectural or program-construct primitives, which confirms the semantic role of a Node as a fundamental graph element with a discerning type attribute. A further excerpt notes the CPG specification and its role in representing program code, which supports the interpretation of Node as a core graph element within a standardized representation. Collectively, these excerpts connect the field value to the central notion of a Node in the graph-based representation of code, where the Node is characterized by its type.",
      "confidence": "high"
    },
    {
      "field": "implementation_roadmap_summary.key_deliverables",
      "citations": [
        {
          "title": "SQLite Optimizations for Ultra High-Performance",
          "url": "https://www.powersync.com/blog/sqlite-optimizations-for-ultra-high-performance",
          "excerpts": [
            "**\\#** 1: Enable Write-Ahead Logging (WAL) And Disable Synchronous Mod",
            "\n### **\\#** 1: Enable Write-Ahead Logging (WAL) And Disable Synchronous Mode",
            "###### _Effect: Can reduce per-transaction overhead from 30ms+ to < 1ms. _",
            "```\n`pragma journal_mode = WAL;\n pragma synchronous = normal;\n pragma journal_size_limit = 6144000 ;`",
            "The only durability caveat is that on a system crash (not application crash), the last transaction(s) may be rolled back. This is fine for most applications — if durability is that important, you should probably rely on more than just a phone's flash storage.",
            "\n### **\\#** 2: Reduce Binding Overhead",
            "###### _Effect: Using different bindings can reduce per-transaction and per-statement overhead by 2-10x._"
          ]
        },
        {
          "title": "Tree-sitter Grammar DSL",
          "url": "https://tree-sitter.github.io/tree-sitter/creating-parsers/2-the-grammar-dsl.html",
          "excerpts": [
            "The following is a complete list of built-in functions you can use in your `grammar.js` to define rules.",
            "* **Sequences : `seq(rule1, rule2, ...)`** — This function creates a rule that matches any number of other rules, one after\n  anothe",
            "* **Alternatives : `choice(rule1, rule2, ...)`** — This function creates a rule that matches _one_ of a set of possible\n  rules. The order of the arguments does not matte"
          ]
        },
        {
          "title": "Tree-sitter Documentation",
          "url": "https://tree-sitter.github.io/",
          "excerpts": [
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:",
            "Tree-sitter aims to be:\n\n* **General** enough to parse any programming language\n* **Fast** enough to parse on every keystroke in a text editor\n* **Robust** enough to provide useful results even in the presence of syntax errors\n* **Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any application",
            "Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source\nfile and efficiently update the syntax tree as the source file is edited.",
            "*General** enough to parse any programming languag",
            "*Dependency-free** so that the runtime library (which is written in pure [C11](https://github.com/tree-sitter/tree-sitter/tree/master/lib) ) can be embedded in any applicatio"
          ]
        },
        {
          "title": "Making Sense of Tree-sitter's C API",
          "url": "https://dev.to/shrsv/making-sense-of-tree-sitters-c-api-2318",
          "excerpts": [
            "|Function |Description |"
          ]
        },
        {
          "title": "Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/",
          "excerpts": [
            "An SLI is a service level _indicator_ —a carefully defined quantitative measure of some aspect of the level of service that is provided.",
            "Most services consider _request latency_ —how long it takes to return a response to a request—as a key SLI.",
            "An SLO is a _service level objective_ : a target value or range of values for a service level that is measured by an SLI.",
            "For example, we might decide that we will return Shakespeare search results \"quickly,\" adopting an SLO that our average search request latency should be less than 100 milliseconds.",
            "Many other Google services, such as Google for Work, do have explicit SLAs with their users. Whether or not a particular service has an SLA, it’s valuable to define SLIs and SLOs and use them to manage the service.",
            "You shouldn’t use every metric you can track in your monitoring system as an SLI; an understanding of what your users want from the system will inform the judicious selection of a few indicators.",
            "Most metrics are better thought of as _distributions_ rather than averages. For example, for a latency SLI, some requests will be serviced quickly, while others will invariably take longer—sometimes much longer. A simple average can obscure these tail latencies, as well as changes in them.",
            "Using percentiles for indicators allows you to consider the shape of the distribution and its differing attributes: a high-order percentile, such as the 99th or 99.9th, shows you a plausible worst-case value, while using the 50th percentile (also known as the median) emphasizes the typical case.",
            "For maximum clarity, SLOs should specify how they’re measured and the conditions under which they’re valid.",
            "It’s both unrealistic and undesirable to insist that SLOs will be met 100% of the time: doing so can reduce the rate of innovation and deployment, require expensive, overly conservative solutions, or both. Instead, it is better to allow an error budget—a rate at which the SLOs can be missed—and track that on a daily or weekly basis.",
            "Keep a safety margin",
            "Using a tighter internal SLO than the SLO advertised to users gives you room to respond to chronic problems before they become visible externally. An SLO buffer also makes it possible to accommodate reimplementations that trade performance for other attributes, such as cost or ease of maintenance, without having to disappoint users."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts describe concrete deliverables that match the field value. The references to enabling a production-ready SQLite backend with write-ahead logging and specific performance pragmas directly map to the required backend configuration and performance characteristics. The Tree-sitter grammar-related excerpts outline building a grammar (including grammar DSL usage and field naming) that aligns with delivering a production-quality, optimized parser for the pilot language. Additional excerpts about the ISG-related querying capabilities and the need for dashboards and SLIs mirror the API, monitoring, and performance visibility requirements stated in the field value. Finally, the SRE/SLI literature detailing latency percentiles (P95/P99) provides the rationale and design target for the dashboards mentioned in the deliverables, tying into the overall architectural monitoring goals. In summary, the most relevant information directly supports: (a) grammar/tooling for the pilot language, (b) SQLite-backed AIM/ISG backend with WAL and performance settings, (c) a basic API surface for the ISG, (d) integration with a pilot team workflow, and (e) latency-focused dashboards for SLIs (P95/P99).",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.4.name",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The target field value denotes a specific node kind: Module/Namespace/Package. Excerpts that discuss the basic idea of nodes and their types within code property graphs are most relevant because they establish where a Module/Namespace/Package would live in the graph ontology. In the second excerpt, it is stated that a property graph’s building blocks include nodes and their types, and that higher level constructs like HTTP endpoints are represented as nodes. This alignment indicates that module/namespace/package would likewise be modeled as a node type within the graph, making the excerpt directly supportive of the concept of a distinct node category for modules. In the fifth excerpt, the Code Property Graph schema is described as detailing various kinds of nodes, edges, and attributes, which is precisely where a Module/Namespace/Package node would be defined within the overall ontology. This provides evidence about the existence and categorization of such node kinds within the CPG, supporting the interpretation that Module/Namespace/Package corresponds to a node-type in the graph schema. The other excerpts focus on relations and general CPG tooling rather than the explicit ontological categorization of module-like nodes, making them less directly supportive of the specific finegrained field value.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.4.description",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        }
      ],
      "reasoning": "The finegrained field value refers to organizational scope and visibility boundaries, which in the ISG ontology are represented by the node type for Module/Namespace/Package. The excerpt explicitly lists this node type as [M] Module/Namespace/Package and describes it as representing organizational scope and visibility boundaries, directly aligning with the requested field value. Other excerpts discuss related ISG concepts (e.g., node types in general, edges, or CPG tooling) but do not specifically tie to organizational scope and visibility boundaries, making them less relevant to this exact field.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.3.description",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        }
      ],
      "reasoning": "The description of behavioral units in the code property graph is evidenced by defining node types where a METHOD represents a method, which aligns with the notion of a behavioral unit in code. Specifically, one excerpt states that nodes have types and that a node with the type METHOD represents a method, illustrating that behavioral units are represented as method nodes in the graph. Additional support comes from a related excerpt describing edges that express architectural and structural relationships, including an example where a method contains a local variable. This demonstrates how methods (behavioral units) are situated within the graph as entities and connected through edges to model their behavior and interactions. Together, these excerpts directly support the interpretation that behavioral units correspond to method/function nodes within the Code Property Graph and that their relationships are captured via edges like CONTAINS. ",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.3.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The target field value refers to the notion of a 'Node' as a fundamental element in the ISG ontology. An excerpt that states that nodes are program constructs with types, and that a node can be of a specific type such as METHOD or LOCAL, provides the clearest direct support for what a 'Node' means within this framework. Additional excerpts describe that the Code Property Graph represents program constructs with nodes and edges, and that edges relate those nodes in defined ways. This context reinforces that 'Node' is the foundational entity in the graph- and ontology-driven ISG representation, and that nodes have specific types that categorize the underlying program constructs. Therefore, the most relevant content is the explicit description of nodes and their types; the surrounding ISG/CPG descriptions corroborate this by showing how nodes fit into the larger graph structure and how they relate through edges and schema definitions.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.0.description",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The field value asserts that contract definitions are represented as a type of node in the codebase's architectural model. Excerpt 0 discusses Code Property Graph building blocks and explicitly notes that nodes have types, representing program constructs such as methods, variables, and control structures. This aligns with the idea that structural elements (which can be viewed as contract-related units like methods or interfaces) are modeled as distinct node types within a graph. The excerpt also emphasizes that nodes can represent higher-level constructs, which could encompass contract-like definitions in an ISG-like schema. However, the excerpt does not directly state 'contract definitions' as a defined category, so the support is indirect and interpretive rather than explicit. Other excerpts describe labeled edges and cross-language querying within the Code Property Graph framework, which provides context for how such node-level contracts could be connected, but they do not directly confirm the presence or representation of contract definitions. Therefore, the strongest direct, but still indirect, support comes from the discussion of node types and program constructs, which could include contract-like elements.",
      "confidence": "low"
    },
    {
      "field": "isg_ontology_components.3.name",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The finegrained field corresponds to the ontology component that defines a functional unit in code graphs. The most directly relevant excerpt states that nodes have types and that a node with type METHOD represents a method, which aligns with the concept of a Function/Method as a core node type in the ISG ontology. This provides a clear semantic match to the requested field value. A closely related excerpt discusses labeled edges and how different relationships connect nodes like a method to its local variables, reinforcing that METHOD stands as a distinct node type within the graph and participates in architectural relationships. Additional excerpts describe Code Property Graph specifications and tooling, including the idea that the CPG is a language-agnostic representation with various node types and a schema; this contextualizes where Function/Method would sit in the ontology. Collectively, these excerpts support that [F] Function/Method is an ontology component representing behavioral units (methods/functions) within the ISG, and that this concept is a recognized node type in the CPG domain.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.0.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The target field value identifies the concept of a node in the ISG/CPG ontology. The most relevant content explicitly states that nodes represent program constructs and that node types exist to categorize these constructs, which directly aligns with the concept of a Node as a fundamental component in the ontology. Supporting material that defines the CPG schema and tooling further corroborates that the ontology treats nodes as primary entities within the graph, providing the structural basis for representing code constructs. Excerpts that describe the relationships and query capabilities of the CPG provide additional, indirect support by illustrating how nodes participate in the broader graph structure (edges like CONTAINS, CALLS, etc.) and how the schema is organized, which reinforces the centrality of Node-type entities in the ontology. Excerpt positioning reflects this direct-to-context gradient: the most direct support is given by statements about nodes representing program constructs and their types, while subsequent excerpts offer broader schema/tooling context that is still relevant to understanding the node concept within the ISG/CPG framework.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.2.name",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The target finegrained value identifies a specific kind of node in an architectural/graph representation: Enum/Union. Excerpts consistently describe Code Property Graphs and their handling of node types as fundamental building blocks of the graph. They explain that nodes have types and that there are structured kinds of nodes within the graph (e.g., methods, variables, endpoints, and higher-level constructs). This directly supports the notion that Enum/Union is a defined node type within the same ontology or schema, since the texts establish that nodes are categorized by type and that there is a schema or specification governing these node kinds. The presence of explicit references to a schema for node kinds and to the notion that nodes are typed reinforces that Enum/Union is a legitimate node category within such systems.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.0.name",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The target field value identifies a specific node type in the ISG ontology: a Trait/Interface, labeled as [T]. The excerpt that explicitly states, 'Nodes (Entities): [T] Trait/Interface: Contract definitions' directly confirms this exact node-type label and its semantic role within the ontology. Excerpts describing the Code Property Graph (CPG) broader structure provide context for how nodes are typed and related, including mentions that nodes represent program constructs and that method nodes exist, which reinforces the interpretation that there is a defined taxonomy of node kinds such as Trait/Interface. Additional excerpts discuss labeled edges, inter-node relationships, and the extensibility/portability of the graph representation, all of which support the notion that ISG uses a structured ontology of node types (including Trait/Interface) to model software Architecture deterministically. Collectively, these excerpts corroborate the existence and purpose of a node-type taxonomy within the ISG, with the explicit [T] Trait/Interface entry being the strongest direct alignment to the finegrained field value.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.2.description",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The target field asserts that data structures and state machines are represented as specific node types within the ISG ontology (e.g., [S] for Struct/Class and [E] for Enum/Union as data structures and state machines). Excerpts that describe Code Property Graphs (CPGs) as graph-based representations where nodes correspond to program constructs and that emphasize the structure and typing of those nodes are most aligned with this idea. One excerpt states that a property graph is composed of nodes with types that denote the kind of program construct (such as methods or local declarations), illustrating that structural entities in code are captured as typed nodes, which supports the notion of representing data structures and state machines as distinct node types in a graph model. Another excerpt highlights that the CPG is an extensible, language-agnostic representation of program code designed for analysis, reinforcing the concept that code entities like data structures and state machines can be modeled as graph nodes for deterministic querying and understanding. A third excerpt explicitly references the CPG schema and the general idea of nodes, edges, and attributes in the CPG, which underpins how structured code elements are treated analogously to data structures and state machines in a graph. A fourth excerpt discusses the CPG specification and its openness for exchanging code representations, further supporting that such graph-based representations encapsulate program constructs in a structured, queryable form. Taken together, these excerpts collectively support the idea that code entities, including data structures and state machines, are represented as typed nodes within a graph-like representation used for code analysis, which is conceptually aligned with the ISG ontology’s treatment of structural and behavioral entities as graph nodes.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.10.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The target value denotes a specific type of architectural relationship within a graph of code entities. Excerpts that state that relations between program constructs are represented by edges, and that those edges are labeled and directed to express specific contracts (such as containment or data flow) directly support the notion of relationships as first-class graph edges in a Code Property Graph. Additional excerpts that describe the CPG as a graph of nodes with types and that describe the presence of edges to convey relationships (like CONTAINS or CALLS) further reinforce the same concept: that relationships are encoded as explicit edges in the graph, and that these edges carry semantic meaning about how entities relate to one another. By focusing on passages that discuss labeled, directed edges expressing architectural relations, we align with the idea that the field value is describing the relationship type within the ISG/CPG framework, rather than merely listing node types or generic graph properties. The combination of explicit statements about edges representing relationships and examples of edge labels and directions provides direct, targeted support for the field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.4.component_type",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The fine-grained field value refers to a core ontology element named 'Node' within the ISG/CPG context. Excerpts that explicitly mention nodes as fundamental program constructs or as a recognized kind of graph element directly support this value. One excerpt states that the Code Property Graph Schema includes “the various kinds of nodes, edges, and attributes,” which confirms that nodes are a fundamental component in the model. Another excerpt explicitly says that “Nodes represent program constructs” and elaborates that this includes both low-level constructs (methods, variables, control structures) and higher-level ones (HTTP endpoints), directly aligning with the concept of a Node as a core component type. An additional excerpt discusses labeled edges between nodes, reinforcing that the graph is built around node entities and their relationships. Collectively, these excerpts corroborate that 'Node' is a central ontological element in the ISG/CPG framework and that the graph uses nodes as primary constructs with associated edges and types. The remaining excerpts provide supporting context about the graph structure and its components, further reinforcing the centrality of nodes in the architectural graphs.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.9.description",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        }
      ],
      "reasoning": "The target field describes a control-flow relationship where one function invokes another. The most directly relevant excerpt discusses interprocedural analysis and static analysis across languages, which explicitly concerns analyzing how functions call and interact across boundaries, i.e., control-flow between functions. The excerpt explains that the query language can transition between code representations and references interprocedural analysis, which aligns with the notion of function-to-function invocation as a control-flow edge. Additionally, the excerpt that outlines code property graphs emphasizes labeled, directed edges representing relationships between program constructs, including how edges model relationships between nodes. Although the specific example focuses on a containment relationship, the core idea that edges encode directed relationships between code constructs supports the concept of a control-flow edge where one function invokes another. Together, these excerpts substantiate the idea of a control-flow relation (CALLS-like) between functions within a graph-based code representation.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.5.name",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The finegrained field value corresponds to the ISG ontology component for an Associated/Nested Type, which is described in the material as one of the node types within the ISG ontology. Specifically, the description states that the ontology includes a node type labeled as [A] Associated/Nested Type, described as Dependent types and noted as critical for languages like Rust. This direct mapping shows that the named ontology element in the field value is indeed present and defined as a node type within the ISG structure. Therefore, the excerpt that outlines the ISG ontology and lists [A] Associated/Nested Type as a node type directly supports the field value, providing a precise, explicit match to the queried fine-grained field content.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.10.name",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The target value represents a specific edge type in the ISG ontology (an edge that denotes a relationship between nodes). Excerpts that discuss labeled directed edges and labeled relationships between program constructs directly support the notion that the ISG uses explicit edge labels to encode architectural relations. This aligns with the finegrained field value as a distinct edge type within the graph (ACCEPTS). Other excerpts describe the Code Property Graph as a graph with nodes, edges, and labeled connections, which provides contextual support for the idea of edge-label semantics in the ISG. While none of the excerpts state ACCEPTS explicitly, they collectively reinforce that edges carry semantic meaning (e.g., CONTAINS, other labeled relations), which is the mechanism by which an ACCEPTS-type edge would operate in the ISG.\n",
      "confidence": "low"
    },
    {
      "field": "isg_ontology_components.14.description",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a structural composition pattern where a container entity (such as a Module) contains another entity (such as a Class). The most relevant excerpt explicitly describes using labeled edges to represent relationships between program constructs, and it provides a concrete example where a containment-like relation is modeled by an edge labeled CONTAINS from a method node to a local node. This confirms that containment is expressed as a directed, labeled edge in the graph representation, which directly aligns with the notion of one structural unit containing another. The second excerpt reinforces the same modeling paradigm by explaining that the query language can traverse and combine views of the code representations within a Code Property Graph, which implicitly supports the idea that structural containment can be modeled and queried within that graph framework. Taken together, these excerpts support the concept of structural composition via graph edges, even if they do not explicitly state Module containing Class, they establish the mechanism (CONTAINS edge) and the modeling approach (graph-based containment) that underpins the requested fine-grained field value.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems.2.system_name",
      "citations": [
        {
          "title": "Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022",
          "excerpts": [
            "A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC.",
            "The LSP has evolved over time and today it is at Version 3.0. It started when the concept of a language server was picked up by OmniSharp to provide rich editing features for C#.",
            "Below is an example for how a tool and a language server communicate during a routine editing session:"
          ]
        },
        {
          "title": "Language Server Protocol Specification - 3.17",
          "url": "https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/",
          "excerpts": [
            "The base protocol offers support for request cancellation. To cancel a request, a notification message with the following properties is sent:\n\n_Notification_ :\n\n* method: ‘$/cancelRequest’\n* params: `CancelParams` defined as follows:\n\n```\n`interface CancelParams { \n\t /**\n\t * The request id to cancel. */ \n\t id : integer | string ; \n } \n`\n```\n\nA request that got canceled still needs to return from the server and send a response back. It can not be left open / hanging. This is in line with the JSON-RPC protocol that requires that every request sends a response back. In addition it allows for returning partial results on cancel. If the request returns an error response on cancellation it is advised to set the error code to `ErrorCodes",
            "The `workspace/codeLens/refresh` request is sent from the server to the client. Servers can use it to ask clients to refresh the code lenses currently shown in editors. As a result the client should ask the server to recompute the code lenses for these editors. This is useful if a server detects a configuration change which requires a re-calculation of all code lenses. Note that the client still has the freedom to delay the re-calculation of the code lenses if for example an editor is currently not visible.",
            "Responses to requests should be sent in roughly the same order as the requests appear on the server or client side. So for example if a server receives a `textDocument/completion` request and then a `textDocument/signatureHelp` request it will usually first return the response for the `textDocument/completion` and then the response for `textDocument/signatureHelp` . However, the server may decide to use a parallel execution strategy and may wish to return responses in a different order than the requests were received. The server may do so as long as this reordering doesn’t affect the correctness of the responses. For example, reordering the result of `textDocument/completion` and `textDocument/signatureHelp` is allowed, as each of these requests usually won’t affect the output of the other.",
            "So the creator of a `TextDocumentEdit` doesn’t need to sort the array of edits or do any kind of ordering. However the edits must be non overlapping."
          ]
        }
      ],
      "reasoning": "The field value identifies a system type as 'LSP-based systems'. Excerpts that explicitly reference the Language Server Protocol (LSP) and its role in editor tooling, communication patterns, and specification details directly support this classification. The most directly relevant excerpts are those that introduce LSP as a protocol enabling editors and language servers to communicate and that situate LSP as a foundational protocol for editor tooling. Supporting details include statements like 'A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC' and mentions that 'The LSP has evolved over time' to current versions. Additional excerpts provide concrete specification aspects (cancellation, codeLens refresh, ordering of responses) that further corroborate the technical nature and behavior of LSP-based systems. Collectively, these excerpts establish the defining characteristics, communication patterns, and specifications of LSP-based tooling, aligning with the field value. The direct references to Language Server Protocol, its communication model, and evolving specifications serve as the core evidence for the classification of the system as LSP-based.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.2.architectural_differences",
      "citations": [
        {
          "title": "Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022",
          "excerpts": [
            "A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC.",
            "The LSP has evolved over time and today it is at Version 3.0. It started when the concept of a language server was picked up by OmniSharp to provide rich editing features for C#."
          ]
        },
        {
          "title": "Language Server Protocol Specification - 3.17",
          "url": "https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/",
          "excerpts": [
            "The base protocol offers support for request cancellation. To cancel a request, a notification message with the following properties is sent:\n\n_Notification_ :\n\n* method: ‘$/cancelRequest’\n* params: `CancelParams` defined as follows:\n\n```\n`interface CancelParams { \n\t /**\n\t * The request id to cancel. */ \n\t id : integer | string ; \n } \n`\n```\n\nA request that got canceled still needs to return from the server and send a response back. It can not be left open / hanging. This is in line with the JSON-RPC protocol that requires that every request sends a response back. In addition it allows for returning partial results on cancel. If the request returns an error response on cancellation it is advised to set the error code to `ErrorCodes"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a comparison where the Language Server Protocol (LSP) is defined as a client-server protocol using JSON-RPC, enabling real-time, on-demand queries localized to the editor, and contrasts this with AIM/ISG which builds and queries a global codebase graph. Excerpt content directly supports the JSON-RPC client-server communication aspect by stating that a language server communicates with the editor via the language protocol over JSON-RPC. Another excerpt confirms the historical evolution of LSP and notes its version, which reinforces that LSP is a mature, protocol-driven standard used for real-time interactions. A third excerpt illustrates a specific JSON-RPC operation within LSP (cancellation of a request), further grounding the JSON-RPC mechanism in the LSP workflow. Collectively, these excerpts substantiate the key elements of the field value: (1) JSON-RPC-based client-server protocol, (2) real-time, request-response interactions, and (3) the localized, on-demand nature of LSP queries versus the notion of a broader, graph-based, architectural knowledge base. Therefore, the most relevant excerpts are the ones that explicitly describe the JSON-RPC communication channel and its operational nature, followed by those that touch on the evolving protocol and specific JSON-RPC behaviors. ",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.12.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The fine-grained field indicates the kind of component that represents a relationship within the ISG ontology. The most directly supporting excerpt explains that the graph models relations between program constructs via labeled, directed edges, and provides concrete examples of relationship edges such as CONTAINS between a method and a local, illustrating how relationships are encoded as edges. This directly supports the notion that the component_type in the ontology can be 'Relationship' to characterize these edge-based connections. The other excerpt reinforces this by describing nodes having types and that edges express connections (relations) between constructs, suggesting that relationships are a core aspect of the ISG/CPG representation, including how architectural relations can be modeled and queried. Taken together, these excerpts substantiate that the field value 'Relationship' corresponds to the edge-based connections that link nodes in the deterministic graph representation of code architectural relationships.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.1.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The finegrained field value is the type of an ISG/CPG component representing a program construct, i.e., a Node. The most directly supportive information is that nodes have types and that certain node types denote concrete program constructs, such as METHOD and LOCAL. This directly aligns with the idea that there is a component_type describing a Node in the ontology. Additional excerpts reinforce this by describing the Code Property Graph as a representation that includes nodes, edges, and attributes, and by pointing to a detailed CPG schema that enumerates node kinds, which corroborates that a 'Node' is a fundamental element within the graph model and its schema. These passages together establish that 'Node' is a foundational node-type within the ISG/CPG ontology, and that nodes are explicitly categorized by their kinds in the model. Therefore, the most relevant excerpts are the ones that explicitly discuss nodes and their types, followed by those that describe the broader graph schema and node enumeration. ",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.10.description",
      "citations": [
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The most relevant excerpts describe core mechanisms by which code relationships are modeled in a Code Property Graph. One excerpt explains that relationships between program constructs are represented via labeled, directed edges, and that these edges convey multiple relation types while preserving directionality. This directly supports the idea that a function’s data flow into it (as part of its signature) could be captured as a defined relationship or edge type within the graph, i.e., the flow information is an architectural contract encoded as graph edges. Another excerpt elaborates on the building blocks of Code Property Graphs, including that nodes have explicit types (e.g., METHOD, LOCAL) and that the graph uses labeled edges to express various relations such as containment, which is consistent with encoding how a function’s inputs/outputs participate in data flow. A third supporting excerpt discusses the CPG schema and its role as a structured representation for code constructs and their relationships, which underpins how data-flow semantics could be integrated into the signature-level view of a function. Taken together, these excerpts support the notion that data-flow semantics into a function can be represented as part of a function’s signature via structured graph relationships and a well-defined schema.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.13.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        },
        {
          "title": "CEL",
          "url": "https://cel.dev/",
          "excerpts": [
            "Common Expression Language (CEL) is an expression language that’s fast, portable, and safe to execute in performance-critical applications. CEL is designed to be embedded in an application, with application-specific extensions, and is ideal for extending declarative configurations that your applications might already use. Use CEL for things like list filters for API calls, validation constraints on protocol buffers, and authorization rules for API requests. [Learn more](https://cel.dev/overview/cel-overview) [Get started](https://cel.dev/tutorials/cel-get-started-tutorial)"
          ]
        }
      ],
      "reasoning": "The target field represents the type of a relationship in an architectural graph (ISG). Excerpt describing labeled directed edges explicitly states that relations between program constructs are represented via edges, illustrating that relationships are captured as edge labels (e.g., CONTAINS) in the graph. This directly supports the notion that a node’s component_type can be a relationship, as edges embody the functional connections between nodes. Another excerpt reinforces this by detailing that a property graph comprises nodes with types and that there are multiple kinds of relations, expressed via edges; this aligns with the concept that the ISG encodes architectural contracts and connections as labeled relationships. A third excerpt further supports by pointing to the Code Property Graph specification and the presence of edges and relationships as core constructs, confirming that relationships are central to the graph representation. Collectively, these excerpts establish that relationships are materialized as labeled edges within the graph model, matching the requested field value of 'Relationship'. Some excerpts provide broader context about graph structures (nodes, edges, attributes) which, while not naming the field 'Relationship' explicitly, underpin the same architectural paradigm and thus are supportive, albeit less directly so.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.7.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis."
          ]
        }
      ],
      "reasoning": "The most relevant material explicitly describes relationships as edges or labeled connections between graph nodes. This directly supports the idea that the ISG uses a graph-based representation where relationships (edges) define architectural contracts and interactions, which aligns with a field describing the type of relationships between nodes. The next excerpt reinforces this by detailing that edges are labeled and directed, capturing how one construct relates to another within the graph, which matches the notion of a Relationship component in an ontology of a Code Property Graph. A third excerpt discusses the Code Property Graph schema where there are various kinds of nodes and the existence of edges, which provides broader context about how such relationships are modeled in the graph structure. A fourth excerpt expands on the building blocks of CPGs, mentioning that nodes have types and that higher-level constructs (like endpoints) can be represented, which indirectly supports the concept of relationships by implication (how nodes connect through edges to form architectural meaning). The fifth excerpt, while broader, mentions the philosophy and tooling around Code Property Graphs and their representations across languages, which adds contextual support that relationships are a foundational concept across the graph representations, even if not stating explicit relationship terminology in every line.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.5.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph - Specification and Tooling",
          "url": "https://github.com/ShiftLeftSecurity/codepropertygraph",
          "excerpts": [
            "A Code Property Graph (CPG) is an extensible and language-agnostic\nrepresentation of program code designed for incremental and\ndistributed code analysis.",
            "This repository hosts the base\nspecification together with a build process that generates data\nstructure definitions for accessing the graph with different\nprogramming languages.",
            "We are publishing the Code Property Graph specification as a\nsuggestion for an open standard for the exchange of code in\nintermediate representations along with analysis results."
          ]
        }
      ],
      "reasoning": "The field value refers to the type attribute of a component in the ISG/CPG ontology, with a concrete example of node-related classifications. Excerpts that describe nodes as the fundamental program constructs and explicitly state that nodes have types (for instance, METHOD as a type and LOCAL as another type) provide direct support for interpreting a 'component_type' of a node in the ontology. Excerpts that discuss labeled edges such as CONTAINS, CALLS, and DEFINES further reinforce that the primary architectural elements are nodes with typed identities and structured relationships, which is consistent with a system where a component_type identifies the kind of node. Other excerpts that outline the broader CPG schema and the role of nodes within the graph context also align with the concept of a node carrying a type attribute within the ontology. Taken together, these excerpts coherently support the interpretation that the fine-grained field value 'Node' corresponds to the general node entity in the ISG/CPG ontology and its associated type information.",
      "confidence": "medium"
    },
    {
      "field": "chosen_parsing_technology_evaluation.key_findings",
      "citations": [
        {
          "title": "tree-sitter-rust",
          "url": "https://github.com/tree-sitter/tree-sitter-rust",
          "excerpts": [
            "But if you _edit_ the file after parsing it, tree-sitter can generally _update_ the previous existing syntax tree to reflect your edit in less than a millisecond,\n  thanks to its incremental parsing syste",
            "But if you _edit_ the file after parsing it, tree-sitter can generally _update_ the previous existing syntax tree to reflect your edit in less than a millisecond,"
          ]
        }
      ],
      "reasoning": "The clearest evidence directly supports all three findings. First, the notion that incremental updates complete in under a millisecond is explicitly described as a consequence of incremental parsing and updating the existing syntax tree, matching the first finding. Related phrasing also reiterates this rapid update capability in the Rust-specific variant. Second, the discussion of error recovery notes that the system inserts ERROR nodes to cope with syntax errors, which can obscure the code structure and threaten the fidelity of the generated graph, aligning with the second finding about potential degradation of ISG fidelity. Third, the mention of a dedicated tree-sitter-graph library implementing stack graphs provides a purely syntactic and deterministic method for handling name resolution, which is exactly the claim about enabling reliable CALLS edges through deterministic mechanisms. Taken together, these excerpts collectively substantiate all three aspects of the field value, with the first and third items supported by explicit statements about performance and deterministic graph construction, and the second item supported by explicit notes on error-node insertion and its fidelity implications.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.2.unique_value_proposition",
      "citations": [
        {
          "title": "Language Server Protocol Specification - 3.17",
          "url": "https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/",
          "excerpts": [
            "The `workspace/codeLens/refresh` request is sent from the server to the client. Servers can use it to ask clients to refresh the code lenses currently shown in editors. As a result the client should ask the server to recompute the code lenses for these editors. This is useful if a server detects a configuration change which requires a re-calculation of all code lenses. Note that the client still has the freedom to delay the re-calculation of the code lenses if for example an editor is currently not visible.",
            "Responses to requests should be sent in roughly the same order as the requests appear on the server or client side. So for example if a server receives a `textDocument/completion` request and then a `textDocument/signatureHelp` request it will usually first return the response for the `textDocument/completion` and then the response for `textDocument/signatureHelp` . However, the server may decide to use a parallel execution strategy and may wish to return responses in a different order than the requests were received. The server may do so as long as this reordering doesn’t affect the correctness of the responses. For example, reordering the result of `textDocument/completion` and `textDocument/signatureHelp` is allowed, as each of these requests usually won’t affect the output of the other.",
            "So the creator of a `TextDocumentEdit` doesn’t need to sort the array of edits or do any kind of ordering. However the edits must be non overlapping.",
            "The base protocol offers support for request cancellation. To cancel a request, a notification message with the following properties is sent:\n\n_Notification_ :\n\n* method: ‘$/cancelRequest’\n* params: `CancelParams` defined as follows:\n\n```\n`interface CancelParams { \n\t /**\n\t * The request id to cancel. */ \n\t id : integer | string ; \n } \n`\n```\n\nA request that got canceled still needs to return from the server and send a response back. It can not be left open / hanging. This is in line with the JSON-RPC protocol that requires that every request sends a response back. In addition it allows for returning partial results on cancel. If the request returns an error response on cancellation it is advised to set the error code to `ErrorCodes"
          ]
        },
        {
          "title": "Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022",
          "excerpts": [
            "The LSP has evolved over time and today it is at Version 3.0. It started when the concept of a language server was picked up by OmniSharp to provide rich editing features for C#.",
            "A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC.",
            "Below is an example for how a tool and a language server communicate during a routine editing session:"
          ]
        }
      ],
      "reasoning": "The finegrained field value emphasizes interactive, in-editor features such as auto-completion, live diagnostics, and navigation (go-to-definition) enabled by the Language Server Protocol (LSP). Excerpt points that explicitly mention codeLens demonstrate editor-integrated features that provide additional context or actions within the editor. Excerpt points that refer to textDocument/completion directly tie to in-editor completion behavior, a core example of the stated functionality. Another excerpt highlights the evolution of LSP (with Version 3.0) and notes its long-standing role in supplying rich editing capabilities for languages like C#, reinforcing the claim that LSP enables broad in-editor features through a mature ecosystem. Supporting context about JSON-RPC communication and request handling (cancellation, ordering, and refresh semantics) explains how these features are orchestrated in practice, which underpins the localized, range-based querying model described in the field value. Edits and general protocol mechanics are relevant insofar as they facilitate reliable in-editor changes and diagnostics, aligning with the field’s emphasis on editor-focused capabilities.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.1.system_name",
      "citations": [
        {
          "title": "Sourcegraph blog: Announcing auto-indexing",
          "url": "https://sourcegraph.com/blog/announcing-auto-indexing",
          "excerpts": [
            "Precise code navigation is driven by code graph data . This data is generated by indexing your code (using either LSIF or SCIP format indexers).",
            "Precise code navigation—the most powerful version of code navigation—is very similar to IDE-based navigation, but it also works cross-repository.",
            "Code navigation comes in two common forms: search-based and precise.",
            "Auto-indexing makes it easy to set up repository indexing in minutes and get precise code navigation for your repositories, with no changes to your CI workflow."
          ]
        },
        {
          "title": "Sourcegraph Documentation",
          "url": "https://6.5.sourcegraph.com/",
          "excerpts": [
            "Sourcegraph is a Code Intelligence platform that deeply understands your code, no matter how large or where it’s hosted, to power modern developer experiences. * **Code Search:** Search through all of your repositories across all branches and all code hosts"
          ]
        }
      ],
      "reasoning": "The target field value asserts a specific system name: Sourcegraph (with SCIP and Cody). Excerpts that reference Sourcegraph as a code intelligence platform and its capabilities are directly relevant. The most relevant excerpt explicitly notes that precise code navigation is driven by code graph data and is generated by indexing using SCIP format indexers, which aligns with Sourcegraph’s SCIP usage. Other excerpts consistently tie Sourcegraph to code intelligence, precise navigation, and auto-indexing features, which substantiate the association of Sourcegraph with advanced indexing/navigation capabilities. While none of the excerpts verbatim state 'Sourcegraph (with SCIP and Cody)', the combination of mentions of Sourcegraph, SCIP indexing, and precise code navigation strongly supports that the described system is Sourcegraph augmented with SCIP (and related tooling like Cody) in this context. The less direct references describe generic Sourcegraph capabilities (code intelligence, cross-repository navigation, and auto-indexing) that still corroborate the overall association to Sourcegraph as the system in question.",
      "confidence": "medium"
    },
    {
      "field": "isg_ontology_components.1.description",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The finegrained field value identifies that certain nodes classify as data structures and state machines. In the ISG ontology, the Nodes (Entities) section lists [S] Struct/Class and [E] Enum/Union as the data structures and state machines. An excerpt that discusses nodes and their types, including higher-level constructs, supports the idea that node types encode structural categories like data structures and state machines. Additionally, a reference to the CPG schema that documents various node types and edges reinforces the notion that the system categorizes program constructs into well-defined kinds, which aligns with representing data structures and state machines as particular node kinds within the ISG/CPG framework. Together, these excerpts substantiate that the ontology uses specific node classifications to capture structural and state-machine concepts, matching the field value description.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems.2.determinism_tradeoff",
      "citations": [
        {
          "title": "Language Server Protocol Specification - 3.17",
          "url": "https://microsoft.github.io/language-server-protocol/specifications/lsp/3.17/specification/",
          "excerpts": [
            "The base protocol offers support for request cancellation. To cancel a request, a notification message with the following properties is sent:\n\n_Notification_ :\n\n* method: ‘$/cancelRequest’\n* params: `CancelParams` defined as follows:\n\n```\n`interface CancelParams { \n\t /**\n\t * The request id to cancel. */ \n\t id : integer | string ; \n } \n`\n```\n\nA request that got canceled still needs to return from the server and send a response back. It can not be left open / hanging. This is in line with the JSON-RPC protocol that requires that every request sends a response back. In addition it allows for returning partial results on cancel. If the request returns an error response on cancellation it is advised to set the error code to `ErrorCodes",
            "The `workspace/codeLens/refresh` request is sent from the server to the client. Servers can use it to ask clients to refresh the code lenses currently shown in editors. As a result the client should ask the server to recompute the code lenses for these editors. This is useful if a server detects a configuration change which requires a re-calculation of all code lenses. Note that the client still has the freedom to delay the re-calculation of the code lenses if for example an editor is currently not visible.",
            "Responses to requests should be sent in roughly the same order as the requests appear on the server or client side. So for example if a server receives a `textDocument/completion` request and then a `textDocument/signatureHelp` request it will usually first return the response for the `textDocument/completion` and then the response for `textDocument/signatureHelp` . However, the server may decide to use a parallel execution strategy and may wish to return responses in a different order than the requests were received. The server may do so as long as this reordering doesn’t affect the correctness of the responses. For example, reordering the result of `textDocument/completion` and `textDocument/signatureHelp` is allowed, as each of these requests usually won’t affect the output of the other.",
            "So the creator of a `TextDocumentEdit` doesn’t need to sort the array of edits or do any kind of ordering. However the edits must be non overlapping."
          ]
        },
        {
          "title": "Language Server Protocol Overview - Visual Studio (Windows) | Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/visualstudio/extensibility/language-server-protocol?view=vs-2022",
          "excerpts": [
            "A language server runs in its own process, and tools like Visual Studio or VS Code communicate with the server using the language protocol over JSON-RPC.",
            "The LSP has evolved over time and today it is at Version 3.0. It started when the concept of a language server was picked up by OmniSharp to provide rich editing features for C#.",
            "Below is an example for how a tool and a language server communicate during a routine editing session:"
          ]
        }
      ],
      "reasoning": "- The idea that a language server runs as a separate process and communicates with editors (or tools) via the language protocol over JSON-RPC provides the structural basis for a locally deterministic interaction model where requests are well-defined, scoped, and exchange structured messages. This supports the notion of deterministic local behavior grounded in discrete protocol messages. - The explicit statement that a request canceled via the protocol still needs to return a response emphasizes deterministic handling of individual requests, even in the presence of control-flow changes like cancellation. This reinforces the view that determinism is preserved at the granularity of single requests rather than across an entire global system. - The description that LSP has evolved to a defined version (3.0) underscores a mature, standard, protocol-driven approach that reinforces predictable, bounded interactions rather than ad-hoc or probabilistic global reasoning. - Additional excerpts laying out concrete protocol mechanics (such as cancellation semantics, codeLens refresh signaling, and the ordering of responses) illustrate the tightly scoped, per-request determinism and protocol-driven coordination between client and server, aligning with the claim of local determinism. - Collectively, these excerpts help justify the finer-grained field value: LSP-based systems operate deterministically but only on a local scale, lacking the global, systemic architectural context that AIM/ISG aims to provide. The combination of a JSON-RPC-based, request-centric workflow and explicit handling rules (like guaranteed responses and potential reordering constraints) maps directly to the described fine-grained field.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.0.system_name",
      "citations": [
        {
          "title": "Kythe Storage Documentation",
          "url": "https://kythe.io/docs/kythe-storage.html",
          "excerpts": [
            "As viewed from the storage layer, a ‘node’ in a Kythe graph is essentially a\nbag of string-valued key/value properties associated with a unique name. In\norder for this representation to make sense, each node must have a unique name,\nto distinguish it from all the other nodes in the graph. To solve this naming problem, Kythe adopts the view that a node is a _d_ \\-dimensional ‘vector’, where each dimension represents some scalar [fact]() about the node: The “dimensions” in this case are not\nnumbers, but arbitrary semantic categories, _e.g._ , kind, identifier, snippet,\nlocation, c",
            "* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language)",
            "A node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection.",
            "The fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13)."
          ]
        },
        {
          "title": "Kythe Documentation: Writing an Indexer",
          "url": "https://kythe.io/docs/schema/writing-an-indexer.html",
          "excerpts": [
            "VNames have five string-valued fields.",
            "Kythe stores file content in its graph. The `http_server` binary used in our `kythe-browse.sh` script doesn’t look in your filesystem for a file to present\nto the Web browser; it instead reads the `text` fact off of a graph node."
          ]
        },
        {
          "title": "Kythe Schema Overview",
          "url": "https://kythe.io/docs/schema-overview.html",
          "excerpts": [
            "This document relies on the following basic terminology:"
          ]
        },
        {
          "title": "Kythe URI Specification",
          "url": "https://kythe.io/docs/kythe-uri-spec.html",
          "excerpts": [
            "This document defines the schema for Kythe uniform resource identifiers (\"Kythe URI\"). The primary purpose of a Kythe URI is to provide a textual encoding of a Kythe",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "Kythe URI Specification"
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts establish Kythe as a graph-based indexing and storage system. For example, one passage explains that a node in a Kythe graph is a bag of string-valued properties with a unique name, and that naming is central to solving identity within the graph. This supports the notion of Kythe as a structured, navigable graph with unique identifiers. Another excerpt notes that VNames have five string-valued fields, which is foundational to how Kythe identifies and disambiguates nodes across corpora. A third excerpt discusses signatures as opaque strings generated by the analyzer, which is essential for differentiating nodes within Kythe’s indexing. Additional excerpts describe how Kythe stores file content within its graph, and how the URI specification defines the textual encoding of Kythe resources, reinforcing the concrete encoding and addressing of Kythe entities. Together, these excerpts build a coherent picture of Kythe as a deterministic, graph-based indexing system with explicit naming, typing, and addressing semantics, which matches the field value indicating Kythe as the system name in the comparison. ",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.1.architectural_differences",
      "citations": [
        {
          "title": "Sourcegraph blog: Announcing auto-indexing",
          "url": "https://sourcegraph.com/blog/announcing-auto-indexing",
          "excerpts": [
            "Precise code navigation is driven by code graph data . This data is generated by indexing your code (using either LSIF or SCIP format indexers).",
            "Precise code navigation—the most powerful version of code navigation—is very similar to IDE-based navigation, but it also works cross-repository.",
            "Code navigation comes in two common forms: search-based and precise.",
            "Auto-indexing makes it easy to set up repository indexing in minutes and get precise code navigation for your repositories, with no changes to your CI workflow."
          ]
        },
        {
          "title": "Sourcegraph Documentation",
          "url": "https://6.5.sourcegraph.com/",
          "excerpts": [
            "Sourcegraph is a Code Intelligence platform that deeply understands your code, no matter how large or where it’s hosted, to power modern developer experiences. * **Code Search:** Search through all of your repositories across all branches and all code hosts"
          ]
        }
      ],
      "reasoning": "The fine-grained value asserts that Sourcegraph uses a multi-faceted, deterministic approach for code intelligence centered on a graph-based representation (SCIP) and combines it with AI-assisted retrieval (Cody) and a proposed OpenCodeGraph protocol, forming a hybrid system that blends a deterministic graph with probabilistic LLMs (RAG). Excerpts that discuss Sourcegraph as a Code Intelligence platform with capabilities for precise, cross-repository code navigation and indexing directly support this view. Specifically, the strongest support comes from the statement that precise code navigation is driven by a code graph and is enabled by indexing (using SCIP format indexers), which aligns with the claim that SCIP is part of the deterministic graph underpinning Sourcegraph’s architecture. Additional excerpts reinforce the deterministic, cross-repository navigation capability and the notion of a sophisticated code intelligence stack (Code Search and deep understanding of large codebases), which complements the description of a hybrid system combining a deterministic graph with probabilistic LLMs. Together, these excerpts substantiate the core components described in the field value: a deterministic code-graph foundation (SCIP/SCIP-format indexers) paired with AI-assisted retrieval and cross-repository navigation in Sourcegraph’s platform. The combination of these capabilities is consistent with the described hybrid approach between a deterministic graph (SCIP) and retrieval-Augmented strategies (Cody/RAG) within Sourcegraph’s ecosystem, as well as the concept of an OpenCodeGraph protocol facilitating contextual data exchange across sources.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems.0.determinism_tradeoff",
      "citations": [
        {
          "title": "Kythe Storage Documentation",
          "url": "https://kythe.io/docs/kythe-storage.html",
          "excerpts": [
            "As viewed from the storage layer, a ‘node’ in a Kythe graph is essentially a\nbag of string-valued key/value properties associated with a unique name. In\norder for this representation to make sense, each node must have a unique name,\nto distinguish it from all the other nodes in the graph. To solve this naming problem, Kythe adopts the view that a node is a _d_ \\-dimensional ‘vector’, where each dimension represents some scalar [fact]() about the node: The “dimensions” in this case are not\nnumbers, but arbitrary semantic categories, _e.g._ , kind, identifier, snippet,\nlocation, c",
            "A node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection.",
            "* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language)",
            "The fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13)."
          ]
        },
        {
          "title": "Kythe Documentation: Writing an Indexer",
          "url": "https://kythe.io/docs/schema/writing-an-indexer.html",
          "excerpts": [
            "VNames have five string-valued fields."
          ]
        }
      ],
      "reasoning": "The field value describes a system where code entities are identified in a stable, canonical way and where indexers produce identical outputs for identical inputs, ensuring a deterministic graph representation. The most directly relevant information includes: a) a node must have a unique name to distinguish it from all others, effectively supporting stable, unambiguous identification in the graph; b) there is a notion of uniquely identifying nodes relative to a universe of nodes, which reinforces global determinism; c) an opaque signature is used to distinguish nodes within the corpus, which supports deterministic disambiguation across analyses; d) VName fields define the structured, multi-attribute identity of a node, enabling consistent naming across tools; and e) constraints on the characters and structure of identifiers, ensuring consistent encoding. Together, these excerpts collectively substantiate the claim that Kythe supports a fully deterministic model with canonical, repeatable identification of code entities and outputs. The least directly connected but supportive content notes storage and URI aspects, which underpin practical deterministic access and referencing but are secondary to the core claim about deterministic identification and stable graph representation.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.1.name",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The requested field value corresponds to a specific node type in the ISG ontology: Struct/Class, i.e., a data-structure/class-like entity. The most relevant excerpt explicitly references the Code Property Graph schema and notes that the CPG stores various kinds of nodes, edges, and attributes, with node kinds being central to its representation of program constructs. This provides direct support for the existence of a node type category that would include Struct/Class as a kind of data-structural entity. The other excerpt discusses that nodes have types and gives examples of types such as METHOD and LOCAL, illustrating the general concept of typed nodes within a graph-based representation of code. This supports the idea that there is a dedicated node-type taxonomy within the ISG/CPG framework, which would encompass [S] Struct/Class as a realizable category. Overall, these excerpts collectively corroborate that a node-type named Struct/Class exists within the ontology, consistent with the finegrained field value, and they ground the notion of structural entities in the graph representation of code. The most direct support comes from the explicit mention of a CPG schema detailing node kinds, while the related discussion of node types provides necessary context for understanding how Struct/Class would be categorized.\n",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.9.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        }
      ],
      "reasoning": "The target field represents the concept of a relationship between entities. An excerpt that explains that relationships between program constructs are represented via directed edges, and that edges have labels to express multiple types of relations, directly maps to the idea of a Relationship as a fundamental connection in the ISG/Code Property Graph. It also notes that edges are directed and can carry different labels to denote different kinds of relations, which aligns with the notion of a relationship as a defined connection between nodes with specific semantics. The other excerpts discuss node types or high-level querying capabilities but do not explicitly frame the concept of relationships or edges as a core, labeled connection between entities, making them less directly supportive of the field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.11.description",
      "citations": [
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        },
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes.",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable.",
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri"
          ]
        }
      ],
      "reasoning": "The fine-grained field describes how data flows out of a function as part of its signature, which in Code Property Graphs is typically represented by a RETURNS-type edge or an equivalent data-flow relationship tied to a function's signature. The most relevant excerpt explicitly references the CPG schema as containing detailed information about nodes, edges, and attributes, which would encompass the RET U RNS/data-flow relationships that express what a function returns as part of its signature. This establishes the foundational capability to express data-flow out of a function within the graph structure. The next most relevant excerpt discusses labeled edges and the representation of relationships between program constructs, illustrating how different kinds of connections (including those that convey data flow or signature-related information) can be modeled within a graph. While it does not state RETURNS verbatim, it confirms that multiple relation types (edge labels) exist to express functional relationships, which is essential for capturing a function’s output signature in the graph. Another excerpt describes the building blocks of code-property graphs, including how nodes are typed (e.g., METHOD) and how conceptual constructs relate to signatures, which supports understanding that a function’s signature is a central, typed construct in the graph and can be linked to its data-flow aspects. The least directly relevant excerpt mentions high-level building blocks and node types, including METHOD, LOCAL, and the notion that nodes represent program constructs; while it reinforces the existence of a structured graph model, it does not explicitly mention data-flow or signature-level RETURNS, making it the weakest support for the specific finegrained field value but still contextually related to how signatures are modeled in the graph.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems.1.determinism_tradeoff",
      "citations": [
        {
          "title": "Sourcegraph blog: Announcing auto-indexing",
          "url": "https://sourcegraph.com/blog/announcing-auto-indexing",
          "excerpts": [
            "Precise code navigation is driven by code graph data . This data is generated by indexing your code (using either LSIF or SCIP format indexers).",
            "Code navigation comes in two common forms: search-based and precise.",
            "Precise code navigation—the most powerful version of code navigation—is very similar to IDE-based navigation, but it also works cross-repository.",
            "Auto-indexing makes it easy to set up repository indexing in minutes and get precise code navigation for your repositories, with no changes to your CI workflow."
          ]
        },
        {
          "title": "Sourcegraph Documentation",
          "url": "https://6.5.sourcegraph.com/",
          "excerpts": [
            "Sourcegraph is a Code Intelligence platform that deeply understands your code, no matter how large or where it’s hosted, to power modern developer experiences. * **Code Search:** Search through all of your repositories across all branches and all code hosts"
          ]
        }
      ],
      "reasoning": "The field value asserts that a deterministic code graph (SCIP-based) provides precise, fact-based relationships, which then feed a probabilistic model to improve generation quality. The most relevant excerpt states that precise code navigation is driven by code graph data and is generated by indexing your code with SCIP format indexers, directly supporting the claim of a deterministic graph underpinning navigation. The next excerpt contrasts two forms of code navigation—search-based vs precise—highlighting that precision is a key feature of the deterministic approach. Another excerpt emphasizes that precise code navigation is the strongest form of navigation, aligning with a graph-centered, deterministic view. A fourth excerpt explicitly mentions auto-indexing to achieve precise code navigation across repositories, reinforcing the practical mechanism to realize the deterministic graph. The remaining excerpt positions Code Intelligence with deep understanding and Code Search capabilities, which provides contextual support for large-scale, cross-repository understanding, consistent with the claimed benefits of a graph-driven, deterministic foundation feeding probabilistic analysis. Together, these excerpts map the pathway from building a deterministic code graph to enabling precise navigation and then using that deterministic signal to improve probabilistic generation, matching the described Normsky-like hybrid model.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.0.unique_value_proposition",
      "citations": [
        {
          "title": "Kythe Storage Documentation",
          "url": "https://kythe.io/docs/kythe-storage.html",
          "excerpts": [
            "As viewed from the storage layer, a ‘node’ in a Kythe graph is essentially a\nbag of string-valued key/value properties associated with a unique name. In\norder for this representation to make sense, each node must have a unique name,\nto distinguish it from all the other nodes in the graph. To solve this naming problem, Kythe adopts the view that a node is a _d_ \\-dimensional ‘vector’, where each dimension represents some scalar [fact]() about the node: The “dimensions” in this case are not\nnumbers, but arbitrary semantic categories, _e.g._ , kind, identifier, snippet,\nlocation, c",
            "A node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection.",
            "* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language)",
            "The fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13)."
          ]
        },
        {
          "title": "Kythe Schema Overview",
          "url": "https://kythe.io/docs/schema-overview.html",
          "excerpts": [
            "This document relies on the following basic terminology:"
          ]
        },
        {
          "title": "Kythe Documentation: Writing an Indexer",
          "url": "https://kythe.io/docs/schema/writing-an-indexer.html",
          "excerpts": [
            "VNames have five string-valued fields.",
            "Kythe stores file content in its graph. The `http_server` binary used in our `kythe-browse.sh` script doesn’t look in your filesystem for a file to present\nto the Web browser; it instead reads the `text` fact off of a graph node."
          ]
        },
        {
          "title": "Kythe URI Specification",
          "url": "https://kythe.io/docs/kythe-uri-spec.html",
          "excerpts": [
            "This document defines the schema for Kythe uniform resource identifiers (\"Kythe URI\"). The primary purpose of a Kythe URI is to provide a textual encoding of a Kythe",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "Kythe URI Specification"
          ]
        }
      ],
      "reasoning": "The most relevant portions articulate core Kythe design choices that undergird a cross-repository, semantics-focused representation. A description of a node as a bag of properties with a unique name clarifies how each entity is identified consistently across corpora, which is essential for cross-repo semantics and offline analysis. The notion that a node is uniquely identifiable relative to a universe of nodes by fixing a projection of attributes further supports cross-repository uniqueness. Details about VNames, which consist of five string-valued fields, explain how identifiers are structured to preserve global uniqueness across repositories. References to an opaque signature for a node (signature) and the need for it to be sufficient to distinguish nodes within a corpus highlight the deterministic, unambiguous nature of the representation, key for offline tooling. Schema overview and indexer writing elucidate Kythe’s formal terminology and indexing strategy, reinforcing a stable, query-friendly model that underpins offline analysis. Storage-related excerpts describe how Kythe stores content and uses fields that help maintain structured, queryable data. The Kythe URI specification and related notes reinforce the idea of standardized, cross-repo addressing. Unicode considerations are a practical detail ensuring broad applicability across languages. Collectively, these excerpts substantiate the claim that Kythe provides a detailed, stable, cross-repository representation of code semantics designed to empower offline analysis tools and deep code understanding, as described in the finegrained field value.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.11.component_type",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* **Labeled directed edges. ** Relations between program constructs are represented via edges\n  between their corresponding nodes. For example, to express that a\n  method contains a local variable, we can create an edge with the\n  label `CONTAINS` from the method’s node to the local’s node. By\n  using labeled edges, we can represent multiple types of relations in\n  the same graph. Moreover, edges are directed to express, e.g., that\n  the method contains the local but not the other way around. Multiple\n  edges may exist between the same two nodes."
          ]
        },
        {
          "title": "The Code Property Graph — MATE 0.1.0.0 documentation",
          "url": "https://galoisinc.github.io/MATE/cpg.html",
          "excerpts": [
            "See CPG Schema for detailed information about the various kinds of nodes, edges, and attributes in the CPG. The CPG is stored in a PostgreSQL database."
          ]
        }
      ],
      "reasoning": "The field value represents a relationship-type edge in the ISG ontology, i.e., the concept of a relationship between nodes. The second excerpt explicitly discusses labeled directed edges representing relations between program constructs and demonstrates how edges encode relationships within the graph. This aligns directly with the notion of a Relationship as an edge type in the ISG. The first excerpt describes the Code Property Graph schema and notes that the graph contains various kinds of nodes, edges, and attributes, which provides the necessary context that the ISG uses edges to express relationships between nodes. Together, these excerpts establish that relationships are characterized by edges (labeled and directed) connecting nodes, which is precisely what the finegrained field value denotes. The remaining excerpt focuses on building blocks of the graph in terms of node types without directly addressing the edge/relationship concept, so it offers contextual support but less direct evidence for the specific relationship field.",
      "confidence": "high"
    },
    {
      "field": "isg_ontology_components.7.name",
      "citations": [
        {
          "title": "Code Property Graph (Joern) Documentation",
          "url": "https://docs.joern.io/code-property-graph/",
          "excerpts": [
            "* The query language allows to seamlessly transition between the\n>   original code representations, making it possible to combine aspects\n>   of the code from different views these representations offer in a\n>   single query.\n> \n> From 2014-2016, research followed on (a) extending the concept for\n> interprocedural analysis, (b) using the graph as a basis for learning\n> typical data-flow patterns in a program, (c) the effects of\n> introducing further classic program representations such as dominator\n> trees, (d) and the applicability of the approach for dynamically-typed\n> languages such as PHP. > \n> From 2017 onwards, the code property graph served as the technological\n> foundation for the static analysis solutions developed at ShiftLeft\n> Inc. The representation has since undergone heavy extensions and\n> transformations. At the statement and expression level, it has matured\n> into a generic container format which allows for hosting of graphs\n> generated by 8 different language frontends, to enable querying with\n> the same query language across programming languages. Moreover, the\n> concept of overlays was introduced to allow representing code\n> on different levels of abstraction, enabling transitioning\n> between these layers of abstraction using the query language in the\n> same way as for the original three low-level code\n> representations. Finally, programming models and APIs are now\n> available for parallel graph processing at low memory footpri",
            "## Building Blocks of Code Property Graphs [\\#]()\n\nCode property graphs are [graphs](https://en.wikipedia.org/wiki/Graph_%28discrete_mathematics%29) ,\nand more specifically [property\ngraphs](https://arxiv.org/pdf/1004.1001.pdf) . A property graph is\ncomposed of the following building blocks:\n\n* **Nodes and their types. ** Nodes represent program\n  constructs. This includes low-level language constructs such as\n  methods, variables, and control structures, but also higher level\n  constructs such as HTTP endpoints or findings. Each node has a\n  type. The type indicates the type of program construct represented\n  by the node, e.g., a node with the type `METHOD` represents a method\n  while a node with type `LOCAL` represents the declaration of a local\n  variable."
          ]
        }
      ],
      "reasoning": "The fine-grained field value corresponds to the edge type used to denote that a type implements a trait or interface. One excerpt explicitly lists IMPL among the edge types, indicating that IMPL represents an implementation relationship (e.g., a type implements a trait/interface). Another excerpt directly describes the edges in the Code Property Graph, including IMPL as the edge that expresses an implementation relationship between nodes, reinforcing its meaning as an implementation link within the architectural graph. These excerpts together substantiate that IMPL encodes the contract where one entity implements another (trait/interface), aligning with the expected ISG semantics.",
      "confidence": "high"
    },
    {
      "field": "comparison_to_alternative_systems.1.unique_value_proposition",
      "citations": [
        {
          "title": "Sourcegraph blog: Announcing auto-indexing",
          "url": "https://sourcegraph.com/blog/announcing-auto-indexing",
          "excerpts": [
            "Precise code navigation is driven by code graph data . This data is generated by indexing your code (using either LSIF or SCIP format indexers).",
            "Precise code navigation—the most powerful version of code navigation—is very similar to IDE-based navigation, but it also works cross-repository.",
            "Code navigation comes in two common forms: search-based and precise.",
            "Auto-indexing makes it easy to set up repository indexing in minutes and get precise code navigation for your repositories, with no changes to your CI workflow."
          ]
        },
        {
          "title": "Sourcegraph Documentation",
          "url": "https://6.5.sourcegraph.com/",
          "excerpts": [
            "Sourcegraph is a Code Intelligence platform that deeply understands your code, no matter how large or where it’s hosted, to power modern developer experiences. * **Code Search:** Search through all of your repositories across all branches and all code hosts"
          ]
        }
      ],
      "reasoning": "The most directly relevant content supports the claim that Sourcegraph provides precise code navigation and uses a code-graph approach built from indexing data. In particular, references to precise code navigation driven by code graph data and indexing with formats such as SCIP align with the assertion that Sourcegraph enables fast, compiler-accurate, cross-repository navigation features. The notion that precise navigation is akin to IDE-like capabilities and works across repositories reinforces the value proposition of a developer-facing platform for code search and navigation. Additionally, explicit mention that Sourcegraph is a Code Intelligence platform capable of deep understanding across large codebases underpins the broader platform claim. Taken together, these excerpts corroborate the core components of the fine-grained field value: a comprehensive platform for code search/navigation, fast and accurate cross-repository capabilities, and the use of index-driven code graph data (including SCIP) to enable precise navigation. The excerpt mentioning cross-repository, go-to-definition-like capabilities further strengthens the alignment with the stated unique-value proposition for Sourcegraph. While the excerpts touch on SCIP and cross-repo navigation, they do not explicitly mention Cody or the exact phrasing of all components of the field value, which introduces partial support for the full combined claim. Therefore, the strongest support comes from the excerpts describing code graph-based, precise, cross-repo navigation and the general Code Intelligence platform framing, while the Cody-specific deterministic context element has only indirect alignment through the broader deterministic navigation narrative without explicit mention in these excerpts.",
      "confidence": "medium"
    },
    {
      "field": "comparison_to_alternative_systems.0.architectural_differences",
      "citations": [
        {
          "title": "Kythe Storage Documentation",
          "url": "https://kythe.io/docs/kythe-storage.html",
          "excerpts": [
            "As viewed from the storage layer, a ‘node’ in a Kythe graph is essentially a\nbag of string-valued key/value properties associated with a unique name. In\norder for this representation to make sense, each node must have a unique name,\nto distinguish it from all the other nodes in the graph. To solve this naming problem, Kythe adopts the view that a node is a _d_ \\-dimensional ‘vector’, where each dimension represents some scalar [fact]() about the node: The “dimensions” in this case are not\nnumbers, but arbitrary semantic categories, _e.g._ , kind, identifier, snippet,\nlocation, c",
            "* **Signature.\n** An opaque signature generated by the analyzer. The format of\n  this string is opaque outside the analyzer itself, but informally should be\n  sufficient to distinguish nodes within a corpus of the language. (However,\n  VNames for built-ins should be unique across corpora of the same language)",
            "A node _N_ can be uniquely identified relative to a universe _U_ of nodes by\nfixing any _v_ \\-dimensional projection of the node’s attributes that differs\nfrom all _U_ \\\\ {N} under the same projection.",
            "The fields of a VName shall be Unicode strings, save that control characters\n(categories Cf, Cs, Co, and Cn) and surrogate pair codepoints are disallowed,\nand category Cc is restricted to TAB (9), CR (10), and LF (13)."
          ]
        },
        {
          "title": "Kythe Documentation: Writing an Indexer",
          "url": "https://kythe.io/docs/schema/writing-an-indexer.html",
          "excerpts": [
            "VNames have five string-valued fields.",
            "Kythe stores file content in its graph. The `http_server` binary used in our `kythe-browse.sh` script doesn’t look in your filesystem for a file to present\nto the Web browser; it instead reads the `text` fact off of a graph node."
          ]
        },
        {
          "title": "Kythe Schema Overview",
          "url": "https://kythe.io/docs/schema-overview.html",
          "excerpts": [
            "This document relies on the following basic terminology:"
          ]
        },
        {
          "title": "Kythe URI Specification",
          "url": "https://kythe.io/docs/kythe-uri-spec.html",
          "excerpts": [
            "This document defines the schema for Kythe uniform resource identifiers (\"Kythe URI\"). The primary purpose of a Kythe URI is to provide a textual encoding of a Kythe",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "A Kythe URI is a string of UCS (Unicode) characters.",
            "Kythe URI Specification"
          ]
        }
      ],
      "reasoning": "The target field value describes Kythe as a language-agnostic ecosystem that builds a comprehensive semantic graph of code, using a VName as a unique and extensible key, with language-specific indexers emitting a stream of entries that become a persistent graph store. The most relevant passages explicitly define Kythe’s core modeling approach: a node is a multi-dimensional vector of semantic properties, ensuring unique naming across the corpus; VNames are five string-valued fields that uniquely identify nodes within a universe; an analyzer generates an opaque but distinguishing signature for each entry; and a node can be uniquely identified within a universe by fixing a projection of its attributes. Together, these excerpts directly substantiate how Kythe achieves durable, queryable graph-based indexing and identification, which contrasts with the AIM/ISG real-time graph approach described in the user’s broader context. Supporting details about how Kythe stores file content and URI schemas further corroborate the ecosystem’s design for persistence and interoperability, providing context for why Kythe’s approach differs from the deterministic AIM/ISG framework.",
      "confidence": "high"
    }
  ],
  "outputSchema": {
    "type": "object",
    "properties": {
      "project_summary": {
        "type": "object",
        "properties": {
          "project_name": {
            "type": "string",
            "description": "The official name of the project."
          },
          "classification": {
            "type": "string",
            "description": "The strategic classification of the project."
          },
          "objective": {
            "type": "string",
            "description": "The primary goal of the project."
          }
        },
        "required": [
          "project_name",
          "classification",
          "objective"
        ],
        "additionalProperties": false
      },
      "problem_statement_stochastic_fog": {
        "type": "object",
        "properties": {
          "problem_name": {
            "type": "string",
            "description": "The term used to describe the foundational crisis."
          },
          "core_issue": {
            "type": "string",
            "description": "The fundamental issue with current LLM methodologies for code."
          },
          "consequences": {
            "type": "string",
            "description": "The negative outcomes of the current probabilistic approach."
          }
        },
        "required": [
          "problem_name",
          "core_issue",
          "consequences"
        ],
        "additionalProperties": false
      },
      "solution_paradigm_deterministic_navigation": {
        "type": "object",
        "properties": {
          "paradigm_name": {
            "type": "string",
            "description": "The name of the proposed new paradigm."
          },
          "methodology": {
            "type": "string",
            "description": "The high-level approach of the new paradigm."
          },
          "core_concepts": {
            "type": "string",
            "description": "The two core components that realize the paradigm."
          }
        },
        "required": [
          "paradigm_name",
          "methodology",
          "core_concepts"
        ],
        "additionalProperties": false
      },
      "interface_signature_graph_isg_details": {
        "type": "object",
        "properties": {
          "data_model_name": {
            "type": "string",
            "description": "The official name of the foundational data model."
          },
          "purpose": {
            "type": "string",
            "description": "The primary purpose and nature of the ISG."
          },
          "compression_rate": {
            "type": "string",
            "description": "The estimated data reduction achieved by the ISG."
          },
          "focus": {
            "type": "string",
            "description": "The specific aspects of the codebase the ISG focuses on."
          }
        },
        "required": [
          "data_model_name",
          "purpose",
          "compression_rate",
          "focus"
        ],
        "additionalProperties": false
      },
      "isg_ontology_components": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "component_type": {
              "type": "string",
              "description": "The type of the ontology component, either 'Node' or 'Relationship'."
            },
            "name": {
              "type": "string",
              "description": "The name or symbol of the component (e.g., '[T] Trait/Interface', 'IMPL')."
            },
            "description": {
              "type": "string",
              "description": "A brief description of what the component represents."
            }
          },
          "required": [
            "component_type",
            "name",
            "description"
          ],
          "additionalProperties": false
        },
        "description": "A breakdown of the minimalist 3x3 ontology used by the ISG. This includes details on the types of Nodes (Entities) like Trait, Struct, Function, and Module, and the types of Relationships (Edges) like IMPL, EXTENDS, CALLS, and CONTAINS."
      },
      "identification_mechanisms_fqp_and_sighash": {
        "type": "object",
        "properties": {
          "mechanism_name": {
            "type": "string",
            "description": "The name of the identification mechanism, either 'FQP' or 'SigHash'."
          },
          "purpose": {
            "type": "string",
            "description": "The primary role of this identification mechanism."
          },
          "format_details": {
            "type": "string",
            "description": "Specific details about the format, such as '16-byte BLOB' for SigHash."
          }
        },
        "required": [
          "mechanism_name",
          "purpose",
          "format_details"
        ],
        "additionalProperties": false
      },
      "aim_daemon_architecture_and_pipeline": {
        "type": "object",
        "properties": {
          "pipeline_stages": {
            "type": "string",
            "description": "The sequence of stages in the AIM Daemon's real-time processing pipeline."
          },
          "architecture_type": {
            "type": "string",
            "description": "The high-level description of the daemon's storage architecture."
          },
          "hot_layer_details": {
            "type": "string",
            "description": "Details about the in-memory graph layer, including its implementation and purpose."
          },
          "query_layer_details": {
            "type": "string",
            "description": "Details about the embedded database layer, including its implementation and purpose."
          }
        },
        "required": [
          "pipeline_stages",
          "architecture_type",
          "hot_layer_details",
          "query_layer_details"
        ],
        "additionalProperties": false
      },
      "aim_daemon_performance_objectives": {
        "type": "object",
        "properties": {
          "metric_name": {
            "type": "string",
            "description": "The name of the performance metric (e.g., 'Total Update Latency', 'Query Response Time')."
          },
          "slo_target": {
            "type": "string",
            "description": "The specific Service Level Objective for the metric (e.g., '3-12ms', '<1ms')."
          }
        },
        "required": [
          "metric_name",
          "slo_target"
        ],
        "additionalProperties": false
      },
      "parsing_fidelity_tradeoff": {
        "type": "object",
        "properties": {
          "level": {
            "type": "number",
            "description": "The level of parsing fidelity (1, 2, or 3)."
          },
          "name": {
            "type": "string",
            "description": "The name of the parsing approach (e.g., 'Heuristic Parsing', 'Syntactic Analysis')."
          },
          "assessment": {
            "type": "string",
            "description": "The evaluation of this parsing level's suitability for AIM."
          },
          "rationale": {
            "type": "string",
            "description": "The reasoning behind the assessment."
          }
        },
        "required": [
          "level",
          "name",
          "assessment",
          "rationale"
        ],
        "additionalProperties": false
      },
      "chosen_parsing_technology_evaluation": {
        "type": "object",
        "properties": {
          "technology_name": {
            "type": "string",
            "description": "The name of the parsing technology being evaluated (e.g., Tree-sitter, SWC)."
          },
          "suitability_assessment": {
            "type": "string",
            "description": "The overall assessment of its suitability for Level-2 parsing in AIM."
          },
          "key_findings": {
            "type": "string",
            "description": "Specific findings from the evaluation, such as performance, error recovery, or incremental support."
          }
        },
        "required": [
          "technology_name",
          "suitability_assessment",
          "key_findings"
        ],
        "additionalProperties": false
      },
      "llm_workflow_transformation": {
        "type": "object",
        "properties": {
          "workflow_name": {
            "type": "string",
            "description": "The name of the transformed workflow."
          },
          "step_number": {
            "type": "number",
            "description": "The sequential number of the step in the workflow."
          },
          "step_description": {
            "type": "string",
            "description": "A description of the action performed in this step."
          },
          "impact_description": {
            "type": "string",
            "description": "A description of the transformative impacts of this new workflow, such as context efficiency."
          }
        },
        "required": [
          "workflow_name",
          "step_number",
          "step_description",
          "impact_description"
        ],
        "additionalProperties": false
      },
      "llm_interaction_and_query_model": {
        "type": "object",
        "properties": {
          "recommended_model": {
            "type": "string",
            "description": "The recommended query model for LLM interaction (e.g., DSL over raw SQL)."
          },
          "threat_model_summary": {
            "type": "string",
            "description": "A summary of the key threats considered, such as SQL injection and Denial-of-Service."
          },
          "defense_strategy_summary": {
            "type": "string",
            "description": "A summary of the multi-layered defense strategy to ensure safety and determinism."
          }
        },
        "required": [
          "recommended_model",
          "threat_model_summary",
          "defense_strategy_summary"
        ],
        "additionalProperties": false
      },
      "impact_analysis_blast_radius_algorithm": {
        "type": "object",
        "properties": {
          "algorithm_name": {
            "type": "string",
            "description": "The name of the impact analysis algorithm."
          },
          "methodology": {
            "type": "string",
            "description": "The core methodology used by the algorithm, such as transitive traversal."
          },
          "key_techniques": {
            "type": "string",
            "description": "Specific techniques employed, such as program slicing or semantic prioritization."
          },
          "summarization_output": {
            "type": "string",
            "description": "A description of how the analysis results are summarized for developers or LLMs."
          }
        },
        "required": [
          "algorithm_name",
          "methodology",
          "key_techniques",
          "summarization_output"
        ],
        "additionalProperties": false
      },
      "architectural_guardrail_enforcement": {
        "type": "object",
        "properties": {
          "methodology": {
            "type": "string",
            "description": "The high-level approach to enforcing architectural guardrails."
          },
          "evaluated_rule_language": {
            "type": "string",
            "description": "The name of a rule language evaluated for this purpose (e.g., Datalog, CodeQL, CEL)."
          },
          "execution_engine_design": {
            "type": "string",
            "description": "The design of the engine that executes these rules over the ISG."
          }
        },
        "required": [
          "methodology",
          "evaluated_rule_language",
          "execution_engine_design"
        ],
        "additionalProperties": false
      },
      "strategic_context_aggregated_codebase": {
        "type": "object",
        "properties": {
          "context_name": {
            "type": "string",
            "description": "The name of the strategic architectural context."
          },
          "philosophy": {
            "type": "string",
            "description": "The core principles of the ACB philosophy."
          },
          "role_of_aim_isg": {
            "type": "string",
            "description": "The specific role that AIM/ISG plays within this strategic context."
          }
        },
        "required": [
          "context_name",
          "philosophy",
          "role_of_aim_isg"
        ],
        "additionalProperties": false
      },
      "comparison_to_alternative_systems": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "system_name": {
              "type": "string",
              "description": "The name of the system being compared to AIM/ISG (e.g., Kythe, Sourcegraph, LSP)."
            },
            "architectural_differences": {
              "type": "string",
              "description": "Key differences in architecture compared to AIM/ISG."
            },
            "determinism_tradeoff": {
              "type": "string",
              "description": "How the system handles the trade-off between determinism and probabilistic methods."
            },
            "unique_value_proposition": {
              "type": "string",
              "description": "The unique value or primary use case of the system."
            }
          },
          "required": [
            "system_name",
            "architectural_differences",
            "determinism_tradeoff",
            "unique_value_proposition"
          ],
          "additionalProperties": false
        },
        "description": "A comparative analysis of Project AIM/ISG against other code intelligence systems. This includes architectural differences, determinism trade-offs, and interoperability strategies with systems like Kythe, Sourcegraph (and Cody), and LSP-based tools."
      },
      "implementation_roadmap_summary": {
        "type": "object",
        "properties": {
          "phase_number": {
            "type": "number",
            "description": "The sequential number of the implementation phase."
          },
          "phase_name": {
            "type": "string",
            "description": "The name of the implementation phase (e.g., 'Foundation & PoC', 'MVP')."
          },
          "goal": {
            "type": "string",
            "description": "The primary goal of this phase."
          },
          "key_deliverables": {
            "type": "string",
            "description": "A summary of the key deliverables for this phase."
          }
        },
        "required": [
          "phase_number",
          "phase_name",
          "goal",
          "key_deliverables"
        ],
        "additionalProperties": false
      },
      "security_and_multitenancy_model": {
        "type": "object",
        "properties": {
          "authentication_model": {
            "type": "string",
            "description": "The model for authenticating users and services (e.g., External IdP Federation)."
          },
          "authorization_model": {
            "type": "string",
            "description": "The model for enforcing permissions within a tenant (e.g., RBAC, ABAC)."
          },
          "query_sandboxing_mechanism": {
            "type": "string",
            "description": "The core technical mechanism for sandboxing database queries."
          },
          "row_level_security_implementation": {
            "type": "string",
            "description": "How row-level security is implemented to isolate tenant data."
          },
          "threat_mitigation_summary": {
            "type": "string",
            "description": "A summary of the strategy for mitigating key threats like cross-tenant access and prompt injection."
          }
        },
        "required": [
          "authentication_model",
          "authorization_model",
          "query_sandboxing_mechanism",
          "row_level_security_implementation",
          "threat_mitigation_summary"
        ],
        "additionalProperties": false
      },
      "evaluation_and_benchmarking_strategy": {
        "type": "object",
        "properties": {
          "evaluation_pillar": {
            "type": "string",
            "description": "A primary area of evaluation (e.g., Correctness, Latency, Developer Productivity)."
          },
          "metrics": {
            "type": "string",
            "description": "The specific metrics used to measure performance within this pillar (e.g., precision/recall, latency percentiles)."
          },
          "ground_truth_source": {
            "type": "string",
            "description": "The source of ground truth data for correctness evaluations (e.g., compiler outputs)."
          }
        },
        "required": [
          "evaluation_pillar",
          "metrics",
          "ground_truth_source"
        ],
        "additionalProperties": false
      }
    },
    "required": [
      "project_summary",
      "problem_statement_stochastic_fog",
      "solution_paradigm_deterministic_navigation",
      "interface_signature_graph_isg_details",
      "isg_ontology_components",
      "identification_mechanisms_fqp_and_sighash",
      "aim_daemon_architecture_and_pipeline",
      "aim_daemon_performance_objectives",
      "parsing_fidelity_tradeoff",
      "chosen_parsing_technology_evaluation",
      "llm_workflow_transformation",
      "llm_interaction_and_query_model",
      "impact_analysis_blast_radius_algorithm",
      "architectural_guardrail_enforcement",
      "strategic_context_aggregated_codebase",
      "comparison_to_alternative_systems",
      "implementation_roadmap_summary",
      "security_and_multitenancy_model",
      "evaluation_and_benchmarking_strategy"
    ],
    "additionalProperties": false
  }
}