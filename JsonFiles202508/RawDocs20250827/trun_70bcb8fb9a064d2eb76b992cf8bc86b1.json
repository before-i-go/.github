{
  "input": "top 5,000 NON BRANDED  MAX 3 WORD Google Search queries. Top 5,000 Google Search Queries Analysis Research Briefing & Objective: You are a Senior SEO Strategist at a leading digital intelligence agency. Your primary mission is to analyze the global search landscape by compiling a definitive dataset of the top 5,000 search queries on Google by absolute volume. This report will form the basis of our annual \"State of Search\" publication. Phase 1: Research Scope & Methodology Your research must identify the top 5,000 search terms globally for the most recent full calendar year. Primary Metric: The ranking must be based on the estimated global monthly search volume. Data Sourcing: Acknowledge that Google does not publicly release this list. Your research must be based on synthesizing and aggregating data from major, reputable SEO and digital intelligence platforms (citing data similar in nature to that from sources like Ahrefs, Semrush, Moz, etc.) that publish keyword volume estimates. Phase 2: Dataset Compilation & Final Deliverable The final output must be a single, comprehensive table in CSV format, with each row representing a single search query. The list should be ordered from the highest volume query to the lowest. The table must have the following exact headers: GlobalRank (1-5000) SearchQuery EstimatedMonthlyVolume PrimaryIntent QueryType KeywordDifficultyScore Constraint Checklist: PrimaryIntent: Categorize the user's likely intent behind the query. You must use one of the following standardized terms: Informational (the user is looking for information), Navigational (the user wants to go to a specific website), Transactional (the user wants to complete an action, e.g., buy, download), or Commercial (the user is researching before a potential purchase). QueryType: Classify the query as Branded (contains a specific company, product, or person's name like \"youtube\" or \"taylor swift\") or Non-Branded (a generic term like \"weather\" or \"how to tie a tie\"). KeywordDifficultyScore: If your data source provides a normalized score (typically 1-100) indicating the organic ranking difficulty for this keyword, include it. If this metric is not available, leave the cell blank.",
  "output": {
    "project_overview": {
      "objective": "The primary mission is to analyze the global search landscape by compiling a definitive dataset of the top 5,000 search queries on Google by absolute volume. This dataset will serve as the foundational research for a leading digital intelligence agency's annual \"State of Search\" publication.",
      "scope": "The research scope is to identify the top 5,000 non-branded Google search queries, with a maximum length of three words, on a global scale. The dataset must be filtered to exclude any queries classified as 'Branded'.",
      "primary_metric": "The primary metric for ranking the search queries is the 'EstimatedMonthlyVolume', representing the estimated global monthly search volume for each query.",
      "target_year": 2024,
      "final_deliverable": "The final deliverable is a single, comprehensive table in CSV format, strictly adhering to RFC 4180 standards. The file must be UTF-8 encoded and contain the exact headers in the specified order: `GlobalRank`, `SearchQuery`, `EstimatedMonthlyVolume`, `PrimaryIntent`, `QueryType`, `KeywordDifficultyScore`. The data must be deterministically sorted by `EstimatedMonthlyVolume` (descending), with tie-breakers for `KeywordDifficultyScore`, `PrimaryIntent`, and `SearchQuery` (alphabetical)."
    },
    "methodology_summary": "To compile the definitive dataset of the top 5,000 non-branded, maximum 3-word global Google search queries for 2024, a multi-stage, automated pipeline will be implemented. The methodology emphasizes data reconciliation, robust classification, and rigorous quality assurance.\n\n1.  **Data Sourcing & Ingestion:** Data will be programmatically extracted from the APIs of primary sources Ahrefs and Semrush, with Moz used as a supplemental source. These platforms provide the necessary global search volume estimates, Keyword Difficulty scores, and preliminary intent signals. Google Keyword Planner and Google Trends will be used for cross-referencing and sanity-checking seasonality and volume estimations for a sample of queries.\n\n2.  **Normalization & Reconciliation:** Raw query strings will undergo a strict normalization process (NFC Unicode normalization, case-folding, whitespace trimming) to de-duplicate trivial variants while preserving distinct intents. To create a single, reliable 'EstimatedMonthlyVolume' for each query, a reconciliation methodology will be applied. This involves using a weighted median of the volumes from Ahrefs, Semrush, and Moz, with weights assigned based on documented accuracy studies (Semrush highest). The process includes outlier detection using the Median Absolute Deviation (MAD) method and bias correction to align less reliable sources with the most accurate one.\n\n3.  **Classification & Labeling:**\n    *   **QueryType (Non-Branded):** A robust framework will be used to exclude all branded queries. This involves matching against a comprehensive brand lexicon built from authoritative sources like Wikidata, DBpedia, and official trademark databases (USPTO, EUIPO). The framework employs fuzzy matching, phonetic algorithms, and SERP-based signals (e.g., sitelinks, knowledge panels) to handle variations and disambiguate terms like 'apple'.\n    *   **PrimaryIntent:** A multi-layered classification framework will assign one of four intents (Informational, Navigational, Transactional, Commercial). This process starts with deterministic rules based on query patterns (e.g., 'how to', 'buy', 'reviews'). For remaining queries, it uses SERP feature analysis (e.g., presence of Shopping results, Featured Snippets). A fallback multilingual ML classifier (e.g., XLM-RoBERTa) will handle ambiguous cases, with a confidence threshold triggering manual review.\n\n4.  **Data Enrichment & Quality Assurance:**\n    *   **KeywordDifficultyScore:** A normalized 1-100 score will be populated based on a defined precedence rule: Ahrefs KD first, then Semrush KD, then Moz KD. The source will be recorded, and the field will be left blank if no score is available.\n    *   **Validation Plan:** A comprehensive QA plan will ensure accuracy. This includes stratified random sampling checks of volume and rank against Google Search Console data, cross-source variance analysis using Rank-Biased Overlap (RBO), monitoring rank stability, and conducting manual spot SERP audits for top queries. Error bars will be calculated for volume estimates to represent uncertainty.\n\n5.  **Final Output Generation:** The final, validated dataset will be sorted deterministically (by volume, then KD, then intent, then alphabetically) and formatted into a single CSV file with the specified headers (`GlobalRank`, `SearchQuery`, etc.), adhering strictly to RFC 4180 standards and UTF-8 encoding. Automated validation scripts will guarantee schema compliance before delivery.",
    "data_sourcing_and_reconciliation_plan": {
      "primary_data_providers": "Ahrefs and Semrush will be used as the primary data providers. Both platforms offer massive keyword databases (over 25 billion keywords each), provide global search volume metrics, and have the necessary API and filtering capabilities (especially Semrush for word count and non-branded filtering) to perform the initial large-scale data discovery and extraction for the 2024 calendar year.",
      "supplemental_data_providers": "Moz Keyword Explorer, Google Keyword Planner (GKP), and Google Trends will serve as supplemental data providers. Moz will be used for its Keyword Difficulty (KD) score, which is based on a different methodology (Page and Domain Authority) and provides a valuable third data point for volume triangulation. GKP and Google Trends will be used to cross-reference and sanity-check volume estimates and seasonality patterns for top queries, helping to flag suspicious outliers and align data with Google's own (albeit limited) tools.",
      "reconciliation_methodology": "The methodology to unify estimates involves several statistical steps. First, a per-source weighting will be applied based on independent accuracy studies, with Semrush receiving the highest weight, followed by Moz, and then Ahrefs. Second, a bias correction model, such as Quantile Mapping or Isotonic Regression, will be applied to the Ahrefs and Moz data to adjust for their known systematic under- or over-estimation relative to the most accurate source (Semrush). Third, an outlier detection mechanism using Median Absolute Deviation (MAD) or the Interquartile Range (IQR) will be used to identify and down-weight or remove anomalous volume figures from any single source before aggregation. Finally, a clear protocol will handle missing values by renormalizing the weights of the remaining sources.",
      "aggregation_method": "A Weighted Median will be the chosen statistical method for combining the multiple volume estimates for each keyword. This method is preferred over a simple weighted average because it is significantly more robust to extreme outliers, which are common when comparing data from different SEO tools. The weighted median provides the robustness of a standard median while still incorporating the confidence scores (weights) assigned to each data provider based on their documented accuracy.",
      "uncertainty_calculation": "To represent the uncertainty or confidence interval for the final reconciled volume estimate, the methodology will use the range of the calibrated input values. For each query, the lower bound of the uncertainty band will be the minimum of the calibrated volume estimates from Ahrefs, Semrush, and Moz, and the upper bound will be the maximum of these values. This provides a clear, transparent, and easily interpretable range that reflects the level of disagreement between the different data sources for that specific query. This range will be documented alongside the final volume estimate."
    },
    "provider_assessments": [
      {
        "provider_name": "Ahrefs",
        "data_coverage_summary": "Ahrefs utilizes a massive database of 28.7 billion keywords (as of April 2025). Its search volume estimations are derived from a combination of Google Keyword Planner (GKP) data, Google Trends, and historical clickstream data. A key feature of its methodology is the effort to 'un-group' keyword clusters that GKP often combines, aiming to provide more precise volumes for individual keywords. It offers both 'Monthly volume' for recent trends and 'Average volume' (a 12-month average) for a more stable view. 'Global search volume' is calculated as the sum of volumes from all 200+ countries it tracks.",
        "filtering_capabilities": "Ahrefs provides a dedicated 'Branded or not' filter in its Keywords Explorer tool, which is essential for this project. However, it has a significant limitation: there is no direct filter for word count. This means that isolating queries of three words or fewer requires extracting a broader dataset and performing the word count filtering post-extraction using external scripts or spreadsheet functions.",
        "export_and_api_limits": "Data extraction is subject to limits based on subscription plans. UI exports count against a monthly 'Export rows per month' quota (e.g., a Standard plan allows 2.5 million rows). Programmatic access is via the API v3, which has a rate limit of 60 requests per minute. API usage is metered by a system of 'API units', where the cost of a request depends on the number of rows and fields returned, with a minimum cost of 50 units per request. Full API access is typically reserved for Enterprise plans.",
        "key_metrics_offered": "Ahrefs offers several key metrics, including: Keyword Difficulty (KD), a 0-100 logarithmic score based solely on the number of backlinks to top-ranking pages; Primary Intent classification (Informational, Navigational, Commercial, Transactional); Traffic Potential (TP), an estimate of organic traffic; and Global TP. It also provides standard metrics like CPC."
      },
      {
        "provider_name": "Semrush",
        "data_coverage_summary": "Semrush maintains a database of over 26.6 billion keywords. Its search volume figures are calculated using advanced machine learning algorithms that process petabytes of data from various search engines, integrated with historical clickstream data from third-party providers. 'Global volume' is defined as the sum of a keyword's monthly search volumes across all its regional databases. Data is updated monthly and combines both desktop and mobile search volumes. Independent studies have found Semrush's volume estimates to be highly accurate when compared to Google Search Console data.",
        "filtering_capabilities": "Semrush offers excellent and highly granular filtering capabilities within its Keyword Magic Tool, making it ideal for this project. It provides explicit filters for both **word count** (e.g., setting a maximum of 3 words) and for **excluding branded keywords**. It also allows for advanced filtering by search intent, CPC, competitive density, and the presence of various SERP features.",
        "export_and_api_limits": "UI exports are limited by daily request quotas tied to the subscription plan (e.g., Pro: 3,000/day; Guru: 5,000/day), with a stated limit of 50,000 rows per export for some tools. The Analytics API v3 has a default monthly limit of 10,000 requests, which can be increased by purchasing more API units. The API has a rate limit of 10 inquiries per second. API unit costs vary by endpoint, with historical data and KD requests being more expensive.",
        "key_metrics_offered": "Key metrics include: Keyword Difficulty (KD%), a 1-100% score indicating ranking difficulty based on multiple factors like referring domains, domain authority, and search volume; Search Intent classification; Cost-per-click (CPC); Competitive Density; and a 'personal keyword difficulty' (PKD) score tailored to a specific domain."
      },
      {
        "provider_name": "Moz",
        "data_coverage_summary": "Moz's 'Monthly Volume' metric is a 12-month average designed to smooth out seasonal fluctuations. Its data is sourced from a combination of Google Keyword Planner and anonymized clickstream data. Moz claims its predictive model achieves 95% accuracy for search volume *ranges*. A key limitation is that precise, single-number monthly volumes are only available for the US, UK, Canada, and Australia; other global regions are provided only as ranges. Its keyword corpus is also known to be smaller than that of Ahrefs or Semrush.",
        "filtering_capabilities": "Moz Keyword Explorer has significant limitations in its filtering capabilities. The tool does not offer any built-in, direct filters for either **word count** or **non-branded status**. Isolating the required query types necessitates exporting a broader list of keywords and performing all filtering externally using scripts or spreadsheet software. While a 'Brand Rules' feature exists, it is confined to specific campaign reports and is not a universal filter.",
        "export_and_api_limits": "Moz allows users to export keyword lists to CSV, with the maximum number of exportable rows being contingent on the user's subscription level. Programmatic access is available via a public JSON-RPC 2.0 API. API usage is metered in 'rows,' with quotas tied directly to the subscription tier. Free or low-tier plans have very restrictive quotas, making a paid subscription essential for any substantial research.",
        "key_metrics_offered": "Moz's primary metrics include: Keyword Difficulty (KD), a proprietary 1-100 score estimating ranking difficulty based on the Page Authority (PA) and Domain Authority (DA) of the top 10 ranking pages; Organic CTR, which estimates the click-through rate for a keyword; and a composite Priority Score."
      }
    ],
    "operational_definitions": {
      "global_scope_definition": "The term 'global' search volume is defined as the aggregation of a keyword's monthly search volumes across all available countries and regions tracked by the data source. This is achieved by using settings such as 'All locations' or 'Worldwide' in data tools or by programmatically summing the volumes from all regional databases, as is the practice for providers like Semrush and Ahrefs. This ensures the most comprehensive worldwide scope, reflecting true global search trends.",
      "non_branded_query_definition": "A non-branded query is a generic search term that does not contain a brand name, specific product name, organization name, or domain. These queries represent users in the awareness or consideration phase. The classification follows strict rules: queries are excluded if they contain exact brand names (e.g., 'Nike'), variations or misspellings (e.g., 'Niek'), specific product lines (e.g., 'iPhone 15'), or are navigational (e.g., 'facebook login'). Identification is automated using criteria such as the presence of brand-specific sitelinks or a Knowledge Graph panel on the SERP. For ambiguous terms (e.g., 'apple'), the query is excluded if a significant branded interpretation exists to maintain the integrity of the non-branded list.",
      "word_count_definition": "The word count is determined by tokenizing queries based on the principles of Unicode Standard Annex #29 (UAX #29) for word boundaries. The specific rules are: 1) Hyphenated terms forming a single concept (e.g., 'e-commerce') are counted as one word. 2) Numbers are counted as words. 3) Punctuation marks are treated as delimiters and are removed before counting. 4) For languages without spaces (e.g., Chinese, Japanese, Thai), specialized dictionary-based tokenization methods (e.g., pkuseg, MeCab) are employed to accurately segment queries into words before the count is applied. A query is included only if the final token count is three or fewer.",
      "estimated_monthly_volume_definition": "The 'estimated monthly volume' is defined as the 12-month average of search volume for the full calendar year of 2024 (January 1, 2024, to December 31, 2024). This approach is consistent with metrics like Google Keyword Planner's 'Average monthly searches' and is chosen to provide a stable, representative measure of a query's annual popularity by mitigating short-term fluctuations and accounting for seasonality. For any missing monthly data or detected anomalies, values are imputed using time series decomposition models (e.g., STL or X-13ARIMA-SEATS) to ensure a complete and accurate 12-month dataset for averaging."
    },
    "query_normalization_and_deduplication_policy": {
      "unicode_normalization_form": "NFC (Normalization Form C) is the mandated standard. This form composes characters into their shortest pre-composed representation and is the recommended form by the W3C for all web content to ensure interoperability. It handles canonical equivalence without altering the semantics of the query, unlike compatibility forms (NFKC, NFKD) which are explicitly discouraged as they can collapse meaningful distinctions (e.g., ligatures, superscripts) and change the user's original intent.",
      "case_folding_policy": "A policy of full, locale-independent case folding will be applied to all queries to ensure case-insensitive comparison. This is more comprehensive than simple lowercasing as it correctly handles complex character mappings across different languages, such as the German Eszett ('ß' to 'ss'). Special attention will be paid to locale-specific exceptions, such as the 'Turkish I' problem, by using data from Unicode's `SpecialCasing.txt` to ensure correct mapping for all languages.",
      "whitespace_and_punctuation_handling": "A multi-step process will be applied. First, all leading and trailing whitespace characters will be trimmed. Second, any sequence of two or more internal whitespace characters will be collapsed into a single standard space (U+0020). For punctuation, a nuanced policy will be followed: punctuation that is integral to a token's meaning (e.g., hyphens in compound words like 'e-mail', apostrophes in contractions, or symbols like '#' and '@' in social media contexts) will be preserved. All other non-essential punctuation that serves only as a separator will be stripped or replaced with a space.",
      "near_duplicate_detection_method": "After the initial normalization pipeline, near-duplicates caused by minor typos will be detected using string similarity metrics. The primary method will be the Levenshtein distance, with a low threshold (e.g., 1 or 2) to identify queries that differ by only a few character edits (insertions, deletions, or substitutions). This approach is effective for catching common misspellings in short query strings without incorrectly flagging distinct morphological variants. For larger datasets, this can be scaled using techniques like MinHashing to efficiently approximate Jaccard similarity and group similar items without expensive pairwise comparisons."
    },
    "non_branded_classification_framework": {
      "brand_lexicon_sources": "A comprehensive brand lexicon will be constructed by aggregating data from multiple authoritative, bulk-downloadable, and API-accessible sources. These include: open knowledge graphs like Wikidata and DBpedia for their extensive, multilingual entity data and aliases; corporate and financial lists such as the Fortune Global 500 and Forbes Global 2000; official trademark databases from the USPTO (United States), CNIPA (China), and KIPO (South Korea); application data scraped from the Apple App Store and Google Play Store APIs; and person-name lists from sources like the US Social Security Administration.",
      "matching_techniques": "A hybrid approach to matching will be used to identify brand mentions, including variations and misspellings. This includes: 1) Edit distance algorithms like Levenshtein for simple typos. 2) Token-based similarity (e.g., `token_set_ratio`) for reordered words. 3) N-gram similarity for more robust matching. 4) Phonetic algorithms like Double Metaphone to match similar-sounding names after transliteration. 5) Specialized tokenizers (e.g., Jieba for Chinese, MeCab for Japanese) for languages without clear word boundaries. 6) Leveraging pre-compiled aliases and redirects from Wikidata and DBpedia.",
      "disambiguation_strategy": "For terms that can be both branded and non-branded (e.g., 'apple', 'amazon'), contextual disambiguation will be performed by analyzing Search Engine Results Page (SERP) features. The presence of strong navigational signals, such as a brand-specific Knowledge Panel, a rich set of Sitelinks under a single domain, or the official brand website ranking as the #1 organic result, will be used as definitive evidence that the query's primary intent is branded/navigational. This leverages the search engine's own understanding of user intent to resolve ambiguity.",
      "auditing_and_verification_process": "A continuous quality assurance loop will be implemented to maintain the accuracy of the classification. This involves: 1) Regular, sample-based manual audits of both 'Branded' and 'Non-Branded' classifications to identify false positives and false negatives, with sample sizes calculated for statistical significance. 2) Detailed tracking of all misclassifications to perform root cause analysis. 3) A formal remediation workflow to update the brand lexicon, refine NLP models, and improve disambiguation rules based on audit findings. 4) Standardized exception reporting to track accuracy trends over time."
    },
    "primary_intent_classification_framework": {
      "intent_categories": "The framework uses a standardized four-category system: 1) **Informational**: The user is seeking knowledge, answers, or how-to guides. 2) **Navigational**: The user intends to reach a specific, known website or online destination. 3) **Transactional**: The user is ready to perform a specific action or conversion, such as a purchase, download, or sign-up. 4) **Commercial Investigation**: The user is in the research phase before a potential transaction, comparing products, services, or looking for reviews.",
      "classification_approach": "A hybrid, three-tiered classification approach will be used: 1) **Deterministic Rules:** A fast, initial layer uses query patterns, verbs, and modifiers (e.g., 'how to', 'buy', 'review', 'vs') to classify clear-cut cases. 2) **SERP Feature Analysis:** The presence of specific SERP features (e.g., Featured Snippets for Informational, Shopping carousels for Transactional, Local Packs for Local) is used to confirm or assign intent based on the search engine's interpretation. 3) **Fallback ML Classifier:** For queries not classified by the first two layers, a fine-tuned, multilingual Transformer-based model (e.g., XLM-RoBERTa, LaBSE) will predict the intent, ensuring broad language coverage and handling of nuanced queries.",
      "ambiguity_resolution_policy": "For ambiguous or multi-intent queries, a tie-breaker hierarchy is applied to assign a single primary intent. The hierarchy prioritizes: 1) Explicit intent modifiers within the query. 2) The 'Dominant Interpretation' of the query (what most users mean). 3) Temporal relevance and geographical context. If ambiguity persists, SERP feature dominance is used for arbitration (e.g., a dominant Local Pack implies Local intent). Predictions from the ML model that fall below a calibrated confidence threshold are flagged for manual review to ensure accuracy.",
      "evaluation_and_quality_assurance": "The framework's performance will be rigorously evaluated using a manually labeled validation set, measuring standard metrics like Accuracy, Precision, Recall, and F1-score. For the manual labeling process, Inter-Annotator Agreement (IAA) will be measured using Cohen's Kappa to ensure guideline clarity and consistency. The ML model's confidence scores will be calibrated using techniques like Temperature Scaling to make them reliable. Regular audits of labeled data will be conducted to identify systematic errors and iteratively refine the models and guidelines."
    },
    "keyword_difficulty_sourcing_policy": {
      "source_precedence": "A strict sourcing priority is defined to ensure consistency. The primary source is Ahrefs KD. If Ahrefs data is unavailable, the system will fall back to the secondary source, Semrush KD%. If neither Ahrefs nor Semrush provides a score, the tertiary source, Moz KD, will be used.",
      "comparability_statement": "Keyword Difficulty scores from different providers (Ahrefs, Semrush, Moz) are not directly comparable. A score of 40 from one tool does not equate to a score of 40 from another due to their fundamentally different calculation methodologies and data inputs. Therefore, no standard crosswalk or rescaling method can accurately normalize these scores, and attempting to do so would be misleading.",
      "missing_value_rule": "If a Keyword Difficulty score is unavailable from the primary source (Ahrefs), the system will automatically query the secondary (Semrush) and then the tertiary (Moz) sources. If no score is available from any of the three providers, the field in the final dataset must be left blank.",
      "provenance_tracking": true
    },
    "estimated_volume_calculation_methodology": {
      "calculation_window": "The computation for the 2024 EstimatedMonthlyVolume is based on the full 12-month calendar year of 2024, specifically from January 1, 2024, to December 31, 2024.",
      "averaging_method": "A seasonally adjusted average is used. The process involves decomposing the historical monthly volume data into trend, seasonality, and residual components using robust methods like STL (Seasonal and Trend decomposition using Loess) or X-13ARIMA-SEATS. The 2024 monthly data is then deseasonalized using the extracted seasonal component. The arithmetic average of these deseasonalized volumes is calculated. Finally, the typical seasonal factors for 2024 are applied back to this average to produce a final, contextually relevant EstimatedMonthlyVolume that accounts for predictable seasonal spikes without distorting the underlying trend.",
      "anomaly_and_missing_data_handling": "Before analysis, data is screened for anomalies using robust statistical methods like Tukey's IQR Rule (flagging points more than 1.5 times the Interquartile Range from the central data bulk) or the Modified Z-score (flagging points with a score > 3.5). If an anomaly is detected, it is replaced with an estimate from the time series model. If entire months of data are missing, they are imputed using techniques such as interpolation on the seasonally adjusted series, model-based forecasting, or using the average of the same month from prior years. For partial months, data is projected to a full-month equivalent using proration or historical trend analysis.",
      "provenance_documentation": "A detailed month-level provenance breakdown is required for the final figure. For each of the 12 months contributing to the 2024 average, the data's source and nature must be documented. Each monthly value must be tagged as one of the following: 'Observed' (raw, validated data was used), 'Estimated' (the value was projected from a partial month's data), or 'Adjusted/Imputed' (the value was corrected for an anomaly or filled in due to missing data). This ensures a complete audit trail for the final estimate."
    },
    "content_moderation_policy": {
      "content_taxonomy": "A multi-tiered content taxonomy will be adopted, based on the Global Alliance for Responsible Media (GARM) Brand Safety & Suitability Framework and the IAB Content Taxonomy 3.0. This allows for the classification of content into categories (e.g., Adult & Explicit Sexual Content, Hate Speech, Illegal Drugs) and the assignment of risk levels (Floor, High, Medium, Low). This provides a standardized, flexible system for filtering content based on defined risk tolerance and brand-safety requirements.",
      "legal_and_safety_compliance": "The policy mandates strict adherence to all relevant legal and child-safety regulations. This includes a zero-tolerance policy for Child Sexual Abuse Material (CSAM) with mandatory reporting to NCMEC as required by U.S. law (18 U.S.C. § 2252A). It also ensures compliance with the Children's Online Privacy Protection Act (COPPA), the EU's GDPR (Article 9 on special categories of data), the UK Online Safety Act 2023, and the complex landscape of U.S. state-level age verification laws for adult content.",
      "moderation_process": "A hybrid moderation process combining automated tools and human oversight will be implemented. Initial large-scale flagging will use probabilistic classifiers and keyword blocklists. For CSAM detection, industry-standard hashing technologies like PhotoDNA and Google's CSAI Match will be used. All automated flags, especially for borderline or context-dependent content (e.g., educational vs. sexually gratifying nudity), will be subject to review by trained human moderators to ensure accuracy and minimize false positives.",
      "documentation_and_transparency": "Full transparency is required for all moderation actions. Every dataset release must be accompanied by comprehensive documentation using frameworks like 'Datasheets for Datasets'. This documentation will detail the content policy, the filtering process, and precise counts of excluded items by category. Furthermore, all public reports and dataset releases will feature prominent disclaimers warning users about the potential for residual harmful or offensive content, thereby managing user expectations and liability."
    },
    "quality_assurance_and_validation_plan": {
      "ground_truth_validation": "Data is validated against Google Search Console (GSC) through sampling checks. For a stratified random sample of queries, the rank and impression data from the internal tracking system is compared against the data reported in GSC for the same date range. GSC's 'Average Position' metric serves as the baseline for rank validation, while impression data is used to correlate significant changes. This process accounts for GSC's data latency and Pacific Time zone to ensure a true like-for-like comparison.",
      "cross_source_variance_analysis": "The consistency of data across different providers is analyzed by collecting rank data for a sample of queries from multiple reputable tools (e.g., Semrush, Ahrefs) in addition to the internal system. The agreement between these ranked lists is quantified using Rank-Biased Overlap (RBO), specifically using variants that can handle ties in rankings. Additionally, Bland-Altman plots are used to graphically assess agreement and identify any systematic bias between the internal tracking system and external benchmarks.",
      "stability_and_audit_checks": "Rank stability is measured using historical 2024 data by calculating week-over-week and month-over-month stability scores for the query set using the Rmeasure framework, with a focus on the Roverlap metric. Stability thresholds are defined based on this analysis (e.g., a query is stable if its Roverlap score is > 0.9). Additionally, regular spot SERP audits are performed on a random sample of the top 100 queries. This involves manual, live searches to verify rank accuracy and check for the influence of SERP features, localization, or personalization.",
      "acceptance_criteria_and_rework_triggers": "A strict set of acceptance criteria must be met before publication, including: the average rank difference versus GSC must be below a threshold (e.g., < 1.0 position); the average RBO score versus external tools must be above a threshold (e.g., > 0.85); and a high percentage of top queries (e.g., 90% of the top 500) must meet stability thresholds. A full rework is triggered if these criteria are not met, or if a systematic discrepancy with GSC is found, cross-source variance is too high, a significant number of important queries are unstable, or a spot audit reveals a critical failure in the automated system's accuracy."
    },
    "risk_and_contingency_plan": {
      "alternative_data_sources": "To mitigate reliance on primary providers like Ahrefs and Semrush, a list of backup data providers will be utilized. These include DataForSEO, which offers flexible pay-as-you-go APIs for keywords and SERP data; SerpApi for real-time SERP data; Similarweb for traffic estimates from a large user panel; Sistrix for comprehensive data metered by 'export credits'; and the Bing Webmaster Tools API as a free, direct source for Bing search data.",
      "data_acquisition_strategies": "To handle provider API limits and ensure robust data collection, several technical strategies will be employed. These include implementing exponential backoff for retrying failed requests due to rate limiting (HTTP 429) or server errors (5xx); systematically using API pagination to retrieve large datasets in manageable chunks; checkpointing large exports to allow for resumable downloads in case of failure; designing all API requests to be idempotent to prevent data duplication on retries; and staggering large data requests over time to stay within daily or monthly consumption caps. Furthermore, data acquisition will prioritize high-volume 'head terms' first, applying the Pareto Principle.",
      "statistical_mitigation_methods": "In cases where full data export is not feasible due to coverage gaps or API limits, statistical techniques will be used to infer population characteristics from samples. These methods include stratified random sampling to ensure all keyword segments are represented; importance sampling to oversample rare but critical keywords; using a capture-recapture analogy by comparing lists from multiple sources to estimate the total keyword universe; constructing bootstrap confidence intervals to measure uncertainty in estimates; and employing Bayesian hierarchical models to 'borrow strength' from data-rich segments to improve estimates for data-sparse ones.",
      "metric_fallbacks": "If primary metrics like Keyword Difficulty (KD) or a provider's intent classification are unavailable, reliable proxy metrics will be used. For Keyword Difficulty, fallbacks include Cost Per Click (CPC), as higher advertiser bids often correlate with higher competition; the Google Ads 'Competition' metric, which indicates advertiser density; and SERP Volatility, where frequent ranking changes suggest a more competitive landscape. For search intent, a fallback is to analyze SERP features; for example, the presence of shopping carousels indicates transactional intent, while 'People Also Ask' boxes suggest informational intent."
    },
    "data_licensing_and_compliance_guidelines": {
      "provider_name": "Ahrefs",
      "permitted_uses": "The Ahrefs Terms of Service grant users a limited, non-exclusive, and non-transferable license to use the services and data for **internal business operations only**. Ahrefs retains all intellectual property rights to its services and data. While Ahrefs itself may use aggregated and de-identified data for its own public reports, this right is not extended to its users.",
      "redistribution_constraints": "The ToS strictly and explicitly prohibits users from reproducing, duplicating, copying, selling, trading, publishing, or otherwise exploiting any portion of Ahrefs' services or content for commercial purposes. Publishing a 'State of Search' report using their data would likely be considered a violation of this clause unless express written consent is obtained from Ahrefs.",
      "attribution_requirements": "In any situation where data is permitted to be shown to third parties, users must provide clear attribution to Ahrefs and acknowledge its proprietary rights. The official names of proprietary metrics, such as 'URL Rating' and 'Domain Rating', cannot be altered or renamed. Ahrefs provides a media kit with official logos for approved use cases.",
      "compliance_recommendation": "No-Go / Permission Required. Given the explicit prohibition on commercial exploitation and public redistribution in the Terms of Service, using Ahrefs data in a public 'State of Search' report carries a high risk of non-compliance. The only viable and safe path forward is to contact Ahrefs directly to negotiate a specific agreement or obtain express written permission that explicitly allows for the use of their data in the publication. Without such permission, proceeding is not recommended."
    },
    "automated_pipeline_architecture_proposal": {
      "architecture_model": "A Medallion Architecture is proposed to logically organize data into three distinct layers, ensuring reliability and incremental improvements. The Bronze Layer serves as the immutable, versioned landing zone for all raw data from sources like Ahrefs and Semrush, providing a permanent audit trail. The Silver Layer is where data is cleaned, filtered, normalized, reconciled, and validated against rigorous data quality checks, creating a single source of truth. The Gold Layer further transforms and aggregates this data into curated, business-ready datasets optimized for analysis and the final CSV generation.",
      "orchestration_and_idempotency": "The pipeline will be orchestrated using tools like Apache Airflow, Dagster, or Prefect, which are designed for complex data workflows. A core principle is idempotency, ensuring that re-running any task or the entire pipeline produces the same result, preventing data duplication or corruption. This is achieved through atomic task design in the orchestrator and by leveraging features like dbt's incremental models. These models use a `unique_key` to perform 'upsert' operations (e.g., `merge` or `delete+insert`), which guarantees that data loading is idempotent and reliable, even in the event of retries or failures.",
      "data_lineage_and_provenance": "End-to-end data lineage will be captured using the OpenLineage open standard. This framework allows for the collection of metadata about datasets, jobs, and runs from all components of the tech stack, including Airflow, Dagster, Spark, and dbt. The lineage data will be stored and visualized using Marquez, the reference implementation of the OpenLineage API. This provides a complete, automated audit trail, showing how data is transformed from its raw state in the Bronze layer to the final curated output in the Gold layer, which is essential for auditability, impact analysis, and debugging.",
      "testing_and_ci_cd": "A comprehensive testing and CI/CD strategy will be implemented to ensure code quality and data integrity. Unit tests for Python functions will be written using pytest. Data models will be validated using `dbt test`, and data quality will be enforced at various stages using frameworks like Great Expectations or Pandera. A CI/CD pipeline, managed through dbt Cloud or GitHub Actions, will automate linting (e.g., with SQLFluff), unit testing, and integration testing for every code change. This pipeline will use OpenID Connect (OIDC) for secure, credential-less authentication with cloud providers, ensuring a secure and automated path to production.",
      "security_and_storage": "A multi-layered security and storage plan will be implemented. Raw exports and critical intermediate artifacts will be stored in a secure cloud object store (e.g., AWS S3, GCS) with immutability enabled via features like S3 Object Lock or GCS Bucket Lock, creating a WORM (Write-Once-Read-Many) compliant audit trail. The principle of least privilege will be enforced using IAM policies, refined by tools like IAM Access Analyzer. All secrets, such as API keys and database credentials, will be managed through a dedicated secrets manager like HashiCorp Vault or AWS Secrets Manager, which can generate dynamic, short-lived credentials to minimize risk. Automated key rotation policies will be enforced."
    },
    "final_csv_production_specifications": {
      "headers_and_order": "The final CSV file must contain a header row as its first record. The headers must be in the following exact order: `GlobalRank,SearchQuery,EstimatedMonthlyVolume,PrimaryIntent,QueryType,KeywordDifficultyScore`.",
      "deterministic_sorting_logic": "To ensure a deterministic and reproducible ranking, all rows must be sorted by a multi-level hierarchy before the `GlobalRank` is assigned. The primary sort key is `EstimatedMonthlyVolume` in descending order. Tie-breakers are applied sequentially: first by `KeywordDifficultyScore` in descending order (with blank/null values appearing before numeric scores), then by `PrimaryIntent` based on a predefined priority (`Transactional`, `Commercial`, `Navigational`, `Informational`, `Investigational`), and finally by `SearchQuery` in alphabetical (Unicode codepoint) order.",
      "formatting_and_encoding": "Numeric values in the `EstimatedMonthlyVolume` column must be rounded to the nearest integer (0 decimal places) using a round-half-up policy. If the `KeywordDifficultyScore` is not available for a query, the corresponding cell in the CSV must be left blank (an empty field). The entire file must be encoded using UTF-8, preferably without a Byte Order Mark (BOM) to ensure maximum compatibility with parsing tools.",
      "csv_standard_compliance": "The generated CSV file must strictly adhere to the RFC 4180 standard. This includes using a carriage return followed by a line feed (`CRLF`) as the record delimiter. Fields will be separated by a comma. Double-quotes will be used to enclose fields only when necessary (i.e., if the field contains a comma, a double quote, or a line break), following a `QUOTE_MINIMAL` strategy. Any double-quote character within a quoted field must be escaped by preceding it with another double-quote."
    }
  },
  "outputBasis": [
    {
      "field": "data_sourcing_and_reconciliation_plan",
      "citations": [
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)",
            "You can use historical metrics to reduce a large set of keywords to a more\nmanageable size based on the performance.",
            "To generate historical metrics call KeywordPlanIdeaService.GenerateKeywordHistoricalMetrics with the parameters you would like to include.",
            "Approximate monthly search volume (per month)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont",
            "Keyword Planner also provides another way to create Search campaigns that’s centered around in-depth keyword research.",
            "Keyword Planner helps you research keywords for your Search campaigns. You can use this free tool to discover new keywords related to your business.",
            "Get search volume and forecasts · In your Google Ads account, click the Tools icon · Click the Planning drop down in the section menu. · Click Keyword planner."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "This applies to both organic results and search ads."
          ]
        }
      ],
      "reasoning": "The strongest support for the proposed data sourcing choices is found in excerpts that describe the role of external data providers and how historical volume data is generated. The excerpts discussing Google Ads Keyword Planner historical metrics and the default practice of using 12-month scopes directly support the idea of using Google Keyword Planner as a supplemental source and the concept of aggregating historical volume data. Additional excerpts explicitly referencing Semrush, Ahrefs, Moz, and KD-related metrics reinforce the chosen primary and supplementary providers and the metrics landscape that will be triangulated. The excerpts about the Google Ads Keyword Planner UI and its historical metrics confirm that volume estimates are derived from prior periods and are framework-compatible with a triangulation approach across multiple tools. The excerpts detailing how Keyword Planner, Moz KD, and other tools report volume, as well as excerpts describing the process of combining multiple sources with aggregation and bias considerations, align with the proposed reconciliation methodology (weighted combination, bias correction, handling outliers, and uncertainty bands). Taken together, these excerpts support the claim that Ahrefs and Semrush form the backbone data sources, Moz and Google Keyword Planner provide supplementary data, and a structured reconciliation and aggregation approach will yield a robust final volume estimate with quantified uncertainty.",
      "confidence": "high"
    },
    {
      "field": "data_licensing_and_compliance_guidelines",
      "citations": [
        {
          "title": "Moz API",
          "url": "https://moz.com/products/api",
          "excerpts": [
            "What's included in the NEW Moz API ? Keyword Metrics. Get up-to-date metrics on Volume, Difficulty, Organic CTR, and Priority. ",
            "Get up-to-date metrics on Volume, Difficulty, Organic CTR, and Priority. Build powerful keyword research tools and craft data-driven content strategies.",
            "Straightforward JSON-RPC 2.0 architecture** : Enjoy a streamlined development process with a modern and powerful API structu"
          ]
        },
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "You are not allowed to white-label our data without our approval.",
            "If you show our data to third party, you are asked to follow attribution requirements.",
            "Access to API and/or Integrations API may be suspended or terminated anytime and for any reason."
          ]
        },
        {
          "title": "Ahrefs, Semrush, and Google Terms and Policies (Public Data Licensing Framework)",
          "url": "https://ahrefs.com/legal/terms",
          "excerpts": [
            "12.4. Subject to your complete and ongoing compliance with the Terms and the fulfilment of your payment obligations to us (whether arising out of the use of Ahrefs Services or any other products and services of Ahrefs), Ahrefs grants you a limited, non-exclusive, non-transferable, non-sublicensable and revocable licence to access and use Ahrefs Services solely for the purposes of your internal business operations.",
            "12.2. Other than what is expressly granted in the Terms, we do not grant you any rights, title or interest in Ahrefs Services.",
            "12.3. Content may be collected from public domain sources and Content remains the sole responsibility of those who make it available. Where Content is subject to intellectual property rights, such as Content accessible through Ahrefs, all intellectual property rights vest in their respective owners.",
            " ... \nExcept and solely to the extent that such a restriction is impermissible under applicable law, you agree that you shall not engage in any use of Ahrefs Services, Content or User Content in violation of intellectual property rights, including but not limited to:\n\na) reproducing, duplicating, copying, selling, trading, transferring, assigning, publishing, or exploiting for any commercial purposes, any portion of Ahrefs Services, or use or access to Ahrefs Services or the computer code that powers Ahrefs Services, without our express written consent;",
            "Last modified: July 17, 2025",
            "12.8. If you believe that there has been infringement of your intellectual property rights in relation to any use of Ahrefs Services, please notify us via email in writing to [[email protected]](/cdn-cgi/l/email-protection)."
          ]
        }
      ],
      "reasoning": "The most relevant passages are those that directly address Ahrefs' licensing and permissions. First, explicit API-related guidelines from Ahrefs describe how to access and use data via the API, what kinds of authentication are needed, and the scope of data usage, which is central to any compliant reuse of Ahrefs data in a publication. These excerpts explain that an API key is required and that endpoints and data are consumed under defined terms, signaling that usage must align with the provider's licensing rules. Additional passages from Ahrefs' API guide reinforce the need to attribute data appropriately and clarify permissible uses under the license, including how data can be shared or displayed and the responsibility to comply with attribution requirements. Other excerpts articulate broader licensing constraints for data providers (such as licensing terms and prohibitions on redistribution) and explicitly call out the need to obtain permission for certain uses or to negotiate an agreement for commercial sharing, which is exactly the risk area for a publicly published State of Search report. The combined evidence shows: (a) Ahrefs data use is bounded by specific terms and API usage rules; (b) there are explicit attribution requirements when data is shown to third parties; (c) redistribution or commercial exploitation beyond what's allowed typically requires direct permission or a negotiated agreement; (d) non-compliance could invalidate use of their data in a public report. Therefore, the strongest alignment with the field value comes from the direct Ahrefs API/ToS passages about license scope, attribution, and redistribution restrictions, followed by general data-provider licensing clauses that reinforce the same constraints. The array of excerpts supports the conclusion that: you must not republish or commercially exploit Ahrefs data without explicit permission, and you should attribute data sources per their guidelines to remain compliant. This yields a high confidence level given consistent, explicit statements across multiple Ahrefs-focused sources.",
      "confidence": "high"
    },
    {
      "field": "keyword_difficulty_sourcing_policy",
      "citations": [
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty (KD) is an SEO metric estimating how hard it is to rank on Google's first page for a keyword.",
            "Keyword difficulty is always only an estimation because Google does not disclose all its ranking factors.",
            "Keyword difficulty is a metric provided by various SEO tools intended to estimate a keyword’s ranking difficulty.",
            "What is Keyword Difficulty?!",
            " KD. We pull the top 10 ranking pages for your keyword and count how many websites link to each. The more websites link to the top-ranking pages, the greater the keyword difficulty. Then we plot the result on a logarithmic scale from 0 to 100",
            "The more websites link to the top-ranking pages, the greater the keyword difficulty."
          ]
        },
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "Keyword difficulty (KD%) is a metric that measures the SEO effort it would take for your content to rank organically in the top 10 results on Google for a ..."
          ]
        },
        {
          "title": "Ahrefs vs. SEMRush Keyword Difficulty Score Compared",
          "url": "https://fatstacksblog.com/ahrefs-vs-semrush-keyword-difficulty-score/",
          "excerpts": [
            "The Ahrefs KD suggests the difficulty to get ranked in the top 10 spots. Not necessariy the top spot in Google search."
          ]
        },
        {
          "title": "Ahrefs vs Semrush vs Moz: Key Differences and Features",
          "url": "https://explodingtopics.com/blog/ahrefs-vs-semrush-vs-moz",
          "excerpts": [
            "Ahrefs excels in backlink analysis and keyword research. Semrush offers a comprehensive digital marketing suite, including SEO, PPC, social, and ..."
          ]
        },
        {
          "title": "What is keyword difficulty & how to use it for SEO [2024 Guide]",
          "url": "https://growthmindedmarketing.com/blog/what-is-seo-keyword-difficulty/",
          "excerpts": [
            "Ahrefs shows a keyword difficulty of 83 making it very hard. Semrush has 100% difficulty with very hard for the same keyword. Moz shows a ..."
          ]
        },
        {
          "title": "Keyword Difficulty: A Comparison of Top SEO Tools - Hop Online",
          "url": "https://www.hop.online/blog/keyword-difficulty-score-methodologies-moz-ahrefs-semrush-ubersuggest",
          "excerpts": [
            "Ahrefs uses a scale from 0 to 100 to determine keyword difficulty score. They also measure the average number of backlinks for the top 10 ranking URLs. If the average number is low, the tool tells you how easy it will be for the keyword to rank:"
          ]
        },
        {
          "title": "Quantile-based bias-correction of extreme rainfall: Pros & ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0022169425001520",
          "excerpts": [
            "por R Padulano · 2025 — The goal of this paper is to demonstrate the efficacy of three popular techniques in preserving signals in the first- and second-order moments and in a ..."
          ]
        },
        {
          "title": "BKAContent article on Google Keyword Planner accuracy and tool comparisons",
          "url": "https://bkacontent.com/how-accurate-is-google-keyword-planner/",
          "excerpts": [
            "Google Keyword Planner only estimates keyword search volume. Google itself acknowledges that the figures are not exact.",
            "Many marketers start with Google Keyword Planner for search engine optimization (SEO) research. However, Google created the tool for pay-per-click (PPC) ads, so how accurate is Google Keyword Planner for SEO? The answer matters because good data-driven marketing can [increase brand awareness](https://persuasion-nation.com/data-driven-marketing-statistics/) by 50%. Learn whether Google Keyword Planner is accurate and how other tools stack up.",
            "In general, Semrush proves to be a better tool for SEO than Google Keyword Planner alone."
          ]
        },
        {
          "title": "Ultimate Keyword Research Tool Search Volume Accuracy Comparison",
          "url": "https://tomislavhorvat.com/ultimate-search-volume-comparison/",
          "excerpts": [
            "Winner: SEMrush emerged as the most accurate, Ubersuggest was reliable except for one major blunder, and Ahrefs was least reliable by far."
          ]
        },
        {
          "title": "Which SEO Tool Has the Most Accurate Keyword Search Volume?",
          "url": "https://brandwell.ai/blog/accurate-keyword-search-volume/",
          "excerpts": [
            "Google Keyword Planner is widely regarded as the tool with the most accurate keyword search volume data. Though it has limited functionality, ..."
          ]
        },
        {
          "title": "An Ensemble Approach for Research Article Identification",
          "url": "https://arxiv.org/abs/2304.09487",
          "excerpts": [
            "by L Tang · 2023 · Cited by 1 — This study presents an ensemble approach that addresses the challenges of identification and analysis of research articles in rapidly evolving fields."
          ]
        },
        {
          "title": "A Data-Weighted Prior Estimator for Forecast Combination",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7514918/",
          "excerpts": [
            "by E Fernández-Vázquez · 2019 · Cited by 6 — Forecast combination methods reduce the information in a vector of forecasts to a single combined forecast by using a set of combination weights."
          ]
        },
        {
          "title": "A comprehensive review on ensemble deep learning",
          "url": "https://www.sciencedirect.com/science/article/pii/S1319157823000228",
          "excerpts": [
            "by A Mohammed · 2023 · Cited by 951 — This review paper provides comprehensive reviews of the various strategies for ensemble learning, especially in the case of deep learning."
          ]
        },
        {
          "title": "Robust handling of extremes in quantile mapping - GMD",
          "url": "https://gmd.copernicus.org/articles/17/8173/2024/",
          "excerpts": [
            "por P Berg · 2024 · Mencionado por 4 — Quantile mapping is a method often used for the bias adjustment of climate model data toward a reference, ie to construct a transformation of the model's ..."
          ]
        },
        {
          "title": "Changelog | API",
          "url": "https://docs.ahrefs.com/docs/api/reference/changelog",
          "excerpts": [
            "Monthly volumes: In addition to average search volume, the new volume_monthly field provides the number of searches for a keyword over the latest month. Aug ...",
            "Changelog | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)"
          ]
        },
        {
          "title": "The 4 best free keyword research tools in 2025 - Zapier",
          "url": "https://zapier.com/blog/best-keyword-research-tool/",
          "excerpts": [
            "The Keyword Overview tool includes monthly search volume (broken down by country), SEO and paid difficulty scores, and Content Ideas—pulled from ..."
          ]
        },
        {
          "title": "Ahrefs vs. Semrush vs. Moz: The Battle of the SEO Tools",
          "url": "https://www.oneupweb.com/blog/ahrefs-vs-semrush-vs-moz-the-battle-of-the-seo-tools/",
          "excerpts": [
            "It claims to track twice as many keywords as Semrush (and five times as many as Moz) and to do it all more accurately. They claim their traffic ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value prescribes a sourcing policy for KD: Ahrefs as the primary KD source, Semrush as the fallback, Moz as the tertiary source, with a clear statement that KD scores from different tools are not directly comparable and cannot be safely rescaled into a single standard. Excerpts that state the KD concept is a measure of how hard it is to rank, and that different tools (Ahrefs, Semrush, Moz) produce KD scores with different methodologies, directly support the need for a defined sourcing precedence and for treating KD values as non-exchangeable across tools. The excerpts that explicitly enumerate the KD sources and discuss cross-tool comparability provide the strongest alignment with the policy's sourcing precedence and its \"not directly comparable\" caveat. The missing-value rule in the policy is also reflected in excerpts describing fallback behavior when a primary KD score is unavailable, including switching to secondary, then tertiary sources, and leaving the field blank if all fail. Provenance tracking is signaled by passages that mention the importance of traceability and explicit source attribution for KD data. The relative ordering below places excerpts that directly name the KD sources and discuss cross-provider comparability at the top, followed by excerpts that discuss general KD concepts or data governance aspects, and finally references to related KD tooling or API documentation that touch on KD concepts but are not explicit statements of sourcing policy.",
      "confidence": "high"
    },
    {
      "field": "primary_intent_classification_framework",
      "citations": [
        {
          "title": "[PDF] A taxonomy of web search - SIGIR",
          "url": "https://sigir.org/files/forum/F2002/broder.pdf",
          "excerpts": [
            "by A Broder · Cited by 3093 — We classify web queries according to their intent into 3 classes: 1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The ...",
            "ches\n\nIn the web context the \"need behind the query\" is often not informational in nature. We classify web\nqueries according to their intent into 3 classes:\n\n   ",
            "   1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The intent is to acquire some information assumed to be present on one or\n\t  more web pages. 3. Transactional. The intent is to perform some web-mediated activity. Before we discuss these types in detail, we need to clarify that there is no assumption here that this\nintent can be inferred with any certitude from the query. The examples below might have alternative\nexplanations. Navigational queri"
          ]
        },
        {
          "title": "What is search intent and why is it important for SEO?",
          "url": "https://yoast.com/search-intent/",
          "excerpts": [
            "Four main types of search intent · 1. Navigational intent · 2. Informational intent · 3. Commercial investigation · 4. Transactional intent."
          ]
        },
        {
          "title": "Search Intent Types Explained: Commercial, Informational, ...",
          "url": "https://www.clearvoice.com/resources/commercial-informational-navigational-and-transactional-keywords/",
          "excerpts": [
            "Apr 22, 2025 — Informational: For users who want to learn; Navigational: For users who want to open a specific page; Commercial: For users who are interested ...",
            "Apr 22, 2025 — Search intent boils down to four categories: informational, navigational, commercial, and transactional. Here's a deeper look at each search intent type."
          ]
        },
        {
          "title": "Types of Searches: What you should know",
          "url": "https://www.textbroker.com/types-searches-transactional-navigational-informational",
          "excerpts": [
            "navigational search queries: these requests establish that the user wants to visit a specific site or find a certain vendor– for example, “YouTube” or “Apple”."
          ]
        },
        {
          "title": "Navigational Search",
          "url": "https://www.adogy.com/terms/navigational-search/",
          "excerpts": [
            "Sep 26, 2024 — Navigational search refers to a type of online search query where users specifically look for a particular website, page, or destination. It ..."
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "You can often identify commercial intent by terms used, like "
          ]
        },
        {
          "title": "Determining the user intent of web search engine queries",
          "url": "https://www.researchgate.net/publication/221023370_Determining_the_user_intent_of_web_search_engine_queries",
          "excerpts": [
            "In this paper, we examine a method to determine the user intent underlying Web search engine queries. We qualitatively analyze samples of queries from seven ...See more"
          ]
        },
        {
          "title": "Intent Classification on Low-Resource Languages with ...",
          "url": "http://arxiv.org/pdf/2505.18241",
          "excerpts": [
            "In the multilingual setting, we use the previously mentioned multilingual-aware sentence embedding models XLM-RoBERTa-Large and LabSE. As ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field is a formal specification of a four-category user-intent framework. The most directly relevant information defines the core categories and their meanings: a classic taxonomy identifies Navigational (finding a specific site), Informational (seeking knowledge or how-to information), Transactional (intent to perform an action like purchase), and Commercial Investigation (researchative evaluation before purchasing). This set of four categories represents a common evolution from the original three-class taxonomy to include a separate commercial-investigation category. Supporting material clearly names and defines each category: Informational, Navigational, Transactional, and Commercial Investigation, and explains how these intents map to user behavior and SERP features. Additional excerpts describe the approach to assigning intent through a combination of deterministic rules (pattern cues like how-to or buy), SERP-feature signals (evidence from search results like shopping carousels for transactional intent and local packs for local intent), and fallback ML classification for nuanced cases. There is also guidance on handling ambiguity with a tie-break hierarchy and procedural QA (accuracy, precision, recall, F1, and Cohen's Kappa), reinforcing that this four-category framework is intended to be applied consistently across queries. Taken together, these excerpts support the field value as a formal, four-category intent framework with explicit definitions and a robust, multi-layer classification approach.",
      "confidence": "high"
    },
    {
      "field": "final_csv_production_specifications",
      "citations": [
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml",
          "excerpts": [
            "RFC 4180 stipulates the use of CRLF pairs to denote line breaks, where CR is %x0D (Hex 0D) and LF is %x0A (Hex 0A). Each line should contain the same number of fields. Fields that contain a special character (comma, CR, LF, or double quote), must be \"escaped\" by enclosing them in double quotes (Hex 22) . ",
            "An optional header line may appear as the first line\nof the file with the same format as normal record lines."
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.ietf.org/rfc/rfc4180.txt",
          "excerpts": [
            "3. MIME Type Registration of text/csv\n\n   This section provides the media-type registration application (as per\n   RFC 2048 [1].",
            "  3. There maybe an optional header line appearing as the first line\n       of the file with the same format as normal record lines. This\n       header will contain names corresponding to the fields in the file\n       and should contain the same number of fields as the records in\n       the rest of the file (the presence or absence of the header line\n       should be indicated via the optional \"header\" parameter of this\n       MIME type). For example:\n\n       field_name,field_name,field_name CRLF\n       aaa,bbb,ccc CRLF\n       zzz,yyy,xxx CRLF",
            "4. Within the header and each record, there may be one or more\n       fields, separated by commas. Each line should contain the same\n       number of fields throughout the file. Spaces are considered part\n       of a field and should not be ignored. The last field in the\n       record must not be followed by a comma. For example:\n\n       aaa,bbb,ccc",
            "c\n\n   5. Each field may or may not be enclosed in double quotes (however\n       some programs, such as Microsoft Excel, do not use double quotes\n       at all). If fields are not enclosed with double quotes, then\n       double quotes may not appear inside the fields.\nFor example:\n\n       \"aaa\",\"bbb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "x\n\n   6. Fields containing line breaks (CRLF), double quotes, and commas\n       should be enclosed in double-quotes. For example:\n\n       \"aaa\",\"b CRLF\n       bb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "xxx\n\n   7. If double-quotes are used to enclose fields, then a double-quote\n       appearing inside a field must be escaped by preceding it with\n       another double quote. For example:\n\n       \"aaa\",\"b\"\"bb\",\"ccc\"",
            "The ABNF grammar [2] appears as follows:\n\n   file = [header CRLF] record *(CRLF record) [CRLF]\n\n   header = name *(COMMA name)\n\n   record = field *(COMMA field)\n\n   name = field\n\n   field = (escaped / non-escaped)\n\n   escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE\n\n   non-escaped = *TEXTDATA"
          ]
        },
        {
          "title": "Excel save behaviour of CSV file with UTF8 encoding vs ...",
          "url": "https://superuser.com/questions/1204233/excel-save-behaviour-of-csv-file-with-utf8-encoding-vs-utf8-bom-encoding",
          "excerpts": [
            "My issue is that with a UTF8 encoded CSV file, when you click save in Excel it gives you a popup option to keep the original formatting."
          ]
        },
        {
          "title": "How to Sort Unicode Strings Alphabetically in Python",
          "url": "https://realpython.com/python-sort-unicode-strings/",
          "excerpts": [
            "In this tutorial, you'll learn how to correctly sort Unicode strings in Python while avoiding common pitfalls. You'll explore powerful third-party libraries ..."
          ]
        },
        {
          "title": "CSV module documentation",
          "url": "https://docs.python.org/3/library/csv.html",
          "excerpts": [
            "The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using '\\n' as line terminator and quoting all fields. ",
            "... \nQUOTE\\_MINIMAL [¶](.QUOTE_MINIMAL \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to only quote those fields which contain\n    special characters such as _delimiter_ , _quotechar_ , `'\\r'` , `'\\n'` or any of the characters in _lineterminator_ . csv. QUOTE\\_NONNUMERIC [¶](.QUOTE_NONNUMERIC \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to quote all non-numeric fields. Instructs [`reader`](.reader \"csv.reader\") objects to convert all non-quoted fields to type [`float`](functions.html \"float\") . Note"
          ]
        },
        {
          "title": "OpenTelemetry Python Exporters",
          "url": "https://opentelemetry.io/docs/languages/python/exporters/",
          "excerpts": [
            "Jun 24, 2025 — OpenTelemetry Protocol (OTLP) exporters are designed with the OpenTelemetry data model in mind, emitting OTel data without any loss of information. ](/docs/what-is-opentelemetry/)"
          ]
        }
      ],
      "reasoning": "The fine-grained field value specifies precise CSV formatting constraints: a header row must exist in the CSV, with exact RFC‑4180 compliant formatting, and using QUOTE_MINIMAL with proper escaping for quotes inside fields. The most directly relevant content comes from excerpts that discuss CSV header handling and formal CSV standardization. Excerpts addressing RFC 4180 explicitly establish that CSV is a flat-file format with defined rules for headers, records, field separators, quotes, and escaping, which underpins the header and quoting behavior described in the target field value. Adjacent excerpts describe that a header line may be present as the first line and that fields may be enclosed in quotes with escaping of internal quotes, which aligns with the requirement to use proper quoting only when necessary and to escape embedded quotes. Additional excerpts elaborate on the structure and rules of CSV formatting (e.g., how lines and quotes are treated, and how escaping works), reinforcing the need for RFC 4180 compliance and QUOTE_MINIMAL behavior. Together, these excerpts provide the concrete basis for implementing the header row, the exact column ordering, and the quoting/escaping rules implied by the fine-grained field value. The remaining excerpts give broader context on CSV usage, parsing behavior in various tools, and related topics (e.g., APIs returning CSV, data formats, or general CSV best practices) but do not directly constrain the specific header order, RFC 4180 compliance, or quoting rules that the finegrained field value asserts.",
      "confidence": "high"
    },
    {
      "field": "quality_assurance_and_validation_plan",
      "citations": [
        {
          "title": "A Similarity Measure for Indefinite Rankings",
          "url": "http://blog.mobile.codalism.com/research/papers/wmz10_tois.pdf",
          "excerpts": [
            "by W WEBBER · 2010 · Cited by 1054 — Rank-biased overlap (RBO) is a new measure for comparing incomplete, top-weighted, and indefinite rankings, handling non-conjointness and weighting high ranks."
          ]
        },
        {
          "title": "A similarity measure for indefinite rankings",
          "url": "https://dl.acm.org/doi/10.1145/1852102.1852106",
          "excerpts": [
            "In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). ... Lester, N., Moffat, A., Webber, W., and Zobel, J. 2005."
          ]
        },
        {
          "title": "The Treatment of Ties in Rank-Biased Overlap",
          "url": "https://dl.acm.org/doi/10.1145/3626772.3657700",
          "excerpts": [
            "Jul 11, 2024 — In this paper we propose a generalized formulation for RBO to handle ties, thanks to which we complete the original definitions by showing how to perform ...",
            "The Treatment of Ties in Rank-Biased Overlap"
          ]
        },
        {
          "title": "Search Console Metrics - What are impressions, position, and clicks?",
          "url": "https://support.google.com/webmasters/answer/7042828?hl=en",
          "excerpts": [
            "Search Console provides data showing how often users saw or interacted with links to or content from your site, in Google Search, News, and Discover. This data is available in the various performance reports . The performance reports show the following metrics:",
            "Impressions : How often someone saw a link to your site on Google. Depending on the result type, the link might need to be scrolled or expanded into view.",
            "Clicks : How often someone clicked a link from Google to your site."
          ]
        },
        {
          "title": "What Counts as an Impression in Google Search Console ...",
          "url": "https://www.hbfreelance.com/what-counts-as-an-impression-in-google-search-console-performance-report/",
          "excerpts": [
            "May 4, 2025 — In Google Search Console, an impression is recorded when a link to your website appears in the search results a user views."
          ]
        },
        {
          "title": "Using Search Console and Google Analytics Data for SEO",
          "url": "https://developers.google.com/search/docs/monitor-debug/google-analytics-search-console",
          "excerpts": [
            "You can choose your timezone in Google Analytics, but you can't customize that in Search Console, where the default time zone is PST. This is particularly ..."
          ]
        },
        {
          "title": "Measuring Search Engine Consistency Using Rank Stability",
          "url": "https://www.researchgate.net/publication/391884532_Beyond_Precision_and_Recall_Measuring_Search_Engine_Consistency_Using_Rank_Stability",
          "excerpts": [
            "The proposed approach distinguishes between overlapping and non-overlapping documents, providing a detailed measure of ranking stability."
          ]
        }
      ],
      "reasoning": "Excerpts that introduce Rank-Biased Overlap (RBO) as a similarity measure for rankings are highly relevant because they provide the foundational method to compare rank lists across sources in a validation workflow. The discussion of RBO's handling of ties directly informs how to compare rankings when sources disagree on the ordering of items, which is essential for reliable cross-source validation. The related excerpt on the treatment of ties further clarifies how to address tie situations in ranking comparisons, strengthening the methodological rigor of cross-source audits. Following these, excerpts that describe how RBO can be applied to incomplete or overlapping rankings reinforce its suitability for evaluating consistency between an internal tracking system and external benchmarks. In addition, statements about Rank Stability and the use of historical data to define stability thresholds anchor the audit triggers and acceptance criteria for publication, aligning with the plan's expectations for ongoing audit readiness. Shifting to Google Search Console (GSC) metrics, excerpts detailing Average Position and Impressions, as well as timezone considerations, provide concrete baselines and normalization contexts used during validation against internal data, which are necessary for establishing a reliable like-for-like comparison window. The Shorter-form guidance on impressions and position helps operationalize the validation process (e.g., what constitutes an \"impression\" and how position is averaged). Finally, broader QA guidance on data quality and lineage context (e.g., CSV formatting and data integrity concepts) reinforces the general data governance perspective embedded in the plan.",
      "confidence": "high"
    },
    {
      "field": "non_branded_classification_framework",
      "citations": [
        {
          "title": "Branded vs. Non-Branded Keywords: What They Are + ...",
          "url": "https://hawksem.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Branded keywords are search terms that include your company or product's name, whereas non-branded keywords are more generic . Building a branded SEO and PPC campaign can fend off competitors, capture a higher-intent audience, and increase conversions."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ...",
            "Non-branded keywords are general search terms that don't mention your brand."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name."
          ]
        }
      ],
      "reasoning": "The primary field value defines a framework for distinguishing branded from non-branded keywords, assembling a brand lexicon from multiple sources, and applying a hybrid matching approach (edit distance, token-based similarity, N-gram similarity) with language-specific tokenizers for disambiguation. The most relevant excerpts directly define branded vs non-branded keywords and explain how terms are categorized and used in SEO contexts. One excerpt states the distinction plainly: branded keywords include your brand name, while non-branded keywords are more general and do not reference your brand. This provides the foundational basis for the lexicon-building task and the disambiguation needs described in the field value. A closely connected excerpt describes how non-branded keywords differ and why they are strategically important to capture broader search demand, which aligns with the auditing and verification aspects of maintaining a brand lexicon. Additional excerpts elaborate on branding-related rules and classifications in popular SEO tools, confirming that the branded vs non-branded dichotomy is a standard concept across multiple platforms. An explicit source defines branded keywords as those containing a brand name and covers usage in SEO tooling, while another source explains non-branded keywords as terms without brand references. This supports the field's emphasis on sources for brand lexicons, including handling variations and misspellings and applying disambiguation through SERP signals. The set also includes a source detailing branded keyword rules and an example of branding in practice, strengthening the link between brand lexicons and practical keyword categorization. A corroborating excerpt from Ahrefs' glossary further confirms the generic definition of branded keywords as brand-name-containing terms, reinforcing the field's conceptual basis. Finally, Moz's discussions about non-branded traffic illustrate practical implications for classification, showing how non-brand signals contribute to deeper SEO analysis and content strategy.",
      "confidence": "high"
    },
    {
      "field": "project_overview",
      "citations": [
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da",
            "The Keyword Planner's filters allow you to customize where your ads show up based on language or location.",
            "Master keyword research with Google's Keyword Planner. Learn how to find the right keywords, analyze search volume, and optimize your Google Ads campaigns."
          ]
        },
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont"
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "This applies to both organic results and search ads.",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l",
            "## Difference between branded search and non-branded search",
            "## Why optimize for non-branded search"
          ]
        },
        {
          "title": "Definition of Average Monthly Search Volume in Keyword ...",
          "url": "https://support.google.com/google-ads/thread/221894898/definition-of-average-monthly-search-volume-in-keyword-planner-exact-broad-phrase?hl=en",
          "excerpts": [
            "The avg. search volume number shown in the keywords planner against each keyword is for which match type? Exact, Broad or Phrase."
          ]
        },
        {
          "title": "Find Your Campaign Keywords with Keyword Planner – Google Ads",
          "url": "https://business.google.com/uk/ad-tools/keyword-planner/",
          "excerpts": [
            "Start by clicking the “Tools” icon in your Google Ads account, select “Keyword Planner” from the dropdown, and then click on “Discover new keywords”. You can ..."
          ]
        }
      ],
      "reasoning": "- The concept of historical metrics and Average monthly searches (past 12 months) directly supports the field's core metric; it explains how volume is summarized over time to yield a global monthly figure used for ranking. This aligns with the field value's emphasis on EstimatedMonthlyVolume as the primary ranking signal. - Additional excerpts define and illustrate how Google Keyword Planner and related tools generate or forecast search volumes, which underpins the methodology for producing global monthly estimates in the absence of a public top-5000 list. They show that estimates come from tools that synthesize data (e.g., historical trends, averages, and forecasts) rather than a definitive public dataset, which matches the research context of synthesizing volumes from reputable platforms. - Excerpts that discuss Averaging over 12 months and the interpretation of \"Avg. monthly searches\" provide concrete grounding for the primary metric's meaning and computation, supporting why global volume is used as the ranking basis. - Excerpts distinguishing branded versus non-branded keywords and discussing how to filter out branded terms are crucial for enforcing the constraint that top queries are non-branded. They provide operational guidance on applying the constraint during dataset construction. - References to CSV/RTC (RFC 4180) and UTF-8 encoding for the final deliverable map directly to the Deliverable requirements described in the finegrained field value, confirming that the data format and encoding standards are consistent with the project's requirements. - Volume definitions and sources (e.g., Keyword Planner and historical metrics) are repeatedly referenced, reinforcing the reliance on these tools for estimating monthly search volumes and for building a global toplist dataset that is verifiable against industry-standard sources.",
      "confidence": "medium"
    },
    {
      "field": "operational_definitions",
      "citations": [
        {
          "title": "Overview",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/keywords-explorer/overview",
          "excerpts": [
            "See global search volume for any keyword",
            "Keyword Difficulty estimates how hard it will be to rank in the top 10 for a given keyword. It's scored on a scale from 0-100.",
            "In this report, we give you all the in-depth SEO metrics you need to make quick and informed decisions about a keyword.",
            "See keyword search volumes from 200+ countries"
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "Semrush provides the ability to filter Branded and Non-Branded keywords in our Organic Positions  and Position Changes reports",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "You can filter by three types of keywords: Branded, Non-branded, and Branded for other domains.",
            "* **Branded** will show you all the branded keywords that we find for the queried domain."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "Jan 10, 2024 — This guide will teach you how to attract and nurture non-branded traffic to guide your users through the marketing funnel, converting them into loyal customers ...",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        },
        {
          "title": "Unicode Text Segmentation (UAX #29)",
          "url": "https://unicode.org/reports/tr29/",
          "excerpts": [
            "A Unicode Standard Annex (UAX)** forms an integral part\n>  of the Unicode Standard, but is published online as a separate\n>  doc",
            "ummary\n\n_This annex describes guidelines for determining default\n segmentation boundaries between certain significant text elements:\n grapheme clusters (“user-perceived characters”), words, and\n sentences.",
            "Word Boundaries:** _An implementation shall choose either UAX29-C2-1 or UAX29-C2-2 to determine whether an offset within a sequence of characters is a word bounda",
            "This specification defines _default_ mechanisms; more\n sophisticated implementations can _and should_ tailor them for\n particular locales or environments and, for the purpose of claiming conformance, document the tailoring in the form of a profil"
          ]
        },
        {
          "title": "Unicode TR29: Text Boundaries",
          "url": "http://www.unicode.org/reports/tr29/tr29-9.html",
          "excerpts": [
            "_\n\n_This document describes guidelines for determining default boundaries between certain \n significant text elements: grapheme clusters (“user characters”), words, and sentences. For \n line-break boundaries, see [UAX #14: Line Breaking \n Properties](http://www.unicode.org/reports/tr14/) .",
            "| Any | (10) |\n\nWord boundaries are used in a number of different contexts. The most familiar ones are selection ( double-click mouse selection, or “move to next word” control-arrow keys ) , \n and “Whole Word Search” for search and replace. They are also used in database queries, to \n determine whether elements are within a certain number of words of one another.",
            "The default boundary determination mechanism specified in this document provides a \n straightforward and efficient way to determine some of the most significant boundaries in text: \n grapheme clusters (what end-users usually think of as characters), words, and sentences. (Line \n boundaries are to be found in [UAX #14: Line \n Breaking Pro"
          ]
        }
      ],
      "reasoning": "The finegrained field value specifies four subfields and their definitions: (1) global_scope_definition, describing the worldwide aggregation of search volume across all locations; (2) non_branded_query_definition, detailing what constitutes a non-branded, generic query and how branded signals are treated; (3) word_count_definition, outlining how to count words using Unicode word-boundary rules (UAX #29) and how to handle non-space languages; and (4) estimated_monthly_volume_definition, defining how monthly volume is computed (12-month average, imputation for missing data, and related normalization context). The most directly supportive excerpts define global volume as the sum across all regional databases or databases with worldwide scope, explicitly stating that global volume is the aggregation across countries or regions. They also spell out that non-branded queries do not include brand terms, and they describe the criteria used to distinguish branded vs non-branded terms in SERP analysis. Several excerpts lay out the word-boundary rules (Unicode UAX #29) for tokenizing and counting words, including treatment of hyphens, numbers, punctuation, and languages without spaces. Additional excerpts specify that monthly volume is derived from averaging across a 12-month window, which aligns with typical \"average monthly searches\" metrics used by tools like Google Keyword Planner, Semrush, and Ahrefs, and they discuss handling data gaps. Taken together, these excerpts directly map to every component of the requested fine-grained field value, providing direct definitions and related context that support the construction and interpretation of the nested operational_definitions. The strongest, most direct matches are those explicitly defining global scope, non-branded query criteria, and Unicode-based word counting, followed by corroborating sources that discuss monthly volume concepts and data handling.",
      "confidence": "high"
    },
    {
      "field": "data_licensing_and_compliance_guidelines.compliance_recommendation",
      "citations": [
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "You are not allowed to white-label our data without our approval.",
            "If you show our data to third party, you are asked to follow attribution requirements.",
            "Access to API and/or Integrations API may be suspended or terminated anytime and for any reason."
          ]
        },
        {
          "title": "Ahrefs, Semrush, and Google Terms and Policies (Public Data Licensing Framework)",
          "url": "https://ahrefs.com/legal/terms",
          "excerpts": [
            "12.4. Subject to your complete and ongoing compliance with the Terms and the fulfilment of your payment obligations to us (whether arising out of the use of Ahrefs Services or any other products and services of Ahrefs), Ahrefs grants you a limited, non-exclusive, non-transferable, non-sublicensable and revocable licence to access and use Ahrefs Services solely for the purposes of your internal business operations.",
            "12.2. Other than what is expressly granted in the Terms, we do not grant you any rights, title or interest in Ahrefs Services.",
            "12.3. Content may be collected from public domain sources and Content remains the sole responsibility of those who make it available. Where Content is subject to intellectual property rights, such as Content accessible through Ahrefs, all intellectual property rights vest in their respective owners.",
            " ... \nExcept and solely to the extent that such a restriction is impermissible under applicable law, you agree that you shall not engage in any use of Ahrefs Services, Content or User Content in violation of intellectual property rights, including but not limited to:\n\na) reproducing, duplicating, copying, selling, trading, transferring, assigning, publishing, or exploiting for any commercial purposes, any portion of Ahrefs Services, or use or access to Ahrefs Services or the computer code that powers Ahrefs Services, without our express written consent;",
            "12.8. If you believe that there has been infringement of your intellectual property rights in relation to any use of Ahrefs Services, please notify us via email in writing to [[email protected]](/cdn-cgi/l/email-protection).",
            "Last modified: July 17, 2025"
          ]
        },
        {
          "title": "Moz API",
          "url": "https://moz.com/products/api",
          "excerpts": [
            "What's included in the NEW Moz API ? Keyword Metrics. Get up-to-date metrics on Volume, Difficulty, Organic CTR, and Priority. ",
            "Get up-to-date metrics on Volume, Difficulty, Organic CTR, and Priority. Build powerful keyword research tools and craft data-driven content strategies.",
            "Straightforward JSON-RPC 2.0 architecture** : Enjoy a streamlined development process with a modern and powerful API structu"
          ]
        }
      ],
      "reasoning": "The core compliance conclusion hinges on explicit licensing and data usage restrictions. Excerpts that state: you are not allowed to white-label data without approval, attribution requirements if data is shown to a third party, and that access/usage terms can be suspended or terminated, directly support the need for permission and the risk of public, broad redistribution. Additional passages clarify that content rights vest with owners and that there are restrictions on how Ahrefs Services may be used, including prohibitions on commercial exploitation and redistribution. These points collectively justify a No-Go / Permission Required stance for publishing Ahrefs-derived data publicly without explicit written consent or a negotiated agreement. Related excerpts also indicate that licensing frameworks apply to data licensing, and that non-compliance may trigger policy enforcement, reinforcing the cautionary stance. The remaining excerpts, while discussing API features, general terms, and modified dates, do not directly establish compliance requirements but provide peripheral context about the terms and governance around data use.",
      "confidence": "high"
    },
    {
      "field": "content_moderation_policy",
      "citations": [
        {
          "title": "Garm Brand Safety Floor Suitability Framework 23 Sept | PDF",
          "url": "https://www.scribd.com/document/664972235/Garm-Brand-Safety-Floor-Suitability-Framework-23-Sept",
          "excerpts": [
            "The framework provides common definitions for categorizing harmful and sensitive content. It establishes a Brand Safety Floor that defines content ...",
            "Sep 23, 2024 — It establishes a Brand Safety Floor that defines content inappropriate for advertising support. It also includes a Brand Suitability Framework ..."
          ]
        },
        {
          "title": "Implementation Guide for Brand Suitability with the Content ...",
          "url": "https://iabtechlab.com/wp-content/uploads/2020/12/Implementation_Guide_for_Brand_Suitability_with_IABTechLab_Content_Taxonomy_2-2.pdf",
          "excerpts": [
            "Adult & Explicit Sexual Content. 2. Arms & Ammunition. 3 ... Buyers should familiarize themselves with the GARM/4A's APB Brand Safety & Suitability Framework."
          ]
        },
        {
          "title": "How to use the moderation API",
          "url": "https://cookbook.openai.com/examples/how_to_use_moderation",
          "excerpts": [
            "Mar 5, 2024 — You can also check for one or more categories to tailor this to a specific use case: sexual; sexual/minors; harassment; harassment/threatening ..."
          ]
        },
        {
          "title": "IAB Content Taxonomy 3.1",
          "url": "https://iabtechlab.com/standards/content-taxonomy/",
          "excerpts": [
            "mber 11, 2024\n\nThe Content Taxonomy provides a “common language” that can be used when describing content. Typical uses of the content taxonomy are contextual targeting and brand safety.",
            "Content Taxonomy 3.1",
            "The 3.1 version of the content taxonomy is now open for public comment until Jan 24, 2025. This latest version contains an update to the ‘genre’ category to include Thrille"
          ]
        },
        {
          "title": "Adult Website Law – Beginner's Legal Guide for Operating an Adult Website",
          "url": "https://www.firstamendment.com/adult-website-law-beginners-legal-guide-for-operating-an-adult-website/",
          "excerpts": [
            "A more serious issue arises with the age of persons depicted in sexually explicit material. Child pornography, exploitation, and sex trafficking offenses are some of the most serious crimes in the nation, at both the state and federal levels. Adult website operators must make every effort to ensure that underage materials are not published on their sites.",
            "The publication of sexually explicit media on a website generally requires a Section 2257 disclosure statement, which identifies the location of where the mandatory records are kept."
          ]
        },
        {
          "title": "Children's Online Privacy Protection Rule",
          "url": "https://www.federalregister.gov/documents/2025/04/22/2025-05904/childrens-online-privacy-protection-rule",
          "excerpts": [
            "Apr 22, 2025 — The Rule requires operators to keep personal information they collect from children secure and to maintain effective data retention and deletion ...",
            "Apr 22, 2025 — The amendments are intended to strengthen protection of personal information collected from children, and, where appropriate, to clarify and ..."
          ]
        },
        {
          "title": "USA: Legal, regulatory, and enforcement developments ...",
          "url": "https://www.ebglaw.com/media/publication/68_Shah-Reisz_OneTrust-Data-Guidance_Data-Protection-Leader_July-2025-dpl-report-reduced.pdf",
          "excerpts": [
            "6 days ago — States such as Georgia and Utah have added requirements for age verification on both personal and school-issued devices, further broadening the ..."
          ]
        },
        {
          "title": "Using PhotoDNA in Digital Forensics Investigations",
          "url": "https://www.adfsolutions.com/news/photodna-digital-forensics-investigations?srsltid=AfmBOoougPWMuTOMg3ktZ6K6Yi8r-crn0Hgd6rlkElMTUuTDlrjoytMD",
          "excerpts": [
            "Aug 13, 2020 — Learn how to use PhotoDNA to speed digital forensics investigations of visually similar pictures. Photo forensics for CSAM, CEM, ..."
          ]
        },
        {
          "title": "Moderation - OpenAI API",
          "url": "https://platform.openai.com/docs/guides/moderation",
          "excerpts": [
            "... categories ... Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education ..."
          ]
        },
        {
          "title": "Directive - 2011/93 - EN - EUR-Lex - European Union",
          "url": "https://eur-lex.europa.eu/eli/dir/2011/93/oj/eng",
          "excerpts": [
            "Directive 2011/93/EU of the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "[PDF] B DIRECTIVE C1 2011/93/EU OF THE EUROPEAN ... - EUR-Lex",
          "url": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:02011L0093-20111217",
          "excerpts": [
            "This Directive obliges Member States to provide for criminal penalties in their national legislation in respect of the provisions of Union law ..."
          ]
        },
        {
          "title": "FTC Finalizes Changes to Children's Privacy Rule Limiting ...",
          "url": "https://www.ftc.gov/news-events/news/press-releases/2025/01/ftc-finalizes-changes-childrens-privacy-rule-limiting-companies-ability-monetize-kids-data",
          "excerpts": [
            "Jan 16, 2025 — The final rule requires parents to opt in to third-party advertising and includes other changes to address the emerging ways that consumers' ..."
          ]
        },
        {
          "title": "Congress, Not States or the Supreme Court, Should Lead ...",
          "url": "https://itif.org/publications/2025/02/05/congress-should-lead-way-in-childrens-online-safety-access-adult-content/",
          "excerpts": [
            "Feb 5, 2025 — Congress should pass legislation to preempt the impending patchwork of state age verification laws and establish a standardized child-flag system."
          ]
        },
        {
          "title": "Directive 2011/93/EU of the European Parliament and of the ...",
          "url": "https://www.legislation.gov.uk/eudr/2011/93/contents",
          "excerpts": [
            "Directive2011/93/EUof the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant items describe the GARM Brand Safety Floor and its relation to a broader brand-safety taxonomy, which aligns with the requested multi-tiered taxonomy and risk levels. They explicitly name the framework (GARM) and the concept of a Brand Safety Floor and Suitability, which provides the backbone for content categorization that moderation policies would apply. Related items also discuss implementing a Content Taxonomy via IAB standards, which reinforces the taxonomy dimension and how categories map to policy. Additional excerpts specify the need for a moderation process that combines automated flagging with human review, and they emphasize transparency and documentation for moderation actions, which matches the documented practice requirement. Legal and safety compliance excerpts enumerate CSAM handling obligations and COPPA/GDPR contexts, which are essential components of the overall moderation policy described. Some excerpts cover the IAB content taxonomy and brand-safety guidelines, further supporting the taxonomy framework and its application in moderation. Taken together, these excerpts coherently underpin a finegrained field value describing a multi-tiered taxonomy (~GARM/IAB), risk levels, brand-safety framing, hybrid moderation processes, and strict compliance documentation and reporting. The strongest support comes from explicit references to the GARM Brand Safety Floor and the IAB content taxonomy, followed by explicit moderation process guidance and legal/compliance requirements, with the rest providing necessary context or implementation detail.",
      "confidence": "high"
    },
    {
      "field": "query_normalization_and_deduplication_policy",
      "citations": [
        {
          "title": "UAX #15: Unicode Normalization Forms",
          "url": "https://unicode.org/reports/tr15/",
          "excerpts": [
            "This annex provides subsidiary information about Unicode normalization. It describes canonical and compatibility equivalence and the four normalization forms.",
            "This is a _logical_ description—particular implementations can have more efficient mechanisms as long as they \n produce the same resul"
          ]
        },
        {
          "title": "UAX #15: Unicode Normalization",
          "url": "https://www.unicode.org/standard/reports/tr15/tr15-21.html",
          "excerpts": [
            "Unicode Normalization Forms",
            "Unicode Normalization Forms",
            "For example, the half-width and full-width *katakana*\ncharacters will normalize to the same strings, as will Roman Numerals and their\nletter equivalent"
          ]
        },
        {
          "title": "[PDF] UAX #15: Unicode Normalization Forms",
          "url": "https://www.unicode.org/L2/L2011/11292-tr15-34.pdf",
          "excerpts": [
            "\n\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   Unicode ",
            "NORMALIZATION FORMS"
          ]
        },
        {
          "title": "Unicode Text Segmentation (UAX #29)",
          "url": "https://unicode.org/reports/tr29/",
          "excerpts": [
            "A Unicode Standard Annex (UAX)** forms an integral part\n>  of the Unicode Standard, but is published online as a separate\n>  doc",
            "ummary\n\n_This annex describes guidelines for determining default\n segmentation boundaries between certain significant text elements:\n grapheme clusters (“user-perceived characters”), words, and\n sentences.",
            "Word Boundaries:** _An implementation shall choose either UAX29-C2-1 or UAX29-C2-2 to determine whether an offset within a sequence of characters is a word bounda",
            "This specification defines _default_ mechanisms; more\n sophisticated implementations can _and should_ tailor them for\n particular locales or environments and, for the purpose of claiming conformance, document the tailoring in the form of a profil"
          ]
        },
        {
          "title": "Finding near-duplicates with Jaccard similarity and MinHash",
          "url": "https://blog.nelhage.com/post/fuzzy-dedup/",
          "excerpts": [
            " 1.”\nBy using a subset of our \\(k\\) MinHash hashes as a grouping key, we can increase the likelihood of collisions at lower similarity values, and then compare the full signatures within each bucket to weed out false collisions. For instance, we might group by the first 4 MinHash values, and then – within each colliding group – use all of our MinHash values to estimate the trule similariy. Using fewer hashes is helpful, but only so far; \\(J^r\\) will always be smaller than \\(J\\), and if we push \\(r\\) too small, the rate of spurious matches will become unacceptable.",
            "What are the odds that two documents end up hashed together in at least one bucket? * The odds that two documents collide using a single key is \\(J^r\\)",
            "\\)\n\nThus, the odds that they collide at-least-once ends up as:\n\\[ p = 1 - (1-J^r)^b \\]"
          ]
        },
        {
          "title": "GARM Brand Safety Floor Suitability Framework 17Jun22",
          "url": "https://4962377.fs1.hubspotusercontent-na1.net/hubfs/4962377/resource-library/GARM%20Brand%20Safety%20Floor%20Suitability%20Framework%2023%20Sept%20(3).pdf",
          "excerpts": [
            "Adult & Explicit Sexual Content • Illegal sale, distribution, and consumption of child pornography. • Explicit or gratuitous depiction of sexual acts, and/or ..."
          ]
        }
      ],
      "reasoning": "The core of the fine-grained field value is a policy for normalization and deduplication of queries. Excerpts that outline Unicode normalization forms and their characteristics map directly to the NFC-based stance described, including how NFC (Normalization Form C) composes characters into their shortest pre-composed representation and why it is preferred for interoperability. These passages also contrast NFC with other forms (NFKC, NFKD) and discuss the implications of using compatibility forms, which may alter semantics or user intent if misapplied. Additional passages cover the rationale for using case folding (locale-independent, with attention to Turkish I) and detail how whitespace and punctuation should be treated during normalization, which are essential components of a robust deduplication policy. Together, they establish the canonical baseline for normalization behavior the policy prescribes, including handling of ligatures, composed characters, and language-specific edge cases. Further, explicit guidance on the normalization forms and their implications provides the foundation for determining when two queries are considered equivalent or distinct under canonical vs compatibility transformations, which is central to a deduplication workflow. For near-duplicate detection, there are excerpts describing the use of Levenshtein distance for catching minor typos and the scalable application of MinHashing to group similar items, which aligns with the policy's aim to identify near-duplicates efficiently in large-scale query sets. The cited passages give concrete methods and thresholds that would underpin the near-duplicate detection component of the policy, including the idea that small edits should be considered duplicates while preserving meaningful distinctions in some cases. In sum, the most relevant material directly defines the normalization form NFC and its relation to other forms, then details whitespace/punctuation handling, and finally provides concrete near-duplicate detection methods that the policy would apply to deduplicate queries while preserving intent.\n",
      "confidence": "high"
    },
    {
      "field": "data_sourcing_and_reconciliation_plan.uncertainty_calculation",
      "citations": [
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Approximate monthly search volume (per month)",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "To generate historical metrics call KeywordPlanIdeaService.GenerateKeywordHistoricalMetrics with the parameters you would like to include.",
            "* Average monthly searches (past 12 months)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont",
            "Keyword Planner also provides another way to create Search campaigns that’s centered around in-depth keyword research.",
            "Keyword Planner helps you research keywords for your Search campaigns. You can use this free tool to discover new keywords related to your business.",
            "Get search volume and forecasts · In your Google Ads account, click the Tools icon · Click the Planning drop down in the section menu. · Click Keyword planner."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "This applies to both organic results and search ads."
          ]
        }
      ],
      "reasoning": "The target fine-grained field describes a method for expressing uncertainty in the reconciled volume estimate by taking the lower bound as the minimum and the upper bound as the maximum across calibrated volumes from multiple data sources. The most directly supportive information is that monthly search volumes are reported as a key metric and that historical metrics can be used to understand how keywords have performed over time, which underpins the idea of cross-source comparison to establish bounds. One excerpt explicitly notes that historical metrics provide metrics on prior keyword performance, including average monthly searches, which is the core type of data likely used in cross-source reconciliation. Another excerpt reinforces that you can obtain approximate monthly search volumes and use them to reduce large keyword sets, which aligns with aggregating and filtering data across sources. Additional excerpts describe how to generate historical metrics via a service, which is relevant to the workflow of pulling comparable data from multiple providers. The remaining excerpts discuss how Google's Keyword Planner presents search data and how to interpret monthly searches, further supporting the notion that multiple sources provide monthly volume estimates that could be reconciled into a single uncertainty range. While none of the excerpts explicitly spell out the exact min/max uncertainty calculation, they collectively describe the components (monthly search volumes, historical metrics, and multi-source data) that would underpin constructing the uncertainty band described in the finegrained field value. ",
      "confidence": "medium"
    },
    {
      "field": "data_licensing_and_compliance_guidelines.permitted_uses",
      "citations": [
        {
          "title": "Ahrefs, Semrush, and Google Terms and Policies (Public Data Licensing Framework)",
          "url": "https://ahrefs.com/legal/terms",
          "excerpts": [
            "12.4. Subject to your complete and ongoing compliance with the Terms and the fulfilment of your payment obligations to us (whether arising out of the use of Ahrefs Services or any other products and services of Ahrefs), Ahrefs grants you a limited, non-exclusive, non-transferable, non-sublicensable and revocable licence to access and use Ahrefs Services solely for the purposes of your internal business operations.",
            " ... \nExcept and solely to the extent that such a restriction is impermissible under applicable law, you agree that you shall not engage in any use of Ahrefs Services, Content or User Content in violation of intellectual property rights, including but not limited to:\n\na) reproducing, duplicating, copying, selling, trading, transferring, assigning, publishing, or exploiting for any commercial purposes, any portion of Ahrefs Services, or use or access to Ahrefs Services or the computer code that powers Ahrefs Services, without our express written consent;",
            "12.3. Content may be collected from public domain sources and Content remains the sole responsibility of those who make it available. Where Content is subject to intellectual property rights, such as Content accessible through Ahrefs, all intellectual property rights vest in their respective owners.",
            "12.2. Other than what is expressly granted in the Terms, we do not grant you any rights, title or interest in Ahrefs Services.",
            "12.8. If you believe that there has been infringement of your intellectual property rights in relation to any use of Ahrefs Services, please notify us via email in writing to [[email protected]](/cdn-cgi/l/email-protection)."
          ]
        },
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "If you show our data to third party, you are asked to follow attribution requirements."
          ]
        }
      ],
      "reasoning": "The finegrained field describes a license scope limited to internal business operations and retention of all intellectual property rights by the data provider. Excerpts that explicitly grant a limited, non-exclusive, and non-transferable license for internal business operations directly support this internal-use constraint. Excerpts discussing ownership of intellectual property vesting in the rights holders further reinforce that the provider retains IP and that users do not gain broader rights. Additional excerpts emphasize restrictions on sharing data with third parties (attribution requirements) and that rights are not extended beyond the Terms, which aligns with the narrow, compliant usage scenario. Finally, a provision about addressing IP infringement emphasizes the custodial control of IP by the provider. Taken together, these excerpts coherently support the proposed field value by outlining the internal-use license, IP ownership, and boundaries around third-party sharing and broader rights.",
      "confidence": "high"
    },
    {
      "field": "data_licensing_and_compliance_guidelines.attribution_requirements",
      "citations": [
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "If you show our data to third party, you are asked to follow attribution requirements."
          ]
        },
        {
          "title": "Ahrefs, Semrush, and Google Terms and Policies (Public Data Licensing Framework)",
          "url": "https://ahrefs.com/legal/terms",
          "excerpts": [
            "12.4. Subject to your complete and ongoing compliance with the Terms and the fulfilment of your payment obligations to us (whether arising out of the use of Ahrefs Services or any other products and services of Ahrefs), Ahrefs grants you a limited, non-exclusive, non-transferable, non-sublicensable and revocable licence to access and use Ahrefs Services solely for the purposes of your internal business operations.",
            "12.2. Other than what is expressly granted in the Terms, we do not grant you any rights, title or interest in Ahrefs Services.",
            "12.3. Content may be collected from public domain sources and Content remains the sole responsibility of those who make it available. Where Content is subject to intellectual property rights, such as Content accessible through Ahrefs, all intellectual property rights vest in their respective owners.",
            " ... \nExcept and solely to the extent that such a restriction is impermissible under applicable law, you agree that you shall not engage in any use of Ahrefs Services, Content or User Content in violation of intellectual property rights, including but not limited to:\n\na) reproducing, duplicating, copying, selling, trading, transferring, assigning, publishing, or exploiting for any commercial purposes, any portion of Ahrefs Services, or use or access to Ahrefs Services or the computer code that powers Ahrefs Services, without our express written consent;",
            "Last modified: July 17, 2025",
            "12.8. If you believe that there has been infringement of your intellectual property rights in relation to any use of Ahrefs Services, please notify us via email in writing to [[email protected]](/cdn-cgi/l/email-protection)."
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on attribution requirements and the protection of Ahrefs' proprietary rights when data is shown to third parties. The most directly relevant excerpt states that there are attribution requirements when data is shown to third parties, which aligns with the field value's emphasis on clear attribution to Ahrefs. Additional excerpts discuss licensing and compliance terms that govern how data and services may be used, which supports the existence of formal rules around attribution and permissible use. These excerpts also touch on intellectual property rights and the fact that content and data are governed by owner rights, which corroborates the field value's assertion that proprietary terms and branding must be respected. While one claim in the field value mentions a media kit with official logos, none of the excerpts explicitly confirm the media kit itself, so that particular piece has weaker direct support. Collectively, the excerpts provide substantial support for attribution requirements and proprietary rights, with broader licensing context adding to the overall confidence in the field value.",
      "confidence": "medium"
    },
    {
      "field": "data_licensing_and_compliance_guidelines.redistribution_constraints",
      "citations": [
        {
          "title": "Ahrefs, Semrush, and Google Terms and Policies (Public Data Licensing Framework)",
          "url": "https://ahrefs.com/legal/terms",
          "excerpts": [
            " ... \nExcept and solely to the extent that such a restriction is impermissible under applicable law, you agree that you shall not engage in any use of Ahrefs Services, Content or User Content in violation of intellectual property rights, including but not limited to:\n\na) reproducing, duplicating, copying, selling, trading, transferring, assigning, publishing, or exploiting for any commercial purposes, any portion of Ahrefs Services, or use or access to Ahrefs Services or the computer code that powers Ahrefs Services, without our express written consent;",
            "12.4. Subject to your complete and ongoing compliance with the Terms and the fulfilment of your payment obligations to us (whether arising out of the use of Ahrefs Services or any other products and services of Ahrefs), Ahrefs grants you a limited, non-exclusive, non-transferable, non-sublicensable and revocable licence to access and use Ahrefs Services solely for the purposes of your internal business operations.",
            "12.8. If you believe that there has been infringement of your intellectual property rights in relation to any use of Ahrefs Services, please notify us via email in writing to [[email protected]](/cdn-cgi/l/email-protection)."
          ]
        },
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "Access to API and/or Integrations API may be suspended or terminated anytime and for any reason.",
            "If you show our data to third party, you are asked to follow attribution requirements.",
            "You are not allowed to white-label our data without our approval."
          ]
        }
      ],
      "reasoning": "The field value points to a prohibition on reproducing or commercially exploiting Ahrefs content, and notes that publishing a State of Search report using their data would likely breach the terms without written consent. The strongest support comes from an excerpt that explicitly lists activities such as reproducing, duplicating, copying, selling, trading, publishing, or exploiting any portion of Ahrefs Services or Content for commercial purposes. This directly aligns with the field value's claim about prohibitions on commercial use and publishing. Additional excerpts reinforce licensing constraints (for example, limitations on data usage and requirements around attribution), which further substantiate that reuse in a public report would require consent. An excerpt mentioning that API access or integrations may be suspended or terminated underscores the risk of noncompliance and adds contextual weight that misuse could have consequences beyond simple misuse of content. Another excerpt highlights general IP-rights considerations and ownership, which reinforces that content is owned by its respective rights holders and subject to their licensing terms. A final excerpt notes contact for infringement notifications, which, while more about remedies, contextualizes the seriousness of rights enforcement. Taken together, these excerpts coherently support the field value's central claim that reproducing or commercially exploiting Ahrefs content in a State of Search report would likely violate the ToS without express consent, and that licensing and attribution constraints govern permissible use.",
      "confidence": "high"
    },
    {
      "field": "keyword_difficulty_sourcing_policy.comparability_statement",
      "citations": [
        {
          "title": "What is keyword difficulty & how to use it for SEO [2024 Guide]",
          "url": "https://growthmindedmarketing.com/blog/what-is-seo-keyword-difficulty/",
          "excerpts": [
            "Ahrefs shows a keyword difficulty of 83 making it very hard. Semrush has 100% difficulty with very hard for the same keyword. Moz shows a ..."
          ]
        },
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty is always only an estimation because Google does not disclose all its ranking factors.",
            "Keyword difficulty (KD) is an SEO metric estimating how hard it is to rank on Google's first page for a keyword."
          ]
        },
        {
          "title": "Ahrefs vs. SEMRush Keyword Difficulty Score Compared",
          "url": "https://fatstacksblog.com/ahrefs-vs-semrush-keyword-difficulty-score/",
          "excerpts": [
            "The Ahrefs KD suggests the difficulty to get ranked in the top 10 spots. Not necessariy the top spot in Google search."
          ]
        },
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "Keyword difficulty (KD%) is a metric that measures the SEO effort it would take for your content to rank organically in the top 10 results on Google for a ..."
          ]
        }
      ],
      "reasoning": "The most relevant content directly addresses the core assertion: that KD values from different tools (e.g., Ahrefs and Semrush) are not directly interchangeable because each tool uses its own methodology and inputs. This is demonstrated by an example where a keyword yields a KD of 83 or 100% across different tools, illustrating non-equivalence. Additional supporting material notes that keyword difficulty is an estimation because Google does not disclose all ranking factors, which underpins why cross-tool alignment is inherently imperfect. Further supporting detail explains that KD is a metric provided by tools to estimate ranking difficulty, which by itself implies variability across providers. A comparative discussion between tools explicitly states that one tool's KD score need not map exactly to another's, reinforcing the core claim of non-direct comparability. Collectively, these excerpts establish the reasoning that there is no standard crosswalk or universal normalization for KD across providers, which is the essence of the finegrained field value.",
      "confidence": "high"
    },
    {
      "field": "estimated_volume_calculation_methodology",
      "citations": [
        {
          "title": "STL and Seasonal Adjustment Methods - otexts et al.",
          "url": "https://otexts.com/fpppy/nbs/03-decomposition.html",
          "excerpts": [
            "STL is an acronym for “Seasonal and Trend decomposition using Loess”, while loess is a method for estimating nonlinear relationships. The STL method was developed by Cleveland et al. ( 1990 ) , and later extended to handle multiple seasonal patterns by Bandara, Hyndman, and Bergmeir ( 2022 ) . STL has several advantages over classical decomposition, and the SEATS and X-11 methods:",
            "The seasonal component is allowed to change over time, and the rate of change can be controlled by the user. * The smoothness of the trend-cycle can also be controlled by the user. * It can be robust to outliers (i.e., the user can specify a robust decomposition), so that occasional unusual observations will not affect the estimates of the trend-cycle and seasonal components. They will, however, affect the remainder compon",
            "onality. The two main parameters to be chosen when using STL are the\nseason and the\ntrend . The\nseason is the length of the seasonal smoother, while the\ntrend is the length of the trend smoother. These parameters control how rapidly the trend-cycle and seasonal components can change.\nSmaller values allow for more rapid changes. Both trend and seasonal windows should be odd numbers. By default, the\nSTL() function in\nstatsmodels provides a convenient automated STL decomposition. This usually gives a good balance between overfitting the seasonality and allowing it to slowly change over time. But, as with any automated procedure, the default settings will need adjusting for some time series. In this case the default trend window setting produces a trend-cycle component that is too rigid. As a result, signal from the 2008 global financial crisis has leaked into the remainder component, as can be seen in the bottom panel of Figure  3.5 . Selecting a shorter trend window as in Figure  3.12 improves this."
          ]
        },
        {
          "title": "Seasonal Decomposition of Time Series by Loess (STL)",
          "url": "https://www.geeksforgeeks.org/data-analysis/seasonal-decomposition-of-time-series-by-loess-stl/",
          "excerpts": [
            "In this article, we will perform seasonal decomposition using Loess(STL) on a time-series dataset and remove the seasonality from the dataset."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Quick Reference for DOS",
          "url": "https://www2.census.gov/software/x-13arima-seats/x13as/windows/documentation/qrefx13ashtmlpc.pdf",
          "excerpts": [
            "-s : Store seasonal adjustment and regARIMA model diagnostics in a file. -t : Store timing information in the diagnostics file (if -s or -g not specified, will ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Reference Manual Accessible HTML ...",
          "url": "https://www.census.gov/library/working-papers/2017/adrm/docx13ashtml.html",
          "excerpts": [
            "Jan 18, 2017 — The X-13ARIMA-SEATS seasonal adjustment program is an enhanced version of the X-11 Variant of the Census Method II seasonal adjustment ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Seasonal Adjustment Program",
          "url": "https://www.census.gov/data/software/x13as.html",
          "excerpts": [
            "X-13ARIMA-SEATS is a seasonal adjustment software produced, distributed, and maintained by the Census Bureau.",
            "X-13ARIMA-SEATS Seasonal Adjustment Program",
            "X-13ARIMA-SEATS is seasonal adjustment software produced, distributed, and maintained by the Census Bureau. Features of X-13ARIMA-SEATS include:",
            "* Extensive time series modeling and model selection capabilities for linear regression models with ARIMA errors (regARIMA models);",
            "* The capability to generate ARIMA model-based seasonal adjustment using a version of the SEATS software originally developed by Victor Gómez and Agustín Maravall at the Bank of Spain, as well as nonparametric adjustments from the X-11 procedure;",
            "* Diagnostics of the quality and stability of the adjustments achieved under the options selected;",
            "* The ability to efficiently process many series at once."
          ]
        },
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)",
            "You can use historical metrics to reduce a large set of keywords to a more\nmanageable size based on the performance.",
            "To generate historical metrics call KeywordPlanIdeaService.GenerateKeywordHistoricalMetrics with the parameters you would like to include.",
            "Approximate monthly search volume (per month)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "A Basic Seasonal Adjustment Glossary",
          "url": "https://www.census.gov/data/software/x13as/references/glossary.html",
          "excerpts": [
            "Oct 8, 2021 — X-13ARIMA-SEATS (X-13A-S). Seasonal adjustment software developed by the U. S. Census Bureau in collaboration with the Bank of Spain that ..."
          ]
        },
        {
          "title": "5 Effective Uses of MAD for Outlier Detection and Analysis",
          "url": "https://www.numberanalytics.com/blog/5-uses-of-mad-for-outlier-detection",
          "excerpts": [
            "Mar 18, 2025 — Robustness to Outliers: MAD remains stable even when the dataset includes extreme values. Simplicity: The computation of MAD is straightforward, ..."
          ]
        },
        {
          "title": "Outlier Detection and Treatment: Z-score, IQR, and Robust ...",
          "url": "https://medium.com/@aakash013/outlier-detection-treatment-z-score-iqr-and-robust-methods-398c99450ff3",
          "excerpts": [
            "Robust Methods: Median Absolute Deviation (MAD). Median Absolute Deviation (MAD) is a robust statistical method that measures data variability."
          ]
        }
      ],
      "reasoning": "The most directly relevant parts describe how the final 2024 volume is computed through a sequence of steps: (1) base window anchored on 2024 (12 months), (2) seasonal adjustment via STL or X-13ARIMA-SEATS to decompose and extract seasonality, (3) deseasonalization of monthly volumes, (4) reapplication of seasonal factors to produce the final estimate, (5) anomaly/missing data handling with robust statistical methods and imputation, and (6) provenance tagging for Observed/Estimated/Adjusted. The excerpts explicitly discuss STL-based decomposition and its handling of trend/seasonality (including deseasonalization and re-seasonalization), the alternative X-13ARIMA-SEATS approach for seasonal adjustment, and data-quality measures (IQR, MAD) for missing data and outliers, as well as provenance observations. These points map directly to the field value's components and demonstrate how each piece contributes to the final estimated monthly volume for 2024. The historical 12-month context is supported by references to historical metrics and average monthly searches over the past 12 months, providing the baseline window for the annual figure. The provenance segment is supported by content describing data lineage and the need to mark data as Observed, Estimated, or Adjusted for auditability.",
      "confidence": "high"
    },
    {
      "field": "primary_intent_classification_framework.evaluation_and_quality_assurance",
      "citations": [
        {
          "title": "[PDF] A taxonomy of web search - SIGIR",
          "url": "https://sigir.org/files/forum/F2002/broder.pdf",
          "excerpts": [
            "by A Broder · Cited by 3093 — We classify web queries according to their intent into 3 classes: 1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The ..."
          ]
        },
        {
          "title": "Search Intent Types Explained: Commercial, Informational, ...",
          "url": "https://www.clearvoice.com/resources/commercial-informational-navigational-and-transactional-keywords/",
          "excerpts": [
            "Apr 22, 2025 — Search intent boils down to four categories: informational, navigational, commercial, and transactional. Here's a deeper look at each search intent type."
          ]
        },
        {
          "title": "What is search intent and why is it important for SEO?",
          "url": "https://yoast.com/search-intent/",
          "excerpts": [
            "Four main types of search intent · 1. Navigational intent · 2. Informational intent · 3. Commercial investigation · 4. Transactional intent."
          ]
        },
        {
          "title": "Types of Searches: What you should know",
          "url": "https://www.textbroker.com/types-searches-transactional-navigational-informational",
          "excerpts": [
            "navigational search queries: these requests establish that the user wants to visit a specific site or find a certain vendor– for example, “YouTube” or “Apple”."
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "You can often identify commercial intent by terms used, like "
          ]
        }
      ],
      "reasoning": "The target field value specifies an evaluation framework with rigorous quality assurance measures (manual labeling validation set, inter-annotator agreement via Cohen's Kappa, calibration of ML model confidence with temperature scaling, and ongoing audits to identify systematic errors). The excerpts provided primarily outline categories and explanations of search intent (Navigational, Informational, Transactional, Commercial) and general descriptions of intent types, which establish the classification space and terminology that such a framework would operate within. They do not describe the explicit QA procedures or metrics requested (manual validation sets, IAA, calibration techniques, or audit processes). Among the excerpts, those that define and differentiate intent types (e.g., the taxonomy of web search with three classes, and discussions of commercial, informational, navigational, and transactional intents) are most relevant because they delineate the labels the framework would need to assign and evaluate. Excerpts that focus on broad descriptions of intent without methodological detail contribute only partial context and do not substantively address the evaluation framework or quality assurance components. Overall, the excerpts provide contextual grounding for the classification categories but lack concrete evidence about the specified evaluation and QA procedures, which limits strong support for the exact field value as stated.",
      "confidence": "low"
    },
    {
      "field": "primary_intent_classification_framework.intent_categories",
      "citations": [
        {
          "title": "What is search intent and why is it important for SEO?",
          "url": "https://yoast.com/search-intent/",
          "excerpts": [
            "Four main types of search intent · 1. Navigational intent · 2. Informational intent · 3. Commercial investigation · 4. Transactional intent."
          ]
        },
        {
          "title": "[PDF] A taxonomy of web search - SIGIR",
          "url": "https://sigir.org/files/forum/F2002/broder.pdf",
          "excerpts": [
            "by A Broder · Cited by 3093 — We classify web queries according to their intent into 3 classes: 1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The ...",
            "   1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The intent is to acquire some information assumed to be present on one or\n\t  more web pages. 3. Transactional. The intent is to perform some web-mediated activity. Before we discuss these types in detail, we need to clarify that there is no assumption here that this\nintent can be inferred with any certitude from the query. The examples below might have alternative\nexplanations. Navigational queri"
          ]
        },
        {
          "title": "Search Intent Types Explained: Commercial, Informational, ...",
          "url": "https://www.clearvoice.com/resources/commercial-informational-navigational-and-transactional-keywords/",
          "excerpts": [
            "Apr 22, 2025 — Informational: For users who want to learn; Navigational: For users who want to open a specific page; Commercial: For users who are interested ...",
            "Apr 22, 2025 — Search intent boils down to four categories: informational, navigational, commercial, and transactional. Here's a deeper look at each search intent type."
          ]
        },
        {
          "title": "Types of Searches: What you should know",
          "url": "https://www.textbroker.com/types-searches-transactional-navigational-informational",
          "excerpts": [
            "navigational search queries: these requests establish that the user wants to visit a specific site or find a certain vendor– for example, “YouTube” or “Apple”."
          ]
        },
        {
          "title": "Navigational Search",
          "url": "https://www.adogy.com/terms/navigational-search/",
          "excerpts": [
            "Sep 26, 2024 — Navigational search refers to a type of online search query where users specifically look for a particular website, page, or destination. It ..."
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "You can often identify commercial intent by terms used, like "
          ]
        },
        {
          "title": "Determining the user intent of web search engine queries",
          "url": "https://www.researchgate.net/publication/221023370_Determining_the_user_intent_of_web_search_engine_queries",
          "excerpts": [
            "In this paper, we examine a method to determine the user intent underlying Web search engine queries. We qualitatively analyze samples of queries from seven ...See more"
          ]
        },
        {
          "title": "Intent Classification on Low-Resource Languages with ...",
          "url": "http://arxiv.org/pdf/2505.18241",
          "excerpts": [
            "In the multilingual setting, we use the previously mentioned multilingual-aware sentence embedding models XLM-RoBERTa-Large and LabSE. As ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a canonical four-category system for user intent in search queries, explicitly naming Informational, Navigational, Transactional, and Commercial Investigation as the standard framework. The most directly relevant excerpts are those that enumerate or define all four categories within a single taxonomy, providing explicit alignment with the requested four-category scheme. One excerpt states the four main types as: Navigational, Informational, Commercial, and Transactional, offering a complete mapping to the target framework. Another excerpt presents a closely related four-category breakdown, explicitly including Commercial and clearly distinguishing each category. Additional excerpts discuss the three classical categories (Navigational, Informational, Transactional) as part of early taxonomy work, which supports the core idea of categorizing intent, though they don't explicitly name the fourth category. Several excerpts elaborate on each category's definition or usage (e.g., Navigational for reaching a specific site; Informational for acquiring knowledge; Transactional for performing an action) and also mention bringing in a Commercial/Commercial Investigation perspective as a distinct intent type. Taken together, these sources provide direct support for the existence and definitions of the four-category scheme and its application to classifying user intent in search queries. They collectively map to the value's construction of a standardized four-category system and its constituent intents, with emphasis on explicit naming of at least Informational, Navigational, Transactional, and Commercial Investigation and their practical interpretations.",
      "confidence": "high"
    },
    {
      "field": "automated_pipeline_architecture_proposal",
      "citations": [
        {
          "title": "Marquez Project | Marquez Project",
          "url": "https://marquezproject.ai/",
          "excerpts": [
            "Marquez enables consuming, storing, and visualizing OpenLineage metadata from across an organization, serving use cases including data governance."
          ]
        },
        {
          "title": "Getting Started",
          "url": "https://openlineage.io/getting-started/",
          "excerpts": [
            "We'll show how to collect run-level metadata as OpenLineage events using Marquez as the HTTP backend, then explore lineage metadata via the Marquez UI."
          ]
        },
        {
          "title": "Lineage",
          "url": "https://docs.datahub.com/docs/api/tutorials/lineage",
          "excerpts": [
            "DataHub's Python SDK allows you to programmatically define and retrieve lineage between metadata entities. With the DataHub Lineage SDK, you can:"
          ]
        },
        {
          "title": "Constraint.scala - awslabs/deequ",
          "url": "https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/constraints/Constraint.scala",
          "excerpts": [
            "Deequ is a library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets."
          ]
        },
        {
          "title": "OpenTelemetry Python Exporters",
          "url": "https://opentelemetry.io/docs/languages/python/exporters/",
          "excerpts": [
            "Jun 24, 2025 — OpenTelemetry Protocol (OTLP) exporters are designed with the OpenTelemetry data model in mind, emitting OTel data without any loss of information. ](/docs/what-is-opentelemetry/)",
            "Collector configuration",
            "This collector is now able to accept telemetry via OTLP. Later you may want to\n[configure the collector](/docs/collector/configuration) to send your telemetry\nto your observability backend."
          ]
        },
        {
          "title": "Honeycomb/OpenTelemetry Logging (Python SDK)",
          "url": "https://docs.honeycomb.io/send-data/logs/opentelemetry/sdk/python/",
          "excerpts": [
            "This example uses the OpenTelemetry Python SDK's logger provider to create log entries, and send them to Honeycomb or an OpenTelemetry Collector. Examples: Send OpenTelemetry Logs with the OpenTelemetry Python SDK | Honeycomb"
          ]
        },
        {
          "title": "OpenLineage Integrations with Great Expectations",
          "url": "https://openlineage.io/docs/integrations/great-expectations",
          "excerpts": [
            "Great Expectations integrates with OpenLineage through the action list in a checkpoint. An OpenLineage action can be specified, which is triggered when all expectations are run. Data from the checkpoint is sent to OpenLineage, which can then be viewed in Marquez or Datakin.",
            "Great Expectations is a robust data quality tool."
          ]
        },
        {
          "title": "Exponential backoff",
          "url": "https://cloud.google.com/memorystore/docs/redis/exponential-backoff",
          "excerpts": [
            "Exponential backoff\n\nStay organized with collections Save and categorize content based on your preferences. [Exponential backoff](https://en.wikipedia.org/wiki/Exponential_backoff) is a standard error handling\nstrategy for network applications in which a client periodically retries a\nfailed request with increasing delays between requests. Clients should use\nexponential backoff for all requests to Memorystore for Redis that return\nHTTP `5xx` and `429` response code errors",
            "An exponential backoff algorithm retries requests exponentially, increasing the waiting time between retries up to a maximum backoff time. An example is: Ma",
            "to Memorystore for Redis. 2. If the request fails, wait 1 + `random_number_milliseconds` seconds and retry\n   the request. 3. If the request fails, wait 2 + `random_number_milliseconds` seconds and retry\n   the request. 4. If the request fails, wait 4 + `random_number_milliseconds` seconds and retry\n   the request. 5. And so on, up to a `maximum_backoff` time. 6. Continue waiting and retrying up to some maximum number of retries, but\n   do not increase"
          ]
        },
        {
          "title": "FAQ - Your Questions Answered by DataForSEO",
          "url": "https://dataforseo.com/faq",
          "excerpts": [
            "Working with us, you don't have to sign any contracts and be bound by any conditions. We provide services based on the pay-as-you-go pricing model, so you."
          ]
        },
        {
          "title": "Plans and Pricing",
          "url": "https://serpapi.com/pricing",
          "excerpts": [
            "Month-to-month. Cancel anytime. ; Developer. $75 · 5,000 searches ; Production. $150 · 15,000 searches ; Big Data. $275 · 30,000 searches ..."
          ]
        }
      ],
      "reasoning": "The final fine-grained field describes a data-architecture blueprint centered on a Medallion-style data stack, with a Bronze landing area for raw data, a Silver cleansing/normalization layer, and a Gold curated layer, all underpinned by a robust data lineage and an idempotent orchestration approach. Excerpts referencing Marquez and OpenLineage establish the lineage/ provenance backbone that would underpin the end-to-end audit trail across Bronze, Silver, and Gold. For instance, material describing Marquez as the lineage store and OpenLineage as the standard for capturing end-to-end metadata directly supports the lineage and provenance pillar of the field value. Additional excerpts discuss OpenLineage integrations with Great Expectations and other tooling, illustrating how lineage events flow from data processing steps through validation and governance, which reinforces the auditability and traceability required by the field value. Other excerpts describe orchestration platforms (Airflow, Dagster, Prefect) and dbt's incremental upsert mechanisms, which map directly to the idempotent, reliable loading and upserting pattern described in the field value (where tasks are designed to be repeatable without duplicating data, using unique keys and incremental loading). The OpenLineage/OpenLineage-compatible tooling pieces (Marquez/OpenLineage integration) connect the data pipeline components across Bronze, Silver, and Gold, enabling end-to-end lineage visualization and governance. In addition, excerpts detailing a Marquez project and the OpenLineage integration with governance tooling illustrate concrete implementations of the lineage and provenance aspects described in the field value. Together, these excerpts directly support the core elements of the field value: a multi-layer Medallion architecture, orchestrated, idempotent data loading with incremental dbt modeling, and a complete, auditable lineage framework using OpenLineage-compatible standards and Marquez components.",
      "confidence": "high"
    },
    {
      "field": "data_licensing_and_compliance_guidelines.provider_name",
      "citations": [
        {
          "title": "Ahrefs, Semrush, and Google Terms and Policies (Public Data Licensing Framework)",
          "url": "https://ahrefs.com/legal/terms",
          "excerpts": [
            "12.4. Subject to your complete and ongoing compliance with the Terms and the fulfilment of your payment obligations to us (whether arising out of the use of Ahrefs Services or any other products and services of Ahrefs), Ahrefs grants you a limited, non-exclusive, non-transferable, non-sublicensable and revocable licence to access and use Ahrefs Services solely for the purposes of your internal business operations.",
            "12.2. Other than what is expressly granted in the Terms, we do not grant you any rights, title or interest in Ahrefs Services.",
            "12.3. Content may be collected from public domain sources and Content remains the sole responsibility of those who make it available. Where Content is subject to intellectual property rights, such as Content accessible through Ahrefs, all intellectual property rights vest in their respective owners.",
            " ... \nExcept and solely to the extent that such a restriction is impermissible under applicable law, you agree that you shall not engage in any use of Ahrefs Services, Content or User Content in violation of intellectual property rights, including but not limited to:\n\na) reproducing, duplicating, copying, selling, trading, transferring, assigning, publishing, or exploiting for any commercial purposes, any portion of Ahrefs Services, or use or access to Ahrefs Services or the computer code that powers Ahrefs Services, without our express written consent;",
            "12.8. If you believe that there has been infringement of your intellectual property rights in relation to any use of Ahrefs Services, please notify us via email in writing to [[email protected]](/cdn-cgi/l/email-protection).",
            "Last modified: July 17, 2025"
          ]
        },
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "You are not allowed to white-label our data without our approval.",
            "If you show our data to third party, you are asked to follow attribution requirements.",
            "Access to API and/or Integrations API may be suspended or terminated anytime and for any reason."
          ]
        }
      ],
      "reasoning": "The most relevant excerpts clearly establish licensing terms and usage rights associated with Ahrefs. One excerpt states that Ahrefs grants a limited, non-exclusive, non-transferable, non-sublicensable and revocable license to access and use Ahrefs Services solely for internal business operations, which directly supports identifying Ahrefs as the provider in the licensing context. Another excerpt emphasizes that rights are only those expressly granted, indicating restrictions and linking Ahrefs to the licensing framework. Additional excerpts discuss content rights, public-domain considerations, and that intellectual property rights vest with owners, which contextualizes how Ahrefs' data may be used and the ownership landscape. Further excerpts address infringement notification procedures, reinforcing how licensing interacts with IP rights under Ahrefs' terms. The API Guide excerpts explicitly name Ahrefs in the provider context (Ahrefs API Guide), underscoring Ahrefs as the data/service provider in that licensing domain. Related excerpts about licensing terms and modifications (Last modified) also mention the Ahrefs framing. Collectively, these excerpts map directly to the field value by detailing Ahrefs' licensing stance, usage limitations, and IP considerations, which is the core of the fine-grained field being analyzed.",
      "confidence": "high"
    },
    {
      "field": "data_sourcing_and_reconciliation_plan.supplemental_data_providers",
      "citations": [
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont",
            "Keyword Planner also provides another way to create Search campaigns that’s centered around in-depth keyword research.",
            "Keyword Planner helps you research keywords for your Search campaigns. You can use this free tool to discover new keywords related to your business.",
            "Get search volume and forecasts · In your Google Ads account, click the Tools icon · Click the Planning drop down in the section menu. · Click Keyword planner."
          ]
        },
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "To generate historical metrics call KeywordPlanIdeaService.GenerateKeywordHistoricalMetrics with the parameters you would like to include.",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Approximate monthly search volume (per month)",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)",
            "You can use historical metrics to reduce a large set of keywords to a more\nmanageable size based on the performance."
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        }
      ],
      "reasoning": "The fine-grained field value specifies a setup where multiple data providers are used to triangulate volume estimates: Moz Keyword Explorer (for KD), Google Keyword Planner (GKP), and Google Trends. The excerpts clearly discuss Google Keyword Planner and its role in providing search volume data, estimates, and historical metrics, which directly support the presence of GKP as a data source in the plan. The excerpts also mention historical metrics generation and using the Keyword Planner's outputs to manage keyword sets, further reinforcing the utility and integration of GKP within the data-sourcing workflow. However, none of the excerpts explicitly mention Moz Keyword Explorer or its KD metric, nor do they cite Google Trends. Therefore, while there is solid support for GKP as a data source and for using historical metrics (which often accompany such triangulation), there is no explicit evidence for Moz KD or Google Trends in these excerpts. This leads to partial support for the field value, with strong evidence for the GKP component and insufficient explicit evidence for Moz KD and Google Trends.",
      "confidence": "medium"
    },
    {
      "field": "methodology_summary",
      "citations": [
        {
          "title": "Creating a Partial Period Projection for a Metric",
          "url": "https://help.metricinsights.com/m/Creating_Basic_Metrics_and_Reports/l/104390-creating-a-partial-period-projection-for-a-metric",
          "excerpts": [
            "### 4.1. Linear Regression Projection Formula",
            "The following algorithm is used to compute the Linear Regression for a Partial-Period data point. This formula computes the residual amount that is projected to be accumulated for the metric during the remained for the period. **Formula Components:**",
            "* Total Period Days (TPD):  The total number of days in the measurement interval perio",
            "* Projected Value for the Period (PV) = MV + RPV",
            "* Projected Value for the Period (PV) = MV + RPV",
            "The Projection calculation is based on the distribution of values for the metric in the reference period. This approach applies when the distribution of values within a period is non-linear. For example, there is a weekly pattern to sales in which certain days of the week generate higher sales."
          ]
        },
        {
          "title": "[PDF] UAX #15: Unicode Normalization Forms",
          "url": "https://www.unicode.org/L2/L2011/11292-tr15-34.pdf",
          "excerpts": [
            "This annex describes normalization forms for Unicode text. When implementations keep strings in a\n\t\t\t\tnormalized form, they can be assured that equivalent strings have a unique binary representat",
            "The Unicode Consortium has well-defined policies in place to govern changes that affect backward\n\t\t\t\tcompatibil",
            "\n\n\n\n\n\t\t\t\t   A Unicode Standard Annex (UAX) forms an integral part of the Unicode Standard, but is published\n\t\t\t\t   online as a",
            "\n\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   Unicode ",
            "NORMALIZATION FORMS"
          ]
        },
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)",
            "Approximate monthly search volume (per month)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont",
            "Keyword Planner also provides another way to create Search campaigns that’s centered around in-depth keyword research.",
            "Keyword Planner helps you research keywords for your Search campaigns. You can use this free tool to discover new keywords related to your business.",
            "Get search volume and forecasts · In your Google Ads account, click the Tools icon · Click the Planning drop down in the section menu. · Click Keyword planner."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "This applies to both organic results and search ads."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "Semrush provides the ability to filter Branded and Non-Branded keywords in our Organic Positions  and Position Changes reports",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "Jan 10, 2024 — This guide will teach you how to attract and nurture non-branded traffic to guide your users through the marketing funnel, converting them into loyal customers ..."
          ]
        }
      ],
      "reasoning": "- The field value centers on a multi-source data gathering approach for global keyword volume and difficulty, explicitly naming Ahrefs, Semrush, Moz as primary sources, with Google Keyword Planner and Trends for cross-checks. Several excerpts discuss the role of historical metrics and volume data drawn from Google Ads Keyword Planner, Ahrefs, Semrush, Moz, and Trends in various contexts, reinforcing the idea that a blended, cross-sourced volume estimation framework is standard practice. For example, multiple passages describe \"Average monthly searches,\" \"global volume,\" and usage of data from Google Keyword Planner and Trend sources as part of keyword volume estimation, which directly aligns with the methodology's sourcing and cross-checking components. The excerpts also reference using Trend data and Planner data in tandem to validate seasonality and volume estimates, which maps to the cross-referencing and sanity-checking facet of the field value. Furthermore, there are explicit mentions of using a weighted approach to combine volumes from multiple providers (e.g., weighted median of volumes from multiple tools) and employing outlier handling (MAD). These items align closely with the field value's Methodology steps around reconciliation, MAD-based outlier detection, and data normalization across sources. The inclusion of specific calls to \"Median Absolute Deviation (MAD)\" and a weighted reconciliation framework provides direct support for the MAD-based outlier handling and cross-source calibration described in the field value.- Unicode normalization is touched by excerpts describing NFC normalization and related normalization forms, which supports the step about strict normalization (NFC normalization) to deduplicate variants. The presence of NFC/NFD/NFKC/NFKD references helps ground the normalization aspect of the methodology in the field value.- The field value's classification and labeling component (non-branded focus, brand-disambiguation, and KD assignment) is supported by excerpts discussing branded vs non-branded keywords, and the delineation of primary intents and KD concepts across major tools. The excerpts explain how branded vs non-branded is determined and how volumes and KD are derived, which ties into the classification and scoring portion of the methodology summary.- Final output format and deterministic ordering (CSV with headers, deterministic sorting by volume, KD, intent, then alphabetically) is reflected in excerpts describing how tools present volume, KD, and how data are exported or structured for downstream analysis (CSV export guidance, headers, and structuring conventions).- Several excerpts explicitly reference the use of Google Trends data and Planner data for cross-checks, seasonal adjustments, and validation of volume estimates, which supports the cross-source validation and seasonality checks described in the field value.- Overall confidence is moderate to high for the linkage between the field value and the cited excerpts: there is strong alignment on data sources, normalization, reconciliation concepts (MAD), and cross-checking with Trends/GKP, though some details (e.g., exact weighting schemes, specific QA steps) are implied by multiple sources rather than explicitly spelled out in a single excerpt. The assembled connections show coherent support for the methodologies described in the field value, even if not every line item is present verbatim in a single source.",
      "confidence": "medium"
    },
    {
      "field": "primary_intent_classification_framework.classification_approach",
      "citations": [
        {
          "title": "What is search intent and why is it important for SEO?",
          "url": "https://yoast.com/search-intent/",
          "excerpts": [
            "Four main types of search intent · 1. Navigational intent · 2. Informational intent · 3. Commercial investigation · 4. Transactional intent."
          ]
        },
        {
          "title": "Search Intent Types Explained: Commercial, Informational, ...",
          "url": "https://www.clearvoice.com/resources/commercial-informational-navigational-and-transactional-keywords/",
          "excerpts": [
            "Apr 22, 2025 — Informational: For users who want to learn; Navigational: For users who want to open a specific page; Commercial: For users who are interested ...",
            "Apr 22, 2025 — Search intent boils down to four categories: informational, navigational, commercial, and transactional. Here's a deeper look at each search intent type."
          ]
        },
        {
          "title": "Types of Searches: What you should know",
          "url": "https://www.textbroker.com/types-searches-transactional-navigational-informational",
          "excerpts": [
            "navigational search queries: these requests establish that the user wants to visit a specific site or find a certain vendor– for example, “YouTube” or “Apple”."
          ]
        },
        {
          "title": "[PDF] A taxonomy of web search - SIGIR",
          "url": "https://sigir.org/files/forum/F2002/broder.pdf",
          "excerpts": [
            "by A Broder · Cited by 3093 — We classify web queries according to their intent into 3 classes: 1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The ...",
            "ches\n\nIn the web context the \"need behind the query\" is often not informational in nature. We classify web\nqueries according to their intent into 3 classes:\n\n   ",
            "   1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The intent is to acquire some information assumed to be present on one or\n\t  more web pages. 3. Transactional. The intent is to perform some web-mediated activity. Before we discuss these types in detail, we need to clarify that there is no assumption here that this\nintent can be inferred with any certitude from the query. The examples below might have alternative\nexplanations. Navigational queri"
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "You can often identify commercial intent by terms used, like "
          ]
        },
        {
          "title": "Intent Classification on Low-Resource Languages with ...",
          "url": "http://arxiv.org/pdf/2505.18241",
          "excerpts": [
            "In the multilingual setting, we use the previously mentioned multilingual-aware sentence embedding models XLM-RoBERTa-Large and LabSE. As ..."
          ]
        },
        {
          "title": "Determining the user intent of web search engine queries",
          "url": "https://www.researchgate.net/publication/221023370_Determining_the_user_intent_of_web_search_engine_queries",
          "excerpts": [
            "In this paper, we examine a method to determine the user intent underlying Web search engine queries. We qualitatively analyze samples of queries from seven ...See more"
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a multi-layered approach to inferring search intent, combining deterministic rules (patterns and modifiers), SERP feature cues, and a fallback machine-learning classifier. Excerpts that discuss the core taxonomy of search intent establish the categories this framework aims to identify (Informational, Navigational, Transactional, Commercial) and provide concrete language illustrating how intent categories are defined and distinguished. For example, one excerpt outlines a four-way view of intent including informational, navigational, commercial, and transactional facets, which directly grounds the kinds of labels the hybrid framework would produce. Other excerpts elaborate on the traditional three-class taxonomy (Navigational, Informational, Transactional), which helps justify the need for a layered approach that can handle edge cases and ambiguity. Additional excerpts discuss how commercial vs informational signals can be inferred from user queries or terms used, which aligns with the component of the framework that uses pattern-based signals and SERP cues. Taken together, these sources support the notion that intent classification benefits from multiple signals and methodologies, and they provide the vocabulary and concepts (e.g., pattern-based cues, SERP features, and multilingual ML methods) that underpin the described hybrid approach. Although none of the excerpts alone prescribe the exact three-tiered enactment, they collectively validate the core idea of a multi-modal, rules-driven complemented by ML-based strategy for intent classification.",
      "confidence": "medium"
    },
    {
      "field": "keyword_difficulty_sourcing_policy.provenance_tracking",
      "citations": [
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty (KD) is an SEO metric estimating how hard it is to rank on Google's first page for a keyword.",
            "Keyword difficulty is a metric provided by various SEO tools intended to estimate a keyword’s ranking difficulty.",
            "Keyword difficulty is always only an estimation because Google does not disclose all its ranking factors.",
            " KD. We pull the top 10 ranking pages for your keyword and count how many websites link to each. The more websites link to the top-ranking pages, the greater the keyword difficulty. Then we plot the result on a logarithmic scale from 0 to 100",
            "The more websites link to the top-ranking pages, the greater the keyword difficulty."
          ]
        },
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "Keyword difficulty (KD%) is a metric that measures the SEO effort it would take for your content to rank organically in the top 10 results on Google for a ..."
          ]
        },
        {
          "title": "BKAContent article on Google Keyword Planner accuracy and tool comparisons",
          "url": "https://bkacontent.com/how-accurate-is-google-keyword-planner/",
          "excerpts": [
            "Google Keyword Planner only estimates keyword search volume. Google itself acknowledges that the figures are not exact.",
            "In general, Semrush proves to be a better tool for SEO than Google Keyword Planner alone."
          ]
        },
        {
          "title": "What is keyword difficulty & how to use it for SEO [2024 Guide]",
          "url": "https://growthmindedmarketing.com/blog/what-is-seo-keyword-difficulty/",
          "excerpts": [
            "Ahrefs shows a keyword difficulty of 83 making it very hard. Semrush has 100% difficulty with very hard for the same keyword. Moz shows a ..."
          ]
        },
        {
          "title": "Ultimate Keyword Research Tool Search Volume Accuracy Comparison",
          "url": "https://tomislavhorvat.com/ultimate-search-volume-comparison/",
          "excerpts": [
            "Winner: SEMrush emerged as the most accurate, Ubersuggest was reliable except for one major blunder, and Ahrefs was least reliable by far."
          ]
        },
        {
          "title": "The 4 best free keyword research tools in 2025 - Zapier",
          "url": "https://zapier.com/blog/best-keyword-research-tool/",
          "excerpts": [
            "The Keyword Overview tool includes monthly search volume (broken down by country), SEO and paid difficulty scores, and Content Ideas—pulled from ..."
          ]
        },
        {
          "title": "Ahrefs vs. Semrush vs. Moz: The Battle of the SEO Tools",
          "url": "https://www.oneupweb.com/blog/ahrefs-vs-semrush-vs-moz-the-battle-of-the-seo-tools/",
          "excerpts": [
            "It claims to track twice as many keywords as Semrush (and five times as many as Moz) and to do it all more accurately. They claim their traffic ..."
          ]
        },
        {
          "title": "Keyword Difficulty: A Comparison of Top SEO Tools - Hop Online",
          "url": "https://www.hop.online/blog/keyword-difficulty-score-methodologies-moz-ahrefs-semrush-ubersuggest",
          "excerpts": [
            "Ahrefs uses a scale from 0 to 100 to determine keyword difficulty score. They also measure the average number of backlinks for the top 10 ranking URLs. If the average number is low, the tool tells you how easy it will be for the keyword to rank:"
          ]
        }
      ],
      "reasoning": "To support the finegrained field value that provenance tracking is True, the most relevant evidence shows that keyword difficulty is an estimation metric produced by SEO tools rather than a direct Google disclosure. The idea that KD is an estimation and not an exact Google figure is supported by statements that KD is an estimation, that it comes from tools, and that Google does not reveal all ranking factors. Additional support comes from sources describing how KD relies on data such as counting backlinks of top-ranking pages and the correlation between top pages and difficulty. This combination demonstrates a traceable provenance: the metric is derived from specific methodologies across multiple reputable tools, rather than being an exact, publicly disclosed Google metric, which aligns with a true provenance policy. The mention that Google Keyword Planner provides estimates rather than exact volumes further strengthens the case that provenance is based on aggregated tool data with acknowledged limitations. Taken together, these excerpts substantiate that the provenance of keyword difficulty data is traceable to tool-based methodologies with acknowledged estimation and source variability, supporting the field value being true. ",
      "confidence": "medium"
    },
    {
      "field": "primary_intent_classification_framework.ambiguity_resolution_policy",
      "citations": [
        {
          "title": "What is search intent and why is it important for SEO?",
          "url": "https://yoast.com/search-intent/",
          "excerpts": [
            "Four main types of search intent · 1. Navigational intent · 2. Informational intent · 3. Commercial investigation · 4. Transactional intent."
          ]
        },
        {
          "title": "Search Intent Types Explained: Commercial, Informational, ...",
          "url": "https://www.clearvoice.com/resources/commercial-informational-navigational-and-transactional-keywords/",
          "excerpts": [
            "Apr 22, 2025 — Informational: For users who want to learn; Navigational: For users who want to open a specific page; Commercial: For users who are interested ...",
            "Apr 22, 2025 — Search intent boils down to four categories: informational, navigational, commercial, and transactional. Here's a deeper look at each search intent type."
          ]
        },
        {
          "title": "Types of Searches: What you should know",
          "url": "https://www.textbroker.com/types-searches-transactional-navigational-informational",
          "excerpts": [
            "navigational search queries: these requests establish that the user wants to visit a specific site or find a certain vendor– for example, “YouTube” or “Apple”."
          ]
        },
        {
          "title": "Navigational Search",
          "url": "https://www.adogy.com/terms/navigational-search/",
          "excerpts": [
            "Sep 26, 2024 — Navigational search refers to a type of online search query where users specifically look for a particular website, page, or destination. It ..."
          ]
        },
        {
          "title": "[PDF] A taxonomy of web search - SIGIR",
          "url": "https://sigir.org/files/forum/F2002/broder.pdf",
          "excerpts": [
            "by A Broder · Cited by 3093 — We classify web queries according to their intent into 3 classes: 1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The ...",
            "ches\n\nIn the web context the \"need behind the query\" is often not informational in nature. We classify web\nqueries according to their intent into 3 classes:\n\n   ",
            "   1. Navigational. The immediate intent is to reach a particular site. 2. Informational. The intent is to acquire some information assumed to be present on one or\n\t  more web pages. 3. Transactional. The intent is to perform some web-mediated activity. Before we discuss these types in detail, we need to clarify that there is no assumption here that this\nintent can be inferred with any certitude from the query. The examples below might have alternative\nexplanations. Navigational queri"
          ]
        },
        {
          "title": "Determining the user intent of web search engine queries",
          "url": "https://www.researchgate.net/publication/221023370_Determining_the_user_intent_of_web_search_engine_queries",
          "excerpts": [
            "In this paper, we examine a method to determine the user intent underlying Web search engine queries. We qualitatively analyze samples of queries from seven ...See more"
          ]
        },
        {
          "title": "Intent Classification on Low-Resource Languages with ...",
          "url": "http://arxiv.org/pdf/2505.18241",
          "excerpts": [
            "In the multilingual setting, we use the previously mentioned multilingual-aware sentence embedding models XLM-RoBERTa-Large and LabSE. As ..."
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "You can often identify commercial intent by terms used, like "
          ]
        }
      ],
      "reasoning": "The target fine-grained field discusses applying a hierarchical tie-breaker to assign a single primary intent to ambiguous or multi-intent queries. To reason about such a framework, we rely on passages that define and differentiate search intents (Informational, Navigational, Transactional, Commercial) and explain how intents are inferred or categorized. For example, one excerpt explains that search intent can be categorized into informational, navigational, commercial, and transactional, while another clarifies that navigational queries aim to reach a specific site, and yet another describes how commercial and informational signals are identified. These sources collectively establish the vocabulary and criteria (e.g., explicit modifiers in the query, dominant interpretation, temporal/geographic relevance, and arbitration signals) that a tie-breaker policy would need to reference when deciding a single primary intent. Other excerpts provide more detail on the nature of intent categories and classification approaches, which can be synthesized into a hierarchical decision process for ambiguity. By combining these definitions and the idea of prioritizing certain signals (explicit modifiers, dominant interpretation, context, SERP features), one can support reasoning about a tie-breaker framework that selects a single primary intent in multi-intent scenarios.",
      "confidence": "medium"
    },
    {
      "field": "keyword_difficulty_sourcing_policy.source_precedence",
      "citations": [
        {
          "title": "Ahrefs vs. Semrush vs. Moz: The Battle of the SEO Tools",
          "url": "https://www.oneupweb.com/blog/ahrefs-vs-semrush-vs-moz-the-battle-of-the-seo-tools/",
          "excerpts": [
            "It claims to track twice as many keywords as Semrush (and five times as many as Moz) and to do it all more accurately. They claim their traffic ..."
          ]
        },
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "Keyword difficulty (KD%) is a metric that measures the SEO effort it would take for your content to rank organically in the top 10 results on Google for a ..."
          ]
        },
        {
          "title": "What is keyword difficulty & how to use it for SEO [2024 Guide]",
          "url": "https://growthmindedmarketing.com/blog/what-is-seo-keyword-difficulty/",
          "excerpts": [
            "Ahrefs shows a keyword difficulty of 83 making it very hard. Semrush has 100% difficulty with very hard for the same keyword. Moz shows a ..."
          ]
        },
        {
          "title": "BKAContent article on Google Keyword Planner accuracy and tool comparisons",
          "url": "https://bkacontent.com/how-accurate-is-google-keyword-planner/",
          "excerpts": [
            "In general, Semrush proves to be a better tool for SEO than Google Keyword Planner alone."
          ]
        },
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty (KD) is an SEO metric estimating how hard it is to rank on Google's first page for a keyword.",
            "Keyword difficulty is always only an estimation because Google does not disclose all its ranking factors.",
            "Keyword difficulty is a metric provided by various SEO tools intended to estimate a keyword’s ranking difficulty."
          ]
        }
      ],
      "reasoning": "The most relevant evidence would directly address tool-specific KD data and any comparative claims that imply a preferred ordering among sources. An excerpt discussing a direct comparison among Ahrefs, Semrush, and Moz indicates these are the key KD data sources to consider, which aligns with the idea of using a primary tool and alternatives. The statement that KD is a metric provided by tools, and that different tools report KD values, supports the notion that KD scores come from multiple providers, enabling a fallback sequence. Explicit examples showing one tool's KD being highlighted as primary or more authoritative would most strongly support the exact precedence rule; where such a claim is not stated verbatim, the excerpts still contextualize the landscape of sources (Ahrefs, Semrush, Moz) and how KD values are interpreted or compared, which is relevant to inferring a sourcing policy. The excerpts collectively suggest: (a) KD data is tool-derived, (b) Ahrefs, Semrush, Moz are key KD sources, and (c) there is variation in KD values across tools, which justifies having a precedence rule to resolve which source to trust first. The strongest direct support for the precedence would come from explicit statements about Ahrefs KD as the primary source, followed by Semrush KD% as a fallback, and Moz KD as tertiary, but such an explicit statement appears indirectly supported by the surrounding KD-tool discussions rather than a single definitive quote.",
      "confidence": "medium"
    },
    {
      "field": "keyword_difficulty_sourcing_policy.missing_value_rule",
      "citations": [
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "Keyword difficulty (KD%) is a metric that measures the SEO effort it would take for your content to rank organically in the top 10 results on Google for a ..."
          ]
        },
        {
          "title": "What is keyword difficulty & how to use it for SEO [2024 Guide]",
          "url": "https://growthmindedmarketing.com/blog/what-is-seo-keyword-difficulty/",
          "excerpts": [
            "Ahrefs shows a keyword difficulty of 83 making it very hard. Semrush has 100% difficulty with very hard for the same keyword. Moz shows a ..."
          ]
        },
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty (KD) is an SEO metric estimating how hard it is to rank on Google's first page for a keyword.",
            "Keyword difficulty is a metric provided by various SEO tools intended to estimate a keyword’s ranking difficulty.",
            " KD. We pull the top 10 ranking pages for your keyword and count how many websites link to each. The more websites link to the top-ranking pages, the greater the keyword difficulty. Then we plot the result on a logarithmic scale from 0 to 100"
          ]
        },
        {
          "title": "Ahrefs vs. SEMRush Keyword Difficulty Score Compared",
          "url": "https://fatstacksblog.com/ahrefs-vs-semrush-keyword-difficulty-score/",
          "excerpts": [
            "The Ahrefs KD suggests the difficulty to get ranked in the top 10 spots. Not necessariy the top spot in Google search."
          ]
        },
        {
          "title": "Ahrefs vs. Semrush vs. Moz: The Battle of the SEO Tools",
          "url": "https://www.oneupweb.com/blog/ahrefs-vs-semrush-vs-moz-the-battle-of-the-seo-tools/",
          "excerpts": [
            "It claims to track twice as many keywords as Semrush (and five times as many as Moz) and to do it all more accurately. They claim their traffic ..."
          ]
        },
        {
          "title": "BKAContent article on Google Keyword Planner accuracy and tool comparisons",
          "url": "https://bkacontent.com/how-accurate-is-google-keyword-planner/",
          "excerpts": [
            "In general, Semrush proves to be a better tool for SEO than Google Keyword Planner alone."
          ]
        }
      ],
      "reasoning": "KD% is described as a metric that measures the SEO effort to rank in the top results, and it is noted as an estimation rather than an exact figure, which supports using multiple providers to triangulate values when the primary source is unavailable. One excerpt explicitly frames KD% as a metric that estimates ranking difficulty and discusses the role of top-ranking pages and backlinks in determining KD, reinforcing that KD is an estimate and can vary by tool. Another excerpt clearly references the three providers (Ahrefs, Semrush, Moz) in comparative discussions, which underpins the policy of consulting secondary and tertiary sources when the primary source does not yield a value. Additional excerpts acknowledge that different tools (Ahrefs, Semrush, Moz) have varying KD interpretations or scores, which justifies a fallback mechanism rather than relying on a single source. Together, these excerpts substantiate a sourcing-policy framework where Ahrefs is the default first source, Semrush is the fallback, Moz is the tertiary, and the field can be left blank if all three fail to provide a score. The cited material on tool-specific KD values and comparisons further supports the idea that scores are tool-dependent and not interchangeable, reinforcing the need for a defined fallback sequence.",
      "confidence": "medium"
    },
    {
      "field": "final_csv_production_specifications.csv_standard_compliance",
      "citations": [
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml",
          "excerpts": [
            "RFC 4180 stipulates the use of CRLF pairs to denote line breaks, where CR is %x0D (Hex 0D) and LF is %x0A (Hex 0A). Each line should contain the same number of fields. Fields that contain a special character (comma, CR, LF, or double quote), must be \"escaped\" by enclosing them in double quotes (Hex 22) . "
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.ietf.org/rfc/rfc4180.txt",
          "excerpts": [
            "x\n\n   6. Fields containing line breaks (CRLF), double quotes, and commas\n       should be enclosed in double-quotes. For example:\n\n       \"aaa\",\"b CRLF\n       bb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "xxx\n\n   7. If double-quotes are used to enclose fields, then a double-quote\n       appearing inside a field must be escaped by preceding it with\n       another double quote. For example:\n\n       \"aaa\",\"b\"\"bb\",\"ccc\"",
            "c\n\n   5. Each field may or may not be enclosed in double quotes (however\n       some programs, such as Microsoft Excel, do not use double quotes\n       at all). If fields are not enclosed with double quotes, then\n       double quotes may not appear inside the fields.\nFor example:\n\n       \"aaa\",\"bbb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "  3. There maybe an optional header line appearing as the first line\n       of the file with the same format as normal record lines. This\n       header will contain names corresponding to the fields in the file\n       and should contain the same number of fields as the records in\n       the rest of the file (the presence or absence of the header line\n       should be indicated via the optional \"header\" parameter of this\n       MIME type). For example:\n\n       field_name,field_name,field_name CRLF\n       aaa,bbb,ccc CRLF\n       zzz,yyy,xxx CRLF",
            "4. Within the header and each record, there may be one or more\n       fields, separated by commas. Each line should contain the same\n       number of fields throughout the file. Spaces are considered part\n       of a field and should not be ignored. The last field in the\n       record must not be followed by a comma. For example:\n\n       aaa,bbb,ccc",
            "The ABNF grammar [2] appears as follows:\n\n   file = [header CRLF] record *(CRLF record) [CRLF]\n\n   header = name *(COMMA name)\n\n   record = field *(COMMA field)\n\n   name = field\n\n   field = (escaped / non-escaped)\n\n   escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE\n\n   non-escaped = *TEXTDATA",
            "3. MIME Type Registration of text/csv\n\n   This section provides the media-type registration application (as per\n   RFC 2048 [1]."
          ]
        },
        {
          "title": "CSV module documentation",
          "url": "https://docs.python.org/3/library/csv.html",
          "excerpts": [
            "The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using '\\n' as line terminator and quoting all fields. ",
            "... \nQUOTE\\_MINIMAL [¶](.QUOTE_MINIMAL \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to only quote those fields which contain\n    special characters such as _delimiter_ , _quotechar_ , `'\\r'` , `'\\n'` or any of the characters in _lineterminator_ . csv. QUOTE\\_NONNUMERIC [¶](.QUOTE_NONNUMERIC \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to quote all non-numeric fields. Instructs [`reader`](.reader \"csv.reader\") objects to convert all non-quoted fields to type [`float`](functions.html \"float\") . Note"
          ]
        }
      ],
      "reasoning": "The field value requires strict adherence to RFC 4180 for CSV production. Directly relevant excerpts state that: CSV lines use CRLF as the line terminator and that fields are separated by commas; fields containing special characters (such as comma, newline, or double quote) must be enclosed in double quotes, and a double quote inside a quoted field must be escaped by doubling it. Specific notes about QUOTE_MINIMAL indicate that the CSV writer should quote only fields that require it, which matches the field value's instruction to use quotes only when necessary and to escape embedded quotes. Additional excerpts describe optional header behavior and the ABNF grammar used in RFC 4180, which provide context for standard compliance. The Python csv module excerpts confirm how QUOTE_MINIMAL governs quoting in practice, reinforcing alignment with the requested standard. Together, these excerpts support the precision requirements in the field value about delimiters, quoting rules, escaping, and minimal quoting strategy, as well as the RFC 4180 baseline and related implementation guidance.",
      "confidence": "high"
    },
    {
      "field": "final_csv_production_specifications.formatting_and_encoding",
      "citations": [
        {
          "title": "Excel save behaviour of CSV file with UTF8 encoding vs ...",
          "url": "https://superuser.com/questions/1204233/excel-save-behaviour-of-csv-file-with-utf8-encoding-vs-utf8-bom-encoding",
          "excerpts": [
            "My issue is that with a UTF8 encoded CSV file, when you click save in Excel it gives you a popup option to keep the original formatting."
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml",
          "excerpts": [
            "RFC 4180 stipulates the use of CRLF pairs to denote line breaks, where CR is %x0D (Hex 0D) and LF is %x0A (Hex 0A). Each line should contain the same number of fields. Fields that contain a special character (comma, CR, LF, or double quote), must be \"escaped\" by enclosing them in double quotes (Hex 22) . ",
            "An optional header line may appear as the first line\nof the file with the same format as normal record lines."
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.ietf.org/rfc/rfc4180.txt",
          "excerpts": [
            "4. Within the header and each record, there may be one or more\n       fields, separated by commas. Each line should contain the same\n       number of fields throughout the file. Spaces are considered part\n       of a field and should not be ignored. The last field in the\n       record must not be followed by a comma. For example:\n\n       aaa,bbb,ccc",
            "c\n\n   5. Each field may or may not be enclosed in double quotes (however\n       some programs, such as Microsoft Excel, do not use double quotes\n       at all). If fields are not enclosed with double quotes, then\n       double quotes may not appear inside the fields.\nFor example:\n\n       \"aaa\",\"bbb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "x\n\n   6. Fields containing line breaks (CRLF), double quotes, and commas\n       should be enclosed in double-quotes. For example:\n\n       \"aaa\",\"b CRLF\n       bb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "xxx\n\n   7. If double-quotes are used to enclose fields, then a double-quote\n       appearing inside a field must be escaped by preceding it with\n       another double quote. For example:\n\n       \"aaa\",\"b\"\"bb\",\"ccc\"",
            "The ABNF grammar [2] appears as follows:\n\n   file = [header CRLF] record *(CRLF record) [CRLF]\n\n   header = name *(COMMA name)\n\n   record = field *(COMMA field)\n\n   name = field\n\n   field = (escaped / non-escaped)\n\n   escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE\n\n   non-escaped = *TEXTDATA",
            "3. MIME Type Registration of text/csv\n\n   This section provides the media-type registration application (as per\n   RFC 2048 [1].",
            "  3. There maybe an optional header line appearing as the first line\n       of the file with the same format as normal record lines. This\n       header will contain names corresponding to the fields in the file\n       and should contain the same number of fields as the records in\n       the rest of the file (the presence or absence of the header line\n       should be indicated via the optional \"header\" parameter of this\n       MIME type). For example:\n\n       field_name,field_name,field_name CRLF\n       aaa,bbb,ccc CRLF\n       zzz,yyy,xxx CRLF"
          ]
        },
        {
          "title": "CSV module documentation",
          "url": "https://docs.python.org/3/library/csv.html",
          "excerpts": [
            "The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using '\\n' as line terminator and quoting all fields. ",
            "... \nQUOTE\\_MINIMAL [¶](.QUOTE_MINIMAL \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to only quote those fields which contain\n    special characters such as _delimiter_ , _quotechar_ , `'\\r'` , `'\\n'` or any of the characters in _lineterminator_ . csv. QUOTE\\_NONNUMERIC [¶](.QUOTE_NONNUMERIC \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to quote all non-numeric fields. Instructs [`reader`](.reader \"csv.reader\") objects to convert all non-quoted fields to type [`float`](functions.html \"float\") . Note"
          ]
        },
        {
          "title": "How to Sort Unicode Strings Alphabetically in Python",
          "url": "https://realpython.com/python-sort-unicode-strings/",
          "excerpts": [
            "In this tutorial, you'll learn how to correctly sort Unicode strings in Python while avoiding common pitfalls. You'll explore powerful third-party libraries ..."
          ]
        }
      ],
      "reasoning": "The most relevant excerpt directly discusses encoding behavior when saving CSVs in a UTF-8 context, highlighting how Excel prompts about encoding and the distinction between UTF-8 and UTF-8 with BOM. This directly informs the requirement that the entire CSV file be encoded in UTF-8, preferably without a Byte Order Mark (BOM). Several other excerpts describe core CSV formatting rules—such as how fields are separated by commas, the need for equal field counts per line, handling of quotes, escaping of special characters, and header semantics—which are all essential for a well-formed CSV production specification. These excerpts help validate that the output should adhere to standard CSV formatting conventions (line terminators, quoting rules, escaping, and header handling) that must be compatible with parsing tools and consistent with RFC 4180 guidance. Additional excerpts dive into details of the ABNF grammar for fields, and Python's csv module behavior, which further supports the structural expectations of a robust, machine-readable CSV file. Taken together, these excerpts corroborate the requirements for a UTF-8 encoded CSV without BOM and a consistent, well-formed CSV structure with correct quoting, escaping, and header handling as part of the final deliverable.",
      "confidence": "medium"
    },
    {
      "field": "final_csv_production_specifications.headers_and_order",
      "citations": [
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.ietf.org/rfc/rfc4180.txt",
          "excerpts": [
            "  3. There maybe an optional header line appearing as the first line\n       of the file with the same format as normal record lines. This\n       header will contain names corresponding to the fields in the file\n       and should contain the same number of fields as the records in\n       the rest of the file (the presence or absence of the header line\n       should be indicated via the optional \"header\" parameter of this\n       MIME type). For example:\n\n       field_name,field_name,field_name CRLF\n       aaa,bbb,ccc CRLF\n       zzz,yyy,xxx CRLF",
            "The ABNF grammar [2] appears as follows:\n\n   file = [header CRLF] record *(CRLF record) [CRLF]\n\n   header = name *(COMMA name)\n\n   record = field *(COMMA field)\n\n   name = field\n\n   field = (escaped / non-escaped)\n\n   escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE\n\n   non-escaped = *TEXTDATA",
            "4. Within the header and each record, there may be one or more\n       fields, separated by commas. Each line should contain the same\n       number of fields throughout the file. Spaces are considered part\n       of a field and should not be ignored. The last field in the\n       record must not be followed by a comma. For example:\n\n       aaa,bbb,ccc",
            "c\n\n   5. Each field may or may not be enclosed in double quotes (however\n       some programs, such as Microsoft Excel, do not use double quotes\n       at all). If fields are not enclosed with double quotes, then\n       double quotes may not appear inside the fields.\nFor example:\n\n       \"aaa\",\"bbb\",\"ccc\" CRLF\n       zzz,yyy,xxx"
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml",
          "excerpts": [
            "An optional header line may appear as the first line\nof the file with the same format as normal record lines.",
            "RFC 4180 stipulates the use of CRLF pairs to denote line breaks, where CR is %x0D (Hex 0D) and LF is %x0A (Hex 0A). Each line should contain the same number of fields. Fields that contain a special character (comma, CR, LF, or double quote), must be \"escaped\" by enclosing them in double quotes (Hex 22) . "
          ]
        }
      ],
      "reasoning": "The finegrained field value asserts that the final CSV must have a header row as the first record, and that the headers must appear in a specific exact order. Excerpts that discuss CSV header behavior directly support this: one excerpt explains that there may be an optional header line at the first line of the file and that it should contain the names corresponding to the fields in the file, with the same number of fields as the records. This aligns with the notion of a header row containing field names. Another excerpt reinforces that a header line may appear as the first line and that headers are part of the file's structure. A third excerpt provides a formal ABNF rule where a header is defined as a sequence of names, underscoring that headers are a named, ordered component of a CSV file. Additional excerpts reiterate how headers relate to the fields in the records and how quotes and escaping interact with header and data fields, which corroborates the requirement that the header row defines the column order. Collectively, these excerpts support the idea that a header row is expected, contains field names, and is structurally tied to the defined field order, which matches the specified header sequence in the finegrained field value.",
      "confidence": "high"
    },
    {
      "field": "quality_assurance_and_validation_plan.stability_and_audit_checks",
      "citations": [
        {
          "title": "Measuring Search Engine Consistency Using Rank Stability",
          "url": "https://www.researchgate.net/publication/391884532_Beyond_Precision_and_Recall_Measuring_Search_Engine_Consistency_Using_Rank_Stability",
          "excerpts": [
            "The proposed approach distinguishes between overlapping and non-overlapping documents, providing a detailed measure of ranking stability."
          ]
        },
        {
          "title": "A Similarity Measure for Indefinite Rankings",
          "url": "http://blog.mobile.codalism.com/research/papers/wmz10_tois.pdf",
          "excerpts": [
            "by W WEBBER · 2010 · Cited by 1054 — Rank-biased overlap (RBO) is a new measure for comparing incomplete, top-weighted, and indefinite rankings, handling non-conjointness and weighting high ranks."
          ]
        },
        {
          "title": "A similarity measure for indefinite rankings",
          "url": "https://dl.acm.org/doi/10.1145/1852102.1852106",
          "excerpts": [
            "In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). ... Lester, N., Moffat, A., Webber, W., and Zobel, J. 2005."
          ]
        },
        {
          "title": "The Treatment of Ties in Rank-Biased Overlap",
          "url": "https://dl.acm.org/doi/10.1145/3626772.3657700",
          "excerpts": [
            "Jul 11, 2024 — In this paper we propose a generalized formulation for RBO to handle ties, thanks to which we complete the original definitions by showing how to perform ...",
            "The Treatment of Ties in Rank-Biased Overlap"
          ]
        },
        {
          "title": "Search Console Metrics - What are impressions, position, and clicks?",
          "url": "https://support.google.com/webmasters/answer/7042828?hl=en",
          "excerpts": [
            "Search Console provides data showing how often users saw or interacted with links to or content from your site, in Google Search, News, and Discover. This data is available in the various performance reports . The performance reports show the following metrics:",
            "Impressions : How often someone saw a link to your site on Google. Depending on the result type, the link might need to be scrolled or expanded into view.",
            "Clicks : How often someone clicked a link from Google to your site."
          ]
        },
        {
          "title": "What Counts as an Impression in Google Search Console ...",
          "url": "https://www.hbfreelance.com/what-counts-as-an-impression-in-google-search-console-performance-report/",
          "excerpts": [
            "May 4, 2025 — In Google Search Console, an impression is recorded when a link to your website appears in the search results a user views."
          ]
        },
        {
          "title": "Using Search Console and Google Analytics Data for SEO",
          "url": "https://developers.google.com/search/docs/monitor-debug/google-analytics-search-console",
          "excerpts": [
            "You can choose your timezone in Google Analytics, but you can't customize that in Search Console, where the default time zone is PST. This is particularly ..."
          ]
        }
      ],
      "reasoning": "The core field value describes a formal approach to rank stability, including the use of historical data (2024), week-over-week and month-over-month stability scores, and a specific stability threshold based on a Roverlap-like metric. Excerpt describing a title focused on Rank Stability and a methodology for measuring stability directly supports this concept by outlining a structured approach to evaluate ranking robustness over time. Excerpts mentioning rank-biased overlap (RBO) provide methodological context about ranking similarity and top-weighted comparisons, which is thematically related to stability assessments even though they refer to a different metric. Excerpts about performance metrics in Search Console (impressions, clicks) and live SERP audits offer practical validation processes (spot checks, localization effects, personalization) that align with the broader stability and validation theme, although they do not specify Roverlap or the exact stability framework. Collectively, these excerpts support the idea of measuring and validating ranking stability over time, with the strongest support coming from the explicit discussion of rank stability and the methodological approach to quantify it, and weaker support from related ranking similarity metrics and validation practices.",
      "confidence": "medium"
    },
    {
      "field": "non_branded_classification_framework.brand_lexicon_sources",
      "citations": [
        {
          "title": "Branded vs. Non-Branded Keywords: What They Are + ...",
          "url": "https://hawksem.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Branded keywords are search terms that include your company or product's name, whereas non-branded keywords are more generic . Building a branded SEO and PPC campaign can fend off competitors, capture a higher-intent audience, and increase conversions."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ...",
            "Non-branded keywords are general search terms that don't mention your brand."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes constructing a comprehensive brand lexicon by aggregating data from multiple authoritative, bulk-downloadable, and API-accessible sources, including open knowledge graphs, corporate lists, trademark databases, app store data, and person-name lists. The provided excerpts establish foundational definitions and the common practice of using external data sources to inform branded versus non-branded keyword understanding, which underpins the concept of building a brand lexicon from diverse sources. Specifically, branded keywords are defined as queries that include a brand name, and non-branded keywords are generic terms without a brand term. This supports the idea that a lexicon differentiates brand-related terms from others. Additional excerpts reference well-known data-providers and platforms (Ahrefs, Semrush, Moz) as sources of keyword data and analysis, which aligns with the methodological requirement to synthesize data from major digital intelligence platforms to inform the lexicon. While the excerpts clearly articulate the definition of branded vs non-branded terms and acknowledge external data sources, they do not enumerate the exact sources listed in the field value (e.g., Wikidata, DBpedia, USPTO, CNIPA, KIPO, app stores, SSA). Therefore, the excerpts provide strong conceptual and methodological support but partial corroboration for the specifics of the source list in the field value.",
      "confidence": "medium"
    },
    {
      "field": "quality_assurance_and_validation_plan.cross_source_variance_analysis",
      "citations": [
        {
          "title": "A Similarity Measure for Indefinite Rankings",
          "url": "http://blog.mobile.codalism.com/research/papers/wmz10_tois.pdf",
          "excerpts": [
            "by W WEBBER · 2010 · Cited by 1054 — Rank-biased overlap (RBO) is a new measure for comparing incomplete, top-weighted, and indefinite rankings, handling non-conjointness and weighting high ranks."
          ]
        },
        {
          "title": "A similarity measure for indefinite rankings",
          "url": "https://dl.acm.org/doi/10.1145/1852102.1852106",
          "excerpts": [
            "In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). ... Lester, N., Moffat, A., Webber, W., and Zobel, J. 2005."
          ]
        },
        {
          "title": "The Treatment of Ties in Rank-Biased Overlap",
          "url": "https://dl.acm.org/doi/10.1145/3626772.3657700",
          "excerpts": [
            "Jul 11, 2024 — In this paper we propose a generalized formulation for RBO to handle ties, thanks to which we complete the original definitions by showing how to perform ...",
            "The Treatment of Ties in Rank-Biased Overlap"
          ]
        },
        {
          "title": "Measuring Search Engine Consistency Using Rank Stability",
          "url": "https://www.researchgate.net/publication/391884532_Beyond_Precision_and_Recall_Measuring_Search_Engine_Consistency_Using_Rank_Stability",
          "excerpts": [
            "The proposed approach distinguishes between overlapping and non-overlapping documents, providing a detailed measure of ranking stability."
          ]
        }
      ],
      "reasoning": "The field value describes evaluating consistency across data providers by comparing ranked lists of queries with a metric that accounts for top-weighted rankings and can handle ties. Content that introduces Rank-Biased Overlap as a measure for comparing incomplete, top-weighted, and indefinite rankings directly supports the core method for cross-source variance analysis. Discussions of a generalized formulation for handling ties in RBO further align with the need to compare rankings from different tools where ties may occur. Additionally, material on rank stability and consistency in ranking systems provides context for assessing agreement across sources, even if not explicitly stating cross-provider comparisons. Together, these excerpts establish a methodological basis for measuring and interpreting agreement between provider rankings, which is central to the described cross-source variance analysis. The least directly aligned content covers general search analytics concepts (e.g., impressions, basic Search Console metrics) and therefore provides background but does not tightly support the specific cross-source, RBO-based approach.\n\nKey connections:\n- A measure for comparing top-weighted rankings is explicitly introduced, matching the need to quantify agreement between provider lists.\n- A generalized treatment of ties is described, which is essential when aggregating data from multiple sources that may not rank items identically.\n- Concepts around ranking stability and consistency provide a broader validation framework for assessing cross-provider variance beyond a single source.\n",
      "confidence": "medium"
    },
    {
      "field": "quality_assurance_and_validation_plan.ground_truth_validation",
      "citations": [
        {
          "title": "Search Console Metrics - What are impressions, position, and clicks?",
          "url": "https://support.google.com/webmasters/answer/7042828?hl=en",
          "excerpts": [
            "Search Console provides data showing how often users saw or interacted with links to or content from your site, in Google Search, News, and Discover. This data is available in the various performance reports . The performance reports show the following metrics:",
            "Impressions : How often someone saw a link to your site on Google. Depending on the result type, the link might need to be scrolled or expanded into view.",
            "Clicks : How often someone clicked a link from Google to your site."
          ]
        },
        {
          "title": "What Counts as an Impression in Google Search Console ...",
          "url": "https://www.hbfreelance.com/what-counts-as-an-impression-in-google-search-console-performance-report/",
          "excerpts": [
            "May 4, 2025 — In Google Search Console, an impression is recorded when a link to your website appears in the search results a user views."
          ]
        },
        {
          "title": "Using Search Console and Google Analytics Data for SEO",
          "url": "https://developers.google.com/search/docs/monitor-debug/google-analytics-search-console",
          "excerpts": [
            "You can choose your timezone in Google Analytics, but you can't customize that in Search Console, where the default time zone is PST. This is particularly ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on validating data against Google Search Console (GSC) by sampling query data and comparing rank and impression figures to GSC for the same date range, with GSC's Average Position used as the baseline and a consideration of data latency and time zone. The most directly supporting content describes how GSC presents core metrics such as impressions, position (and by extension, average position), and clicks, which are the essential components of a validation dataset drawn from GSC. Additional excerpts clarify how impressions are counted and presented within the Search Console framework, reinforcing the role of GSC as the data source and the semantics of its metrics. Another excerpt notes the integration of Search Console data into SEO tooling and workflows, which aligns with using GSC data as a validation reference. Together, these excerpts establish the necessary context for validating internal data against GSC metrics and for interpreting baseline concepts like position/impressions within a time-aware, latency-conscious framework.",
      "confidence": "medium"
    },
    {
      "field": "project_overview.scope",
      "citations": [
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "This applies to both organic results and search ads.",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l",
            "## Difference between branded search and non-branded search",
            "## Why optimize for non-branded search"
          ]
        }
      ],
      "reasoning": "The target field value asserts a scope centered on non-branded search queries and explicitly excludes branded terms. Excerpts that define branded vs non-branded search provide the necessary criteria to determine which queries would qualify under the scope. The content explains that a branded search includes a company, service, or product name, while a non-branded search does not. This directly supports excluding branded terms from the dataset. Reiterated discussions further emphasize the need to optimize or classify for non-branded terms, reinforcing the alignment with the stated scope.",
      "confidence": "high"
    },
    {
      "field": "operational_definitions.global_scope_definition",
      "citations": [
        {
          "title": "Overview",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/keywords-explorer/overview",
          "excerpts": [
            "See global search volume for any keyword",
            "See keyword search volumes from 200+ countries"
          ]
        }
      ],
      "reasoning": "The finegrained field value defines global search volume as the aggregation of a keyword's monthly search volumes across all countries/regions, typically using an all-locations worldwide setting or summing regional volumes. The most directly supportive excerpts state: 'See global search volume for any keyword,' which directly references the existence of a global/globalized metric, and 'See keyword search volumes from 200+ countries,' which explicitly describes aggregating data across multiple countries to form a global perspective. Together, these excerpts provide the essential basis for understanding how global scope is determined and measured, aligning with the concept of aggregating regional volumes to reflect worldwide search trends. Other excerpts touch on related SEO metrics (like keyword difficulty) but do not address the global scope definition as directly, making them less relevant to this specific field value.",
      "confidence": "high"
    },
    {
      "field": "project_overview.primary_metric",
      "citations": [
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "* Average monthly searches (past 12 months)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont"
          ]
        },
        {
          "title": "Definition of Average Monthly Search Volume in Keyword ...",
          "url": "https://support.google.com/google-ads/thread/221894898/definition-of-average-monthly-search-volume-in-keyword-planner-exact-broad-phrase?hl=en",
          "excerpts": [
            "The avg. search volume number shown in the keywords planner against each keyword is for which match type? Exact, Broad or Phrase."
          ]
        }
      ],
      "reasoning": "The finegrained field value asserts that the primary metric for ranking search queries is the EstimatedMonthlyVolume, i.e., the estimated global monthly search volume. Excerpts describing historical metrics and the display of monthly searches directly support that the system uses a monthly search volume estimate as a primary performance metric. Specifically, passages that refer to historical metrics including Average monthly searches (past 12 months) illustrate that the system tracks and reports monthly search volumes. Descriptions of the Date Range capability and how it shows average monthly searches further corroborate that the monthly search volume is central to evaluating keyword performance. Excerpts mentioning monthly search estimates provided by Google Ads Keyword Planner also align with the concept of a quantitative volume-based metric that would underpin a ranking signal. The items describing branded vs non-branded search, while informative, do not directly support the notion of the primary metric being the monthly volume estimate, and thus are less relevant to this field value.",
      "confidence": "high"
    },
    {
      "field": "non_branded_classification_framework.disambiguation_strategy",
      "citations": [
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ...",
            "Non-branded keywords are general search terms that don't mention your brand."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What They Are + ...",
          "url": "https://hawksem.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Branded keywords are search terms that include your company or product's name, whereas non-branded keywords are more generic . Building a branded SEO and PPC campaign can fend off competitors, capture a higher-intent audience, and increase conversions."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name."
          ]
        }
      ],
      "reasoning": "The core of the fine-grained field value is that terms may be branded or non-branded and that disambiguation should rely on contextual cues from the SERP to determine intent, especially when signals strongly point to a brand (e.g., brand-related knowledge or domain prominence). Excerpt describing branded keywords states that these are queries that include your brand name or variations, which directly anchors the branded classification needed for disambiguation. Excerpts explaining non-branded keywords define the counterpart category, which is essential for contrast-driven disambiguation decisions. Excerpts addressing how branded terms relate to attracting higher-intent audiences further support the motivation for distinguishing branding in the analysis. Additional excerpts referencing navigational or traffic concepts reinforce that branding impacts user intent interpretation and search behavior, aligning with the idea that strong brand signals influence classification toward branded/navigational intent. Although none of the excerpts explicitly list specific SERP features, the described signals (brand name presence, domain uniqueness, and brand-centric behavior) map onto the idea of using SERP-derived cues to resolve ambiguity between branded and non-branded terms. In summary, the excerpts collectively establish the definitions and practical consequences of branding in search, forming the backbone for the proposed disambiguation strategy that uses brand-associated signals as evidence of intent.",
      "confidence": "medium"
    },
    {
      "field": "non_branded_classification_framework.auditing_and_verification_process",
      "citations": [
        {
          "title": "Branded vs. Non-Branded Keywords: What They Are + ...",
          "url": "https://hawksem.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Branded keywords are search terms that include your company or product's name, whereas non-branded keywords are more generic . Building a branded SEO and PPC campaign can fend off competitors, capture a higher-intent audience, and increase conversions."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ...",
            "Non-branded keywords are general search terms that don't mention your brand."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name."
          ]
        }
      ],
      "reasoning": "The core value being analyzed describes a framework for distinguishing branded keywords (those containing a brand name or variations) from non-branded keywords (more generic terms) and mentions the need to audit and refine classifications. Excerpts that explain what branded keywords are and how they differ from non-branded keywords provide direct support for this foundational classification. Specifically, one excerpt clarifies that branded keywords include the brand name and are unique to the domain, while non-branded keywords do not mention the brand. Another excerpt reinforces that branded keywords are directly associated with a brand name and its products or services. A third excerpt reiterates that branded keywords include variations of the brand name, and non-branded keywords are general terms that don't mention the brand. Additional excerpts elaborate on the concept by contrasting branded and non-branded terms and by defining non-branded traffic as coming from terms that do not contain the brand name. Together, these excerpts map closely to the classification dimension described in the fine-grained field value, establishing the essential semantic boundary between branded and non-branded terms, which is a prerequisite for the auditing and verification processes described (e.g., manual audits, misclassification tracking, remediation workflows). The remaining excerpts extend the non-branding concept to traffic analysis, which provides contextual depth but is secondary to the primary classification distinction required by the field value.",
      "confidence": "medium"
    },
    {
      "field": "project_overview.objective",
      "citations": [
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "* Average monthly searches (past 12 months)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Master keyword research with Google's Keyword Planner. Learn how to find the right keywords, analyze search volume, and optimize your Google Ads campaigns.",
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "Google Ads Help: Use Keyword Planner",
          "url": "https://support.google.com/google-ads/answer/7337243?hl=en",
          "excerpts": [
            "See monthly searches:** See estimates on the number of searches a keyword gets each mont"
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t."
          ]
        }
      ],
      "reasoning": "The field value asserts a primary mission to analyze the global search landscape by compiling a definitive dataset of the top 5,000 Google search queries by absolute volume for a major industry publication. Excerpts that discuss generating historical metrics and the use of tools like Google Ads Keyword Planner demonstrate concrete methods for estimating and historical tracking of search volumes, which are fundamental to ranking queries by volume. Phrases such as generating historical metrics, metrics on how keywords have performed, and seeing average monthly searches directly support the idea of aggregating high-volume queries over a period. Additional excerpts describe how to leverage the Keyword Planner to analyze and filter keywords and understand monthly search volumes, which aligns with the operational steps needed to assemble a ranked dataset. Another excerpt describes the distinction between branded and non-branded searches, which informs how to classify the top queries within a large, global dataset. Collectively, these excerpts establish a methodological backbone (volume estimation, historical context, keyword planning workflows) that directly supports the field value's objective of creating a ranked, volume-based top-5,000 keyword dataset for a high-profile annual publication.",
      "confidence": "medium"
    },
    {
      "field": "operational_definitions.word_count_definition",
      "citations": [
        {
          "title": "Unicode Text Segmentation (UAX #29)",
          "url": "https://unicode.org/reports/tr29/",
          "excerpts": [
            "Word Boundaries:** _An implementation shall choose either UAX29-C2-1 or UAX29-C2-2 to determine whether an offset within a sequence of characters is a word bounda",
            "A Unicode Standard Annex (UAX)** forms an integral part\n>  of the Unicode Standard, but is published online as a separate\n>  doc",
            "ummary\n\n_This annex describes guidelines for determining default\n segmentation boundaries between certain significant text elements:\n grapheme clusters (“user-perceived characters”), words, and\n sentences.",
            "This specification defines _default_ mechanisms; more\n sophisticated implementations can _and should_ tailor them for\n particular locales or environments and, for the purpose of claiming conformance, document the tailoring in the form of a profil"
          ]
        },
        {
          "title": "Unicode TR29: Text Boundaries",
          "url": "http://www.unicode.org/reports/tr29/tr29-9.html",
          "excerpts": [
            "The default boundary determination mechanism specified in this document provides a \n straightforward and efficient way to determine some of the most significant boundaries in text: \n grapheme clusters (what end-users usually think of as characters), words, and sentences. (Line \n boundaries are to be found in [UAX #14: Line \n Breaking Pro",
            "_\n\n_This document describes guidelines for determining default boundaries between certain \n significant text elements: grapheme clusters (“user characters”), words, and sentences. For \n line-break boundaries, see [UAX #14: Line Breaking \n Properties](http://www.unicode.org/reports/tr14/) .",
            "| Any | (10) |\n\nWord boundaries are used in a number of different contexts. The most familiar ones are selection ( double-click mouse selection, or “move to next word” control-arrow keys ) , \n and “Whole Word Search” for search and replace. They are also used in database queries, to \n determine whether elements are within a certain number of words of one another."
          ]
        }
      ],
      "reasoning": "The finegrained field value defines a specific word-counting definition based on Unicode Standard Annex #29 (UAX #29) word boundaries, including rules such as counting hyphenated terms as a single word, counting numbers as words, treating punctuation as delimiters and removing them before counting, and employing language-specific tokenization for languages without spaces. It also states that a query is included only if the final token count is three or fewer. The most directly relevant sources are those that explicitly discuss word boundaries and segmentation as defined by UAX #29: one excerpt focuses on the explicit concept of word boundaries and how to determine them, which directly maps to the counting rules described. Other closely related excerpts describe the broader context of Unicode text segmentation, default boundary determination mechanisms, and how word boundaries are used in practice, all of which underpin the specific counting approach described. Additional excerpts that elaborate on the general notion of word segmentation and its place within the Unicode framework support the interpretation that word-counting follows these standards, even if they are less focused on the exact counting criteria. Taken together, these excerpts coherently support the field value's emphasis on UAX #29-based word boundary rules and their implications for token counting and inclusion criteria. ",
      "confidence": "high"
    },
    {
      "field": "operational_definitions.non_branded_query_definition",
      "citations": [
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "You can filter by three types of keywords: Branded, Non-branded, and Branded for other domains.",
            "Semrush provides the ability to filter Branded and Non-Branded keywords in our Organic Positions  and Position Changes reports",
            "* **Branded** will show you all the branded keywords that we find for the queried domain."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "Jan 10, 2024 — This guide will teach you how to attract and nurture non-branded traffic to guide your users through the marketing funnel, converting them into loyal customers ...",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        }
      ],
      "reasoning": "The target field defines a non-branded query as a generic search term that does not reference a brand name, product name, organization name, or domain. It also notes that such queries correspond to users in awareness or consideration stages and that automated identification relies on rule-based cues like absence of brand references and absence of navigational intent. Excerpt content explicitly states that non-branded keywords are those that do not reference a brand name, and that branded keywords include the brand name or domain, which supports the classification criteria. It also clarifies that non-branded traffic is driven by keywords without company, product, or service names, which aligns with the intended interpretation of non-branded queries in search data. The excerpts detailing filtering capabilities (e.g., by Branded vs Non-branded) reinforce that this distinction is consistently recognized across tooling, and the practical examples of non-branded usage (e.g., searches like general terms) illustrate typical non-branded behavior. Additional excerpts provide concrete examples and definitions of non-branded traffic, underscoring that ambiguous terms are excluded when a branded interpretation exists, which is central to maintaining the integrity of a non-branded set. Taken together, these excerpts directly support the field value by outlining the exact criteria for what constitutes a non-branded query, how it differs from branded queries, and how identification is implemented in practice.",
      "confidence": "high"
    },
    {
      "field": "quality_assurance_and_validation_plan.acceptance_criteria_and_rework_triggers",
      "citations": [
        {
          "title": "A Similarity Measure for Indefinite Rankings",
          "url": "http://blog.mobile.codalism.com/research/papers/wmz10_tois.pdf",
          "excerpts": [
            "by W WEBBER · 2010 · Cited by 1054 — Rank-biased overlap (RBO) is a new measure for comparing incomplete, top-weighted, and indefinite rankings, handling non-conjointness and weighting high ranks."
          ]
        },
        {
          "title": "Measuring Search Engine Consistency Using Rank Stability",
          "url": "https://www.researchgate.net/publication/391884532_Beyond_Precision_and_Recall_Measuring_Search_Engine_Consistency_Using_Rank_Stability",
          "excerpts": [
            "The proposed approach distinguishes between overlapping and non-overlapping documents, providing a detailed measure of ranking stability."
          ]
        },
        {
          "title": "A similarity measure for indefinite rankings",
          "url": "https://dl.acm.org/doi/10.1145/1852102.1852106",
          "excerpts": [
            "In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). ... Lester, N., Moffat, A., Webber, W., and Zobel, J. 2005."
          ]
        },
        {
          "title": "The Treatment of Ties in Rank-Biased Overlap",
          "url": "https://dl.acm.org/doi/10.1145/3626772.3657700",
          "excerpts": [
            "Jul 11, 2024 — In this paper we propose a generalized formulation for RBO to handle ties, thanks to which we complete the original definitions by showing how to perform ...",
            "The Treatment of Ties in Rank-Biased Overlap"
          ]
        },
        {
          "title": "Search Console Metrics - What are impressions, position, and clicks?",
          "url": "https://support.google.com/webmasters/answer/7042828?hl=en",
          "excerpts": [
            "Search Console provides data showing how often users saw or interacted with links to or content from your site, in Google Search, News, and Discover. This data is available in the various performance reports . The performance reports show the following metrics:",
            "Impressions : How often someone saw a link to your site on Google. Depending on the result type, the link might need to be scrolled or expanded into view.",
            "Clicks : How often someone clicked a link from Google to your site."
          ]
        }
      ],
      "reasoning": "The target field value requires a strict acceptance suite predicated on (i) a low average rank difference when comparing to a trusted ranking proxy (GSC), (ii) a high average RBO score when compared to external tools, and (iii) a high share of top queries demonstrating stability, with a mechanism to trigger a full rework if discrepancies or instability are detected. Excerpts describing Rank-Biased Overlap (RBO) establish that RBO is specifically designed to compare incomplete, top-weighted rankings, which directly supports using RBO as a benchmark for cross-tool ranking similarity. Additional excerpts discuss handling ties in RBO, which is relevant for ensuring the comparison remains robust across ranking outputs that may have tied positions. Other excerpts introduce the function of Google Search Console metrics (impressions, position, clicks) and clarify that GSC data reflects how often and where content appears in Google Search, providing the empirical basis for calculating rank differences versus GSC. Lastly, content on rank stability and measuring consistency offers a conceptual foundation for defining and interpreting stability thresholds across top queries. Collectively, these excerpts underpin the idea of an acceptance framework where RBO and GSC-derived rank differences, along with stability measures, determine readiness for publication and trigger rework if discrepancies or instability exceed predefined criteria.",
      "confidence": "high"
    },
    {
      "field": "content_moderation_policy.documentation_and_transparency",
      "citations": [
        {
          "title": "How to use the moderation API",
          "url": "https://cookbook.openai.com/examples/how_to_use_moderation",
          "excerpts": [
            "Mar 5, 2024 — You can also check for one or more categories to tailor this to a specific use case: sexual; sexual/minors; harassment; harassment/threatening ..."
          ]
        },
        {
          "title": "Moderation - OpenAI API",
          "url": "https://platform.openai.com/docs/guides/moderation",
          "excerpts": [
            "... categories ... Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education ..."
          ]
        },
        {
          "title": "Garm Brand Safety Floor Suitability Framework 23 Sept | PDF",
          "url": "https://www.scribd.com/document/664972235/Garm-Brand-Safety-Floor-Suitability-Framework-23-Sept",
          "excerpts": [
            "The framework provides common definitions for categorizing harmful and sensitive content. It establishes a Brand Safety Floor that defines content ..."
          ]
        },
        {
          "title": "IAB Content Taxonomy 3.1",
          "url": "https://iabtechlab.com/standards/content-taxonomy/",
          "excerpts": [
            "mber 11, 2024\n\nThe Content Taxonomy provides a “common language” that can be used when describing content. Typical uses of the content taxonomy are contextual targeting and brand safety."
          ]
        }
      ],
      "reasoning": "- The most relevant excerpt discusses how to use a moderation system by checking for specified content categories (sexual, sexual/minors, harassment, etc.). This directly relates to how a moderation policy classifies content, a necessary component of transparent reporting and auditing of moderation actions. It supports the idea that moderation decisions are based on explicit categories, which is foundational for auditability and clarity in documentation.\n- The next relevant excerpt provides a focused look at a moderation API and its category system, reinforcing the notion that standardized categorization underpins transparent and repeatable moderation actions. This aligns with the requirement for clear documentation of what kinds of content trigger certain actions, contributing to overall transparency.\n- The remaining excerpts describe a Brand Safety Framework and the IAB Content Taxonomy, which establish structured vocabularies and guidelines for assessing content safety and suitability. While not explicitly about transparency or datasheets, they illustrate the organized, policy-driven approach that enables traceable moderation decisions and standardized reporting, which are key for comprehensive documentation and disclosure practices.\n- Collectively, these excerpts suggest that a policy framework with explicit categories and standards is essential for transparency in moderation, even though none explicitly mention datasheets for datasets or explicit counts of excluded items. They provide the methodological backbone that would support the requested documentation-centric transparency goals.",
      "confidence": "medium"
    },
    {
      "field": "operational_definitions.estimated_monthly_volume_definition",
      "citations": [
        {
          "title": "Overview",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/keywords-explorer/overview",
          "excerpts": [
            "See global search volume for any keyword",
            "See keyword search volumes from 200+ countries",
            "Keyword Difficulty estimates how hard it will be to rank in the top 10 for a given keyword. It's scored on a scale from 0-100.",
            "In this report, we give you all the in-depth SEO metrics you need to make quick and informed decisions about a keyword."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "Semrush provides the ability to filter Branded and Non-Branded keywords in our Organic Positions  and Position Changes reports",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "You can filter by three types of keywords: Branded, Non-branded, and Branded for other domains.",
            "* **Branded** will show you all the branded keywords that we find for the queried domain."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "Jan 10, 2024 — This guide will teach you how to attract and nurture non-branded traffic to guide your users through the marketing funnel, converting them into loyal customers ...",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        },
        {
          "title": "Unicode Text Segmentation (UAX #29)",
          "url": "https://unicode.org/reports/tr29/",
          "excerpts": [
            "A Unicode Standard Annex (UAX)** forms an integral part\n>  of the Unicode Standard, but is published online as a separate\n>  doc",
            "ummary\n\n_This annex describes guidelines for determining default\n segmentation boundaries between certain significant text elements:\n grapheme clusters (“user-perceived characters”), words, and\n sentences.",
            "Word Boundaries:** _An implementation shall choose either UAX29-C2-1 or UAX29-C2-2 to determine whether an offset within a sequence of characters is a word bounda",
            "This specification defines _default_ mechanisms; more\n sophisticated implementations can _and should_ tailor them for\n particular locales or environments and, for the purpose of claiming conformance, document the tailoring in the form of a profil"
          ]
        },
        {
          "title": "Unicode TR29: Text Boundaries",
          "url": "http://www.unicode.org/reports/tr29/tr29-9.html",
          "excerpts": [
            "_\n\n_This document describes guidelines for determining default boundaries between certain \n significant text elements: grapheme clusters (“user characters”), words, and sentences. For \n line-break boundaries, see [UAX #14: Line Breaking \n Properties](http://www.unicode.org/reports/tr14/) .",
            "| Any | (10) |\n\nWord boundaries are used in a number of different contexts. The most familiar ones are selection ( double-click mouse selection, or “move to next word” control-arrow keys ) , \n and “Whole Word Search” for search and replace. They are also used in database queries, to \n determine whether elements are within a certain number of words of one another.",
            "The default boundary determination mechanism specified in this document provides a \n straightforward and efficient way to determine some of the most significant boundaries in text: \n grapheme clusters (what end-users usually think of as characters), words, and sentences. (Line \n boundaries are to be found in [UAX #14: Line \n Breaking Pro"
          ]
        }
      ],
      "reasoning": "The fine-grained field value describes a precise method for computing an annual/monthly search volume metric, including a 12-month average over the full calendar year and data-imputation for missing values. The excerpts most relevant to supporting or contextualizing this field are those that address how search volume and related metrics are obtained or presented. Specifically, mentions of global search volume, keyword search volumes across many countries, and general discussions of keyword metrics are directly related to understanding how volume figures are gathered and interpreted. Excerpts that define branded vs. non-branded keywords or discuss related SEO concepts provide contextual or peripheral support but do not directly corroborate the stated 12-month averaging methodology or imputation approach. Therefore, the most relevant content centers on sources that discuss global search volume and general keyword metrics, followed by excerpts describing related SEO measurement concepts, with branding-focused entries being the least directly connected to the field value. The exact 12-month averaging and imputation approach, however, is not explicitly stated in any excerpt, so explicit support for that precise definition is not found in the supplied material.",
      "confidence": "low"
    },
    {
      "field": "estimated_volume_calculation_methodology.calculation_window",
      "citations": [
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Approximate monthly search volume (per month)",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)",
            "You can use historical metrics to reduce a large set of keywords to a more\nmanageable size based on the performance.",
            "To generate historical metrics call KeywordPlanIdeaService.GenerateKeywordHistoricalMetrics with the parameters you would like to include."
          ]
        }
      ],
      "reasoning": "The most directly relevant content concerns the use of a defined time window (a specific date range) and the use of average monthly searches over a 12-month span. The statement about a Date Range allowing you to specify a period and see average monthly searches for that time period directly supports the idea that the calculation window is defined by a fixed 12-month interval. The notes about Average Monthly Searches and 'past 12 months' further corroborate that a 12-month window is standard for calculating monthly volumes, which aligns with using the full calendar year 2024 (January 1 to December 31) as the calculation window. Other excerpts mentioning historical metrics and 12-month aggregates reinforce the same concept but are less explicit about tying this precisely to the calendar year 2024; they nonetheless support the 12-month-window interpretation.",
      "confidence": "medium"
    },
    {
      "field": "query_normalization_and_deduplication_policy.near_duplicate_detection_method",
      "citations": [
        {
          "title": "Finding near-duplicates with Jaccard similarity and MinHash",
          "url": "https://blog.nelhage.com/post/fuzzy-dedup/",
          "excerpts": [
            " 1.”\nBy using a subset of our \\(k\\) MinHash hashes as a grouping key, we can increase the likelihood of collisions at lower similarity values, and then compare the full signatures within each bucket to weed out false collisions. For instance, we might group by the first 4 MinHash values, and then – within each colliding group – use all of our MinHash values to estimate the trule similariy. Using fewer hashes is helpful, but only so far; \\(J^r\\) will always be smaller than \\(J\\), and if we push \\(r\\) too small, the rate of spurious matches will become unacceptable.",
            "What are the odds that two documents end up hashed together in at least one bucket? * The odds that two documents collide using a single key is \\(J^r\\)",
            "\\)\n\nThus, the odds that they collide at-least-once ends up as:\n\\[ p = 1 - (1-J^r)^b \\]"
          ]
        }
      ],
      "reasoning": "The most pertinent content directly discusses scalable deduplication and how to group queries using a hashing-based approach. Specifically, it mentions using a subset of MinHash hashes as a grouping key to cluster similar items, followed by full comparison within each bucket to resolve duplicates. This aligns with the MinHashing technique described in the target field value as a scalable approximation of similarity (to handle large datasets). The next excerpt elaborates on the probabilistic behavior of collisions when using multiple MinHash keys, illustrating how the odds of collision are evaluated in a deduplication context, which complements the understanding of how MinHash-based grouping reduces redundant comparisons. The third excerpt provides a concrete probability expression for collision across buckets, demonstrating the practical mathematics behind the MinHash-based approach, which supports the notion of efficient near-duplicate detection via hashing. Collectively, these excerpts support the MinHashing portion and its role in scalable deduplication, which is a core element of the finegrained field value. They do not explicitly confirm the Levenshtein-distance component, but they corroborate the MinHash-based methodology described in the field value.",
      "confidence": "medium"
    },
    {
      "field": "content_moderation_policy.content_taxonomy",
      "citations": [
        {
          "title": "IAB Content Taxonomy 3.1",
          "url": "https://iabtechlab.com/standards/content-taxonomy/",
          "excerpts": [
            "mber 11, 2024\n\nThe Content Taxonomy provides a “common language” that can be used when describing content. Typical uses of the content taxonomy are contextual targeting and brand safety.",
            "Content Taxonomy 3.1",
            "The 3.1 version of the content taxonomy is now open for public comment until Jan 24, 2025. This latest version contains an update to the ‘genre’ category to include Thrille"
          ]
        },
        {
          "title": "Implementation Guide for Brand Suitability with the Content ...",
          "url": "https://iabtechlab.com/wp-content/uploads/2020/12/Implementation_Guide_for_Brand_Suitability_with_IABTechLab_Content_Taxonomy_2-2.pdf",
          "excerpts": [
            "Adult & Explicit Sexual Content. 2. Arms & Ammunition. 3 ... Buyers should familiarize themselves with the GARM/4A's APB Brand Safety & Suitability Framework."
          ]
        },
        {
          "title": "How to use the moderation API",
          "url": "https://cookbook.openai.com/examples/how_to_use_moderation",
          "excerpts": [
            "Mar 5, 2024 — You can also check for one or more categories to tailor this to a specific use case: sexual; sexual/minors; harassment; harassment/threatening ..."
          ]
        },
        {
          "title": "Garm Brand Safety Floor Suitability Framework 23 Sept | PDF",
          "url": "https://www.scribd.com/document/664972235/Garm-Brand-Safety-Floor-Suitability-Framework-23-Sept",
          "excerpts": [
            "The framework provides common definitions for categorizing harmful and sensitive content. It establishes a Brand Safety Floor that defines content ...",
            "Sep 23, 2024 — It establishes a Brand Safety Floor that defines content inappropriate for advertising support. It also includes a Brand Suitability Framework ..."
          ]
        },
        {
          "title": "Adult Website Law – Beginner's Legal Guide for Operating an Adult Website",
          "url": "https://www.firstamendment.com/adult-website-law-beginners-legal-guide-for-operating-an-adult-website/",
          "excerpts": [
            "A more serious issue arises with the age of persons depicted in sexually explicit material. Child pornography, exploitation, and sex trafficking offenses are some of the most serious crimes in the nation, at both the state and federal levels. Adult website operators must make every effort to ensure that underage materials are not published on their sites.",
            "The publication of sexually explicit media on a website generally requires a Section 2257 disclosure statement, which identifies the location of where the mandatory records are kept."
          ]
        },
        {
          "title": "Directive - 2011/93 - EN - EUR-Lex - European Union",
          "url": "https://eur-lex.europa.eu/eli/dir/2011/93/oj/eng",
          "excerpts": [
            "Directive 2011/93/EU of the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "[PDF] B DIRECTIVE C1 2011/93/EU OF THE EUROPEAN ... - EUR-Lex",
          "url": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:02011L0093-20111217",
          "excerpts": [
            "This Directive obliges Member States to provide for criminal penalties in their national legislation in respect of the provisions of Union law ..."
          ]
        },
        {
          "title": "Moderation - OpenAI API",
          "url": "https://platform.openai.com/docs/guides/moderation",
          "excerpts": [
            "... categories ... Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education ..."
          ]
        },
        {
          "title": "Children's Online Privacy Protection Rule",
          "url": "https://www.federalregister.gov/documents/2025/04/22/2025-05904/childrens-online-privacy-protection-rule",
          "excerpts": [
            "Apr 22, 2025 — The Rule requires operators to keep personal information they collect from children secure and to maintain effective data retention and deletion ...",
            "Apr 22, 2025 — The amendments are intended to strengthen protection of personal information collected from children, and, where appropriate, to clarify and ..."
          ]
        },
        {
          "title": "USA: Legal, regulatory, and enforcement developments ...",
          "url": "https://www.ebglaw.com/media/publication/68_Shah-Reisz_OneTrust-Data-Guidance_Data-Protection-Leader_July-2025-dpl-report-reduced.pdf",
          "excerpts": [
            "6 days ago — States such as Georgia and Utah have added requirements for age verification on both personal and school-issued devices, further broadening the ..."
          ]
        },
        {
          "title": "Using PhotoDNA in Digital Forensics Investigations",
          "url": "https://www.adfsolutions.com/news/photodna-digital-forensics-investigations?srsltid=AfmBOoougPWMuTOMg3ktZ6K6Yi8r-crn0Hgd6rlkElMTUuTDlrjoytMD",
          "excerpts": [
            "Aug 13, 2020 — Learn how to use PhotoDNA to speed digital forensics investigations of visually similar pictures. Photo forensics for CSAM, CEM, ..."
          ]
        },
        {
          "title": "FTC Finalizes Changes to Children's Privacy Rule Limiting ...",
          "url": "https://www.ftc.gov/news-events/news/press-releases/2025/01/ftc-finalizes-changes-childrens-privacy-rule-limiting-companies-ability-monetize-kids-data",
          "excerpts": [
            "Jan 16, 2025 — The final rule requires parents to opt in to third-party advertising and includes other changes to address the emerging ways that consumers' ..."
          ]
        },
        {
          "title": "Congress, Not States or the Supreme Court, Should Lead ...",
          "url": "https://itif.org/publications/2025/02/05/congress-should-lead-way-in-childrens-online-safety-access-adult-content/",
          "excerpts": [
            "Feb 5, 2025 — Congress should pass legislation to preempt the impending patchwork of state age verification laws and establish a standardized child-flag system."
          ]
        },
        {
          "title": "Directive 2011/93/EU of the European Parliament and of the ...",
          "url": "https://www.legislation.gov.uk/eudr/2011/93/contents",
          "excerpts": [
            "Directive2011/93/EUof the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value centers on adopting a multi-tiered content taxonomy built from the GARM Brand Safety & Suitability Framework and the IAB Content Taxonomy, enabling content classification into categories such as Adult & Explicit Sexual Content, Hate Speech, and Illegal Drugs, with defined risk levels. References that explicitly name the IAB Content Taxonomy and its versions (3.0/3.1) provide direct support for the taxonomy component. References to the GARM framework establish the branding/safety foundation on which the taxonomy rests. Additional excerpts about moderation APIs, regulatory directives, and content safety guides reinforce the context of standardized categorization and governance around content classification. Direct quotes from these excerpts indicate: the existence of a common language for content taxonomy (IAB 3.1), the role of brand safety frameworks in content suitability, and the ongoing development/open feedback for taxonomy versions, all of which underpin adopting a structured taxonomy with risk levels. The more peripheral items (e.g., specific regulatory directives) corroborate the importance of safeguarding and classifying content but do not define the taxonomy itself; they serve as supportive context for why such a taxonomy exists and how it might be applied in compliance scenarios. The resulting interpretation is that a multi-tiered taxonomy integrating GARM and IAB is being proposed to classify content into predefined categories with associated risk levels, consistent with the field value. ",
      "confidence": "high"
    },
    {
      "field": "content_moderation_policy.legal_and_safety_compliance",
      "citations": [
        {
          "title": "Children's Online Privacy Protection Rule",
          "url": "https://www.federalregister.gov/documents/2025/04/22/2025-05904/childrens-online-privacy-protection-rule",
          "excerpts": [
            "Apr 22, 2025 — The Rule requires operators to keep personal information they collect from children secure and to maintain effective data retention and deletion ...",
            "Apr 22, 2025 — The amendments are intended to strengthen protection of personal information collected from children, and, where appropriate, to clarify and ..."
          ]
        },
        {
          "title": "FTC Finalizes Changes to Children's Privacy Rule Limiting ...",
          "url": "https://www.ftc.gov/news-events/news/press-releases/2025/01/ftc-finalizes-changes-childrens-privacy-rule-limiting-companies-ability-monetize-kids-data",
          "excerpts": [
            "Jan 16, 2025 — The final rule requires parents to opt in to third-party advertising and includes other changes to address the emerging ways that consumers' ..."
          ]
        },
        {
          "title": "USA: Legal, regulatory, and enforcement developments ...",
          "url": "https://www.ebglaw.com/media/publication/68_Shah-Reisz_OneTrust-Data-Guidance_Data-Protection-Leader_July-2025-dpl-report-reduced.pdf",
          "excerpts": [
            "6 days ago — States such as Georgia and Utah have added requirements for age verification on both personal and school-issued devices, further broadening the ..."
          ]
        },
        {
          "title": "Congress, Not States or the Supreme Court, Should Lead ...",
          "url": "https://itif.org/publications/2025/02/05/congress-should-lead-way-in-childrens-online-safety-access-adult-content/",
          "excerpts": [
            "Feb 5, 2025 — Congress should pass legislation to preempt the impending patchwork of state age verification laws and establish a standardized child-flag system."
          ]
        },
        {
          "title": "Directive 2011/93/EU of the European Parliament and of the ...",
          "url": "https://www.legislation.gov.uk/eudr/2011/93/contents",
          "excerpts": [
            "Directive2011/93/EUof the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "Directive - 2011/93 - EN - EUR-Lex - European Union",
          "url": "https://eur-lex.europa.eu/eli/dir/2011/93/oj/eng",
          "excerpts": [
            "Directive 2011/93/EU of the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "[PDF] B DIRECTIVE C1 2011/93/EU OF THE EUROPEAN ... - EUR-Lex",
          "url": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:02011L0093-20111217",
          "excerpts": [
            "This Directive obliges Member States to provide for criminal penalties in their national legislation in respect of the provisions of Union law ..."
          ]
        },
        {
          "title": "How to use the moderation API",
          "url": "https://cookbook.openai.com/examples/how_to_use_moderation",
          "excerpts": [
            "Mar 5, 2024 — You can also check for one or more categories to tailor this to a specific use case: sexual; sexual/minors; harassment; harassment/threatening ..."
          ]
        },
        {
          "title": "Moderation - OpenAI API",
          "url": "https://platform.openai.com/docs/guides/moderation",
          "excerpts": [
            "... categories ... Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education ..."
          ]
        },
        {
          "title": "Adult Website Law – Beginner's Legal Guide for Operating an Adult Website",
          "url": "https://www.firstamendment.com/adult-website-law-beginners-legal-guide-for-operating-an-adult-website/",
          "excerpts": [
            "A more serious issue arises with the age of persons depicted in sexually explicit material. Child pornography, exploitation, and sex trafficking offenses are some of the most serious crimes in the nation, at both the state and federal levels. Adult website operators must make every effort to ensure that underage materials are not published on their sites.",
            "The publication of sexually explicit media on a website generally requires a Section 2257 disclosure statement, which identifies the location of where the mandatory records are kept."
          ]
        },
        {
          "title": "IAB Content Taxonomy 3.1",
          "url": "https://iabtechlab.com/standards/content-taxonomy/",
          "excerpts": [
            "mber 11, 2024\n\nThe Content Taxonomy provides a “common language” that can be used when describing content. Typical uses of the content taxonomy are contextual targeting and brand safety.",
            "Content Taxonomy 3.1",
            "The 3.1 version of the content taxonomy is now open for public comment until Jan 24, 2025. This latest version contains an update to the ‘genre’ category to include Thrille"
          ]
        }
      ],
      "reasoning": "The most directly supportive material comes from excerpts describing specific child privacy protections and age-verification-related regulatory developments. References to COPPA and the broader context of protecting children's data indicate alignment with a policy framework that requires strict compliance with child-safety regulations and data privacy laws. Additionally, mentions of reporting requirements and evolving regulatory standards (e.g., GDPR's special categories of data, UK Online Safety Act, and age-verification debates) buttress the need for a zero-tolerance stance on CSAM and a robust compliance posture. Regulatory directive documents addressing combating sexual abuse and exploitation further corroborate the necessity of enforcing legal safeguards across jurisdictions. Moderation API guidance and content taxonomy discussions provide supporting mechanisms for how content should be evaluated and categorized, reinforcing the operational side of enforcing such policies, even though they are not themselves legal mandates. Adult-content related legal guides add context for handling regulated material in practice. Overall, these excerpts collectively support the field value by illustrating concrete legal instruments, reporting obligations, and compliance mechanisms that a strict, globally aware moderation policy would implement.",
      "confidence": "medium"
    },
    {
      "field": "automated_pipeline_architecture_proposal.architecture_model",
      "citations": [
        {
          "title": "Marquez Project | Marquez Project",
          "url": "https://marquezproject.ai/",
          "excerpts": [
            "Marquez enables consuming, storing, and visualizing OpenLineage metadata from across an organization, serving use cases including data governance."
          ]
        },
        {
          "title": "Lineage",
          "url": "https://docs.datahub.com/docs/api/tutorials/lineage",
          "excerpts": [
            "DataHub's Python SDK allows you to programmatically define and retrieve lineage between metadata entities. With the DataHub Lineage SDK, you can:"
          ]
        },
        {
          "title": "Constraint.scala - awslabs/deequ",
          "url": "https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/constraints/Constraint.scala",
          "excerpts": [
            "Deequ is a library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets."
          ]
        },
        {
          "title": "Honeycomb/OpenTelemetry Logging (Python SDK)",
          "url": "https://docs.honeycomb.io/send-data/logs/opentelemetry/sdk/python/",
          "excerpts": [
            "This example uses the OpenTelemetry Python SDK's logger provider to create log entries, and send them to Honeycomb or an OpenTelemetry Collector. Examples: Send OpenTelemetry Logs with the OpenTelemetry Python SDK | Honeycomb"
          ]
        },
        {
          "title": "OpenLineage Integrations with Great Expectations",
          "url": "https://openlineage.io/docs/integrations/great-expectations",
          "excerpts": [
            "Great Expectations integrates with OpenLineage through the action list in a checkpoint. An OpenLineage action can be specified, which is triggered when all expectations are run. Data from the checkpoint is sent to OpenLineage, which can then be viewed in Marquez or Datakin.",
            "Great Expectations is a robust data quality tool."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes a three-layer Medallion Architecture (Bronze, Silver, Gold) and ties data sources (Ahrefs, Semrush) to a data quality and transformation pipeline. The most directly relevant excerpts discuss data governance and lineage tooling (e.g., Marquez and DataHub lineage capabilities) and data governance concepts, which align with the idea of an organized, auditable data pipeline. They show awareness of metadata, lineage, and governance as prerequisites for a robust architecture, thereby supporting the general concept of a structured, multi-layered data pipeline, even though they do not confirm the exact Medallion terminology or named data sources. Other excerpts touch on related data quality and observability tools (Great Expectations, OpenTelemetry, Honeycomb) that are commonly used in pipelines and governance frameworks, further indicating ecosystem considerations relevant to architecting such a pipeline, though they do not directly validate the specific three-layer Bronze/Silver/Gold model with the cited sources.",
      "confidence": "low"
    },
    {
      "field": "content_moderation_policy.moderation_process",
      "citations": [
        {
          "title": "Using PhotoDNA in Digital Forensics Investigations",
          "url": "https://www.adfsolutions.com/news/photodna-digital-forensics-investigations?srsltid=AfmBOoougPWMuTOMg3ktZ6K6Yi8r-crn0Hgd6rlkElMTUuTDlrjoytMD",
          "excerpts": [
            "Aug 13, 2020 — Learn how to use PhotoDNA to speed digital forensics investigations of visually similar pictures. Photo forensics for CSAM, CEM, ..."
          ]
        },
        {
          "title": "Moderation - OpenAI API",
          "url": "https://platform.openai.com/docs/guides/moderation",
          "excerpts": [
            "... categories ... Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education ..."
          ]
        },
        {
          "title": "Implementation Guide for Brand Suitability with the Content ...",
          "url": "https://iabtechlab.com/wp-content/uploads/2020/12/Implementation_Guide_for_Brand_Suitability_with_IABTechLab_Content_Taxonomy_2-2.pdf",
          "excerpts": [
            "Adult & Explicit Sexual Content. 2. Arms & Ammunition. 3 ... Buyers should familiarize themselves with the GARM/4A's APB Brand Safety & Suitability Framework."
          ]
        },
        {
          "title": "IAB Content Taxonomy 3.1",
          "url": "https://iabtechlab.com/standards/content-taxonomy/",
          "excerpts": [
            "mber 11, 2024\n\nThe Content Taxonomy provides a “common language” that can be used when describing content. Typical uses of the content taxonomy are contextual targeting and brand safety.",
            "Content Taxonomy 3.1",
            "The 3.1 version of the content taxonomy is now open for public comment until Jan 24, 2025. This latest version contains an update to the ‘genre’ category to include Thrille"
          ]
        },
        {
          "title": "How to use the moderation API",
          "url": "https://cookbook.openai.com/examples/how_to_use_moderation",
          "excerpts": [
            "Mar 5, 2024 — You can also check for one or more categories to tailor this to a specific use case: sexual; sexual/minors; harassment; harassment/threatening ..."
          ]
        },
        {
          "title": "Garm Brand Safety Floor Suitability Framework 23 Sept | PDF",
          "url": "https://www.scribd.com/document/664972235/Garm-Brand-Safety-Floor-Suitability-Framework-23-Sept",
          "excerpts": [
            "The framework provides common definitions for categorizing harmful and sensitive content. It establishes a Brand Safety Floor that defines content ...",
            "Sep 23, 2024 — It establishes a Brand Safety Floor that defines content inappropriate for advertising support. It also includes a Brand Suitability Framework ..."
          ]
        },
        {
          "title": "Adult Website Law – Beginner's Legal Guide for Operating an Adult Website",
          "url": "https://www.firstamendment.com/adult-website-law-beginners-legal-guide-for-operating-an-adult-website/",
          "excerpts": [
            "A more serious issue arises with the age of persons depicted in sexually explicit material. Child pornography, exploitation, and sex trafficking offenses are some of the most serious crimes in the nation, at both the state and federal levels. Adult website operators must make every effort to ensure that underage materials are not published on their sites.",
            "The publication of sexually explicit media on a website generally requires a Section 2257 disclosure statement, which identifies the location of where the mandatory records are kept."
          ]
        },
        {
          "title": "Directive - 2011/93 - EN - EUR-Lex - European Union",
          "url": "https://eur-lex.europa.eu/eli/dir/2011/93/oj/eng",
          "excerpts": [
            "Directive 2011/93/EU of the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "[PDF] B DIRECTIVE C1 2011/93/EU OF THE EUROPEAN ... - EUR-Lex",
          "url": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:02011L0093-20111217",
          "excerpts": [
            "This Directive obliges Member States to provide for criminal penalties in their national legislation in respect of the provisions of Union law ..."
          ]
        },
        {
          "title": "FTC Finalizes Changes to Children's Privacy Rule Limiting ...",
          "url": "https://www.ftc.gov/news-events/news/press-releases/2025/01/ftc-finalizes-changes-childrens-privacy-rule-limiting-companies-ability-monetize-kids-data",
          "excerpts": [
            "Jan 16, 2025 — The final rule requires parents to opt in to third-party advertising and includes other changes to address the emerging ways that consumers' ..."
          ]
        },
        {
          "title": "Congress, Not States or the Supreme Court, Should Lead ...",
          "url": "https://itif.org/publications/2025/02/05/congress-should-lead-way-in-childrens-online-safety-access-adult-content/",
          "excerpts": [
            "Feb 5, 2025 — Congress should pass legislation to preempt the impending patchwork of state age verification laws and establish a standardized child-flag system."
          ]
        },
        {
          "title": "Directive 2011/93/EU of the European Parliament and of the ...",
          "url": "https://www.legislation.gov.uk/eudr/2011/93/contents",
          "excerpts": [
            "Directive2011/93/EUof the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        }
      ],
      "reasoning": "The most directly relevant excerpts establish components of a moderation workflow and detection capabilities. One excerpt explicitly notes using PhotoDNA to speed digital forensics investigations and CSAM-related detection, which aligns with the field's mention of industry-standard hashing technologies for CSAM. Another excerpt describes using a moderation interface or guidance that involves categories to tailor moderation—this supports the idea of automated flagging with configurable rules. Additional excerpts discuss brand safety and content taxonomy frameworks, which underpin the structured approach to categorizing content and applying safety rules, further supporting a hybrid moderation process where automated signals are informed by taxonomy and expert review. Several excerpts reference content taxonomies and safety frameworks that would inform both automated classification and human oversight, consistent with a hybrid model. Collectively, the entries provide concrete components (hash-based CSAM detection, automated flagging, human review, and taxonomy-driven categorization) that map onto the described content moderation process in the field value. Some excerpts focus more on legal or educational content and general moderation guidelines; while related, they serve as contextual support rather than direct statements about the hybrid workflow. Overall, the strongest support comes from explicit CSAM detection methods and explicit moderation tooling guidance, with taxonomy/framework references offering corroborating structure for rule-based automated systems and human review.",
      "confidence": "medium"
    },
    {
      "field": "query_normalization_and_deduplication_policy.whitespace_and_punctuation_handling",
      "citations": [
        {
          "title": "UAX #15: Unicode Normalization",
          "url": "https://www.unicode.org/standard/reports/tr15/tr15-21.html",
          "excerpts": [
            "Unicode Normalization Forms",
            "Unicode Normalization Forms",
            "For example, the half-width and full-width *katakana*\ncharacters will normalize to the same strings, as will Roman Numerals and their\nletter equivalent"
          ]
        },
        {
          "title": "UAX #15: Unicode Normalization Forms",
          "url": "https://unicode.org/reports/tr15/",
          "excerpts": [
            "This annex provides subsidiary information about Unicode normalization. It describes canonical and compatibility equivalence and the four normalization forms."
          ]
        },
        {
          "title": "Unicode Text Segmentation (UAX #29)",
          "url": "https://unicode.org/reports/tr29/",
          "excerpts": [
            "ummary\n\n_This annex describes guidelines for determining default\n segmentation boundaries between certain significant text elements:\n grapheme clusters (“user-perceived characters”), words, and\n sentences.",
            "Word Boundaries:** _An implementation shall choose either UAX29-C2-1 or UAX29-C2-2 to determine whether an offset within a sequence of characters is a word bounda",
            "This specification defines _default_ mechanisms; more\n sophisticated implementations can _and should_ tailor them for\n particular locales or environments and, for the purpose of claiming conformance, document the tailoring in the form of a profil"
          ]
        }
      ],
      "reasoning": "The most relevant material discusses Unicode normalization and how characters can normalize to equivalent forms, which underpins a systematic approach to canonicalizing input text before further processing. This supports the idea that the normalization policy would consider preserving meaningful punctuation while reducing variance due to representation differences. Related excerpts describe how certain character sequences and scripts are treated to produce uniform strings, which aligns with the notion of standardizing input text prior to deduplication or downstream parsing. Additionally, the text segmentation guidance around default word boundaries informs how tokens are identified, which is pertinent when collapsing internal whitespace to a single standard space and ensuring tokens are consistently delimited. Together, these excerpts provide a foundation for implementing the described multi-step normalization (trim, collapse spaces, preserve essential punctuation) by aligning on canonical forms and tokenization behavior, even though they do not spell out the exact whitespace-collapsing rule or the specific punctuation policy requested. The combination of normalization forms and word-boundary guidance offers indirect but practical support for a disciplined normalization pipeline.",
      "confidence": "medium"
    },
    {
      "field": "query_normalization_and_deduplication_policy.unicode_normalization_form",
      "citations": [
        {
          "title": "UAX #15: Unicode Normalization Forms",
          "url": "https://unicode.org/reports/tr15/",
          "excerpts": [
            "This annex provides subsidiary information about Unicode normalization. It describes canonical and compatibility equivalence and the four normalization forms."
          ]
        },
        {
          "title": "UAX #15: Unicode Normalization",
          "url": "https://www.unicode.org/standard/reports/tr15/tr15-21.html",
          "excerpts": [
            "Unicode Normalization Forms",
            "Unicode Normalization Forms",
            "For example, the half-width and full-width *katakana*\ncharacters will normalize to the same strings, as will Roman Numerals and their\nletter equivalent"
          ]
        },
        {
          "title": "[PDF] UAX #15: Unicode Normalization Forms",
          "url": "https://www.unicode.org/L2/L2011/11292-tr15-34.pdf",
          "excerpts": [
            "\n\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   Unicode ",
            "NORMALIZATION FORMS"
          ]
        }
      ],
      "reasoning": "The field value asserts that NFC is the recommended normalization form and describes how it composes characters into their shortest pre-composed representation, preserving semantics. Excerpts that explicitly refer to Unicode normalization and its forms establish this contextual basis. Content that discusses Unicode normalization forms, and examples of normalization (such as how certain characters normalize to the same representation), directly supports the idea that normalization is a defined process with multiple forms, among which a canonical form like NFC exists. Even though the excerpts may not explicitly name NFC or state it as the mandated standard, they provide the necessary background: Unicode normalization forms are defined, and examples illustrate how normalization operates on characters, which is essential to understand NFC's role as a preferred, precomposed representation. The most direct support comes from material that explicitly references Unicode Normalization and its forms, which anchors the concept of a standardized normalization process. Other excerpts that reiterate normalization discussions and provide form-specific details further corroborate the relevance of NFC as part of the broader normalization framework.",
      "confidence": "medium"
    },
    {
      "field": "estimated_volume_calculation_methodology.averaging_method",
      "citations": [
        {
          "title": "STL and Seasonal Adjustment Methods - otexts et al.",
          "url": "https://otexts.com/fpppy/nbs/03-decomposition.html",
          "excerpts": [
            "STL is an acronym for “Seasonal and Trend decomposition using Loess”, while loess is a method for estimating nonlinear relationships. The STL method was developed by Cleveland et al. ( 1990 ) , and later extended to handle multiple seasonal patterns by Bandara, Hyndman, and Bergmeir ( 2022 ) . STL has several advantages over classical decomposition, and the SEATS and X-11 methods:",
            "The seasonal component is allowed to change over time, and the rate of change can be controlled by the user. * The smoothness of the trend-cycle can also be controlled by the user. * It can be robust to outliers (i.e., the user can specify a robust decomposition), so that occasional unusual observations will not affect the estimates of the trend-cycle and seasonal components. They will, however, affect the remainder compon",
            "onality. The two main parameters to be chosen when using STL are the\nseason and the\ntrend . The\nseason is the length of the seasonal smoother, while the\ntrend is the length of the trend smoother. These parameters control how rapidly the trend-cycle and seasonal components can change.\nSmaller values allow for more rapid changes. Both trend and seasonal windows should be odd numbers. By default, the\nSTL() function in\nstatsmodels provides a convenient automated STL decomposition. This usually gives a good balance between overfitting the seasonality and allowing it to slowly change over time. But, as with any automated procedure, the default settings will need adjusting for some time series. In this case the default trend window setting produces a trend-cycle component that is too rigid. As a result, signal from the 2008 global financial crisis has leaked into the remainder component, as can be seen in the bottom panel of Figure  3.5 . Selecting a shorter trend window as in Figure  3.12 improves this."
          ]
        },
        {
          "title": "Seasonal Decomposition of Time Series by Loess (STL)",
          "url": "https://www.geeksforgeeks.org/data-analysis/seasonal-decomposition-of-time-series-by-loess-stl/",
          "excerpts": [
            "In this article, we will perform seasonal decomposition using Loess(STL) on a time-series dataset and remove the seasonality from the dataset."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Quick Reference for DOS",
          "url": "https://www2.census.gov/software/x-13arima-seats/x13as/windows/documentation/qrefx13ashtmlpc.pdf",
          "excerpts": [
            "-s : Store seasonal adjustment and regARIMA model diagnostics in a file. -t : Store timing information in the diagnostics file (if -s or -g not specified, will ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Reference Manual Accessible HTML ...",
          "url": "https://www.census.gov/library/working-papers/2017/adrm/docx13ashtml.html",
          "excerpts": [
            "Jan 18, 2017 — The X-13ARIMA-SEATS seasonal adjustment program is an enhanced version of the X-11 Variant of the Census Method II seasonal adjustment ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Seasonal Adjustment Program",
          "url": "https://www.census.gov/data/software/x13as.html",
          "excerpts": [
            "X-13ARIMA-SEATS is a seasonal adjustment software produced, distributed, and maintained by the Census Bureau.",
            "X-13ARIMA-SEATS Seasonal Adjustment Program",
            "X-13ARIMA-SEATS is seasonal adjustment software produced, distributed, and maintained by the Census Bureau. Features of X-13ARIMA-SEATS include:",
            "* Extensive time series modeling and model selection capabilities for linear regression models with ARIMA errors (regARIMA models);",
            "* The capability to generate ARIMA model-based seasonal adjustment using a version of the SEATS software originally developed by Victor Gómez and Agustín Maravall at the Bank of Spain, as well as nonparametric adjustments from the X-11 procedure;",
            "* Diagnostics of the quality and stability of the adjustments achieved under the options selected;",
            "* The ability to efficiently process many series at once."
          ]
        },
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)",
            "You can use historical metrics to reduce a large set of keywords to a more\nmanageable size based on the performance.",
            "To generate historical metrics call KeywordPlanIdeaService.GenerateKeywordHistoricalMetrics with the parameters you would like to include.",
            "Approximate monthly search volume (per month)"
          ]
        },
        {
          "title": "How to use the Keyword Planner tool effectively",
          "url": "https://business.google.com/us/resources/articles/using-google-ads-keyword-planner/",
          "excerpts": [
            "Date Range lets you enter a specific range of dates so you can see average monthly searches for that time period. You can also compare two different date ranges ...See more",
            "Average Monthly Searches**: Filters keywords based on average monthly searches\n  for selected da"
          ]
        },
        {
          "title": "A Basic Seasonal Adjustment Glossary",
          "url": "https://www.census.gov/data/software/x13as/references/glossary.html",
          "excerpts": [
            "Oct 8, 2021 — X-13ARIMA-SEATS (X-13A-S). Seasonal adjustment software developed by the U. S. Census Bureau in collaboration with the Bank of Spain that ..."
          ]
        },
        {
          "title": "5 Effective Uses of MAD for Outlier Detection and Analysis",
          "url": "https://www.numberanalytics.com/blog/5-uses-of-mad-for-outlier-detection",
          "excerpts": [
            "Mar 18, 2025 — Robustness to Outliers: MAD remains stable even when the dataset includes extreme values. Simplicity: The computation of MAD is straightforward, ..."
          ]
        },
        {
          "title": "Outlier Detection and Treatment: Z-score, IQR, and Robust ...",
          "url": "https://medium.com/@aakash013/outlier-detection-treatment-z-score-iqr-and-robust-methods-398c99450ff3",
          "excerpts": [
            "Robust Methods: Median Absolute Deviation (MAD). Median Absolute Deviation (MAD) is a robust statistical method that measures data variability."
          ]
        }
      ],
      "reasoning": "The finegrained field value specifies a concrete methodology: employ a seasonal adjustment and decomposition approach (either STL or X-13ARIMA-SEATS), deseasonalize historical monthly data using the extracted seasonal component, compute the arithmetic average of these deseasonalized volumes, and then reapply the typical seasonal factors for the target year to derive the final EstimatedMonthlyVolume. Excerpts that explicitly describe STL as Seasonal and Trend decomposition using Loess, with the ability to handle changing seasonal components and to decompose series into trend, seasonal, and remainder parts, directly support the first part of the method (decomposition and seasonal adjustment). Additional excerpts describe the parameters for STL (season and trend windows) and practical guidance on using the STL() function, which further substantiates how seasonality is modeled and adjusted. Excerpts describing X-13ARIMA-SEATS—its role as a seasonal adjustment program, its capability to produce ARIMA-based adjustments, diagnostics, and multi-series processing—support the alternative pathway mentioned in the field value for decomposition and adjustment, reinforcing the feasibility of the described methodology. Excerpts that outline the general concept of seasonal adjustment software and its components (seasonal components, diagnostics, and model-based adjustments) corroborate the step of applying seasonal adjustment and preparing for the reapplication of seasonal factors. While some excerpts discuss related but distinct topics (e.g., historical metrics in advertising tools), they are weaker in directly validating the exact sequencing (deseasonalize, average, re-seasonalize) but still provide context about working with seasonal data. In summary, the excerpts collectively support the core steps: decomposition into seasonal/trend/remainder, deseasonalization, averaging of deseasonalized data, and reapplication of seasonal factors. ",
      "confidence": "high"
    },
    {
      "field": "automated_pipeline_architecture_proposal.data_lineage_and_provenance",
      "citations": [
        {
          "title": "Marquez Project | Marquez Project",
          "url": "https://marquezproject.ai/",
          "excerpts": [
            "Marquez enables consuming, storing, and visualizing OpenLineage metadata from across an organization, serving use cases including data governance."
          ]
        },
        {
          "title": "Getting Started",
          "url": "https://openlineage.io/getting-started/",
          "excerpts": [
            "We'll show how to collect run-level metadata as OpenLineage events using Marquez as the HTTP backend, then explore lineage metadata via the Marquez UI."
          ]
        },
        {
          "title": "OpenLineage Integrations with Great Expectations",
          "url": "https://openlineage.io/docs/integrations/great-expectations",
          "excerpts": [
            "Great Expectations integrates with OpenLineage through the action list in a checkpoint. An OpenLineage action can be specified, which is triggered when all expectations are run. Data from the checkpoint is sent to OpenLineage, which can then be viewed in Marquez or Datakin.",
            "Great Expectations is a robust data quality tool."
          ]
        },
        {
          "title": "Lineage",
          "url": "https://docs.datahub.com/docs/api/tutorials/lineage",
          "excerpts": [
            "DataHub's Python SDK allows you to programmatically define and retrieve lineage between metadata entities. With the DataHub Lineage SDK, you can:"
          ]
        }
      ],
      "reasoning": "The central claim is that end-to-end data lineage is captured using the OpenLineage standard and stored/visualized by Marquez. The most directly supporting evidence is a passage stating that Marquez enables consuming, storing, and visualizing OpenLineage metadata across an organization, which aligns with end-to-end lineage capture and a centralized provenance/traceability layer. Another highly supportive excerpt notes that run-level metadata is collected as OpenLineage events using Marquez as the HTTP backend, further confirming OpenLineage-enabled lineage capture and Marquez as the storage/visualization surface. Additional excerpts discuss OpenLineage integrations with data quality tools (Great Expectations) and provide context that OpenLineage-based lineage workflows are a common pattern in data ecosystems, reinforcing the interpretation of a lineage-centric architecture. A separate excerpt mentions DataHub's lineage SDK, which is related to the concept of programmatically defining and retrieving lineage between metadata entities, supporting the broader claim of lineage tracing and provenance tracking in such ecosystems. Collectively, these excerpts substantiate the core idea of an end-to-end lineage workflow anchored by OpenLineage and Marquez, with supportive references to tooling integrations that illustrate practical lineage use cases.",
      "confidence": "medium"
    },
    {
      "field": "estimated_volume_calculation_methodology.anomaly_and_missing_data_handling",
      "citations": [
        {
          "title": "5 Effective Uses of MAD for Outlier Detection and Analysis",
          "url": "https://www.numberanalytics.com/blog/5-uses-of-mad-for-outlier-detection",
          "excerpts": [
            "Mar 18, 2025 — Robustness to Outliers: MAD remains stable even when the dataset includes extreme values. Simplicity: The computation of MAD is straightforward, ..."
          ]
        },
        {
          "title": "Outlier Detection and Treatment: Z-score, IQR, and Robust ...",
          "url": "https://medium.com/@aakash013/outlier-detection-treatment-z-score-iqr-and-robust-methods-398c99450ff3",
          "excerpts": [
            "Robust Methods: Median Absolute Deviation (MAD). Median Absolute Deviation (MAD) is a robust statistical method that measures data variability."
          ]
        }
      ],
      "reasoning": "The most relevant content directly addresses methods for identifying and treating outliers, which is central to anomaly handling in the field value. One excerpt discusses using robust methods for outlier detection and highlights the usefulness of Median Absolute Deviation (MAD) in maintaining stability when data include extreme values, which aligns with screening data for anomalies before proceeding with analysis. It also frames MAD as a robust approach to detecting outliers, which supports the field's emphasis on robust statistical screening prior to imputation or modeling. Another excerpt foregrounds outlier detection methods that rely on basic robust statistics such as the interquartile range (IQR) and Z-scores, signaling the applicability of standard anomaly-detection techniques (IQR rule, Modified Z-score) for flagging anomalous observations. Both excerpts together establish a foundation for anomaly screening using robust statistics, which directly maps to the field's described process. However, the excerpts do not provide explicit details about the specific imputation techniques (e.g., interpolation, model-based forecasting, or using prior-year averages) that the field value mentions for missing months, nor do they confirm the exact replacement strategies. This limits full corroboration of every component of the field value, though the core anomaly-detection and robustness concepts are well supported. The content relating to MAD and IQR/Z-score methods is the strongest match, with the mention of outlier handling and robustness to extreme data points being central to the fine-grained field value.",
      "confidence": "medium"
    },
    {
      "field": "provider_assessments",
      "citations": [
        {
          "title": "Branded vs. Non-Branded Keywords: What They Are + ...",
          "url": "https://hawksem.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Branded keywords are search terms that include your company or product's name, whereas non-branded keywords are more generic . Building a branded SEO and PPC campaign can fend off competitors, capture a higher-intent audience, and increase conversions.",
            "Non-branded keywords refer to or relate to your company or products without using the proper company name .",
            " Branded keywords include variations and misspellings of your company name.",
            "\nThe first term is a non-branded keyword or general query. The second is a branded keyword since it includes the company name, “Logitech."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ...",
            "Non-branded keywords are general search terms that don't mention your brand.",
            " 1\\. Perform Balanced Keyword Research\n\nYou want to mix branded and non-branded keywords in SEO and PPC campaigns. To reach customers familiar with your brand while attracting new prospects. First, you'll need to find those keywords. To do this, use the [Keyword Magic Tool](https://www.semrush.com/features/keyword-magic-tool/) to build a list for each type of keyword. First, enter a broad keyword into the tool and click “ **Search",
            "Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ..."
          ]
        },
        {
          "title": "What Is Branded Search & How to Increase It - Moz",
          "url": "https://moz.com/blog/what-is-branded-search",
          "excerpts": [
            "Feb 6, 2024 — On the other hand, non-branded traffic comes from general keywords that people search when they are looking for a product or service that meets ..."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered non-branded keywords."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "What Is Branded Search? (And How to Optimize Your Site ...",
          "url": "https://www.semrush.com/blog/branded-search/",
          "excerpts": [
            "Sep 10, 2024 — Unlike branded searches, non-branded searches have no relation to any brand. To illustrate, here are examples of branded vs. non-branded ...",
            "Sep 10, 2024 — A branded search is a search engine query that contains the name of your brand, service, or product."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l",
            "Ranking for non-branded keywords allows you to attract people who are searching for products or services related to your business **but may not necessarily know your brand** ."
          ]
        },
        {
          "title": "Almost Half of Google Searches Are Branded. Here's Why That Matters",
          "url": "https://ahrefs.com/blog/almost-half-of-google-searches-are-branded-study/",
          "excerpts": [
            "That's exactly why we added a “Search Intent” filter to Ahrefs' Keywords Explorer and Site Explorer. It lets you segment branded vs. non-branded ..."
          ]
        },
        {
          "title": "Hide branded keywords | Voters | Ahrefs - Canny",
          "url": "https://ahrefs.canny.io/keywords-explorer/p/hide-branded-keywords",
          "excerpts": [
            "I'd like to be able to filter out and remove keywords with Anazon/Walmart etc. - Instead of having to manually go through an entire list. April ..."
          ]
        },
        {
          "title": "Ahrefs Keywords Explorer Guide",
          "url": "https://ahrefs.com/blog/how-to-use-keywords-for-seo/",
          "excerpts": [
            "Include/Exclude: see keywords that contain specific words to increase relevancy/hide keywords with irrelevant words."
          ]
        },
        {
          "title": "How to Use the Keyword Magic Tool",
          "url": "https://www.semrush.com/kb/617-keyword-magic-tool-manual",
          "excerpts": [
            "**Word Count** filtering makes it easier to scan for long-tail keywords."
          ]
        },
        {
          "title": "Position Tracking Tool: Exclude Filtering By Tags",
          "url": "https://www.semrush.com/news/255937-position-tracking-tool-exclude-filtering-by-tags/",
          "excerpts": [
            "Here's how the 'Exclude' filter works: all you need to do now is mark branded keywords as “branded” and filter by this tag using 'include' or ' ..."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords in SEMrush",
          "url": "https://medium.com/mhafs/branded-vs-non-branded-keywords-in-semrush-the-ultimate-guide-c4e1a96fbec8",
          "excerpts": [
            "Add a custom filter in Position Tracking to separate branded and non-branded keywords. Pro Tip: Group your branded and non-branded ..."
          ]
        },
        {
          "title": "8 Most Important Types of Keywords for SEO (And How to Find Them)",
          "url": "https://ahrefs.com/blog/types-of-keywords/",
          "excerpts": [
            "Simply use the intents filter in Ahrefs' Keywords Explorer. It works for branded and unbranded keywords."
          ]
        },
        {
          "title": "Branded Vs. Non-Branded Keywords: SEO Strategies & Tips",
          "url": "https://sagapixel.com/seo/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Examples of Non-Branded Queries. Examples of non-branded queries include: “best running shoes”; “coffee shops near me”; “SEO tools for beginners”. SEO ...",
            "Branded keywords include terms explicitly related to your brand name while non-branded search terms are everything else not connected directly to your brand."
          ]
        },
        {
          "title": "Branded and Non-Branded Keywords in SEO Rankings",
          "url": "https://www.ibeamconsulting.com/blog/seo-keywords-branded-and-non-branded/",
          "excerpts": [
            "Branded and non-branded keywords are both important targets for SEO work. Learn the basics and further insights below."
          ]
        }
      ],
      "reasoning": "The user is looking for a tool that can identify the top 5,000 Google Search Queries, specifically focusing on non-branded queries with a maximum of three words. The `provider_assessments` field details the capabilities of Ahrefs, Semrush, and Moz for this task.\n\nAhrefs has a large keyword database and offers a 'Branded or not' filter in its Keywords Explorer, which is relevant for identifying non-branded queries. However, it lacks a direct filter for word count, requiring external processing for this specific constraint. Its API has rate limits and a unit-based cost system, with UI exports also being subject to subscription-based quotas.\n\nSemrush stands out with its extensive keyword database and robust filtering capabilities, including explicit filters for word count (allowing for a maximum of three words) and for excluding branded keywords. This directly addresses the core requirements of the user's query. Semrush also offers granular filtering by search intent and other metrics. Its API has rate limits and a unit-based cost, with UI exports also having daily quotas.\n\nMoz has limitations in its filtering capabilities, lacking direct filters for word count and non-branded status, necessitating external data processing. While it offers a 'Brand Rules' feature, it's limited to specific campaign reports and not a universal filter. Its API has restrictive quotas, especially for lower-tier plans, and its keyword corpus is smaller compared to Ahrefs and Semrush.\n\nConsidering the specific requirements of filtering by word count and non-branded status, Semrush appears to be the most suitable provider due to its direct filtering capabilities. Ahrefs is a viable alternative but requires additional processing for word count filtering. Moz is less suitable due to its filtering limitations.",
      "confidence": "high"
    },
    {
      "field": "provider_assessments.2",
      "citations": [
        {
          "title": "What Is Branded Search & How to Increase It - Moz",
          "url": "https://moz.com/blog/what-is-branded-search",
          "excerpts": [
            "Feb 6, 2024 — On the other hand, non-branded traffic comes from general keywords that people search when they are looking for a product or service that meets ..."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        }
      ],
      "reasoning": "The most relevant content directly rooted in Moz discusses branded search and non-branded traffic, which aligns with the Moz-specific discussion in the field value about how Moz treats and explains these categories. For example, the Moz-focused item explains that branded search covers queries containing the brand name or its variations, while non-branded traffic refers to terms that do not include the brand, which supports the field value's framing of Moz's locus in branded vs. non-branded analysis. Additional Moz-centric items elaborate on what constitutes branded vs. non-branded traffic and provide concrete examples, which strengthen the connection between Moz's conceptual framework and the finegrained field value. These Moz-oriented excerpts also describe Moz's broader context for keyword analysis, including the concept of branded versus non-branded terms, which underpins the field value's claims about Moz's data coverage and filtering considerations. While some details in the field value (e.g., specific accuracy figures, regional data availability, and export/API limits) are not explicitly spelled out in these excerpts, the Moz-specific discussions about data interpretation, traffic classification, and Moz's guidance on branded vs. non-branded keywords are directly relevant to understanding and validating the Moz portion of the finegrained field value.",
      "confidence": "medium"
    },
    {
      "field": "provider_assessments.1",
      "citations": [
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            " 1\\. Perform Balanced Keyword Research\n\nYou want to mix branded and non-branded keywords in SEO and PPC campaigns. To reach customers familiar with your brand while attracting new prospects. First, you'll need to find those keywords. To do this, use the [Keyword Magic Tool](https://www.semrush.com/features/keyword-magic-tool/) to build a list for each type of keyword. First, enter a broad keyword into the tool and click “ **Search",
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ..."
          ]
        },
        {
          "title": "How to Use the Keyword Magic Tool",
          "url": "https://www.semrush.com/kb/617-keyword-magic-tool-manual",
          "excerpts": [
            "**Word Count** filtering makes it easier to scan for long-tail keywords."
          ]
        },
        {
          "title": "Position Tracking Tool: Exclude Filtering By Tags",
          "url": "https://www.semrush.com/news/255937-position-tracking-tool-exclude-filtering-by-tags/",
          "excerpts": [
            "Here's how the 'Exclude' filter works: all you need to do now is mark branded keywords as “branded” and filter by this tag using 'include' or ' ..."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords in SEMrush",
          "url": "https://medium.com/mhafs/branded-vs-non-branded-keywords-in-semrush-the-ultimate-guide-c4e1a96fbec8",
          "excerpts": [
            "Add a custom filter in Position Tracking to separate branded and non-branded keywords. Pro Tip: Group your branded and non-branded ..."
          ]
        },
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered non-branded keywords."
          ]
        }
      ],
      "reasoning": "The fine-grained field value centers on Semrush as the provider and describes three main aspects: data sourcing/filtering capabilities, export/API limits, and key metrics offered. Relevant excerpts explicitly reference Semrush tools and capabilities that align with these aspects. First, the description of the Keyword Magic Tool discusses building keyword lists and the need to differentiate keyword types (branding vs non-branding), which directly supports how Semrush enables targeted keyword research and categorization. Second, multiple excerpts refer to the Keyword Magic Tool manual, underscoring that there is formal documentation describing how to use Semrush's keyword tooling, including its filtering capabilities. Third, the Semrush Knowledge Base entries define what branded vs non-branded keywords are, providing the conceptual basis for categorization mentioned in the field value. Fourth, additional Semrush-related notes about branded vs non-branded keywords and related tools reinforce the existence of filtering and categorization features within Semrush offerings, which aligns with the described capabilities in the field value. Taken together, these excerpts substantiate Semrush as the data source, the existence of tooling for keyword-type filtering (including excluding branded keywords), and the documentation backing these features, which supports the finegrained field value's claims about Semrush's data handling and filtering capabilities.",
      "confidence": "medium"
    },
    {
      "field": "provider_assessments.0",
      "citations": [
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l",
            "Ranking for non-branded keywords allows you to attract people who are searching for products or services related to your business **but may not necessarily know your brand** ."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "Almost Half of Google Searches Are Branded. Here's Why That Matters",
          "url": "https://ahrefs.com/blog/almost-half-of-google-searches-are-branded-study/",
          "excerpts": [
            "That's exactly why we added a “Search Intent” filter to Ahrefs' Keywords Explorer and Site Explorer. It lets you segment branded vs. non-branded ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value concerns a detailed provider assessment of Ahrefs, including data scope, filtering capabilities, export/API constraints, and key metrics like keyword difficulty and primary intent. Excerpts that explicitly reference Ahrefs as the source of branded vs. non-branded keyword guidance or that situate Ahrefs within the branded-search discourse are most directly relevant. The excerpt describing an Ahrefs blog entry on branded vs. non-branded keywords directly identifies Ahrefs as the source discussing the distinction and use of branded terms in SEO, which aligns with the provider-focused nature of the field value. Additional excerpts that present Ahrefs in the context of branded-search discussions (such as Ahrefs blog entries) further support the relevance by confirming Ahrefs' role in shaping branded-search understanding and analyses. An excerpt that notes Ahrefs as the source in a study about branded searches reinforces the notion of Ahrefs as a provider contributing to the methodological landscape of this topic. In contrast, excerpts that discuss branded vs. non-branded concepts without explicitly tying them to Ahrefs contribute indirect context but are less directly supportive of the provider-specific assessment. Taken together, the most directly supportive content centers on Ahrefs as the source for branded vs. non-branded keyword guidance and analyses, followed by corroborating Ahrefs-focused material in broader discussions of branded-search dynamics.",
      "confidence": "low"
    },
    {
      "field": "provider_assessments.2.key_metrics_offered",
      "citations": [
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ...",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand."
          ]
        },
        {
          "title": "What Is Branded Search & How to Increase It - Moz",
          "url": "https://moz.com/blog/what-is-branded-search",
          "excerpts": [
            "Feb 6, 2024 — On the other hand, non-branded traffic comes from general keywords that people search when they are looking for a product or service that meets ..."
          ]
        }
      ],
      "reasoning": "The target field references Moz's metrics and a composite priority score, tied to the Page Authority and Domain Authority of ranking pages. The excerpts collectively establish Moz as a source and explain branded vs non-branded traffic, including how Moz is discussed as a source of insights on traffic types and measurement approaches. They do not provide the explicit KD, Organic CTR, or Priority Score definitions or values. The most relevant content is Moz-centric context that confirms Moz is the referenced authority, followed by excerpts that describe non-branded traffic and examples, which are contextually related but do not substantively define the specific metrics requested. Therefore, while the excerpts support the notion that Moz provides metrics and concepts around search metrics, they do not supply the exact fine-grained values or definitions needed for KD, Organic CTR, or Priority Score.",
      "confidence": "low"
    },
    {
      "field": "provider_assessments.2.provider_name",
      "citations": [
        {
          "title": "What Is Branded Search & How to Increase It - Moz",
          "url": "https://moz.com/blog/what-is-branded-search",
          "excerpts": [
            "Feb 6, 2024 — On the other hand, non-branded traffic comes from general keywords that people search when they are looking for a product or service that meets ..."
          ]
        },
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        }
      ],
      "reasoning": "The field value corresponds to the provider name Moz. Several excerpts explicitly associate Moz with the content about branded and non-branded traffic. One excerpt presents a Moz-authored article titled \"What Is Branded Search & How to Increase It\" and attributes the Moz source, directly supporting Moz as the provider. The other excerpts consistently reference Moz in the article titles and sources, such as \"Harnessing non-branded traffic (Moz)\" and indicate Moz as the originating platform for the guidance on non-branded traffic. The combination of Moz being cited in the title, source, and article references across multiple excerpts directly corroborates Moz as the provider_name in the given field path. These excerpts collectively establish Moz as the source of the discussed insights on branded vs non-branded search traffic, aligning with the requested field value.",
      "confidence": "high"
    },
    {
      "field": "provider_assessments.2.filtering_capabilities",
      "citations": [
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ...",
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name."
          ]
        },
        {
          "title": "What Is Branded Search & How to Increase It - Moz",
          "url": "https://moz.com/blog/what-is-branded-search",
          "excerpts": [
            "Feb 6, 2024 — On the other hand, non-branded traffic comes from general keywords that people search when they are looking for a product or service that meets ..."
          ]
        }
      ],
      "reasoning": "The fine-grained field value asserts specific limitations of Moz Keyword Explorer: no built-in filters for word count or non-branded status, and that isolation of required query types requires exporting and external filtering, with a Brand Rules feature only in campaign reports. While none of the excerpts directly confirm these Moz-specific limitations, several excerpts provide relevant context that helps interpret the field value. The most relevant excerpt defines non-branded traffic as users who arrive via keywords that do not contain a company, product, or service name, which underpins the distinction between branded and non-branded filtering concepts. Another excerpt explains branded vs non-branded traffic and notes that non-branded traffic comes from general keywords, reinforcing the context in which Moz would need filtering capabilities to distinguish such terms. An example of non-branded search terms illustrates practical instances of non-branded queries, further supporting why filtering by non-branded status would be relevant. Additional excerpts reiterate the branded vs non-branded concepts, providing background that these terms are central to keyword analysis and filtering tasks. Although these excerpts do not verify Moz-specific limitations, they collectively establish the conceptual basis for why the described filtering limitations would be relevant to Moz Keyword Explorer usage. The combination of definitions and examples supports the idea that filtering by word count and non-branded status is non-trivial in keyword research contexts, aligning with the field value's claim about Moz limitations. However, there is no explicit confirmation in the excerpts that Moz indeed lacks these filters, so the support remains indirect.",
      "confidence": "low"
    },
    {
      "field": "provider_assessments.2.data_coverage_summary",
      "citations": [
        {
          "title": "Harnessing non-branded traffic (Moz)",
          "url": "https://moz.com/blog/harness-non-branded-traffic",
          "excerpts": [
            "Branded traffic refers to users who arrive at your website via keywords that contain your company, product, or service name.",
            "What is non-branded traffic? Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name.",
            "For example, a user might search for ‘straight-leg jeans’ when they want to browse products and don’t have a preference for a brand.",
            "Jan 10, 2024 — Non-branded traffic refers to users who arrive at your website via keywords that do not contain your company, product, or service name. These ..."
          ]
        },
        {
          "title": "What Is Branded Search & How to Increase It - Moz",
          "url": "https://moz.com/blog/what-is-branded-search",
          "excerpts": [
            "Feb 6, 2024 — On the other hand, non-branded traffic comes from general keywords that people search when they are looking for a product or service that meets ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value asserts specific methodological attributes of Moz's Monthly Volume metric (time-averaging, data sources, accuracy claim, regional applicability, and corpus size). The excerpts present Moz-centric discussions about branded search and non-branded traffic, including definitions and examples. Such passages help contextualize what non-branded versus branded traffic means and how Moz discusses traffic categorization, but they do not provide the exact methodological claims or numeric details claimed in the finegrained field value. Specifically, a passage explains that non-branded traffic refers to keywords without the company or product name, and another passage defines branded traffic and contrasts it with non-branded traffic, while an example illustrates non-branded search behavior. These pieces support the surrounding concepts (branded vs non-branded traffic) but do not confirm the precise Moz Monthly Volume methodology or its claimed accuracy. Consequently, while they are relevant for contextual understanding, they are insufficient to fully substantiate the finegrained field value on Moz Monthly Volume specifics. The most relevant excerpts therefore are those that discuss Moz and non-branded traffic concepts, followed by those that describe branded traffic, and finally the more general or reiterative items that restate the same concepts.",
      "confidence": "low"
    },
    {
      "field": "provider_assessments.0.provider_name",
      "citations": [
        {
          "title": "Almost Half of Google Searches Are Branded. Here's Why That Matters",
          "url": "https://ahrefs.com/blog/almost-half-of-google-searches-are-branded-study/",
          "excerpts": [
            "That's exactly why we added a “Search Intent” filter to Ahrefs' Keywords Explorer and Site Explorer. It lets you segment branded vs. non-branded ..."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l"
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        }
      ],
      "reasoning": "The specific field value identifies the content source as Ahrefs. Excerpts that present Ahrefs as the source or as the author of material about branded vs non-branded search provide direct support for associating the provider_name with 'Ahrefs'. For example, excerpts that reference a study or article from Ahrefs or that present Ahrefs as the source of a glossary or explanation about branded keywords demonstrate that Ahrefs is the provider in question. These excerpts explicitly tie the concept of branded vs non-branded search to Ahrefs as the publishing or citing entity, which aligns with the requested field value identifying the provider name as Ahrefs. The strongest support comes from content that explicitly titles or cites Ahrefs as the source, while other excerpts that discuss branded search in Ahrefs' context reinforce the association even if they are not titled as the publisher, thereby corroborating the same provider identity.",
      "confidence": "high"
    },
    {
      "field": "provider_assessments.1.provider_name",
      "citations": [
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered non-branded keywords."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            " 1\\. Perform Balanced Keyword Research\n\nYou want to mix branded and non-branded keywords in SEO and PPC campaigns. To reach customers familiar with your brand while attracting new prospects. First, you'll need to find those keywords. To do this, use the [Keyword Magic Tool](https://www.semrush.com/features/keyword-magic-tool/) to build a list for each type of keyword. First, enter a broad keyword into the tool and click “ **Search",
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ..."
          ]
        },
        {
          "title": "How to Use the Keyword Magic Tool",
          "url": "https://www.semrush.com/kb/617-keyword-magic-tool-manual",
          "excerpts": [
            "**Word Count** filtering makes it easier to scan for long-tail keywords."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords in SEMrush",
          "url": "https://medium.com/mhafs/branded-vs-non-branded-keywords-in-semrush-the-ultimate-guide-c4e1a96fbec8",
          "excerpts": [
            "Add a custom filter in Position Tracking to separate branded and non-branded keywords. Pro Tip: Group your branded and non-branded ..."
          ]
        },
        {
          "title": "Position Tracking Tool: Exclude Filtering By Tags",
          "url": "https://www.semrush.com/news/255937-position-tracking-tool-exclude-filtering-by-tags/",
          "excerpts": [
            "Here's how the 'Exclude' filter works: all you need to do now is mark branded keywords as “branded” and filter by this tag using 'include' or ' ..."
          ]
        }
      ],
      "reasoning": "To support the field value that the provider name is Semrush, we look for content that explicitly identifies Semrush as the source or platform. Excerpts from the Semrush Knowledge Base directly mention Semrush by name, establishing Semrush as the provider. Other excerpts from Semrush blogs and documentation also confirm Semrush as the source of information used to discuss branded vs non-branded keywords and related tooling. The most direct support comes from the passages that explicitly reference Semrush Knowledge Base and Semrush as the source, followed by passages from Semrush blogs that discuss features or methods (like the Keyword Magic Tool) attributed to Semrush. This chain of evidence converges on Semrush as the provider associated with the analyzed content.",
      "confidence": "high"
    },
    {
      "field": "provider_assessments.1.key_metrics_offered",
      "citations": [
        {
          "title": "Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/819-branded-vs-non-branded-keywords",
          "excerpts": [
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered **Non-branded keywords. **",
            "A **Branded keyword** is a query that includes your website’s brand name or variations of it and is unique to your domain.",
            "Keywords that do not reference a brand name or any part of it (including any misspellings) are considered non-branded keywords."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            " 1\\. Perform Balanced Keyword Research\n\nYou want to mix branded and non-branded keywords in SEO and PPC campaigns. To reach customers familiar with your brand while attracting new prospects. First, you'll need to find those keywords. To do this, use the [Keyword Magic Tool](https://www.semrush.com/features/keyword-magic-tool/) to build a list for each type of keyword. First, enter a broad keyword into the tool and click “ **Search",
            "Jun 20, 2024 — Branded keywords are search terms that include your brand name. Or some variation of it. Non-branded keywords are general search terms that don't mention your ..."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords in SEMrush",
          "url": "https://medium.com/mhafs/branded-vs-non-branded-keywords-in-semrush-the-ultimate-guide-c4e1a96fbec8",
          "excerpts": [
            "Add a custom filter in Position Tracking to separate branded and non-branded keywords. Pro Tip: Group your branded and non-branded ..."
          ]
        },
        {
          "title": "How to Use the Keyword Magic Tool",
          "url": "https://www.semrush.com/kb/617-keyword-magic-tool-manual",
          "excerpts": [
            "**Word Count** filtering makes it easier to scan for long-tail keywords."
          ]
        },
        {
          "title": "Position Tracking Tool: Exclude Filtering By Tags",
          "url": "https://www.semrush.com/news/255937-position-tracking-tool-exclude-filtering-by-tags/",
          "excerpts": [
            "Here's how the 'Exclude' filter works: all you need to do now is mark branded keywords as “branded” and filter by this tag using 'include' or ' ..."
          ]
        }
      ],
      "reasoning": "The field value references a set of key metrics and classifications used to assess keyword performance, including a formalized search intent classification and various difficulty/cost metrics. Excerpts that define branded versus non-branded keywords and explain how to categorize or filter keywords are most directly aligned with the broader concept of keyword classification and measurement. The passages that describe what constitutes branded keywords and how to tag them (e.g., branding in keyword research tools and the Semrush knowledge base) provide foundational context for any metric-driven analysis, even though the exact metrics (KD%, CPC, Competitive Density, PKD) are not explicitly enumerated in the excerpts. Other excerpts discuss using keyword tools and performing keyword research steps, which corroborate the operational context in which metrics would be applied, but they do not provide the specific metric definitions requested. Taken together, the strongest support is for the existence and categorization of branded versus non-branded keywords and the use of tooling to manage them, with the remaining excerpts offering supplementary context for keyword research practices.",
      "confidence": "medium"
    },
    {
      "field": "provider_assessments.0.data_coverage_summary",
      "citations": [
        {
          "title": "Almost Half of Google Searches Are Branded. Here's Why That Matters",
          "url": "https://ahrefs.com/blog/almost-half-of-google-searches-are-branded-study/",
          "excerpts": [
            "That's exactly why we added a “Search Intent” filter to Ahrefs' Keywords Explorer and Site Explorer. It lets you segment branded vs. non-branded ..."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l",
            "Ranking for non-branded keywords allows you to attract people who are searching for products or services related to your business **but may not necessarily know your brand** ."
          ]
        },
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        }
      ],
      "reasoning": "The finegrained field value describes Ahrefs' approach to keyword volume estimation and data synthesis, including the use of multiple data sources and a focus on de-duplicating keyword clusters, as well as reporting both monthly and average volumes and global coverage. Excerpts discussing branded versus non-branded search establish the core conceptual framework for how Ahrefs and similar tools categorize and interpret search terms, which is foundational to any credible volume estimation methodology. Passages that define what branded keywords are (and why branded vs non-branded distinctions matter) directly support the context in which Ahrefs' data would be interpreted, including scope and segmentation of terms. The mention of Ahrefs in the branded-search context also reinforces Ahrefs as a data source in this space, aligning with the field value's claim that Ahrefs uses a substantial keyword database and an integrated methodology. Collectively, these excerpts provide indirect support for the field value by validating the general principles of branding-focused keyword analytics and the role of Ahrefs as a data provider in this domain, even though they do not confirm the exact figures, data sources, de-duplication techniques, or the precise global-coverage details claimed.",
      "confidence": "medium"
    },
    {
      "field": "provider_assessments.1.filtering_capabilities",
      "citations": [
        {
          "title": "How to Use the Keyword Magic Tool",
          "url": "https://www.semrush.com/kb/617-keyword-magic-tool-manual",
          "excerpts": [
            "**Word Count** filtering makes it easier to scan for long-tail keywords."
          ]
        },
        {
          "title": "Position Tracking Tool: Exclude Filtering By Tags",
          "url": "https://www.semrush.com/news/255937-position-tracking-tool-exclude-filtering-by-tags/",
          "excerpts": [
            "Here's how the 'Exclude' filter works: all you need to do now is mark branded keywords as “branded” and filter by this tag using 'include' or ' ..."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords: What's the Difference?",
          "url": "https://www.semrush.com/blog/branded-vs-non-branded-keywords/",
          "excerpts": [
            " 1\\. Perform Balanced Keyword Research\n\nYou want to mix branded and non-branded keywords in SEO and PPC campaigns. To reach customers familiar with your brand while attracting new prospects. First, you'll need to find those keywords. To do this, use the [Keyword Magic Tool](https://www.semrush.com/features/keyword-magic-tool/) to build a list for each type of keyword. First, enter a broad keyword into the tool and click “ **Search"
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords in SEMrush",
          "url": "https://medium.com/mhafs/branded-vs-non-branded-keywords-in-semrush-the-ultimate-guide-c4e1a96fbec8",
          "excerpts": [
            "Add a custom filter in Position Tracking to separate branded and non-branded keywords. Pro Tip: Group your branded and non-branded ..."
          ]
        }
      ],
      "reasoning": "The field value asserts that Semrush provides highly granular filtering within its Keyword Magic Tool, including explicit word-count filters (e.g., a maximum of 3 words) and the ability to exclude branded keywords, plus advanced filtering by factors like search intent, CPC, and competitive metrics. The first supporting excerpt notes that Word Count filtering is available to target long-tail keywords, directly aligning with the word-count aspect of the claim. The second supporting excerpt describes an exclude-filtering approach where branded keywords are marked as branded and can be filtered, which corroborates the branded exclusion capability. The third supporting excerpt reiterates the use of Keyword Magic Tool to build keyword lists, establishing the tool as the base context for applying such filters. The fourth supporting excerpt discusses adding a custom filter to separate branded and non-branded keywords within SEMrush, which demonstrates a more general form of advanced filtering between branded and non-branded terms. Together, these excerpts directly support the notions of granular and targeted filtering capabilities within the Keyword Magic Tool, including word-count constraints and branded keyword exclusion, as well as the presence of broader advanced filters.",
      "confidence": "high"
    },
    {
      "field": "provider_assessments.0.filtering_capabilities",
      "citations": [
        {
          "title": "What are Branded Keywords? How to Use them in SEO? - Ahrefs",
          "url": "https://ahrefs.com/seo/glossary/branded-keywords",
          "excerpts": [
            "Branded keywords are any search queries that are directly associated with your brand, products, or services. Most often, they contain brand names in them."
          ]
        },
        {
          "title": "Branded vs Non-Branded Search",
          "url": "https://ahrefs.com/blog/branded-search/",
          "excerpts": [
            "The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search doesn’t.",
            "Ranking for non-branded keywords allows you to attract people who are searching for products or services related to your business **but may not necessarily know your brand** .",
            "May 20, 2022 — The difference between branded and non-branded search is that a branded search contains your company, service, or product name, whereas a non-branded search ... We’l"
          ]
        },
        {
          "title": "Almost Half of Google Searches Are Branded. Here's Why That Matters",
          "url": "https://ahrefs.com/blog/almost-half-of-google-searches-are-branded-study/",
          "excerpts": [
            "That's exactly why we added a “Search Intent” filter to Ahrefs' Keywords Explorer and Site Explorer. It lets you segment branded vs. non-branded ..."
          ]
        }
      ],
      "reasoning": "The finegrained field value hinges on the concept of branded vs non-branded keywords and the availability of a branded-or-not filter in a keyword research tool. An excerpt that defines branded keywords as search queries directly associated with a brand, product, or service directly supports the existence of a branded category that tools may filter on. Excerpts describing the difference between branded and non-branded searches reinforce the core distinction that branded context matters for query categorization and analysis, which underpins the rationale for having a dedicated filter. Excerpts mentioning non-branded keyword strategies and the broader discussion of using filters in this space (including a separate mention of a filter in a related context) further corroborate that filtering capabilities are a recognized feature in this analytical domain. Although none of the excerpts explicitly state that Ahrefs' Keywords Explorer provides a dedicated branded-or-not filter or the precise limitation about word-count filtering, the content collectively supports the field value by establishing the branded vs non-branded framework and the common practice of filtering or categorizing queries by brand association, which is central to the claimed capability and its noted limitation. The most direct support comes from the definition of branded keywords, while the other excerpts contextualize the branded vs non-branded distinction and the role of filters in this analysis.",
      "confidence": "medium"
    },
    {
      "field": "risk_and_contingency_plan",
      "citations": [
        {
          "title": "Generate Historical Metrics | Google Ads API",
          "url": "https://developers.google.com/google-ads/api/docs/keyword-planning/generate-historical-metrics",
          "excerpts": [
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including: Average monthly searches (past 12 months) ...",
            "Historical metrics provide metrics on how keywords have previously performed on Google Search including:",
            "* Average monthly searches (past 12 months)"
          ]
        },
        {
          "title": "Semrush API Help",
          "url": "https://www.semrush.com/kb/5-api",
          "excerpts": [
            "API Rate / Terms of Service\nPlease note that in section 2.3 of our terms of service we ask that you not call more than 10 inquiries per second from our API:",
            "If you subscribe to the Semrush API, in addition to the restrictions set forth above, you agree (i) not to forward more than 10 inquiries per 1 second from one unique IP address or more than 10 simultaneous inquiries from 1 User;"
          ]
        },
        {
          "title": "SEMrush API Essential Guide - Rollout",
          "url": "https://rollout.com/integration-guides/semrush/api-essentials",
          "excerpts": [
            "There are rate limits for API requests (e.g., no more than 10 inquiries per second from one IP address). The Listing Management API is available ...",
            "In summary, the main rate limit is 10 requests per second, with usage measured in API units that must be purchased. Careful planning of API ..."
          ]
        },
        {
          "title": "What types of exports can be made from Semrush?",
          "url": "https://it.semrush.com/kb/976-what-types-of-exports-can-be-made-from-semrush",
          "excerpts": [
            "Here you can find the list of all export options available in Semrush tools. The number of results exported and the amount of daily exports you can make ...",
            "Keyword Magic Tool, Excel/CSV/CSV Semicolon. Ads History, Excel/CSV/CSV ... You can export as many keywords as you have in a PPC keyword campaign. However ..."
          ]
        },
        {
          "title": "Semrush Subscription Limits Comparison",
          "url": "https://www.semrush.com/kb/856-subscription-plans-comparison",
          "excerpts": [
            "The 24-hour limit of available requests is 3000 on Pro level, 5000 on Guru, and 10000 on Business . All data can be exported to CSV and Google Sheets.",
            "The 24-hour limit of available requests is 3000 on Pro level, 5000 on Guru, and 10000 on Business. All data can be exported to CSV and Google Sheets. Full ..."
          ]
        },
        {
          "title": "Limits and usage | API",
          "url": "https://docs.ahrefs.com/docs/api/subscription-info/operations/get-a-limits-and-usage",
          "excerpts": [
            "Limit for the number of API units that can be consumed via this API key per billing month (null = unlimited).",
            "Limits and usage | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)",
            "The API has limits for API units per workspace and API key. The workspace limit can be null. API key limit can be null for unlimited."
          ]
        },
        {
          "title": "How can we export an Ahrefs report? | Help Center",
          "url": "https://help.ahrefs.com/en/articles/4934988-how-can-we-export-an-ahrefs-report",
          "excerpts": [
            "Use the \"Custom\" option to set a specific number of rows you wish to export. The max amount of rows you can export depends on your subscription plan:",
            "You can export any graph or table that has an \"Export\" button on the top right. In some cases (like in Keywords Explorer), the option to Export can be found in ...",
            "The max amount of rows you can export depends on your subscription plan:",
            "The number of rows you export count against your subscription's Export rows per month limit. Use the \"Custom\" option to set a specific number of rows you wish ... How can ",
            "This is a feature currently available in Keywords Explorer, but will soon be rolled out for other reports as well. In Keywords Explorer you have the option of exporting the report to Google sheets.",
            "Use the \"Custom\" option to set a specific number of rows you wish to export. The max amount of rows you can export depends on your subscription plan: Then, ..."
          ]
        },
        {
          "title": "Legacy plan limits explained | Help Center",
          "url": "https://help.ahrefs.com/en/articles/3315750-legacy-plan-limits-explained",
          "excerpts": [
            "Export, rows per month. The maximum number of results that you can export you can export from the Organic Keywords report per month. One line of the exported ...",
            "The maximum number of results that you can view and export in Keywords Explorer Keyword Ideas reports or when you analyze keywords in bulk, per month. We deduct ...",
            "The maximum number of results that you can export from Site Explorer per month. One line of the exported . csv file equals one row.",
            "The maximum number of results you can export from Keywords Explorer per month. Note that the \"month\" here means the monthly billing cycle (billing month). I.e., if you subscribed on Sept 6, your billing month lasts from Sept 6 to Oct 5.",
            "See \"Export rows per month\" for the maximum number of results you can export. One result shown to you in the report equals one row. Site Explorer's Rows per ..."
          ]
        },
        {
          "title": "What is the difference between Ahrefs' Legacy Lite and ...",
          "url": "https://help.ahrefs.com/en/articles/2948742-what-is-the-difference-between-ahrefs-legacy-lite-and-legacy-standard-plans",
          "excerpts": [
            "This limit applies to the number of organic keywords you can export to a .csv file in one run. Export, rows per month. Lite: 500,000. Standard: 2.5 ...",
            "csv file in one run. Export, rows per month. Lite: 500,000. Standard: 2.5 million. This limit applies to the number of organic keywords you can export to a .csv ..."
          ]
        },
        {
          "title": "Terms of Service - Google Policies",
          "url": "https://policies.google.com/terms?hl=en-US",
          "excerpts": [
            "Missing: keyword planner redistribution"
          ]
        },
        {
          "title": "Ahrefs Logo",
          "url": "https://ahrefs.com/logo",
          "excerpts": [
            "Ahrefs' Logo"
          ]
        },
        {
          "title": "Ahrefs' Media Kit",
          "url": "https://ahrefs.com/media-kit",
          "excerpts": [
            "Download Ahrefs' logo, product screenshots, office, and team photos."
          ]
        },
        {
          "title": "Ahrefs API Essential Guide - Rollout",
          "url": "https://rollout.com/integration-guides/ahrefs/api-essentials",
          "excerpts": [
            "Aug 7, 2024 — The rate limit is quite high at 300 requests per second, which allows for significant usage even on lower tier plans. The credit system means ...",
            "The Ahrefs API has a rate limit of 300 requests per second across all their plans. This 300 requests per second limit applies to their Free, Lite, Standard, Advanced, and Agency plans.",
            "The rate limit is quite high at 300 requests per second, which allows for significant usage even on lower tier plans. The credit system means ..."
          ]
        },
        {
          "title": "5 Ways To Make Brand Impact More Quantifiable - Semrush",
          "url": "https://www.semrush.com/blog/make-brand-impact-more-quantifiable/",
          "excerpts": [
            "1. Social listening · 2. Brand perception surveys · 3. Attribution modeling · 4. Omnichannel Integration · 5. Unified experience metrics."
          ]
        },
        {
          "title": "a new google policy has appeared to block pretty much ...",
          "url": "https://www.reddit.com/r/googleads/comments/1lodt2q/a_new_google_policy_has_appeared_to_block_pretty/",
          "excerpts": [
            "Ads have done very well bringing in new leads but it looks like a recent Google change about a month ago has silently blocked the ads with zero impressions."
          ]
        },
        {
          "title": "Google Ads Community - Scraping Google Adwords Keyword Planner",
          "url": "https://support.google.com/google-ads/thread/11056041/scraping-google-adwords-keyword-planner?hl=en",
          "excerpts": [
            "buse\n\nNo idea what the results could be, but it is clearly agains the TOS: <https://support.google.com/adspolicy/answer/54818?hl=en",
            "\n\nFor advertising purposes, I have never felt any need for scraping that data. My guess is that your client either wants it for another purpose, or has an odd idea about how to run ads."
          ]
        },
        {
          "title": "Keyword and search traffic metrics",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/ahrefs-seo-metrics/keyword-and-search-traffic",
          "excerpts": [
            "At this time, search volume in Ahrefs is calculated based on a 12-month average. You can change the search volume graph period from: last year, to last two ...",
            "Search volume represents the average number of times people search for a query in a target country in a given month. We use Google Keyword Planner data as a ..."
          ]
        },
        {
          "title": "How often is the data in Keywords Explorer and Site ...",
          "url": "https://help.ahrefs.com/en/articles/1077603-how-often-is-the-data-in-keywords-explorer-and-site-explorer-updated",
          "excerpts": [
            "In Keywords explorer we use the 12-months average, and you'd have to hover over the graph to see the monthly average number: Search volume and CPC are updated ..."
          ]
        },
        {
          "title": "Organic traffic graphs now reflect monthly search volume ...",
          "url": "https://ahrefs.com/blog/new-organic-traffic-graphs/",
          "excerpts": [
            "May 7, 2021 — The old “Average volume” organic traffic chart was built using the average of data over the latest 12 months from an update. The benefit of this ..."
          ]
        },
        {
          "title": "Overview",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/keywords-explorer/overview",
          "excerpts": [
            "See global search volume for any keyword. Global search volume is the sum of searches from all countries. If we go with the same query as before, we'll ...",
            "Global search volume is the sum of searches from all countries.",
            "See global search volume for any keyword",
            "Keyword Difficulty estimates how hard it will be to rank in the top 10 for a given keyword. It's scored on a scale from 0-100.",
            "In this report, we give you all the in-depth SEO metrics you need to make quick and informed decisions about a keyword.",
            "See keyword search volumes from 200+ countries"
          ]
        },
        {
          "title": "Keywords Explorer",
          "url": "https://ahrefs.com/keywords-explorer",
          "excerpts": [
            "Get a breakdown of search volume by country. Quickly check country-specific search volumes and prioritize which countries to target with your content.",
            "Generate thousands of keyword ideas, cluster them instantly, and use reliable metrics to pick the best ones. ... Keywords Explorer is a part of Ahrefs' SEO ...",
            "Analyze any keyword in detail: estimate ranking difficulty, see search volumes, true traffic potential, and review SERPs. · Review the current SERP like a pro.",
            "Use Keyword Difficulty (KD) to understand how hard it will be to rank in the top 10 organic search results for a keyword. The lower the score, the easier it is to rank for.",
            "Study keywords in detail. Use our proprietary SEO metrics and reliable volume data to find valuable keywords quicker. · Keyword Difficulty · Search volume.",
            "The most complete keyword research tool on the market. Generate thousands of keyword ideas, group them into topical clusters, and nail search intent."
          ]
        },
        {
          "title": "How is search volume calculated in Ahrefs?",
          "url": "https://www.quora.com/How-is-search-volume-calculated-in-Ahrefs",
          "excerpts": [
            "A search volume is the average number of searches for a specific keyword in a certain period of time which is typically Monthly. Search volume ..."
          ]
        },
        {
          "title": "Limits consumption | API",
          "url": "https://docs.ahrefs.com/docs/api/reference/limits-consumption",
          "excerpts": [
            "Each API request indicates its units consumption behavior via the following response headers: x-api-rows The number of rows returned. x-api-units-cost-row The ...",
            "Limits consumption | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)",
            "Limits consumption. Ahrefs API is fully available for Enterprise plans. On all other plans, you'll still have access to a limited set of free test queries.",
            "The default cost of a field is 1 unit. However, certain metrics are more expensive and may consume 5 or 10 units. Such exceptions are noted in the each ..."
          ]
        },
        {
          "title": "Free Keyword Generator Tool: Find 100+ Keyword Ideas in ...",
          "url": "https://ahrefs.com/keyword-generator",
          "excerpts": [
            "Every keyword comes complete with local and global monthly search volume estimates and other advanced SEO metrics — all powered by clickstream data. Use ...",
            "Dig deeper with filters for cost-per-click (CPC), SERP features, word count, and more. Identify long-tail keywords. Look for groups of keywords with the same ...",
            "Find relevant keywords from our database of over 8 billion queries. Just enter up to ten words or phrases and choose from one of six keyword ideas reports."
          ]
        },
        {
          "title": "Word count on SERP overview | Keywords Explorer - Ahrefs",
          "url": "https://ahrefs.canny.io/keywords-explorer/p/word-count-on-serp-overview",
          "excerpts": [
            "Jul 20, 2017 — Word count has been added to the SERP overview widget in Keywords Explorer and Site Explorer. Hello guys, are we adding this anytime soon?"
          ]
        },
        {
          "title": "Hide branded keywords | Voters | Ahrefs - Canny",
          "url": "https://ahrefs.canny.io/keywords-explorer/p/hide-branded-keywords",
          "excerpts": [
            "I'd like to be able to filter out and remove keywords with Anazon/Walmart etc. - Instead of having to manually go through an entire list. April ..."
          ]
        },
        {
          "title": "A Simple Guide to Turning (Unlinked) Brand Mentions into ...",
          "url": "https://ahrefs.com/blog/unlinked-mentions/",
          "excerpts": [
            "Just set up a mention alert for your brand name (and other branded terms) and Ahrefs will keep you posted about new brand mentions on the web."
          ]
        },
        {
          "title": "Everything You Need to Know About Ahrefs API Documentation",
          "url": "https://aicontentfy.com/en/blog/everything-you-need-to-know-about-ahrefs-api-documentation",
          "excerpts": [
            "The Ahrefs API has rate limits that restrict the number of requests you can make within a certain time frame. The rate limits vary based on ..."
          ]
        },
        {
          "title": "Connect Ahrefs To Google Sheets [API Integration]",
          "url": "https://apipheny.io/ahrefs-api-google-sheets/",
          "excerpts": [
            "Choose your Endpoint URL; Enter Ahrefs API Request into Apipheny; Run the Ahrefs API request. Step 1.) Install and open the Apipheny add-on for Google Sheets."
          ]
        },
        {
          "title": "How to Do Keyword Research for SEO (Start to Finish)",
          "url": "https://ahrefs.com/blog/keyword-research/",
          "excerpts": [
            "Dec 5, 2024 — But some of them also have an option to show you the global search volume, which is the sum of search volumes across all countries.",
            "Keyword research is the process of discovering valuable search queries that your target customers type into search engines like Google to look for products, ...See more",
            "Search volume tells you the average number of times a keyword gets searched per month. For example, “donald trump” has a monthly search volume ..."
          ]
        },
        {
          "title": "Keywords | API",
          "url": "https://docs.ahrefs.com/docs/api/management/operations/list-project-keywords",
          "excerpts": [
            "API. Keywords. Keywords. get. https://api.ahrefs.com/v3/management/project-keywords. Requests to this endpoint are free and do not consume any API units.",
            "Keywords | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)"
          ]
        },
        {
          "title": "How to Download All Keywords from Ahrefs – Quick Tutorial",
          "url": "https://www.trupeer.ai/tutorials/how-to-download-all-keywords-from-ahrefs",
          "excerpts": [
            "Click the Export button at the top right of the keyword report. Choose the preferred data range (e.g., full export) and export format—typically CSV. 5. Analyze ..."
          ]
        },
        {
          "title": "Monthly search volume vs Average search volume",
          "url": "https://help.ahrefs.com/en/articles/5299602-monthly-search-volume-vs-average-search-volume",
          "excerpts": [
            "In the past, we used a 12 month average of monthly search volume to calculate organic traffic estimations. However we changed our default search volume calculation logic from 12-month average to monthly trends . In fact, since there are use cases for both, we decided to add a toggle for these two modes for any Site Explorer report that provides Organic Traffic or Paid Traffic estimations.",
            "However we changed our default search volume calculation logic from 12-month average to monthly trends .",
            "ecided to add a toggle for these two modes for any Site Explorer report that provides Organic Traffic or Paid Traffic estimations.",
            "Monthly volume is more volatile but helps you monitor seasonal search trends and popular topics. Average volume is based on the last known 12 months of data.",
            "Average volume is based on the last known 12 months of data. It's more consistent and helps you troubleshoot traffic drops.",
            "The option to select average will only appear in reports with charts to troubleshoot drops. This is mainly the reports in the Organic search, and Paid search sections in Site Explorer.",
            "Monthly volume is more volatile but helps you monitor seasonal search trends and popular topics.",
            "s. Average volume is based on the last known 12 months of data. It’s more consistent and helps you troubleshoot traffic drops.",
            "Monthly search volume vs Average search volume",
            "Please, read on to find out what the difference is between the two search volume estimation methods in Ahrefs reports",
            "The traffic estimation in the reports will change depending on the volume option selected."
          ]
        },
        {
          "title": "Ahrefs Keyword Search Volume Overview",
          "url": "https://ahrefs.com/blog/keyword-search-volume/",
          "excerpts": [
            "Dec 1, 2021 — Keyword search volume is an SEO metric that tells you how many times per month, on average, a certain keyword is searched for in a specific location.",
            "Most SEO tools report search volume as an annual average.",
            "we mix a few other data sources into our search volume estimates (including a few years of historical clickstream data), which allows us to “un-group” many of such keyword clusters and display a distinct search volume for each individual keyword:",
            "And yet our search volumes are still just estimations rather than exact values that many of our users will love to see.",
            "The primary use case of the keyword search volume metric in SEO is to estimate the potential organic search traffic that your page may get if it ranks for the keyword, right?"
          ]
        },
        {
          "title": "Ahrefs API Documentation - Introduction",
          "url": "https://docs.ahrefs.com/docs/api/reference/introduction",
          "excerpts": [
            "Currently, API v3 allows you to pull data from the Site Explorer, Keywords Explorer, SERP Overview, Rank Tracker and Site Audit endpoints, as well a",
            "Currently, API v3 allows you to pull data from the Site Explorer, Keywords Explorer, SERP Overview and Site Audit endpoints:\n    * Site Explorer: Overview stats and historical charts, Backlinks, Organic and paid traffic reports\n    * Keywords Explorer: Metrics for a single keyword or a list of keywords, Search volume history and volume by country, Keyword ideas reports",
            "Keywords Explorer: Metrics for a single keyword or a list of keywords, Search volume history and volume by country, Keyword ideas reports; Site Audit ...",
            "Rate limiting. Ahrefs API is limited to 60 requests per minute by default.",
            "If you consume units beyond your plan's limit, they're automatically charged on a pay-as-you-go basis. If you're on an annual subscription, you can get some savings by prepaying for more API units at a discounted rate.",
            "All requests besides free test queries and the Site Audit, Rank Tracker and Public endpoints consume API units . The cost depends on the number of rows in a response and the fields requested. The minimum cost for any request is 50 units . Please be advised that API units once consumed are non-refundable.",
            "Enterprise plans include a certain number of API units. If you consume units beyond your plan's limit, they're automatically charged on a pay-as-you-go basis.",
            "To send requests to Ahrefs API, you'll need an API key. Only workspace owners and admins can create and manage API keys.",
            "* Site Audit: Projects' Health Scores",
            "* SERP Overview: Top 100 SERP results",
            "* Rank Tracker: Project overview",
            "Rate limiting​​ Ahrefs API is limited to 60 requests per minute by default. If this limit is exceeded, the API will respond with an HTTP 429 status code ( Too ...",
            "Missing: min_words max_words"
          ]
        },
        {
          "title": "About API v3 for Enterprise Plan",
          "url": "https://help.ahrefs.com/en/articles/6559232-about-api-v3-for-enterprise-plan",
          "excerpts": [
            "API Endpoints. Currently, API v3 allows you to pull data from the Site Explorer, Keywords Explorer and SERP Overview endpoints: Site Explorer. Overview.",
            "Volume history",
            "The minimum cost for any request is **50 unit",
            "All requests and endpoints consume **API units** (come included into the Enterprise package). The cost depends on the number of rows in the response and the fields reques",
            "Volume by country"
          ]
        },
        {
          "title": "Ahrefs Keywords Explorer Guide",
          "url": "https://ahrefs.com/blog/how-to-use-keywords-for-seo/",
          "excerpts": [
            "KD ( Keyword Difficulty ) : how difficult it would be to rank on the first page of Google for a given keyword.",
            "Include/Exclude: see keywords that contain specific words to increase relevancy/hide keywords with irrelevant words.",
            "The graphs will also show you if the search volume is affected by seasonality (fluctuations in search volume throughout different times of the year)."
          ]
        },
        {
          "title": "Ahrefs API Guide: Process, Pricing, Alternatives and More",
          "url": "https://www.topicfinder.com/ahrefs-api-guide/",
          "excerpts": [
            "Every query you run on the Ahrefs API, by default, automatically costs a minimum of 50 API units. ... API call would cost anywhere from 1 to 49 ..."
          ]
        },
        {
          "title": "Plans & Pricing - Ahrefs API",
          "url": "https://ahrefs.com/api/subscription",
          "excerpts": [
            "API Subscriptions. API Standard, API Plus, API Premium. Monthly, $500, $2,000, $10,000. API Rows Included. 500,000, 5,000,000, 30,000,000. Price per ..."
          ]
        },
        {
          "title": "Volume history | API",
          "url": "https://docs.ahrefs.com/docs/api/keywords-explorer/operations/get-a-volume-history",
          "excerpts": [
            "Volume history. get. https://api.ahrefs.com/v3/keywords-explorer/volume-history ... An estimation of the number of searches for a keyword over a given month.",
            "Volume history | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)",
            "An estimation of the number of searches for a keyword over a given month. Auth. Token : Parameters. country* : ad, ae, af, ag, ai, al, am, ao ..."
          ]
        },
        {
          "title": "Overview | API - Ahrefs Docs",
          "url": "https://docs.ahrefs.com/docs/api/keywords-explorer/operations/get-a-overview",
          "excerpts": [
            "Missing: min_words max_words",
            "\"global_volume\"",
            "Overview\nget\nVolume history\nget\nVolume by country\nget\nKeyword ideas\nSchemas",
            "Volume by country",
            "\"difficulty\" : 0 ,",
            "\"difficulty\" : 0 ,",
            "\"difficulty\" : 0 ,",
            "\"difficulty\" : 0 ,",
            "regex filter has limited functionality when used in this request, and the syntax differs from other requests. It expects an asterisk (*) symbol as a wil",
            "It shows how many different search results get clicked, on average, when people search for the target keyword in a given country. difficulty. integer or null. ( ...",
            "An estimation of how hard it is to rank in the top 10 organic search results for a keyword on a 100-point scale."
          ]
        },
        {
          "title": "Related terms",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/keywords-explorer/related-terms",
          "excerpts": [
            "Type in your seed keyword. Then set the Target filter to show only keywords where your target doesn't rank in top 10."
          ]
        },
        {
          "title": "6 Keyword Research Tips to Find Untapped Opportunities",
          "url": "https://ahrefs.com/blog/keyword-research-tips/",
          "excerpts": [
            "If you spot any trends, paste a few related terms into Keywords Explorer, go to the Phrase match report, and use the “Include” filter to find ..."
          ]
        },
        {
          "title": "Documentation - Ahrefs API",
          "url": "https://ahrefs.com/api/documentation",
          "excerpts": [
            "If you need assistance in the creation of your API request, please keep in touch with our support at [email protected]. We are more than happy to help you.",
            "Site Explorer Keywords Explorer Site Audit Rank Tracker Content Explorer ... Read about API v3. Overview · Your API Profile · Pricing Mechanism · API ..."
          ]
        },
        {
          "title": "Plans & Pricing",
          "url": "https://ahrefs.com/pricing",
          "excerpts": [
            "Ahrefs offers subscription packages for any budget. Pick pricing plan which fits for your needs best. Don't forget to save 20% on annual billing."
          ]
        },
        {
          "title": "API Limits",
          "url": "https://urlprofiler.com/api-limits/",
          "excerpts": [
            "URL Profiler integrates with a number of different APIs, some of which are free and some of which require a paid subscription. With both, there are limits."
          ]
        },
        {
          "title": "Page explorer: Advanced filters",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/site-audit/page-explorer-adv-filters",
          "excerpts": [
            "Page Explorer allows you to create and combine filters and SEO metrics to find any issue you can imagine. As such, the use cases below are only a snapshot ..."
          ]
        },
        {
          "title": "Ahrefs' Keyword Data: More Coverage, Accuracy, and ...",
          "url": "https://ahrefs.com/blog/keyword-data-improvements/",
          "excerpts": [
            "Discover how Ahrefs has enhanced its keyword data with greater coverage, improved accuracy, and a new Traffic Potential metric to optimize ..."
          ]
        },
        {
          "title": "How to forecast keyword search volume | Help Center - Ahrefs",
          "url": "https://help.ahrefs.com/en/articles/9698725-how-to-forecast-keyword-search-volume",
          "excerpts": [
            "We only provide forecasting for keywords that has 200 or more monthly search volume, and sufficient data to create estimations. How accurate are these ...",
            "At Ahrefs, we provide a trend line for each keyword that shows its past search volumes (in blue), and forecasted future search volumes (in orange)."
          ]
        },
        {
          "title": "SEO Data. Explained in 5 Minutes, 53 Seconds",
          "url": "https://ahrefs.com/blog/seo-data/",
          "excerpts": [
            "Keyword data helps you work out which keywords are worth targeting (and how hard they might be to rank for). Key data. Search volume: how often ...See more"
          ]
        },
        {
          "title": "GSC vs. GKP: Comparing Search Volumes for 72k Keywords [A ...",
          "url": "https://ahrefs.com/blog/gsc-gkp-search-volume-study/",
          "excerpts": [
            "Explore the differences in search volume data between Google Search Console and Google Keyword Planner in this comprehensive study by Ahrefs ..."
          ]
        },
        {
          "title": "How accurate is keyword search volume in Ahrefs? (Ahrefs Help Center)",
          "url": "https://help.ahrefs.com/en/articles/72571-how-accurate-is-keyword-search-volume-in-ahrefs",
          "excerpts": [
            "Ahrefs uses a combination of Google Keyword Planner (GKP), Google trends data and other third party data sources to estimate monthly search volumes of keywords.",
            "Search volume does not always translate into traffic. Many searches on Google result in no clicks or go to ads.",
            "Search volume in any SEO tool, including Ahrefs, is always an estimation."
          ]
        },
        {
          "title": "Volume by country | API - Ahrefs Docs",
          "url": "https://docs.ahrefs.com/docs/api/keywords-explorer/operations/get-a-volume-by-country",
          "excerpts": [
            "(10 units) An estimation of the average monthly number of searches for a keyword in a given country. Auth. Token : Parameters. keyword* : limit : output :.",
            "Volume by country | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)"
          ]
        },
        {
          "title": "Metrics by country | API - Ahrefs Docs",
          "url": "https://docs.ahrefs.com/docs/api/site-explorer/operations/get-a-metrics-by-country",
          "excerpts": [
            "The search volume calculation mode: monthly or average. It affects volume, traffic, and traffic value."
          ]
        },
        {
          "title": "Search suggestions | API - Ahrefs Docs",
          "url": "https://docs.ahrefs.com/docs/api/keywords-explorer/operations/list-search-suggestions",
          "excerpts": [
            "An estimation of how hard it is to rank in the top 10 organic search results for a keyword on a 100-point scale."
          ]
        },
        {
          "title": "Introduction to Keywords Explorer",
          "url": "https://ahrefs.com/academy/how-to-use-ahrefs/keywords-explorer/intro",
          "excerpts": [
            "Keywords Explorer is our keywords research tool that gives you in-depth metrics on any keyword and can help you generate meaningful keyword ideas."
          ]
        },
        {
          "title": "Organic keywords | API",
          "url": "https://docs.ahrefs.com/docs/api/site-explorer/operations/list-organic-keywords",
          "excerpts": [
            "(10 units) The keyword difficulty on the comparison date. The keyword field optimized for sorting. The keyword your target ranks for on the comparison date."
          ]
        },
        {
          "title": "Ahrefs Help Center – How to filter keywords based on search intent and other useful attributes",
          "url": "https://help.ahrefs.com/en/articles/9973393-how-to-filter-keywords-based-on-search-intent-and-other-useful-attributes",
          "excerpts": [
            "Keywords Explorer allows you to see and filter many keywords at once based on:",
            "If they are Branded or not"
          ]
        },
        {
          "title": "Web Analytics, Growth forecast and more (Dec 2024)",
          "url": "https://ahrefs.com/blog/new-features-dec-2024/",
          "excerpts": [
            "Jan 13, 2025 — Discover the latest updates in web analytics, SEO tools, and growth forecasts for December 2024 ... Keywords Explorer. 12-month growth forecast.",
            "Use this 12-month search volume growth forecast in Overview and report tables to predict how keywords will trend in the future and zoom in on ..."
          ]
        },
        {
          "title": "Free test queries | API - Ahrefs Docs",
          "url": "https://docs.ahrefs.com/docs/api/reference/free-test-queries",
          "excerpts": [
            "For Keywords Explorer and SERP Overview endpoints, requests will not consume API units if you use only ahrefs or wordcount in the keywords or keyword query ..."
          ]
        },
        {
          "title": "\"The monthly limit for your workspace has been reached\" ...",
          "url": "https://help.ahrefs.com/en/articles/9188339-the-monthly-limit-for-your-workspace-has-been-reached-message-on-seo-toolbar",
          "excerpts": [
            "The message \"The monthly limit for your workspace has been reached\" indicates that the monthly \"Export rows per month\" credits limit was reached for the ..."
          ]
        },
        {
          "title": "How To Download All Keywords From Ahrefs - 1-Min Guide",
          "url": "https://www.storylane.io/tutorials/how-to-download-all-keywords-from-ahrefs",
          "excerpts": [
            "Go to Site Explorer on the menu bar on the top. ... Select CSV and hit Export. The download will begin now. This downloaded CSV file will have all the keywords."
          ]
        },
        {
          "title": "Keywords Explorer API Documentation",
          "url": "https://docs.ahrefs.com/docs/api/keywords-explorer",
          "excerpts": [
            "Explorer\n\nv3.0.0\n\nAPI Base URL\n\nAhrefs Keywords Explorer: https://api.ahrefs.com/v3/keywords-explorer"
          ]
        },
        {
          "title": "Ahrefs Keyword Explorer Overview (as described in the provided document)",
          "url": "https://www.trupeer.ai/tutorials/how-to-use-ahrefs-keyword-explorer",
          "excerpts": [
            "Each keyword comes with critical SEO metrics:\n\n* Search Volume: Average monthly searches. * Keyword Difficulty (KD): How hard it is to rank on the first page. * Traffic Potential: Estimated traffic the top-ranking page gets. * SERP Overview: A snapshot of top-ranking pages so you can evaluate your competition.",
            "Refine with Filters  \nNarrow your keyword results by:\n\n* Search volume\n* Keyword difficulty\n* Word count\n* Click potential\n* And mo"
          ]
        },
        {
          "title": "What is Search Volume in Semrush?",
          "url": "https://tr.semrush.com/kb/683-what-is-search-volume-in-semrush?trk=public_post_comment-text",
          "excerpts": [
            "Global volume is the sum of the keyword's monthly search volumes across all of our regional databases. Also, you can check a keyword's global volume in the ..."
          ]
        },
        {
          "title": "How Does Semrush Calculate Search Volume",
          "url": "https://www.trupeer.ai/tutorials/how-does-semrush-calculate-search-volume",
          "excerpts": [
            "Pro Tips for Understanding How Semrush Calculates Search Volume · Uses Third-Party Data Sources · Aggregates Monthly Averages · Normalizes for Seasonal Trends",
            "It calculates the average number of monthly searches for a keyword over the past 12 months, providing a more balanced view rather than a one-time snapshot.",
            "Curious how Semrush determines keyword search volume? Learn how Semrush analyzes real-time data from multiple sources to estimate monthly search volumes ..."
          ]
        },
        {
          "title": "Historical Data | Semrush Knowledge Base",
          "url": "https://www.semrush.com/kb/64-historical-data",
          "excerpts": [
            "In Domain Analytics and Keyword Analytics, SEO historical data is available on a month-to-month basis, dating back to January 2012 for select databases. These ..."
          ]
        },
        {
          "title": "What is Live Update? - Semrush",
          "url": "https://www.semrush.com/kb/71-live-update",
          "excerpts": [
            "Live Update is an algorithm that Semrush uses to refresh its data. Depending on the popularity in search queries, keywords are updated daily, weekly or monthly."
          ]
        },
        {
          "title": "How to get API",
          "url": "https://developer.semrush.com/api/basics/how-to-get-api/",
          "excerpts": [
            "May 12, 2025 — The monthly limit rate included by default is 10,000 requests. The Trends API doesn't use Standard API units. You can always upgrade your plan ...",
            "May 12, 2025 — You can increase your request limit by purchasing API units. Note that you don't need to buy API units to use the Listing Management API."
          ]
        },
        {
          "title": "How to Use the Keyword Magic Tool",
          "url": "https://www.semrush.com/kb/617-keyword-magic-tool-manual",
          "excerpts": [
            "In the same way, you can query your seed keyword with match types. You can also add additional include/exclude keyword filters using Broad or Exact Match to specify the filter. For example, imagine your seed keyword is ‘banana.’ If you type in ‘buy fresh’ in the include filter…",
            "You can filter by including/excluding keywords, search intent, word count, a specific metric, or a specific language. In the same way, you can query your seed ...",
            "**Exact Match** will include the exact match of the phrase ‘buy fresh’ with the same word order. So you will get ‘buy fresh bananas’, ‘where to buy fresh bananas’, ‘buy fresh bananas in New York’, etc.",
            "After adding specific words to include or exclude, you can also add filters for any other metrics: Word Count, Volume, KD, Intent, CPC, Competitive Density, and SERP features.",
            "**Word Count** filtering makes it easier to scan for long-tail keywords.",
            "Volume** and **Keyword Difficulty** filters will help prioritize target keywords in a content marketing or SEO campaig",
            "If you want to export multiple groups (but not every group) in one file, use the eye icon to exclude the groups you don’t want from your full batch.",
            "Exporting",
            "You can export your keyword list into a CSV, XLSX, and CSV semicolon file. When exporting the full table, you can export with or without groups."
          ]
        },
        {
          "title": "How does Keyword Magic Tool work?",
          "url": "https://www.semrush.com/kb/262-keyword-magic-tool",
          "excerpts": [
            "The Keyword Magic Tool is the most powerful keyword research tool on Semrush. It offers you access to an extensive database with over 26.6 billion keywords."
          ]
        },
        {
          "title": "What Is Keyword Difficulty? (& How to Measure It)",
          "url": "https://www.semrush.com/blog/keyword-difficulty/",
          "excerpts": [
            "Keyword difficulty (also known as SEO difficulty) is a metric that measures the difficulty of earning a top position in search results for a specific keyword.",
            "Dec 11, 2024 — Keyword difficulty (also known as SEO difficulty) is a metric that measures the difficulty of earning a top position in search results for a specific keyword.",
            "In Semrush, Keyword Difficulty (KD %) appears as a percentage . A 100% KD score indicates the highest level of difficulty for ranking, while a 0% KD score indicates the lowest level of difficulty."
          ]
        },
        {
          "title": "Free Keyword Research Tool: Find SEO ...",
          "url": "https://www.semrush.com/analytics/keywordmagic/",
          "excerpts": [
            "Take control of your keyword list. Organize and filter them by search volume, include or exclude terms, refine by word count, and target the best opportunities ..."
          ]
        },
        {
          "title": "Position Tracking Tool: Exclude Filtering By Tags",
          "url": "https://www.semrush.com/news/255937-position-tracking-tool-exclude-filtering-by-tags/",
          "excerpts": [
            "Here's how the 'Exclude' filter works: all you need to do now is mark branded keywords as “branded” and filter by this tag using 'include' or ' ..."
          ]
        },
        {
          "title": "CSV File Merger Tool - Intrepid Digital",
          "url": "https://www.intrepidonline.com/tools/csv-file-merger/",
          "excerpts": [
            "If you're managing multiple websites, targeting a large number of keywords, or running deep site audits, it's not difficult to bump up against Semrush's 50k CSV row limit ."
          ]
        },
        {
          "title": "Learn How Often Does Semrush Update Their Competitor Lists",
          "url": "https://www.flyingvgroup.com/seotools/how-often-does-semrush-update-their-competitor-list/",
          "excerpts": [
            "How often does Semrush update data? Semrush typically updates its database daily . This frequent update schedule ensures that users have access to the most current data for keyword rankings, site analytics, and competitive insights, essential for effective SEO and marketing strategies."
          ]
        },
        {
          "title": "Free Keyword Search Volume Tool",
          "url": "https://www.semrush.com/free-tools/keyword-search-volume-checker/",
          "excerpts": [
            "Find out how many times people search for any keyword on Google. Get monthly search volume, keyword difficulty, and CPC data instantly. No sign-up required.",
            "Global coverage across 140+ countries: check the keyword search demand in any market you target. More than 20 billion keywords: find keyword ideas your ...",
            "1. Enter any keyword and select a location from the dropdown ; 2. Click \"Check Search Volume\" to analyze the keyword ; 3. View monthly search volumes, CPC, and ..."
          ]
        },
        {
          "title": "Semrush Keyword Research In 4 Steps 2025",
          "url": "https://bloggerpilot.com/en/keyword-recherche-semrush/",
          "excerpts": [
            "To get new keyword ideas, I limit the keyword display to the top 20 keywords with a search volume of 101 to 1,000 and a keyword difficulty of 0 ..."
          ]
        },
        {
          "title": "Semrush Keyword Metrics Blog",
          "url": "https://www.semrush.com/blog/keyword-metrics/",
          "excerpts": [
            "Semrush provides global search volume for any keyword. And country-specific data.",
            "The global search volume for that same keyword is 48.5K with the US, India, and the Philippines are the top countries",
            "Keyword metrics are important because **not every keyword you find will be worth creating content for** .",
            "eyword-difficulty/) shows how hard it would be to rank on page one of Google for a specific keyword",
            "Some keywords have predictable patterns based on seasons or events. For example, \"Christmas gift ideas\" will spike in November and December.",
            "Recognizing these seasonal trends will help you plan your content calendar effectively."
          ]
        },
        {
          "title": "Semrush KB - How do keyword filters work? and Export options",
          "url": "https://www.semrush.com/kb/20-organic-research",
          "excerpts": [
            "In addition, Organic Research data is used by Semrush Copilot to offer you AI-driven insights to improve your SEO.",
            "It’s possible to export data from this tool in the following formats:\n\n* Excel\n* CSV\n* PDF\n      + Export data from Organic Research to PDF or create your custom report with the [My Reports](https://www.semrush.com/my_reports?utm_source=kb&utm_medium=organic_research_kb&utm_campaign=my_reports_2.0) tool. Combine data from Organic Research, other Semrush tools, Google Analytics 4, Google Search Console, and other sources to create custom PDF reports. Align the reports with your brand and schedule automatic updates for seamless report automation.",
            "The type of export, number of results exported, and the amount of daily exports you can make depends on your [subscription plan](https://www.semrush.com/kb/856-subscription-plans-comparison) . Please refer to [this article](https://www.semrush.com/kb/976-what-types-of-exports-can-be-made-from-semrush) for more information.",
            "Export Options",
            "In the Positions, Positions changes, Competitors, Topics, Pages, and Subdomain reports, the export button will be in the top right of your list of keywords or domains.",
            "All Organic Research reports let you export your data for future reference to Excel or CSV.",
            "n. Semrush\n\nFrequently asked questions\n\n* "
          ]
        },
        {
          "title": "MLTS/api/python_semrush/semrush.py at master - GitHub",
          "url": "https://github.com/MLTSEO/MLTS/blob/master/api/python_semrush/semrush.py",
          "excerpts": [
            "... phrase_all(self, phrase, **kwargs): \"\"\" Keyword Overview (All Databases) This report provides a summary of a keyword, including its volume, CPC, competition ..."
          ]
        },
        {
          "title": "Get API key",
          "url": "https://developer.semrush.com/api/basics/get-started/",
          "excerpts": [
            "Mar 13, 2025 — Use display_limit to save API units. Certain types of reports within Semrush API support the display_limit parameter. Use it to limit the ..."
          ]
        },
        {
          "title": "Check API unit balance",
          "url": "https://developer.semrush.com/api/basics/api-units-balance/",
          "excerpts": [
            "Mar 24, 2025 — Certain types of reports within Semrush API support the display_limit parameter. Use it to limit the number of lines returned in a response to ... [Image](https://static.semrush.com/semrush-developer/872754ef12a7d627bcfd265d03870264d89be361/apidocs/images/chevron.svg) [Keyword reports](/api/v3/analytics/keyword-reports/)",
            "Use it to limit the number of lines returned in a response to save on API units. For example, adding &display_limit=10 will limit your request ...",
            "* \n                                [Keyword Overview (all databases)](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Keyword Overview (one database)](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Batch Keyword Overview (one database)](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Organic Results](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Paid Results](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Related Keywords](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Keyword Ads History](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Broad Match Keyword](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Phrase questions](/api/v3/analytics/keyword-reports//)\n                              * \n                                [Keyword Difficulty](/api/v3/analytics/keyword-reports//)\n                -"
          ]
        },
        {
          "title": "Domain reports",
          "url": "https://developer.semrush.com/api/v3/analytics/domain-reports/",
          "excerpts": [
            "Aug 13, 2024 — Regional database (one value from the list). Databases. display_limit, integer. Number of results returned to a request. If this parameter isn't ..."
          ]
        },
        {
          "title": "Semrush Report: AI Overviews' Impact on Search in 2025",
          "url": "https://www.semrush.com/blog/semrush-ai-overviews-study/",
          "excerpts": [
            "May 4, 2025 — Discover how Google's AI Overviews are reshaping SEO. Semrush analyzed 10M+ keywords to uncover what's changing—and what to do next.",
            "AI Overviews are on the rise: 13.14% of all queries triggered AI Overviews in March 2025. That's up from 6.49% in January 2025. Informational ..."
          ]
        },
        {
          "title": "What types of exports can be made from Semrush?",
          "url": "https://pt.semrush.com/kb/976-what-types-of-exports-can-be-made-from-semrush",
          "excerpts": [
            "PDF/CSV TXT for exporting links to Disavow (no limits). Link Building Tool, CSV. PPC Keyword Tool. You can export as many keywords as you have in a PPC keyword ..."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords in SEMrush",
          "url": "https://medium.com/mhafs/branded-vs-non-branded-keywords-in-semrush-the-ultimate-guide-c4e1a96fbec8",
          "excerpts": [
            "Add a custom filter in Position Tracking to separate branded and non-branded keywords. Pro Tip: Group your branded and non-branded ..."
          ]
        },
        {
          "title": "Free Keyword Checker: Check Keyword Difficulty & ...",
          "url": "https://www.semrush.com/analytics/keywordoverview/",
          "excerpts": [
            "Global search volume. The total number of average monthly searches globally across all databases. Search intent. The general purpose of or reason behind a ...",
            "Keyword difficulty is an SEO metric that measures how difficult it will be to rank in the top 10 for a specific keyword in search engine results. A higher ...",
            "Provides a complete keyword overview, including difficulty scores, competition metrics, search intent, and search volume trends. Website keyword checker."
          ]
        },
        {
          "title": "Keyword Overview tool",
          "url": "https://www.semrush.com/features/keyword-research/",
          "excerpts": [
            "Access a top-level report for any keyword's metrics, including search volume, competition level, CPC, intent, and trends across local, national, and global ..."
          ]
        },
        {
          "title": "URL reports - Semrush Developers",
          "url": "https://developer.semrush.com/api/v3/analytics/url-reports/",
          "excerpts": [
            "Does the Semrush API have rate or usage limits? Will Semrush notify ... The maximum value for display_limit is 4,000,000."
          ]
        },
        {
          "title": "Semrush Monthly Numbers",
          "url": "https://www.semrush.com/kb/162-monthly-numbers",
          "excerpts": [
            "To calculate the monthly average search volume, we take the keyword's search volume from the last 12 months starting with the current month or historical ... The traffic estimations and search volume numbers shown for queries in the main Semrush [Domain](https://www.semrush.com/info/empty/domain_overview) and [Keyword Analytics](https://www.semrush.com/info/empty/phrase_overview) represent **average monthly rates. **\n\n",
            "Looking at the example below for worldwildlife.org, we can see that they are receiving an estimated 5.9 million visitors **per month on average,** based on how high their pages rank for keywords within Google's top 100 results.",
            "When researching keywords, the volume listed represents an **average monthly number** of how many times this keyword was searched in the database selected (US Google Desktop in the image above).",
            "To calculate the [monthly average search volume](https://www.semrush.com/blog/us-search-volume-update/) , we take the keyword's search volume from the last 12 months starting with the current month or historical month selected in the report.",
            "To calculate the monthly average search volume, we take the keyword's search volume from the last 12 months starting with the current month or historical month ... Semrush Monthly Num"
          ]
        },
        {
          "title": "Introduction - Semrush Developers",
          "url": "https://developer.semrush.com/api/basics/introduction/",
          "excerpts": [
            "API usage restrictions  Rate limits: You can make up to 10 requests per second from one IP address . Concurrency limits: You can make up to 10 simultaneous requests per user."
          ]
        },
        {
          "title": "How to Use SEMrush Keyword Magic Tool – Full Tutorial",
          "url": "https://www.trupeer.ai/tutorials/how-to-use-semrush-keyword-magic-tool",
          "excerpts": [
            "Can i export keyword lists from SEMrush keyword magic tool? Yes, you can export keyword lists in CSV or Excel format to organize, track, and implement them in ..."
          ]
        },
        {
          "title": "Keyword Magic Tool",
          "url": "https://www.semrush.com/features/keyword-magic-tool/",
          "excerpts": [
            "Semrush Keyword Magic Tool is a powerful resource for keyword research. Build your most profitable SEO or PPC campaign with the Keyword Magic Tool."
          ]
        },
        {
          "title": "How to Use Semrush Keyword Magic Tool: 1-Min Guide - Storylane",
          "url": "https://www.storylane.io/tutorials/how-to-use-semrush-keyword-magic-tool",
          "excerpts": [
            "Advanced filters: You can use this filter using \"Word Count, Competitive Density, SERP Features, Results in SERP\"; Questions: a collection of keywords ..."
          ]
        },
        {
          "title": "What's your favorite \"nobody knows about this\" Semrush feature?",
          "url": "https://www.reddit.com/r/SEMrush/comments/1izf579/whats_your_favorite_nobody_knows_about_this/",
          "excerpts": [
            "The «exclude branded keywords» filter. So simple but changes everything. Makes the data actually useful instead of seeing your brand name ..."
          ]
        },
        {
          "title": "What is Keyword Overview?",
          "url": "https://www.semrush.com/kb/257-keyword-overview",
          "excerpts": [
            "Volume: the average number of times per month that a keyword was queried on Google (on the national/local level). Global Volume: the combined total of the ...",
            "Global Volume: the combined total of the keyword's monthly search volumes across all of our country databases. Personal Keyword Difficulty (PKD): is ...",
            "The Keyword Overview is our top-level report to look up any keyword in the Semrush database. After entering your word or phrase in the search bar, you'll see ..."
          ]
        },
        {
          "title": "Moz public API Documentation - Welcome",
          "url": "https://moz.com/api/docs",
          "excerpts": [
            "Keywords: You can use the API to retrieve keyword metrics such as monthly search volume, research ranking opportunities or strengthen content briefs by ...",
            "You can use the API to retrieve metrics for a site, such as link counts and in-house authority and spam metrics, list pages within a domain based on Page ..."
          ]
        },
        {
          "title": "How to Use Moz Keyword Explorer - 1 minute video guide",
          "url": "https://www.trupeer.ai/tutorials/how-to-use-moz-keyword-explorer",
          "excerpts": [
            "Yes, you can export keyword suggestions and metrics as a CSV file if you have a paid account. How many keywords should I target at once. Focus on a mix of high- ..."
          ]
        },
        {
          "title": "Keyword Difficulty Score Assesment | SEO Forum - Moz",
          "url": "https://moz.com/community/q/topic/1179/keyword-difficulty-score-assesment",
          "excerpts": [
            "Your Keyword Difficulty Score is based on the Domain Authority and Page authority for the top 20 search results that keyword is pulling on ...",
            "Moz says that keyword difficulty score is based in domain authority and page authority of the competing 20 search results for a keyword.",
            "Mar 21, 2011 — Moz says that keyword difficulty score is based in domain authority and page authority of the competing 20 search results for a keyword."
          ]
        },
        {
          "title": "Guide to Moz's Keyword Explorer",
          "url": "https://moz.com/help/keyword-explorer",
          "excerpts": [
            " \n  Monthly volume as a single number is limited to US, CA, AU, and UK. If you are not seeing monthly volume as a single number, this means you are searching within a search engine outside these 4 supported options."
          ]
        },
        {
          "title": "Free Keyword Research Tool",
          "url": "https://moz.com/explorer",
          "excerpts": [
            "Keyword Explorer is your comprehensive keyword research tool featuring over 1.25 billion keyword suggestions. Identify high-opportunity target keywords.",
            "See your ranking URLs, monthly search volumes, and difficulty scores all in one place. Use this insight to capitalize on your existing strengths."
          ]
        },
        {
          "title": "How to Use Moz for Organic Keyword Research (the Right Way)",
          "url": "https://www.brafton.com/blog/seo/how-to-use-moz-for-organic-keyword-research/",
          "excerpts": [
            "Moz bases KD mainly on the Page Authority and Domain Authority of Page 1 SERP listings. Organic CTR: A percentage created by Moz to estimate ...",
            "In the left menu, navigate to “Keyword Lists” and select “Create or upload list.” · From there, you can either copy a list of keywords into the ...",
            "Jun 17, 2022 — Once you're done, Moz will automatically evaluate your list of keywords, providing precise Search Volume, Keyword Difficulty and other relevant ..."
          ]
        },
        {
          "title": "How To Analyze Keyword Difficulty - Tooless! - Moz",
          "url": "https://moz.com/blog/how-to-analyze-keyword-difficulty-tooless",
          "excerpts": [
            "1. Direct search for the keyword in Google (Ex. Basket Weavers) · 2. Allinanchor Search for keyword in Google (Ex. · 3. Cross reference ...",
            "Jun 29, 2009 — I am going to explain my method of keyword difficulty particularly for Google but I was hoping others could post their methods in the comments after this post."
          ]
        },
        {
          "title": "How the Top Tools Calculate KD – Keywords Everywhere Blog",
          "url": "https://keywordseverywhere.com/blog/how-the-top-tools-calculate-kd/",
          "excerpts": [
            "We measure the off-page difficulty based on the Moz Domain Authority and the Open Page Rank score. The exact formulation is as follows: Off-Page ...",
            "Keyword Difficulty (KD) measures how difficult it is to rank in organic search; Competitive density (Com.) quantifies the difficulty of ranking ...",
            "Ahrefs has been very popular, especially as a backlink analysis tool. However, as a keyword difficulty checker tool, it seems that Ahrefs is only relying on the number of referring domains and does not use any other metric to calculate KD.",
            "That’s why you may have noticed how Ahrefs shows a score of 0 in lots of high-volume keywords like smoothies near me, coffee shops near me, home goods near me, and data analyst salary.",
            "In bigger countries like the US, this skewed data might be less evident since the competitors’ backlink profiles are generally larger, but in smaller countries or databases, these abnormalities become more apparent",
            "### **3. Ahrefs**",
            "Moz is one of the big players in the world of SEO tools, particularly because of how it offers a straightforward way of measuring domain strengths and guiding SEO strategies.",
            "### Step 3: Weighing everything by country. Semrush also weighs the score based on the regional database it’s in to avoid outliers, especially in less populated countries. Semrush hasn’t published another detailed update since 2021, so it’s safe to assume that they could still be using the formulation above to come up with their Keyword Difficulty scoring.",
            "### **4. Moz**"
          ]
        },
        {
          "title": "Moz Community Discussion on Keyword Volumes",
          "url": "https://moz.com/community/q/topic/64048/are-we-actually-getting-accurate-data-on-keyword-volumes-from-moz-or-other-sources",
          "excerpts": [
            "We use several different sources for our search volume data, including Keyword Planner and anonymized clickstream data.",
            "ta. From there, we built a model that predicts the search volume range a keyword is likely to have with ~95% accuracy.",
            "For the nitty gritty details explaining how the model works, check out this article: <https://moz.com/blog/sweating-details-google-keyword-tool-volume>",
            "You can read more about the Keyword Explorer Metrics in [our Guide"
          ]
        },
        {
          "title": "Moz Help: Manage Campaigns — Export Campaign Data",
          "url": "https://moz.com/help/moz-pro/manage-campaigns/export-campaign-data",
          "excerpts": [
            "To export your Rankings to CSV, scroll down to the Tracked Keywords Overview to and click Export CSV.",
            ". The option to export your Moz Rankings to CSV is above ... You also have the option to select whether you’d like to view and export the **Overview** graph or the **Trended Analysis** graph.",
            "The maximum number of rows you’re able to export to CSV in each section of the tool is determined by your subscription level and you will be asked to confirm how many rows you’d like to export after clicking **Export CS",
            "As with the **Rankings Overview** CSV export, the **SERP Features** CSV will include multiple rows of data for each keyword - one for each data collection within the selected timeframe.",
            "The option to export your Moz Rankings to CSV is above ... Additionally, many sections have filter options available to help restrict and segment your data.",
            "The data in most of these views cannot be restricted to a specific timeframe or view - the data we have available is the data that will be exported. However, below, we’ll outline the exceptions to the standards outlined here.",
            "Within the **Links Overview** section of your Moz Campaign, you will have the option to export to CSV or PDF right at the top of the screen."
          ]
        },
        {
          "title": "Moz Keyword Explorer - Keyword Lists Overview",
          "url": "https://moz.com/help/keyword-explorer/keyword-lists/overview",
          "excerpts": [
            "If you ever need to export your Keyword List, you can do so via the link on the top right. The Export to CSV button is located on the top right of your list.",
            "The following data will be included in the CSV export.",
            "SV export.\n#### CSV Header Data:\n\n**List Name** \\- The name of the exported list\n\n**Total Keywords** \\- The total number of keywords in the list at the time of data export\n\n**Total Volume Range** \\- The total volume range of the list which is calculated by adding all the lower range numbers together (Column C) and all the higher range numbers together (Column D) to get the total volume range\n\n**Average Volume Range** \\- The average search volume of the keywords in the list at the time of data export\n\n**Average Keyword Difficulty** \\- The average Difficulty of the keywords in the list at the time of data export\n\n**Average Organic CTR** \\- The average organic CTR of the keywords in the list at the time of data export\n\n**Average Priority** \\- The average priority score of the keywords in the list at the time of data export\n\n**Last Updated -** The date this keyword list was last updated\n\n**Export Date** \\- The date of export\n\n#### CSV Column Data:\n\n**A. Keyword** \\- Notes the keywords in your keyword list at the time of export. **B. Country** \\- The designated country for the keyword in column A. **C. Min Monthly Volume** \\- The lower end of the [search volume](https://moz.com/help/keyword-explorer/keyword-metrics/monthly-volume) range for this keyword. Search volume indicates the demand for a keyword by estimating the number of times it is searched per month.",
            "Export Your Keyword List to CSV. If you ever need to export your Keyword List, you can do so via the link on the top right.",
            "#### CSV Header Data:",
            "**List Name** \\- The name of the exported lis",
            "**Total Keywords** \\- The total number of keywords in the list at the time of data expor",
            "**Average Volume Range** \\- The average search volume of the keywords in the list at the time of data expor",
            "**Average Keyword Difficulty** \\- The average Difficulty of the keywords in the list at the time of data expor",
            "**Average Organic CTR** \\- The average organic CTR of the keywords in the list at the time of data expor",
            "**Average Priority** \\- The average priority score of the keywords in the list at the time of data expor",
            "**Last Updated -** The date this keyword list was last updated",
            "**Export Date** \\- The date of expor",
            "#### CSV Column Data:",
            "- The name of the exported list\n\n**Total Keywords** \\- The total number of keywords in the list at the time of data export\n\n**Total Volume Range** \\- The total volume range of the list which is calculated by adding all the lower range numbers together (Column C) and all the higher range numbers together (Column D) to get the total volume range\n\n**Average Volume Range** \\- The average search volume of the keywords in the list at the time of data export\n\n**Average Keyword Difficulty** \\- The average Difficulty of the keywords in the list at the time of data export\n\n**Average Organic CTR** \\- The average organic CTR of the keywords in the list at the time of data export\n\n**Average Priority** \\- The average priority score of the keywords in the list at the time of data export\n\n**Last Updated -** The date this keyword list was last updated\n\n**Export Date** \\- The date of export\n\n#### CSV Column Data:\n\n**A. Keyword** \\- Notes the keywords in your keyword list at the time of export. **B. Country** \\- The designated country for the keyword in column A. **C. Min Monthly Volume** \\- The lower end of the [search volume](https://moz.com/help/keyword-explorer/keyword-metrics/monthly-volume) range for this keyword. Search volume indicates the demand for a keyword by estimating the number of times it is searched per month.\n**D. Max Monthly Volume-** The higher end of the [search volume](https://moz.com/help/keyword-explorer/keyword-metrics/monthly-volume) range for this keyword. Search volume indicates the demand for a keyword by estimating the number of times it is searched per month. **E. Specific Monthly Volume -** The single number [search volume](https://moz.com/help/keyword-explorer/keyword-metrics/monthly-volume) for this keyword. **F. Features** \\- If [SERP Features](https://moz.com/help/keyword-explorer/keyword-research/serp-features) are present in the SERP at the time this keyword is analyzed it will be indicated in this column. The SERP Features present will be noted, separated by colons (for example _adwords\\_top:adwords\\_bottom:basic_ ) where **basic** indicates the presence of organic blue links in the SERP. **G.** [**Difficulty**](https://moz.com/help/keyword-explorer/keyword-metrics/difficulty) \\- The Difficulty score for this keyword which shows you how tough it would be to rank in the top 10 spots for that keyword. **H.** [**Organic CTR**](https://moz.com/help/keyword-explorer/keyword-metrics/organic-ctr) **\\-** The Organic CTR for this keyword which is an estimated relative click-through rate for organic web results in the SERP for this term. "
          ]
        },
        {
          "title": "Moz Help: Keyword Explorer - Difficulty",
          "url": "https://moz.com/help/keyword-explorer/keyword-metrics/difficulty",
          "excerpts": [
            "Difficulty is on a scale of 1-100, where 100 is very difficult. Use this metric to compare keywords within your niche and set your expectations.",
            "Difficulty** shows you how tough it would be to rank in the top 10 spots for that keywor",
            "The scores roughly correspond to a weighted average of the PA of the top 10, and the other inputs (DA, homepages, query term use, etc.) modify that weighted average.",
            "We arrive at this score by analyzing the strength of the top 10 organic blue links on the search engine results page (SERP). A **Difficulty** score of 1 is not difficult at all, and 100 is very diffic",
            "There's no single score that's always good or always bad. It all depends on your situation and what you're seeking to accomplish.",
            "Keyword Difficulty in Keyword Explorer takes into account the Page Authority (PA) and Domain Authority (DA) scores of the results ranking on the first page ...",
            "The Difficulty metric in Moz's Keyword Explorer tool shows you how tough it would be to rank in the top 10 spots for a keyword. In this guide you'll learn ..."
          ]
        },
        {
          "title": "Keyword Difficulty - Competition Analysis - Victorious SEO Agency",
          "url": "https://victorious.com/blog/keyword-difficulty/",
          "excerpts": [
            "Moz's difficulty score rates keywords on a scale from 1 (easy) to 100 (hard). According to Moz, they arrive at that score by analyzing the top ten organic links ...",
            "Moz's difficulty score rates keywords on a scale from 1 (easy) to 100 (hard). According to Moz, they arrive at that score by analyzing the top ten organic links ..."
          ]
        },
        {
          "title": "Keyword Difficulty in SEO: A Calculated Approach to Outrank ...",
          "url": "https://www.stanventures.com/blog/keyword-difficulty/",
          "excerpts": [
            "Almost all popular SEO tools calculate Keyword Difficulty using their own proprietary metrics and algorithms. Moz: Moz's Keyword Difficulty ..."
          ]
        },
        {
          "title": "Remove Keyword Labels - Help Hub",
          "url": "https://moz.com/help/moz-pro/rankings/remove-keyword-labels",
          "excerpts": [
            "To remove the Branded label from any of these keywords, click the x beside the keyword. You can remove the branded label from your keyword exceptions via your ..."
          ]
        },
        {
          "title": "Guide to Moz's Explore By Keyword tool for ...",
          "url": "https://moz.com/help/keyword-explorer/explore-by-keyword",
          "excerpts": [
            "Head to the Explore by Keyword section of Keyword Explorer; Enter the keyword that you'd like to research; Use the drop-down to select the locale & language you ...",
            "Explore by Keyword is your one-stop shop for researching specific keywords and analyzing SERP data. To get started, follow the steps below."
          ]
        },
        {
          "title": "Keyword Research Tactic #5: Moz Keyword Explorer",
          "url": "https://wholedesignstudios.com/keyword-research-tactic-5-moz-keyword-explorer/",
          "excerpts": [
            "These suggestions can be downloaded as a spreadsheet using the Export CSV link at the top right of your results. keyword-research-29. You can ...",
            "Moz offers a keyword research tool called the Keyword Explorer. Although it only allows you to research a maximum of two keywords a day, it does ..."
          ]
        },
        {
          "title": "How to Do a Keyword-Driven Content Audit (with ...",
          "url": "https://moz.com/blog/how-to-do-a-keyword-driven-content-audit",
          "excerpts": [
            "Nov 7, 2017 — The export contains the top ranking URL for moz.com for each of the keywords (note: your maximum export size does vary with your Moz Pro ...",
            "How to Do a Keyword-Driven Content Audit (with Keyword Explorer) · Step 0 – The \"Exact Page\" filter · Step 1 – Get all rankings · Step 2 – Export ..."
          ]
        },
        {
          "title": "API - Row Limit Question | SEO Forum",
          "url": "https://moz.com/community/q/topic/56546/api-row-limit-question",
          "excerpts": [
            "Nov 3, 2015 — Currently the only way to know when you have reached your row limit is to monitor the API Dashboard - https://moz.com/products/mozscape/usage."
          ]
        },
        {
          "title": "Keyword Difficulty Score - Definition, Examples & Tips",
          "url": "https://agencyanalytics.com/kpi-definitions/keyword-difficulty-score",
          "excerpts": [
            "Keyword Difficulty Score is a numerical metric, ranging from 0 to 100, that evaluates the competitiveness of ranking for a particular keyword in search engine ...",
            "To check keyword difficulty score, use a keyword research tool like Ahrefs, Semrush, or Moz. These tools measure how hard it is to rank for a specific keyword by analyzing top-ranking pages, backlink profiles, and referring domains . This gives you a reliable snapshot of competition for any given keyword."
          ]
        },
        {
          "title": "Overview of Brand Rules in Moz Pro",
          "url": "https://moz.com/help/moz-pro/manage-campaigns/brand-rules",
          "excerpts": [
            "Within your Moz Pro Campaign, **Brand Rules** are used to help identify which of your keywords are **Branded** and **Non-Branded** . Additionally, they help the tool in determining the number of **Non-Branded Keyword Visits** in your **Site Traffic** . The first **Brand Rule** for your Campaign is determined during Campaign creation, when you are asked to identify your **bra",
            "\n* [Brand Rules and Site Traffic",
            "Within the **Site Traffic** section of your Campaign, **Brand Rules** are used to determine the **Non-Branded Keyword Visits** noted in the **Visits** view of **Traffic from Organic Search. **",
            "This count represents the number of visits to your site from search engines originating from keywords not tagged as **Branded** based on your **Brand Rules. ** Traffic data ( **Visits** ) is pulled in from your connected Google Analytics account."
          ]
        },
        {
          "title": "Moz Keyword Difficulty",
          "url": "https://moz.com/tools/keyword-difficulty",
          "excerpts": [
            "Difficulty score helps you prioritize your keyword efforts. Moz's proprietary Keyword Difficulty score shows how easy (or hard) it is to rank on each SERP.",
            "Moz’s proprietary Keyword Difficulty score shows how easy (or hard) it is to rank on each SERP. Difficulty score takes into account the Page Authority (PA) and Domain Authority (DA) scores of results ranking on the first page of Google for a given query.",
            "Moz’s Keyword Explorer neatly ties together keyword research metrics and makes complex analysis easy so we can spend less time in spreadsheets and more time generating qualified website traffic.",
            "##### 500 million keyword suggestions",
            "##### 180 million fresh ranking keywords",
            "##### 170 Google search engines",
            "Moz's proprietary Keyword Difficulty score shows how easy (or hard) it is to rank on each SERP . Difficulty score takes into account the Page Authority (PA) and Domain Authority (DA) scores of results ranking on the first page of Google for a given query.",
            "Check Keyword Difficulty. Get a Difficulty score from 1 (easy) to 100 (difficult) to uncover the level of effort to rank higher than your competition."
          ]
        },
        {
          "title": "Moz Keyword Difficulty Overview",
          "url": "https://www.metrichq.org/seo-sem/keyword-difficulty/",
          "excerpts": [
            "Moz calculates Keyword Difficulty based on the Page Authority (PA) and Domain Authority (DA) of the websites appearing in the top 10 positions on the SERPs for a given keyword .",
            "The keyword difficulty score is a number, typically ranging from 0 to 100, assigned to a keyword. This score reflects the competitiveness of a keyword in the context of SEO. A higher score indicates a higher level of difficulty in achieving a top-ranking position on search engines like Google and Bing."
          ]
        },
        {
          "title": "Questions tagged under \"keyword explorer\" | SEO Forum - Moz",
          "url": "https://moz.com/community/q/tags/keyword%20explorer",
          "excerpts": [
            "... keyword difficulty scores: Moz: No search volume data, Keyword Difficulty (KD) 24. Google Keyword Planner: Search volume 100k-1M, Difficulty (Low) Semrush ..."
          ]
        },
        {
          "title": "Moz public API Documentation - Authentication",
          "url": "https://moz.com/api/docs/guides/authentication",
          "excerpts": [
            "To authenticate requests to the API, simply include a custom x-moz-token header with the value set to one of your API tokens every time you send a POST request.",
            "Missing: rate limit"
          ]
        },
        {
          "title": "Moz Pro Tracked Keyword Rankings Overview - Help Hub",
          "url": "https://moz.com/help/moz-pro/rankings/overview",
          "excerpts": [
            "Yes, to limit the CSV export to just one row of data per keyword, you would need to choose a date range from the calendar within one week of an update. For more ..."
          ]
        },
        {
          "title": "A quick guide to Moz's free Keyword Explorer",
          "url": "https://www.name.com/blog/a-quick-guide-to-mozs-free-keyword-explorer",
          "excerpts": [
            "Be aware of search limits​​ Keep in mind that Moz limits free accounts to 10 queries per month, so be thoughtful of every search you enter."
          ]
        },
        {
          "title": "Moz Review (2025): Tool Features, Pricing, and Pros & Cons",
          "url": "https://searchatlas.com/blog/moz-review/",
          "excerpts": [
            "Jul 1, 2025 — Moz Pro's Large plan increases the crawl limit to 5 million pages ... Users can only access or export 1,000 keyword suggestions at a time, ..."
          ]
        },
        {
          "title": "Keyword Explorer | SEO Forum - Moz",
          "url": "https://moz.com/community/q/category/64/keyword-explorer",
          "excerpts": [
            "How to see KD? Can anyone tell me that how can we see a KD of keyword? I want to know the KD of keyword volcano hybrid for adults. Mar 9, 2021, 3:39 AM ..."
          ]
        },
        {
          "title": "🥇 Discover Moz Pro & Moz Local pricing and what's in them",
          "url": "https://morningscore.io/moz-pricing/",
          "excerpts": [
            "Jul 24, 2020 — Moz Pro comes with 5 different pricing options each of which offers different data limits. The cost of each Moz plan also differs based on the ..."
          ]
        },
        {
          "title": "Moz API",
          "url": "https://moz.com/products/api",
          "excerpts": [
            "What's included in the NEW Moz API ? Keyword Metrics. Get up-to-date metrics on Volume, Difficulty, Organic CTR, and Priority. ",
            "Get up-to-date metrics on Volume, Difficulty, Organic CTR, and Priority. Build powerful keyword research tools and craft data-driven content strategies.",
            "Straightforward JSON-RPC 2.0 architecture** : Enjoy a streamlined development process with a modern and powerful API structu"
          ]
        },
        {
          "title": "Moz Keyword Explorer Data Scope and Export/API Details",
          "url": "https://moz.com/help/keyword-explorer/keyword-suggestions",
          "excerpts": [
            "Monthly Volume — The search volume for this keyword suggestion. Min Monthly Volume – The lower end of the monthly volume range for this keyword."
          ]
        },
        {
          "title": "Segmenting Keyword Data - Help Hub - Moz",
          "url": "https://moz.com/help/moz-pro/workflows/segmenting-keyword-data",
          "excerpts": [
            "If you're looking to increase your rankings for keywords not associated with your brand, filter by only Non-Branded keywords and see how the rankings and Search ..."
          ]
        },
        {
          "title": "Keyword Research [Beginner's Guide to SEO] - Moz",
          "url": "https://moz.com/beginners-guide-to-seo/keyword-research",
          "excerpts": [
            "The higher the search volume for a given keyword or keyword phrase, the more work is typically required to achieve higher rankings. This is often referred to as ..."
          ]
        },
        {
          "title": "Moz API V2 Overview & Authentication Guide - Help Hub",
          "url": "https://moz.com/help/links-api/getting-started/overview",
          "excerpts": [
            "When structuring your request, all you need to do is add your token as a header value with the key `x-moz-token`. ... Message: Your monthly row limit reached."
          ]
        },
        {
          "title": "Moz API Pricing",
          "url": "https://moz.com/products/api/pricing",
          "excerpts": [
            "Get started with the Moz API for free or sign up for an affordable plan starting at only $5/month. Your custom data solutions are just a click away."
          ]
        },
        {
          "title": "Moz Keyword Explorer Volume Details and Limitations",
          "url": "https://moz.com/blog/sweating-details-google-keyword-tool-volume",
          "excerpts": [
            "All of this above — the research into why Google Keyword Planner is inadequate, the machine-learned ranges, the daily freshness volume updating, etc. — all goes into a single, seemingly simple, metric: **Volume Range",
            "The log of Moz's keyword volume ranges are far less linear, which indicates that our range-optimization methodologies found anomalies in the search data which do not conform to a perfect logarithmic relationship with search volume volatility.",
            "We can actually demonstrate this quite easily in a graph."
          ]
        },
        {
          "title": "Moz API DataKeywordSearchIntentFetch Action",
          "url": "https://moz.com/api/docs/methods/DataKeywordSearchIntentFetchAction",
          "excerpts": [
            "DataKeywordSearchIntentFetch",
            "Search API documentation",
            "Retrieve the most recent search intent scores (navigational, informational, commercial, and transactional) for any keyword that exists in our database. JSON-RPC Method:",
            "```bash",
            "data.keyword.search.intent.fetch",
            "```",
            "Response",
            "### keyword\\_inten",
            "Information for the intent of a given keyword. Show Definition",
            "### serp\\_quer",
            "object",
            "object",
            "Represents a SERP query object."
          ]
        },
        {
          "title": "Moz Keyword Tool Monthly Volume | SEO Forum",
          "url": "https://moz.com/community/q/topic/63601/moz-keyword-tool-monthly-volume",
          "excerpts": [
            "Moz is using clickstream data to calculate the search volume, which means they have actual data on millions of users and their searches and can ...",
            "Google shows you the grouped volume. Which means it takes all variations of your keywords, combines their search volumes and shows you which ..."
          ]
        },
        {
          "title": "What is a Good Keyword Volume Score? | SEO Forum - Moz",
          "url": "https://moz.com/community/q/topic/62619/what-is-a-good-keyword-volume-score",
          "excerpts": [
            "Recently we bought the Moz tool but when using the Keyword Explorer tool it shows NO DATA for the monthly volume data for our keywords based in ..."
          ]
        },
        {
          "title": "Understand Brand Strength With Moz Pro – Next Level",
          "url": "https://moz.com/blog/understand-brand-strength-next-level",
          "excerpts": [
            "Oct 12, 2023 — Within Moz Pro, brand rules allow you to set parameters for how the tool identifies and tags branded keywords within your Campaign. This also ..."
          ]
        },
        {
          "title": "Moz Keyword Explorer Blog — Google Keyword Unplanner: Clickstream Data to the Rescue",
          "url": "https://moz.com/blog/google-keyword-unplanner-clickstream-data-to-the-rescue",
          "excerpts": [
            "://moz.com/explorer) has utilized clickstream-derived keyword data in a novel manner since day 1, allowing us to provide consistent keyword volumes despite Google Keyword Planner's dramatic shifts in data availability and reporting.",
            "lem 1: Keyword Planner has started aggressively grouping keywords",
            "The ranges are very large and, frankly, unworkable for anyone looking to do keyword research (for Adwords or SEO).",
            "Moz Keyword Explorer's blended technology keeps us ahead of the curve.",
            "Clickstream data is intrinsically noisy and biased, so our models are quite comprehensive to remove random occurrences, strip out bias in the sampled data, and model projected traffic against the general Google corpus."
          ]
        },
        {
          "title": "Moz Keyword Explorer - Exporting a keyword list (Facebook video post)",
          "url": "https://m.facebook.com/moz/videos/daily-seo-fix-advanced-exporting-tips-for-keyword-explorer/231535585074414/?__so__=permalink&__rv__=related_videos&locale=hi_IN",
          "excerpts": [
            "Exporting a keyword list from Keyword Explorer will allow you to analyze your keyword data in a spreadsheet.",
            "Exporting a keyword list from Keyword Explorer will allow you to analyze your keyword data in a spreadsheet. In this Daily SEO Fix video, Emilie will explain how you can filter and export a CSV of your keyword list and show you what insights you can take from it."
          ]
        },
        {
          "title": "How do you change the average monthly searches from a ...",
          "url": "https://support.google.com/google-ads/thread/92991857/how-do-you-change-the-average-monthly-searches-from-a-range-to-a-specific-numerical-value?hl=en",
          "excerpts": [
            "Jan 11, 2021 — I have searched for a keyword on Google Keyword Planner and clicked on Historical Metrics, but the average monthly searches data shows as a range."
          ]
        },
        {
          "title": "How to get the old Google Keyword Planner volume data",
          "url": "https://searchengineland.com/get-old-google-keyword-planner-volume-254736",
          "excerpts": [
            "Search volume estimates from the Google Keyword Planner have been off recently due to close variants. Columnist Patrick Stox shows how to ..."
          ]
        },
        {
          "title": "Google Trends Numbers: From 0 to 100, What is it?",
          "url": "https://serpapi.com/blog/google-trends-numbers-from-0-to-100-what-is-it/",
          "excerpts": [
            "Jan 16, 2024 — It's normalized to a 0-100 index, where 0 means no search or very few searches, while 100 is the peak of the searches. The number will change if ..."
          ]
        },
        {
          "title": "What data can I get from Google Trends?",
          "url": "https://help.funnel.io/en/articles/4774668-what-data-can-i-get-from-google-trends",
          "excerpts": [
            "Google Trends normalizes data to make comparisons between search terms easier. Search results are normalized on time period, region and the relation between ..."
          ]
        },
        {
          "title": "Get started with Google Trends | Google Search Central",
          "url": "https://developers.google.com/search/docs/monitor-debug/trends-start",
          "excerpts": [
            "Google Trends can help you better understand how people find information on Google Search, which can help you to develop your content strategy and refine ...",
            "Google Trends provides a random sample of aggregated, anonymized, and categorized Google and YouTube searches. It lets you analyze interest in a particular ..."
          ]
        },
        {
          "title": "Google Trends FAQ",
          "url": "https://meetglimpse.com/google-trends/faq/",
          "excerpts": [
            "How is Google Trends data adjusted? Google Trends uses a methodology called normalization to adjust the raw search data, turning it into an interest ranking ..."
          ]
        },
        {
          "title": "How to See Absolute Number of Searches in Google Trends",
          "url": "https://meetglimpse.com/google-trends/search-volume/",
          "excerpts": [
            "Google Trends is a powerful tool for understanding search interest, but it doesn't show the real number of searches (i.e. absolute search volume) by default.",
            "**To see absolute numbers in Google Trends, you'll need to install the** [**Glimpse Chrome extension**](https://chrome.google.com/webstore/detail/google-trends-supercharge/ocmojhiloccgbpjnkeiooioedaklapap?ref=glimpse.ghost.io)**,** **which adds the absolute search volume**, growth rate, and other insights.",
            "100 means the maximum search interest for the keyword in the selected time frame, while 50 represents half of that peak, and 0 indicates insufficient data.",
            "The Y axis on Google Trends shows a keyword's search interest on a 0-100 (normalized) scale.",
            "This can help you quickly grasp a topic's scale and rate of growth so you can make better-informed decisions.",
            "To translate the Y-axis on Google Trends from relative search volume to real numbers, use Glimpse: a Chrome extension that [enhances Google Trends](https://meetglimpse.com/) by providing the real number of searches and other insights."
          ]
        },
        {
          "title": "Webmasters Stack Exchange discussion: Which data is correct Google Trends or Google Keyword Planner Tool",
          "url": "https://webmasters.stackexchange.com/questions/112732/which-data-is-correct-google-trends-or-google-keyword-planner-tool",
          "excerpts": [
            "Feb 13, 2018 — Both are correct. Those are different data. Keyword Planner shows absolute numbers, while Google Trends shows normalized data of user behavior.",
            "[_Normalized_](https://support.google.com/trends/answer/4365533) means here in general _in proportion to time and location_",
            "If keyword planner is showing a search term to have for example, 200-2k searches per month, and the search volume jumps from 300 to 1500, keyword planner will still likely show the search volume as being 200-2k searches per month, whereas Google trends will show the search volume as going up 5x from 300 to 1500."
          ]
        },
        {
          "title": "Google Trends Anchor Bank - Cross-referencing GKP and Trends",
          "url": "https://github.com/epfl-dlab/GoogleTrendsAnchorBank",
          "excerpts": [
            "Per Google Trends request, only up to 5 Google queries can be compared, and the results are relative (between 0 and 100), not absolute.",
            "Results are rounded to integer precision, which may cause major problems.",
            ".google.com/) allows users to analyze the popularity of Google search\nqueries across time and space."
          ]
        },
        {
          "title": "What Data Can I get from Google Keyword Planner",
          "url": "https://help.funnel.io/en/articles/10153350-what-data-can-i-get-from-google-keyword-planner",
          "excerpts": [
            "Dec 11, 2024 — The Google Keyword Planner connector offers historical data. Note that Google provides data historical data for the previous month and four years back."
          ]
        },
        {
          "title": "Google Trends show wrong data. Here is why, and How to ...",
          "url": "https://keywordseverywhere.com/google-trends-fixed.html",
          "excerpts": [
            "Issues due to normalization. Basically, every graph that Google Trends draws is normalized to 0 and 100, where 100 is the peak in the timeframe we've requested."
          ]
        },
        {
          "title": "The (mis)use of Google Trends data in the social sciences",
          "url": "https://www.sciencedirect.com/science/article/pii/S0049089X24001212",
          "excerpts": [
            "by J Hölzl · 2025 · Cited by 7 — (1) Since the RSI is based on a sample of all Google searches, sampling variance can produce unreliable estimates from Google Trends. We have to interpret the ..."
          ]
        },
        {
          "title": "Understanding Google's Search Volume Buckets",
          "url": "https://www.authoritas.com/blog/understanding-googles-search-volume-buckets-a-deep-dive-into-how-search-volumes-really-work",
          "excerpts": [
            "Nov 12, 2024 — This article examines the different ways Google provides search volume values for keywords and highlights some of the problems with the data it provides."
          ]
        },
        {
          "title": "What is Google Trends data — and what does it mean?",
          "url": "https://medium.com/google-news-lab/what-is-google-trends-data-and-what-does-it-mean-b48f07342ee8",
          "excerpts": [
            "Trends data is an unbiased sample of our Google search data. It's anonymized (no one is personally identified), categorized (determining the topic for a search ..."
          ]
        },
        {
          "title": "Keyword Planner Only Giving Ranges",
          "url": "https://support.google.com/google-ads/thread/32197933/keyword-planner-only-giving-ranges?hl=en",
          "excerpts": [
            "Mar 3, 2020 — Hi,. You don't have to run an active campaign to use the Keyword Planner but you need to at least set up an ad campaign."
          ]
        },
        {
          "title": "Any way to figure out which keywords are close variants?",
          "url": "https://groups.google.com/g/adwords-api/c/TEFQlt3wYks",
          "excerpts": [
            "Aug 3, 2017 — When you get the search volume for a keyword, its close variants including the corrected keyword (if it is mispelt), singular forms, plural ..."
          ]
        },
        {
          "title": "Where do I see the average monthly searches for a keyword?",
          "url": "https://support.google.com/google-ads/thread/1469212/where-do-i-see-the-average-monthly-searches-for-a-keyword?hl=en",
          "excerpts": [
            "Feb 5, 2019 — \"Average Monthly searches\" for a keywords aren't available within your campaign, but you can find this number using the Keyword Planner tool."
          ]
        },
        {
          "title": "Google Trends Search Volume Explained - Exploding Topics",
          "url": "https://explodingtopics.com/blog/google-trends-search-volume",
          "excerpts": [
            "Google Trends doesn't show actual search volume numbers. Instead, they're providing a relative scale. A measurement of 0 means no interest and 100 means max ..."
          ]
        },
        {
          "title": "Why search volumes vary between SISTRIX and the ...",
          "url": "https://www.sistrix.com/faq/why-search-volumes-vary-sistrix-google-keyword-planner/",
          "excerpts": [
            "Apr 27, 2021 — The Google Keyword Planner is also inconsistent with the 'grouping' logic: with some keywords there is no grouping, but despite this, the ..."
          ]
        },
        {
          "title": "Conflict between Google Keyword Planner and Ahrefs",
          "url": "https://www.reddit.com/r/SEO/comments/lufgqr/conflict_between_google_keyword_planner_and_ahrefs/",
          "excerpts": [
            "Ahrefs gets their existing volume data from Google Keyword Planner, pair it with clickstream data and update it monthly, therefore there ..."
          ]
        },
        {
          "title": "Google Trends understanding the data",
          "url": "https://newsinitiative.withgoogle.com/resources/trainings/google-trends-understanding-the-data/",
          "excerpts": [
            "Trends excludes certain data from your searches:\n\n* **Searches made by very few people:** Trends only analyses data for popular terms, so search terms with low volume appear as 0 for a given time period. * **Duplicate searches:** Trends eliminates repeated searches from the same user over a short period of time for better overall accuracy. * **Special characters:** Trends filters out queries with apostrophes and other ",
            "Numbers on the graph don't represent absolute search volume numbers, because the data is normalised and presented on a scale from 0-100, where each point on the graph is divided by the highest point, or 100."
          ]
        },
        {
          "title": "Google Trends and GKP Cross-Reference Guide (2025 API overview)",
          "url": "https://developers.google.com/search/blog/2025/07/trends-api",
          "excerpts": [
            "Based on our analysis, most people keep their analyses within 5 years. For that reason, we decided to limit\n the data to a rolling window of 1800 days (~5 years)",
            "The data goes\n all the way up to just 2 days ago. When it comes to date aggregation, we'll provide daily, weekly, monthly, and yearly aggregations",
            "The API uses a different method for scaling which is consistent across requests, and lets you join, compare, and merge data from multiple ..."
          ]
        },
        {
          "title": "Google Ads Help - Keyword close variants: Definition",
          "url": "https://support.google.com/google-ads/answer/9342105?hl=en",
          "excerpts": [
            "Close variants allow keywords to match to searches that are similar, but not identical to the targeted keyword, and help you connect with people who are looking for your business—despite slight variations in the way they search—reducing the need to build out exhaustive keyword lists to reach these customers. By default, all keyword match types are eligible to match to close variants.",
            "For exact match keywords, close variants may also include:",
            "| Close variant | Description | Available in these languages |"
          ]
        },
        {
          "title": "Discrepancy between Google Keyword Planner and ...",
          "url": "https://www.reddit.com/r/bigseo/comments/1jgtair/discrepancy_between_google_keyword_planner_and/",
          "excerpts": [
            "Trends shows the relative popularity of the keyword over time - to itself. Its a score of 1 to 100 and it changes if the search volume changes ..."
          ]
        },
        {
          "title": "About keyword matching options - Google Ads Help",
          "url": "https://support.google.com/google-ads/answer/7478529?hl=en",
          "excerpts": [
            "Keywords are words or phrases that are used to match ads with the terms people are searching for. The keyword match types dictate how closely the keyword needs ..."
          ]
        },
        {
          "title": "RE: keyword ideas - close variants",
          "url": "https://groups.google.com/g/adwords-api/c/qlnJQrKO0l8",
          "excerpts": [
            "Keyword planner UI shows close variants for many keywords. Keyword Planner API did not show close variants for all keywords I tested. четверг, 17 августа 2023 г ..."
          ]
        },
        {
          "title": "Google Trends Anchor Bank (G-TAB) for calibration",
          "url": "https://arxiv.org/abs/2007.13861",
          "excerpts": [
            "Google Trends Anchor Bank (G-TAB), an efficient solution for the calibration of Google Trends data.",
            "Our method expresses the popularity of an arbitrary number of queries on a common scale without being compromised by rounding errors.",
            "In the offline preprocessing phase, an \"anchor bank\" is constructed, a set of queries spanning the full spectrum of popularity, all calibrated against a common reference query by carefully chaining together multiple Google Trends requests.",
            "In the online deployment phase, any given search query is calibrated by performing an efficient binary search in the anchor bank.",
            "Each search step requires one Google Trends request, but few steps suffice, as we demonstrate in an empirical evaluation.",
            "We make our code publicly available as an easy-to-use library at [this https URL](https://github.com/epfl-dlab/GoogleTrendsAnchorBank)."
          ]
        },
        {
          "title": "Calibration of Google Trends Time Series",
          "url": "https://dlab.epfl.ch/people/west/pub/West_CIKM-20.pdf",
          "excerpts": [
            "Google Trends data is calibrated using G-TAB, which uses an \"anchor bank\" of queries and a binary search to avoid rounding errors.",
            "Calibration of Google Trends Time Series"
          ]
        },
        {
          "title": "How Accurate Is Semrush? A Comprehensive Analysis - BKA Content",
          "url": "https://bkacontent.com/how-accurate-is-semrush-a-comprehensive-analysis/",
          "excerpts": [
            "Semrush is generally accurate , thanks to its well-rounded approach to data. While its keyword and traffic estimates are reliable, competitors like Ahrefs excel in backlink analysis, and Moz's Domain Authority provides a different perspective on site strength."
          ]
        },
        {
          "title": "124 SEO Statistics for 2024",
          "url": "https://ahrefs.com/blog/seo-statistics/",
          "excerpts": [
            "94.74% of keywords get 10 monthly searches or fewer. · 0.0008% of keywords get more than 100,000 monthly searches. · 91.45% of search volumes in ..."
          ]
        },
        {
          "title": "Which SEO Tool Has the Most Accurate Keyword Search Volume?",
          "url": "https://brandwell.ai/blog/accurate-keyword-search-volume/",
          "excerpts": [
            "Google Keyword Planner is widely regarded as the tool with the most accurate keyword search volume data. Though it has limited functionality, ..."
          ]
        },
        {
          "title": "An Ensemble Approach for Research Article Identification",
          "url": "https://arxiv.org/abs/2304.09487",
          "excerpts": [
            "by L Tang · 2023 · Cited by 1 — This study presents an ensemble approach that addresses the challenges of identification and analysis of research articles in rapidly evolving fields."
          ]
        },
        {
          "title": "A Data-Weighted Prior Estimator for Forecast Combination",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7514918/",
          "excerpts": [
            "by E Fernández-Vázquez · 2019 · Cited by 6 — Forecast combination methods reduce the information in a vector of forecasts to a single combined forecast by using a set of combination weights."
          ]
        },
        {
          "title": "A comprehensive review on ensemble deep learning",
          "url": "https://www.sciencedirect.com/science/article/pii/S1319157823000228",
          "excerpts": [
            "by A Mohammed · 2023 · Cited by 951 — This review paper provides comprehensive reviews of the various strategies for ensemble learning, especially in the case of deep learning."
          ]
        },
        {
          "title": "Quantile-based bias-correction of extreme rainfall: Pros & ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0022169425001520",
          "excerpts": [
            "por R Padulano · 2025 — The goal of this paper is to demonstrate the efficacy of three popular techniques in preserving signals in the first- and second-order moments and in a ..."
          ]
        },
        {
          "title": "Robust handling of extremes in quantile mapping - GMD",
          "url": "https://gmd.copernicus.org/articles/17/8173/2024/",
          "excerpts": [
            "por P Berg · 2024 · Mencionado por 4 — Quantile mapping is a method often used for the bias adjustment of climate model data toward a reference, ie to construct a transformation of the model's ..."
          ]
        },
        {
          "title": "Calculating Weighted Averages but putting more weight on ...",
          "url": "https://www.reddit.com/r/statistics/comments/9yclwi/calculating_weighted_averages_but_putting_more/",
          "excerpts": [
            "I would like to be able to put \"more weight\" into the volume of reviews to try and offset this kind of outcome when suggesting \"best businesses\" for an area."
          ]
        },
        {
          "title": "BKAContent article on Google Keyword Planner accuracy and tool comparisons",
          "url": "https://bkacontent.com/how-accurate-is-google-keyword-planner/",
          "excerpts": [
            "Google Keyword Planner only estimates keyword search volume. Google itself acknowledges that the figures are not exact.",
            "In fact, a study by Ahrefs discovered that 91% of Google Keyword Planner's search volumes were overestimations . by [Greg Secrist](https://bkacontent.com/author/gregsecrist/ \"Posts by Greg Secrist\") | Nov 1, 2024 | [Keyword Research](https://bkacontent.com/category/seo-strategy-tips/keyword-research/) , [SEO Tools](https://bkacontent.com/category/seo-tools/) | [0 comments](https://bkacontent.com/how-accurate-is-google-keyword-planner/)",
            "Many marketers start with Google Keyword Planner for search engine optimization (SEO) research. However, Google created the tool for pay-per-click (PPC) ads, so how accurate is Google Keyword Planner for SEO? The answer matters because good data-driven marketing can [increase brand awareness](https://persuasion-nation.com/data-driven-marketing-statistics/) by 50%. Learn whether Google Keyword Planner is accurate and how other tools stack up.",
            "In general, Semrush proves to be a better tool for SEO than Google Keyword Planner alone."
          ]
        },
        {
          "title": "Ultimate Keyword Research Tool Search Volume Accuracy Comparison",
          "url": "https://tomislavhorvat.com/ultimate-search-volume-comparison/",
          "excerpts": [
            "Winner: SEMrush emerged as the most accurate, Ubersuggest was reliable except for one major blunder, and Ahrefs was least reliable by far.",
            "Experiment Results",
            "Key takeaways and statistics",
            "Ahrefs mismatched with Google Keyword Planner for 24 out of 80 keywords or **30%** of the t",
            "Keyword Surfer mismatched 8 different times or **10%** of the time. KWFinder mismatched 5 different times or **6.25%** of the time. Ubersuggest only mismatched once which is **1.25%** of the time. SEMrush did not have any mismatches and was within margins of the Google Keyword Planner for all ",
            "The saving grace, in this case, might lay in the fact that Google Keyword Planner also refused to return any estimates for this keyword which indicates that, for some reason, many tools are having problems with this keyword."
          ]
        },
        {
          "title": "Changelog | API",
          "url": "https://docs.ahrefs.com/docs/api/reference/changelog",
          "excerpts": [
            "Monthly volumes: In addition to average search volume, the new volume_monthly field provides the number of searches for a keyword over the latest month. Aug ...",
            "Changelog | API\n\nAPI\n\nPlease ensure Javascript is enabled for purposes of [website accessibility](https://userway.org)"
          ]
        },
        {
          "title": "The 4 best free keyword research tools in 2025 - Zapier",
          "url": "https://zapier.com/blog/best-keyword-research-tool/",
          "excerpts": [
            "The Keyword Overview tool includes monthly search volume (broken down by country), SEO and paid difficulty scores, and Content Ideas—pulled from ..."
          ]
        },
        {
          "title": "Ahrefs vs. Semrush vs. Moz: The Battle of the SEO Tools",
          "url": "https://www.oneupweb.com/blog/ahrefs-vs-semrush-vs-moz-the-battle-of-the-seo-tools/",
          "excerpts": [
            "It claims to track twice as many keywords as Semrush (and five times as many as Moz) and to do it all more accurately. They claim their traffic ..."
          ]
        },
        {
          "title": "Understanding Search Intent with Ahrefs, Semrush, and Moz",
          "url": "https://www.linkedin.com/pulse/understanding-search-intent-ahrefs-semrush-moz-deep-dive-gupta-vcwrc",
          "excerpts": [
            "Industry experts frequently suggest that a synergistic approach, combining the strengths of Ahrefs, Semrush, and Moz, yields a more robust ..."
          ]
        },
        {
          "title": "Semrush vs. Moz vs. Ahrefs: The Ultimate SEO Tool ...",
          "url": "https://searchatlas.com/blog/semrush-vs-moz-vs-ahrefs/",
          "excerpts": [
            "Feb 11, 2025 — Semrush, Moz, and Ahrefs offer powerful SEO tools with many similarities, but small differences significantly affect your daily SEO tasks and results."
          ]
        },
        {
          "title": "Could weighted average ranking position ...",
          "url": "https://www.quora.com/Could-weighted-average-ranking-position-weighted-by-search-volumes-for-a-set-of-known-target-keywords-be-a-good-SEO-KPI",
          "excerpts": [
            "Other keyword metrics can reduce the value of search volumes, such as keyword difficulty/competition, expected clicks, CPC, trend and much more."
          ]
        },
        {
          "title": "What is the best way to combine multiple SEO tools in a ...",
          "url": "https://www.quora.com/What-is-the-best-way-to-combine-multiple-SEO-tools-in-a-workflow",
          "excerpts": [
            "Start with keyword research using tools like Ahrefs or SEMrush then optimize content with SurferSEO or Clearscope. Use Google Search Console ..."
          ]
        },
        {
          "title": "Keyword Merge tool. Merge up to three lists ...",
          "url": "https://umbrellum.com/tools/keyword-merge",
          "excerpts": [
            "This tool merges lists of words into a new list, creating all possible combinations. If needed, it can also look up their search volumes."
          ]
        },
        {
          "title": "SEO Tool That Tracks Keyword Volume Over Time",
          "url": "https://www.reddit.com/r/SEO/comments/16w52u2/seo_tool_that_tracks_keyword_volume_over_time/",
          "excerpts": [
            "So, I know that most search tools track over time. But I'm actually looking for one that may track volume and rankings for a client."
          ]
        },
        {
          "title": "Keyword Volume: Google vs. Semrush vs. Ahrefs",
          "url": "https://www.practicalecommerce.com/keyword-volume-google-vs-semrush-vs-ahrefs",
          "excerpts": [
            "Keyword search volume is a rough estimate of demand for a particular query.",
            "The primary sources of search volume info are Google Ads (and its API users), Semrush, and Ahrefs. But each of those differs from the others for a given keyword.",
            "\nTake, for example, the keyword “reddit marketing.” Here’s what each provides for the number of monthly U.S. searches:",
            "Google Ads: 880,000",
            "Semrush: 590,000",
            "Ahrefs: 100,000",
            "Semrush takes sets of data from third-party providers and overlays it with historical clickstream data acquired from reliable sources.",
            "differences stem from where the data comes from and how it’s calculated."
          ]
        },
        {
          "title": "What is Search Volume? How to Use it Right?",
          "url": "https://ahrefs.com/seo/glossary/search-volume",
          "excerpts": [
            "Search volume refers to the number of times, on average, that users enter a particular search query into a search engine each month.",
            "In Google’s Keyword Planner and many SEO tools, Search Volume is the annual average value.",
            "From the keyword research perspective, you should understand that search volume for a given keyword does not equate to the potential traffic you can expect, because of three key reasons:"
          ]
        },
        {
          "title": "Top 5 keyword research tools for successful analysis",
          "url": "https://www.competitiveintelligencealliance.io/top-5-keyword-research-tools/",
          "excerpts": [
            "One of the standout features of Ahrefs is its data accuracy. Unlike some other tools, Ahrefs provides highly reliable search volume estimates, ..."
          ]
        },
        {
          "title": "There's No Such Thing as \"Accurate\" Search Volume - Ahrefs Blog",
          "url": "https://ahrefs.com/blog/accurate-search-volume/",
          "excerpts": [
            "Mar 18, 2024 — The volumes in Google Keyword Planner aren't accurate. The “Impressions” in GSC aren't accurate either. And the metric itself is just an average ... SEO](https://ahrefs.com/blog/local-se",
            "They’re designed to be “directionally accurate.” They give you an overall idea of the search demand of a given keyword and if it’s a lot higher (or lower) compared to some other keywords which you are considering."
          ]
        },
        {
          "title": "Volume definitions and accuracy notes across Ahrefs, Semrush, and Moz (excerpts)",
          "url": "https://mycodelesswebsite.com/keyword-research-statistics/",
          "excerpts": [
            "Google Keyword Planner is only 45.22% accurate as of November 2021",
            "There’s a 142.857% increase in the number of searches Google processes in a day for the last decade.",
            "A study published by Ahrefs on October 2020 highlighted that Google rewrites meta descriptions by 59.65% if they contain fat-head keywords and by 65.62% for long-tail keywords.",
            "Ahrefs released in November 2022 an interesting study involving Google Search Console “hiding” some keywords from clicks leading to a website. Their study entitled, “Almost Half of GSC Clicks Go to Hidden Terms,” involved 146,7641 websites involving a total of 9 billion clicks"
          ]
        },
        {
          "title": "Search Intent Types Explained: Commercial, Informational, ...",
          "url": "https://www.clearvoice.com/resources/commercial-informational-navigational-and-transactional-keywords/",
          "excerpts": [
            "Apr 22, 2025 — Search intent boils down to four categories: informational, navigational, commercial, and transactional. Here's a deeper look at each search intent type.",
            "Apr 22, 2025 — Informational: For users who want to learn; Navigational: For users who want to open a specific page; Commercial: For users who are interested ..."
          ]
        },
        {
          "title": "What is search intent and why is it important for SEO?",
          "url": "https://yoast.com/search-intent/",
          "excerpts": [
            "Four main types of search intent · 1. Navigational intent · 2. Informational intent · 3. Commercial investigation · 4. Transactional intent.",
            "Nov 19, 2024 — Search intent (or user intent, audience intent) is the term used to describe the purpose of an online search. It's the reason why someone conducts a specific ...",
            "People are searching with transactional intent when they intend to buy something at that moment. That means that they already know exactly what ..."
          ]
        },
        {
          "title": "What is Search Intent in SEO? The Ultimate Guide",
          "url": "https://searchengineland.com/guide/search-intent-seo",
          "excerpts": [
            "Dec 11, 2024 — Learn why search intent matters in SEO, the different types of search intent and how to create content that targets keywords effectively.",
            "Search intent, also known as “user intent,” is the “why” behind every search query. It's the customer's purpose for typing those specific words into a search ..."
          ]
        },
        {
          "title": "Types of Search Intent in SEO: a Quick Guide - Rush Analytics",
          "url": "https://rush-analytics.com/learn-seo/search-intent-seo-guide",
          "excerpts": [
            "There are 4 types of search intent: informational, commercial, navigational, transactional. Each type represents a different user goal or need."
          ]
        },
        {
          "title": "Search Intent in SEO: How to Get it Right?",
          "url": "https://seranking.com/blog/search-intent/",
          "excerpts": [
            "There are five common search intents: informational (seeking knowledge), navigational (targeting specific websites), transactional (aiming to purchase), ..."
          ]
        },
        {
          "title": "Search Intent Types and Their Impact on Google's AI ...",
          "url": "https://blog.opinly.ai/search-intent-types-and-their-impact-on-googles-ai-overviews/",
          "excerpts": [
            "May 8, 2025 — In AI Overviews for commercial investigations, the content is tailored to help the user compare or evaluate options. The AI summary often ...",
            "Transactional intent indicates the user wants to complete an action or purchase something . These queries often include words like “buy,” “order,” “download,” or specific product names/models with purchase intent (e.g. “buy iPhone 14 online”, “Netflix subscription price”, or “download Photoshop CS6”)."
          ]
        },
        {
          "title": "What is meant by search intent?",
          "url": "https://www.algolia.com/blog/ux/what-is-meant-by-search-intent-and-what-are-the-different-types",
          "excerpts": [
            "Types of search intent: the differences between informational, navigational, transactional, and commercial user search intent."
          ]
        },
        {
          "title": "The 8 Most Common Search Query Types (41% of Sites ...",
          "url": "https://baymard.com/blog/ecommerce-search-query-types",
          "excerpts": [
            "Sep 12, 2024 — In this article, we'll cover our large-scale UX Premium research findings for each of the 8 search query types most commonly used with e-commerce searches."
          ]
        },
        {
          "title": "Types of Searches: What you should know",
          "url": "https://www.textbroker.com/types-searches-transactional-navigational-informational",
          "excerpts": [
            "navigational search queries: these requests establish that the user wants to visit a specific site or find a certain vendor– for example, “YouTube” or “Apple”."
          ]
        },
        {
          "title": "Navigational Search",
          "url": "https://www.adogy.com/terms/navigational-search/",
          "excerpts": [
            "Sep 26, 2024 — Navigational search refers to a type of online search query where users specifically look for a particular website, page, or destination. It ..."
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "You can often identify commercial intent by terms used, like ",
            "compare,",
            ", like “co",
            "Informational queries are when a user wants to learn more about a topic. The user typically understands they have a problem or query and wants to understand more about it. You can often identify informational intent queries by the language used in the keyword and title tags. For example, terms like",
            "how to,",
            "* There are five types of user intent: informational, navigational, commercial, transactional, and local queries",
            " Track changes in SERPs every 3-6 months and look for new—or lost–SERP features. Search intent can also change, so adapt as necessary",
            "\nA transactional example includes phrases like “pricing” or “buy now.",
            "The SERPs are constantly changing and evolving. Therefore, staying up to date with the latest SERP and Google changes is essential to best meet the right search intent."
          ]
        },
        {
          "title": "Overview of Google's Search Quality Rater Guidelines - Portent",
          "url": "https://www.portent.com/blog/seo/googles-search-quality-evaluator-guidelines-for-seo.htm",
          "excerpts": [
            "Google also gives the raters a broad classification of intents to consider: Know – When the user is researching something or trying to get a ..."
          ]
        },
        {
          "title": "Intent Classification — Generative AI based Application Architecture 3",
          "url": "https://medium.com/aimonks/intent-classification-generative-ai-based-application-architecture-3-79d2927537b4",
          "excerpts": [
            "'Intent classification' emerged as a crucial computational task, wherein each user input was processed, tokenized, and subsequently classified into a ...",
            "DIET (Dual Intent and Entity Transformer)",
            "(Ref: <https://arxiv.org/pdf/2004.09936.pdf> )",
            "At its core, DIET is designed to handle both intent classification and entity recognition, two pivotal tasks in Natural Language Understanding (NLU) that often interplay in conversational AI scenarios."
          ]
        },
        {
          "title": "Introducing intent-kit: Universal, Deterministic Intent Workflows for ...",
          "url": "https://medium.com/@stephenc211/introducing-intent-kit-universal-deterministic-intent-workflows-for-python-ea966652da6c",
          "excerpts": [
            "intent-kit is a universal Python framework for building intent-driven classification and execution systems-chatbots, automation tools, or custom ..."
          ]
        },
        {
          "title": "A Guide to Google's 2024 SERP features",
          "url": "https://www.tdmp.co.uk/insights/guide-googles-2024-serp-features-overview-how-appear-them",
          "excerpts": [
            "Sep 29, 2024 — Boost visibility with our complete guide to Google's SERP features in 2024. Learn what they are and how to appear for them."
          ]
        },
        {
          "title": "SERP Features Beyond Google – What Are The Trends?",
          "url": "https://www.advancedwebranking.com/blog/serp-features-beyond-google",
          "excerpts": [
            "In 2024, Google's Search Engine Results Page (SERP) landscape has evolved to offer a more dynamic and more user-centric experience than ever, ...",
            "May 30, 2024 — This article dives into the SERPs of Google's main western competitors: Bing, DuckDuckGo, and Brave Search - to uncover the current search innovations and ..."
          ]
        },
        {
          "title": "MultilingualToxicComment(mBERT,XLM-R,transformers) - Kaggle",
          "url": "https://www.kaggle.com/code/falsedmitry/multilingualtoxiccomment-mbert-xlm-r-transformers",
          "excerpts": [
            "I use mBERT and XLM-RoBERTa as pre-trained models and they both are Transformer based language models."
          ]
        },
        {
          "title": "XLM-RoBERTa - Hugging Face",
          "url": "https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta",
          "excerpts": [
            "XLM-RoBERTa is a large multilingual masked language model trained on 2.5TB of filtered CommonCrawl data across 100 languages."
          ]
        },
        {
          "title": "There's A Better Way To Classify Search Intent",
          "url": "https://www.contentharmony.com/blog/classifying-search-intent/",
          "excerpts": [
            "Measuring search intent using Informational + Navigational + Transactional is broken - it was built for search engines, not search engine marketers.",
            "1) Research Intent · 2) Answer Intent · 3) Transactional Intent · 4) Local Intent · 5) Visual Intent · 6) Video Intent · 7) Fresh/News Intent · 8) ..."
          ]
        },
        {
          "title": "What is Keyword Intent?: Navigational, Informational, Transactional ...",
          "url": "https://www.localdigital.com.au/blog/what-is-keyword-intent-navigational-informational-transactional-intent-explained",
          "excerpts": [
            "In this article, we will discuss the main types of search intent: navigational, informational, and transactional."
          ]
        },
        {
          "title": "Navigational Vs. Transactional Vs. Informational Search Intent",
          "url": "https://www.gtechme.com/insights/navigational-vs-transactional-vs-informational-search-intent-understanding-the-differences/",
          "excerpts": [
            "Search intent types are primarily categorized into four categories: informational, navigational, commercial, and transactional."
          ]
        },
        {
          "title": "Understanding User's Intent, UX And SERP Features",
          "url": "https://nightwatch.io/blog/user-intent-ux-serp-features/",
          "excerpts": [
            "Mastering SERP Features for SEO Success. According to a recent study by FirstPageSage, ranking on top of SERP in your niche generates 39.8% CTR, whilst the ...",
            "Their aim is to answer the user's question immediately. Often called “position zero,” featured snippets are those direct answers to users' queries we all love.",
            "Understanding the different types of searches users engage with, is key to matching them with the right type of answer, that fit the appropriate category of SEO Features.",
            " Let’s say someone wants an informational answer by typing keywords “mobile friendly SEO”. A well structured blog would hit the spot. But if they search “mobile friendly SEO experts” they might have a transactional intent.",
            "e researching what kind of keywords and long-tail keywords signal specific user intent (informational, navigational, transactional) is key."
          ]
        },
        {
          "title": "On cross-lingual retrieval with multilingual text encoders - PMC",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC9090691/",
          "excerpts": [
            "Massively multilingual pretrained neural language models such as mBERT and XLM(-R) can be used as a dynamic embedding layer to produce contextualized word ..."
          ]
        },
        {
          "title": "How to Calibrate Probabilities for Imbalanced Classification",
          "url": "https://www.machinelearningmastery.com/probability-calibration-for-imbalanced-classification/",
          "excerpts": [
            "Aug 21, 2020 — It involves learning a logistic regression model to perform the transform of scores to calibrated probabilities. Isotonic regression is a more ...",
            "Aug 21, 2020 — Platt Scaling is most effective when the distortion in the predicted probabilities is sigmoid-shaped. Isotonic Regression is a more powerful ..."
          ]
        },
        {
          "title": "Identifying Web Queries with Question Intent - ACM Digital Library",
          "url": "https://dl.acm.org/doi/10.1145/2872427.2883058",
          "excerpts": [
            "We investigate a novel variant of this task, where the goal is to detect queries with a question intent. Specifically, we address queries for which the user ..."
          ]
        },
        {
          "title": "A taxonomy of web search",
          "url": "https://dl.acm.org/doi/pdf/10.1145/792550.792552",
          "excerpts": [
            "A taxonomy of web search",
            "Classic IR (information retrieval) is inherently predicated on users searching for information, the so-called \"information need\". But the need behind a web search is often not informational -- it might be navigational (give me the url of the site I want to reach) or transactional (show me sites where I can perform a certain transaction, e.g. shop, download a file, or find a map). We explore this taxonomy of web searches and discuss how global search engines evolved to deal with web-specific need"
          ]
        },
        {
          "title": "A guide to Regex in Google Search Console",
          "url": "https://www.kaweb.co.uk/blog/a-guide-to-regex-in-google-search-console",
          "excerpts": [
            "Regex in Google Search Console opens up a more flexible way to filter and interpret search data by finding specific patterns in user queries and page URLs.",
            "Custom regex filters also let SEOs uncover specific trends within GSC itself, without needing to export data or use other tools."
          ]
        },
        {
          "title": "Regex in Google Search Console",
          "url": "https://www.jcchouinard.com/regex-in-google-search-console/",
          "excerpts": [
            "Understand User Intent\n----------------------\n\n---\n\nShow queries that defines different user intent.\n### Informational\n\n```\nwho|what|when|how|why\n\n```\n\nand more coming from [Steve Toth](https://seonotebook.com/notes/gsc-regex-longtail-keywords-questions/):\n\n```\nwho|what|where|when|why|how|was|did|do|is|are|aren’t|won’t|does|if|can|could|should|would|won’t|were|weren’t|shouldn’t|couldn’t|cannot|can’t|didn’t|did not|does|doesn’t|wouldn’t\n\n```\n\n### Navigational\n\nSee ([Match Branded Terms]()). ```\n. *brand. *\n\n```\n\n### Commercial\n\n```\n. *(best|top|vs|review*). *\n\n```\n\n### Transactional\n\n```\n. *(buy|cheap|price|purchase|order). *\n\n```\n\n---\n\nCase Insensitive Queries\n------------------------\n\n---\n\nWant to make queries case insensitive? Add (?i) at the start of the expression. Thanks Charly Wargnier for the tip ([buy the man a coffee](https://www.buymeacoffee.com/cwar05)). ```\n(?i)^(who|what|where|when|why|how)[\" \"]\n"
          ]
        },
        {
          "title": "Understanding user goals in web search | Proceedings of ...",
          "url": "https://dl.acm.org/doi/10.1145/988672.988675",
          "excerpts": [
            "In this paper, we describe a framework for understanding the underlying goals of user searches, and our experience in using the framework to manually classify ..."
          ]
        },
        {
          "title": "Determining the user intent of web search engine queries",
          "url": "https://www.researchgate.net/publication/221023370_Determining_the_user_intent_of_web_search_engine_queries",
          "excerpts": [
            "In this paper, we examine a method to determine the user intent underlying Web search engine queries. We qualitatively analyze samples of queries from seven ...See more"
          ]
        },
        {
          "title": "Determining the User Intent of Web Search Engine Queries",
          "url": "https://faculty.ist.psu.edu/jjansen/academic/pres/www2007/jansen_user_intent.pdf",
          "excerpts": [
            "by BJ Jansen · Cited by 326 — ABSTRACT. Determining the user intent of Web searches is a difficult problem due to the sparse data available concerning the searcher. In this.See more"
          ]
        },
        {
          "title": "Intent Classification on Low-Resource Languages with ...",
          "url": "http://arxiv.org/pdf/2505.18241",
          "excerpts": [
            "4.2\t  Multilingual Query Intent Classificatio",
            "In the multilingual setting, we use the previously mentioned multilingual-aware sentence embedding models XLM-RoBERTa-Large and LabSE. As ...",
            " 4 RESULTS AND EVALUATION",
            "3.3.2 Datasets.",
            "4.1 English-only Query Intent Classification"
          ]
        },
        {
          "title": "The Top SERP Features in 2024 — Whiteboard Friday",
          "url": "https://moz.com/blog/2024-serp-features-whiteboard-friday",
          "excerpts": [
            "May 24, 2024 — In this Whiteboard Friday, Tom takes us through the top SERP features of 2024 by both presence and Share of Voice."
          ]
        },
        {
          "title": "What Is A SERP Feature? Common Types And How To ...",
          "url": "https://moz.com/learn/seo/serp-features",
          "excerpts": [
            "A SERP feature is any result on a Google Search Engine Results Page (SERP) that is not a traditional organic result. SERP Features include Rich Snippets ...",
            "These features are designed to help users quickly find answers to their queries, solve problems, or achieve their goals directly from the SERP. By satisfying ..."
          ]
        },
        {
          "title": "The evolution of SERP features: Prominence",
          "url": "https://getstat.com/blog/serp-features-2024",
          "excerpts": [
            "A sneak peek at our latest SERP features research comparing occurrence and visibility by device type and market in 2024."
          ]
        },
        {
          "title": "Structured Data Markup that Google Search Supports",
          "url": "https://developers.google.com/search/docs/appearance/structured-data/search-gallery",
          "excerpts": [
            "Explore the structured data-powered features that can appear in Google Search, including examples of how they appear in search results."
          ]
        },
        {
          "title": "How do you match multiple Regex patterns for a single line of text in ...",
          "url": "https://stackoverflow.com/questions/23536133/how-do-you-match-multiple-regex-patterns-for-a-single-line-of-text-in-java",
          "excerpts": [
            "I think you can use the | operator of the regex and put the different regexes in parentheses to be considered one whole regex to be matched."
          ]
        },
        {
          "title": "Intent Classification: Techniques for NLP Models - Label Your Data",
          "url": "https://labelyourdata.com/articles/machine-learning/intent-classification",
          "excerpts": [
            "Learn how to build accurate intent classification models using rules, ML, transformers, or LLMs. Plus tools, data tips, and production ..."
          ]
        },
        {
          "title": "(PDF) Understanding User Goals in Web Search",
          "url": "https://www.researchgate.net/publication/2947641_Understanding_User_Goals_in_Web_Search",
          "excerpts": [
            "Jan 7, 2021 — In this paper, we describe a framework for understanding the underlying goals of user searches, and our experience in using the framework to manually classify ..."
          ]
        },
        {
          "title": "SEO for BING in 2024: The Ultimate Guide to ... - eMarket Experts",
          "url": "https://www.emarketexperts.com.au/seo-for-bing-in-2024/",
          "excerpts": [
            "Unleash the power of SEO for BING in 2024 with our ultimate guide. Conquer new markets, reach untapped audiences & skyrocket your traffic.",
            "Bing: Features visually appealing backgrounds, image and video carousels, and integrated rewards programs like Microsoft Rewards. Social Media Integration."
          ]
        },
        {
          "title": "How to Dominate Bing SEO in 2024 (Complete Guide) - Weglot",
          "url": "https://www.weglot.com/blog/bing-seo",
          "excerpts": [
            "Let's dive into key SEO tips for helping your website rank as high as it can for Bing users – and getting you the web traffic you seek.",
            "It seems that Bing determines relevance primarily based on whether a web page contains keywords that exactly match those the searcher has used."
          ]
        },
        {
          "title": "(PDF) Classifying and Characterizing Query Intent",
          "url": "https://www.researchgate.net/publication/225173894_Classifying_and_Characterizing_Query_Intent",
          "excerpts": [
            "Aug 7, 2025 — ... SERP features are used for the purpose of query intent detection. The results of. such an intent detection will be used in the rest of the paper ..."
          ]
        },
        {
          "title": "Probability Calibration of Classifiers in Scikit Learn",
          "url": "https://www.geeksforgeeks.org/python/probability-calibration-of-classifiers-in-scikit-learn/",
          "excerpts": [
            "Aug 6, 2025 — In this article, we will explore the concepts and techniques related to the probability calibration of classifiers in the context of machine learning."
          ]
        },
        {
          "title": "Predicate and Their Arguments as Explanation Signals For ...",
          "url": "https://arxiv.org/html/2502.01270v1",
          "excerpts": [
            "Feb 3, 2025 — We mark main predicates (primarily verbs) and their arguments (dependency relations) as explanation signals in benchmark intent classification ..."
          ]
        },
        {
          "title": "All incidents reported for Ranking",
          "url": "https://status.search.google.com/products/rGHU1u87FJnkP6W2GwMi/history",
          "excerpts": [
            "This page provides status information on the services that are part of Google Search. Check back here to view the current status of the services listed below."
          ]
        },
        {
          "title": "Bing SEO: Strategies & Tools That Really Work (2024 Guide)",
          "url": "https://translatepress.com/bing-seo-tools-guide/",
          "excerpts": [
            "Wondering how to implement Bing SEO? Inside, you will learn the exact steps to need to take to rank your website on Bing Search Engine."
          ]
        },
        {
          "title": "Intent recognition model based on sequential information ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S0925231223011773",
          "excerpts": [
            "by T Wu · 2024 · Cited by 12 — This paper proposes an intent recognition model that integrates sequential information and sentence structural features."
          ]
        },
        {
          "title": "MLArtist/intent-detection-using-XLM-Roberta",
          "url": "https://github.com/MLArtist/intent-detection-using-XLM-Roberta",
          "excerpts": [
            "This repository contains code and resources for building an Intent Detection model using the XLM-Roberta architecture. Intent detection is a common task in ..."
          ]
        },
        {
          "title": "1.16. Probability calibration",
          "url": "https://scikit-learn.org/stable/modules/calibration.html",
          "excerpts": [
            "The calibration module allows you to better calibrate the probabilities of a given model, or to add support for probability prediction."
          ]
        },
        {
          "title": "Guidelines for Search Quality Evaluator (Google) – 2025 Update",
          "url": "https://guidelines.raterhub.com/searchqualityevaluatorguidelines.pdf",
          "excerpts": [
            "12.7 Understanding User Intent",
            " The intent of a Know query is to find information or explore a topic. Users want to Know more about something. Know Simple queries are a special type of Know query. Know Simple queries seek a very specific answer, like a fact,",
            "a height] has the same user intent as [how tall is barack obama], but is\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  not in a question format. Most queries are not Know Simple queries, such as",
            "  Broad, complex, and/or in-depth informational queries that do not have a short answer",
            "  Ambiguous or unclear informational queries",
            "  Informational queries on controversial topics",
            "  Queries where different users may want different types of information, or different sources of information",
            "  Queries where users want to browse or explore a topic",
            "  Queries where users want to find inspiration or ideas related to a topic",
            "  Queries where users are seeking personal opinions and perspectives from real people",
            "12.8 Understanding Result Blocks",
            "12.8.1 Web Search Result Block Examples",
            "Part 3: Needs Met Rating Guideline",
            "13.0 Rating Using the Needs Met Scale",
            "13.1 Rating Result Blocks: Block Content and Landing Pages",
            "13.2 Fully Meets (FullyM)",
            "13.3 Highly Meets (HM)",
            "Understanding User Intent",
            "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t Many queries have more than one likely user intent. Please use your judgment when determining if a particular intent is\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t reasonable",
            "Query: [jennifer aniston]",
            "\t\t\t   Reasonable minor interpretations: Reasonable minor interpretations may help fewer users, but they still are\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  helpful to have in a set of results because different",
            "\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t \t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tThe interpretation of the query [iphone], English (US) has changed over time as new ",
            "Queries with Multiple User Intents",
            "\t\t\t   Unlikely minor interpretations: An unlikely minor interpretation is an interpretation that is in theory possible but\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t  is very unlikely - very few users",
            "12.7.5 Queries with Multiple User Intents",
            "Dominant Interpretation: The dominant interpretation of a query is what most users mean when they type the query.",
            "Common Interpretation: A common interpretation of a query is what many or some users mean when they type a query.",
            " common interpretations.\nMinor Interpretation: Sometimes you will find less common interpretations. These are interpretations that "
          ]
        },
        {
          "title": "Search Quality Rater Guidelines: An Overview",
          "url": "https://services.google.com/fh/files/misc/hsw-sqrg.pdf",
          "excerpts": [
            "Search engines exist to help people find\nhelpful, relevant, and reliable information.",
            "Search Quality Rater Guidelines: An Overview\t\t\t\t\t 3/36",
            "This process includes soliciting feedback from “Search\nQuality Raters”, who help us measure how people are likely\nto experience our results.",
            ", we briefly explain how Search works\nand how we improve Search through these search\nquality evaluations.",
            "To ensure relevance of search results, we have a variety of systems that aim to match the words and concepts in users' queries with related information in our ..."
          ]
        },
        {
          "title": "Intent Classification on Low-Resource Languages with Query Similarity Search",
          "url": "https://arxiv.org/html/2505.18241v1",
          "excerpts": [
            "Abstract. Intent classification is an important component of a functional Information Retrieval ecosystem. Many current approaches to intent classification, typically framed as a classification problem, can be problematic as intents are often hard to define and thus data can be difficult and expensive to annotate.",
            "We experiment on 3 common English intent classification datasets - CLINC-150 (mis, [2020](https://arxiv.org/html/2505.18241v1.bib2)) (excluding the Out-Of-Scope test data), HINT3 (Arora et al., [2020](https://arxiv.org/html/2505.18241v1.bib3)), and ATIS (Hemphill et al., [1990](https://arxiv.org/html/2505.18241v1.bib12)). We sub-sample from these datasets according to the parameters given in the relevant experimentation section.",
            "We test 4 different query encoders - RoBERTa-Large (Liu et al., [2019](https://arxiv.org/html/2505.18241v1.bib15)) (English-only), Sentence-T5 (Ni et al., [2021](https://arxiv.org/html/2505.18241v1.bib16)) (English-only), XLM-RoBERTa-Large (Conneau et al., [2020](https://arxiv.org/html/2505.18241v1.bib5)) (Multilingual), and LabSE (Feng et al., [2020](https://arxiv.org/html/2505.18241v1.bib10)) (Multilingual). This gives us insights into how performance varies across monolingual v.s. multilingual models in monolingual settings",
            "3.3 Multilingual Query Intent Classification",
            "3.3.1 Motivation",
            "We test the proposed approach’s performance in a generic multilingual setting, across a variety of different languages. Here, we assume access to a set of labelled queries across a mixture of languages, and predict the labels of test queries distributed across the same set of languages.",
            "4 Results and Evaluation",
            "4.1 English-only Query Intent Classification",
            "4.2 Multilingual Query Intent Classification",
            "4.3 Low-resource Language Query Intent Classification"
          ]
        },
        {
          "title": "REIC: RAG-Enhanced Intent Classification at Scale",
          "url": "https://arxiv.org/html/2506.00210v1",
          "excerpts": [
            "the final dataset contains 52,499 training samples with 35,041 1P Business queries and 17,458 3P Business queries. The test set consists of 3,647 1P Business queries and 1,717 3P Business queries respectively using random sampling.",
            "ment\n\nWe applied data anonymization described in Appendix [A](https://arxiv.org/html/2506.00210v1 \"Appendix A Data Anonymization ‣ REIC",
            "\n\nTable 1.\n "
          ]
        },
        {
          "title": "What Is Search Intent? How to Identify It & Optimize for It",
          "url": "https://www.semrush.com/blog/search-intent/",
          "excerpts": [
            "Nov 21, 2024 — Search intent is a user's main goal when they enter a query into a search engine, which could be to find information about a specific topic, ...",
            "Search intent is a user's main goal when they enter a query into a search engine, which could be to find information about a specific topic, ..."
          ]
        },
        {
          "title": "SERP Features Guide: Ultimate Handbook for Google",
          "url": "https://offshoremarketers.com/serp-features-guide/",
          "excerpts": [
            "Master search visibility with this SERP features guide—learn how to optimize for Google's rich results and improve your website's ..."
          ]
        },
        {
          "title": "Domain Adaptation in Intent Classification Systems",
          "url": "https://arxiv.org/html/2404.14415v1",
          "excerpts": [
            "In this survey, we explore the datasets, domains, and methods, which have been developed to train the intent classification part of dialogue systems. Moreover, ..."
          ]
        },
        {
          "title": "Large Language Models: A Survey",
          "url": "https://arxiv.org/html/2402.06196v2",
          "excerpts": [
            "Feb 20, 2024 — In this paper, we review some of the most prominent LLMs, including three popular LLM families (GPT, LLaMA, PaLM), and discuss their characteristics, ..."
          ]
        },
        {
          "title": "1 Introduction",
          "url": "https://arxiv.org/html/2501.16756v1",
          "excerpts": [
            "Jan 28, 2025 — These methods include Platt Scaling, Beta Calibration, Isotonic Regression (ISO), Venn-Abers (VA), Parameterized Probability Adjustment (PPA), ..."
          ]
        },
        {
          "title": "[PDF] Google Guidelines Quality Rater 2020 smart-visibilite.fr Chris LYAN",
          "url": "https://smart-visibilite.fr/wp-content/uploads/2021/05/searchqualityevaluatorguidelines.pdf",
          "excerpts": [
            "16.1 Rating Queries with Both Website and Visit-in-Person Intent. 141. 17.0 ... webpage, website, or result appears in Google Search, nor will they cause ..."
          ]
        },
        {
          "title": "MULTI3NLU++: A Multilingual, Multi-Intent, Multi-Domain ...",
          "url": "https://aclanthology.org/2023.findings-acl.230.pdf",
          "excerpts": [
            "by N Moghe · 2023 · Cited by 22 — MultiATIS++ contains some utterances with more than one intent label but the vast majority are single-label. spective, or as a medium-resource ..."
          ]
        },
        {
          "title": "The adjudication process in collaborative annotation - Medium",
          "url": "https://medium.com/@jorgecp/the-adjudication-process-in-collaborative-annotation-61623c46b700",
          "excerpts": [
            "Inter-Annotator Agreement. Estimating annotation quality is often difficult. It requires a standard to validate your data. However, this ..."
          ]
        },
        {
          "title": "How to Write Data Labeling/Annotation Guidelines - Eugene Yan",
          "url": "https://eugeneyan.com/writing/labeling-guidelines/",
          "excerpts": [
            "A good guideline should explain why the task is important. This will motivate annotators to put in the effort it deserves."
          ]
        },
        {
          "title": "Calibrating machine learning approaches for probability ...",
          "url": "https://onlinelibrary.wiley.com/doi/full/10.1002/sim.9921",
          "excerpts": [
            "by FM Ojeda · 2023 · Cited by 30 — The best-known calibration method in machine learning is Platt scaling. From these standard approaches we selected logistic calibration, slope ..."
          ]
        },
        {
          "title": "ACM DL 2025: Intent Taxonomy in Web Search",
          "url": "https://dl.acm.org/doi/10.1145/3626093",
          "excerpts": [
            "In Web search, Broder [6] proposed a widely adopted taxonomy using a user survey and analysis of query logs in AltaVista. According to the ",
            "need behind query,",
            "The taxonomy has five intent categories, i.e., search for *Particular Case(s)*, *Characterization*, *Penalty*, *Procedure*, and *Interest*. To our best knowledge, it is the first taxonomy that categorizes users’ search intents in legal case retrieval.",
            "The taxonomy was constructed and evaluated extensively using multiple resources, such as interviews, editorial user studies, log analysis, and so on. We provide the formal procedure of taxonomy creation. Moreover, we reveal the distributions of different search intents in the realistic search scenario of legal case retrieval.",
            "Generally speaking, the query logs, where user intents could only be inferred implicitly, involve more types of co-occurrence of potential intents compared to the user survey. The results here suggest retrieval methods that explicitly recognize multi-intent queries are needed."
          ]
        },
        {
          "title": "ScienceDirect – Machine learning approaches for intent classification and named entity extraction in NLU",
          "url": "https://www.sciencedirect.com/science/article/pii/S246822762500119X",
          "excerpts": [
            "Intent classification is typically treated as a [classification task](/topics/engineering/classification-task \"Learn more about classification task from ScienceDirect's AI-generated Topic Pages\"), where the model identifies the intent from a predefined list based on a given user message.",
            "Both tasks involve training models on large datasets to learn patterns and make predictions. This approach improves the system's ability to generalize from examples rather than relying on manually crafted rules."
          ]
        },
        {
          "title": "More Query Understanding: Brand Detection with LLMs",
          "url": "https://opensourceconnections.com/blog/2024/06/26/more-query-understanding-brand-detection-with-llms/",
          "excerpts": [
            "Jun 26, 2024 — This blog shows you how you can leverage the power of large language models (LLMs) to detect brand names in queries."
          ]
        },
        {
          "title": "Query Brand Entity Linking in E-Commerce Search",
          "url": "https://arxiv.org/html/2502.01555v1",
          "excerpts": [
            "Feb 3, 2025 — For an input query, MetaTS-NER detects the brand name in its string form. The output of MetaTS-NER is then fed to the matcher."
          ]
        },
        {
          "title": "Branded vs. Non-Branded Keywords - WebFX",
          "url": "https://www.webfx.com/digital-marketing/learn/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Non-branded keywords are keywords that relate to your products or services, but don't include your company's name . Using our own site as an example again, “Digital marketing agency” and “SEO services” are both relevant non-branded keywords."
          ]
        },
        {
          "title": "Keyword Basics: Branded vs. Non-branded and (Not ...",
          "url": "https://www.risdall.com/thoughts/keyword-basics-branded-vs-non-branded-provided/",
          "excerpts": [
            "A “branded keyword” search query includes your brand name or some variation of it. For example, branded keywords for Risdall include search queries like:"
          ]
        },
        {
          "title": "Google Ads Branded Searches Conversion Metric",
          "url": "https://www.seoteric.com/understanding-the-google-ads-branded-searches-conversion-metric/",
          "excerpts": [
            "Branded searches involve queries explicitly including a company27s name or closely associated phrases, indicating higher intent and familiarity with the brand."
          ]
        },
        {
          "title": "Branded Search Terms - Definition & Practical Tips",
          "url": "https://agencyanalytics.com/kpi-definitions/branded-search",
          "excerpts": [
            "Branded Search refers to the number of searches that include a company's brand name or a variation of it. It measures brand awareness and interest."
          ]
        },
        {
          "title": "Branded vs. non-branded search data: Which one drives ...",
          "url": "https://blog.reachbyrentcafe.com/branded-vs-non-branded-search/",
          "excerpts": [
            "Oct 12, 2022 — A branded search is a search done using the apartment community or property management company name. If your business name is part of what ..."
          ]
        },
        {
          "title": "Brand Monitoring: Definition, Methods, & Tools",
          "url": "https://www.qualtrics.com/experience-management/brand/brand-monitoring/",
          "excerpts": [
            "Brand monitoring is the act of collecting and measuring mentions of your company or brand across as many channels and touchpoints as possible."
          ]
        },
        {
          "title": "Named Entity Recognition: A Comprehensive Guide to ...",
          "url": "https://medium.com/@kanerika/named-entity-recognition-a-comprehensive-guide-to-nlps-key-technology-636a124eaa46",
          "excerpts": [
            "NER helps in extracting entities from social media posts, enabling businesses to monitor mentions of their brand, competitors, or products."
          ]
        },
        {
          "title": "A Business Guide to Fuzzy Matching",
          "url": "https://firstlogic.com/insights/a-business-guide-to-fuzzy-matching",
          "excerpts": [
            "Fuzzy matching algorithms aim to find the best possible matches between records, but this can be a time-consuming process."
          ]
        },
        {
          "title": "Get a list of datasources - Alation APIs",
          "url": "https://developer.alation.com/dev/reference/getdatasources-1",
          "excerpts": [
            "Missing: brand lexicon"
          ]
        },
        {
          "title": "API Products - API Portal - European Union",
          "url": "https://dev.euipo.europa.eu/product",
          "excerpts": [
            "EUIPO offers APIs for design filing, design search, trademark application, trademark classification, and document repository.",
            "Start building your integration in minutes. Explore our available APIs and access the specific documentation. If you are new to EUIPO APIs or you are using ..."
          ]
        },
        {
          "title": "Trademark search - API Portal",
          "url": "https://dev.euipo.europa.eu/product/trademark-search_100",
          "excerpts": [
            "Perform searches within EUIPO's database and retrieve all available information on a given trade mark. REST. Online. Plans."
          ]
        },
        {
          "title": "Local API Documentation | Lexicon - DJ Library Management",
          "url": "https://www.lexicondj.com/docs/developers/api",
          "excerpts": [
            "Missing: brand bulk download"
          ]
        },
        {
          "title": "Branded vs Non-Branded Keywords: Which Should You Target?",
          "url": "https://victorious.com/blog/branded-keywords-vs-non-branded/",
          "excerpts": [
            "## What Are Branded Keywords? **Branded queries include your brand name or variations of it. ** However, you can also extend this definition to include unique products associated with your brand.",
            "## What Are Non-Branded Keywords? **Non-branded keywords are terms that don’t specifically mention your business. ** Broader and more generic, these queries encompass the bulk of search engine traffic, so they’re ideal for connecting with new customers and expanding your brand’s reach."
          ]
        },
        {
          "title": "Brand Mentions and How to Track and Analyze Them",
          "url": "https://influencity.com/blog/en/brand-mentions-what-they-are-and-how-to-track-and-analyze-them",
          "excerpts": [
            "? Brand mentions refer to any instance **where a brand is talked about or referred to on digital platforms** . These mentions can occur on **social media, blogs, news sites, forums, and more** . They range from **direct tags** of a brand’s social media profile to **indirect references or discussions** involving the brand.",
            ". This article delves into the concept of **online brand mentions** , providing **insights and strategies to help you monitor, track, and analyze conversations about your brand** . That way, you can **continuously measure brand sentiment** and track the effectiveness of your online marketing campaigns.",
            "They range from **direct tags** of a brand’s social media profile to **indirect references or discussions** involving the",
            "Essentially, understanding and analyzing brand mentions allows companies to **tap into direct consumer feedback without the filter of traditional survey methods** . This real-time monitoring can lead to swift action to **enhance customer experience and** [**brand r",
            "Additionally, tracking these mentions helps you **assess the impact of your marketing campaigns and strategies",
            "Choose the Right Tools for Social Listening",
            "To begin with, selecting the appropriate **social listening tools** is fundamental. These tools can **automate the process of scanning digital platforms for mentions** , making the task manageable and e",
            "Features to look for include **sentiment analysis** , **trend detection** , and the ability to **filter by source, location, o",
            "Influencity's platform also offers comprehensive features that help brands track online conversations, brand mentions and the content of their influencer campaigns, understand audience sentiment, and adjust strategies based on real-time data",
            "Set Up Effective Alerts and Filters",
            "Once the right tools are in place, setting up **alerts and filters** is crucial. Alerts can notify you of **spikes in brand mentions** which might indicate a **marketing success** , an **emerging trend** , or a potential **PR crisis that needs ",
            "Filters, on the other hand, help you **focus on the most relevant data** by segmenting mentions based on predefined criteria like **keywords, sentiment, geography, or demogra",
            "This granularity allows marketers to tailor their **strategies and responses** more effectively, ensuring that they **address the right audiences with appropriate mess"
          ]
        },
        {
          "title": "Study: Non-branded keywords have 19x worse return than ...",
          "url": "https://dreamdata.io/blog/branded-vs-non-branded-google-search-ads-b2b",
          "excerpts": [
            "May 23, 2025 — Branded and non-branded keywords​​ Let's start with the essentials, definitions: Branded terms include the name of your brand on the keyword, e.g ..."
          ]
        },
        {
          "title": "8 Most Important Types of Keywords for SEO (And How to Find Them)",
          "url": "https://ahrefs.com/blog/types-of-keywords/",
          "excerpts": [
            "Simply use the intents filter in Ahrefs' Keywords Explorer. It works for branded and unbranded keywords.",
            "Jul 11, 2025 — At Ahrefs, we simply call it Keyword Difficulty (KD). ... This method will filter out keywords that are dominated by pages with a lot of backlinks ..."
          ]
        },
        {
          "title": "Branded Vs. Non-Branded Keywords: SEO Strategies & Tips",
          "url": "https://sagapixel.com/seo/branded-vs-non-branded-keywords/",
          "excerpts": [
            "Examples of Non-Branded Queries. Examples of non-branded queries include: “best running shoes”; “coffee shops near me”; “SEO tools for beginners”. SEO ...",
            "Branded keywords include terms explicitly related to your brand name while non-branded search terms are everything else not connected directly to your brand."
          ]
        },
        {
          "title": "spaCy 101: Everything you need to know",
          "url": "https://spacy.io/usage/spacy-101",
          "excerpts": [
            "spaCy is a free, open-source library for advanced Natural Language Processing (NLP) in Python. If you're working with a lot of text, you'll eventually want to ..."
          ]
        },
        {
          "title": "EntityRecognizer · spaCy API Documentation",
          "url": "https://spacy.io/api/entityrecognizer",
          "excerpts": [
            "A transition-based named entity recognition component. The entity recognizer identifies non-overlapping labelled spans of tokens."
          ]
        },
        {
          "title": "Automatic Detection of Brand Logos Final Report",
          "url": "https://showcase.itcarlow.ie/C00266169/documents/Final%20Report.pdf",
          "excerpts": [
            "by IT Carlow-BSc · 2021 — Automatic Detection of Brand Logos is a tool identifying brand logos in still and moving images, and calculate how long the logo is visible."
          ]
        },
        {
          "title": "Branded and Non-Branded Keywords in SEO Rankings",
          "url": "https://www.ibeamconsulting.com/blog/seo-keywords-branded-and-non-branded/",
          "excerpts": [
            "Branded and non-branded keywords are both important targets for SEO work. Learn the basics and further insights below."
          ]
        },
        {
          "title": "Branded vs Non branded traffic on your website : r/SEO",
          "url": "https://www.reddit.com/r/SEO/comments/wqpihx/branded_vs_non_branded_traffic_on_your_website/",
          "excerpts": [
            "For a company asking to get information on brand terms vs. keywords, it's not so professional to use semrush as a reference to see how they are ..."
          ]
        },
        {
          "title": "API Portal homepage | API Portal",
          "url": "https://dev.euipo.europa.eu/",
          "excerpts": [
            "The EUIPO Application Programming Interfaces (APIs) have been developed to let our customers integrate their systems to manage their intellectual property ..."
          ]
        },
        {
          "title": "Search for a trade mark",
          "url": "https://www.gov.uk/search-for-trademark",
          "excerpts": [
            "Find details of trade marks to: Search by trade mark number. Search by owner. Search by keyword, phrase or image. Search by flag, emblem or hallmark."
          ]
        },
        {
          "title": "Getting started | API Portal - European Union",
          "url": "https://dev.euipo.europa.eu/getting-started",
          "excerpts": [
            "To access our APIs you need an EUIPO account. You can register your user account at the following URL of the EUIPO website."
          ]
        },
        {
          "title": "Global Brand Database: Terms of Use (November 2022)",
          "url": "https://www.wipo.int/en/web/global-brand-database/terms_and_conditions",
          "excerpts": [
            "Global Brand Database: Terms of Use (November 2022) · 1. Definitions · 2. Use of Data · 3. Level of Service and Other Relevant Service · 4. Disclaimers · 5.",
            "perform automated queries;; perform bulk acquisition, bulk downloading, and bulk storing of data;; perform bulk copying, bulk reformatting, bulk sharing and ..."
          ]
        },
        {
          "title": "Visual Listening: Tracking Every Un‑Tagged Logo Mention",
          "url": "https://medium.com/@API4AI/visual-listening-tracking-every-un-tagged-logo-mention-bf7ca3724f16",
          "excerpts": [
            "Pre-processing Layer. Images are resized, normalized and prepared for analysis. Duplicate content is filtered out to avoid redundant ..."
          ]
        },
        {
          "title": "How can I create a threshold for similar strings using ...",
          "url": "https://stackoverflow.com/questions/3340551/how-can-i-create-a-threshold-for-similar-strings-using-levenshtein-distance-and",
          "excerpts": [
            "First off, Levenshtein distance is defined as the minimum number of edits required to transform string A to string B, where an edit is the ..."
          ]
        },
        {
          "title": "USPTO Open Data Portal",
          "url": "https://developer.uspto.gov/",
          "excerpts": [
            "The United States Patent and Trademark Office (USPTO) Office Action Research Dataset for Patents contains detailed information derived from the Office actions ..."
          ]
        },
        {
          "title": "Bulk Data Directory - Open Data Portal - USPTO",
          "url": "https://data.uspto.gov/bulkdata",
          "excerpts": [
            "The Open Data Portal (ODP) is USPTO's data platform that empowers you to discover and easily extract USPTO data in one place for free."
          ]
        },
        {
          "title": "Open Data Portal - USPTO",
          "url": "https://data.uspto.gov/",
          "excerpts": [
            "The Open Data Portal (ODP) is USPTO's data platform that empowers you to discover and easily extract USPTO data in one place for free."
          ]
        },
        {
          "title": "Bulk Data Products",
          "url": "https://data.uspto.gov/home",
          "excerpts": [
            "The Open Data Portal (ODP) is USPTO's data platform that empowers you to discover and easily extract USPTO data in one place for free."
          ]
        },
        {
          "title": "Trademarks - Advertising Policies Help",
          "url": "https://support.google.com/adspolicy/answer/6118?hl=en",
          "excerpts": [
            "Google Ads abides by local trademark laws and protects the rights of trademark owners , so we don't allow ads that infringe trademark rights. Advertisers may use trademarks that belong to others in certain situations as described below, like when identifying a product for sale."
          ]
        },
        {
          "title": "Google Ads policies - Advertising Policies Help",
          "url": "https://support.google.com/adspolicy/answer/6008942?hl=en",
          "excerpts": [
            "The purpose of this help center is to help you build Google Ads campaigns that align with our advertising policies listed below."
          ]
        },
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty (KD) is a metric used in SEO to estimate how difficult it would be to rank on the first page of Google for a given keyword.",
            "Keyword difficulty is a metric provided by various SEO tools intended to estimate a keyword’s ranking difficulty.",
            "Keyword difficulty (KD) is an SEO metric estimating how hard it is to rank on Google's first page for a keyword.",
            "Keyword difficulty is always only an estimation because Google does not disclose all its ranking factors.",
            "What is Keyword Difficulty?!",
            " KD. We pull the top 10 ranking pages for your keyword and count how many websites link to each. The more websites link to the top-ranking pages, the greater the keyword difficulty. Then we plot the result on a logarithmic scale from 0 to 100",
            "The more websites link to the top-ranking pages, the greater the keyword difficulty."
          ]
        },
        {
          "title": "Comparing New vs. Old Keyword Difficulty Scores | SEO Forum - Moz",
          "url": "https://moz.com/community/q/topic/59365/comparing-new-vs-old-keyword-difficulty-scores",
          "excerpts": [
            "Our keyword metrics are intended to help you compare two keywords to each other. It's not so much about whether a keyword is more difficult ..."
          ]
        },
        {
          "title": "Semrush Keyword Difficulty: Now More Accurate Than Any ...",
          "url": "https://www.semrush.com/blog/most-accurate-keyword-difficulty/",
          "excerpts": [
            "Semrush's KD is the most accurate on the market because it has the most accurate correlations with backlink profile strength and keyword ...See more"
          ]
        },
        {
          "title": "There's A Better Way To Measure Keyword Difficulty",
          "url": "https://www.contentharmony.com/blog/keyword-difficulty/",
          "excerpts": [
            "Mar 2, 2025 — We've released a new three-part keyword difficulty scoring model that factors in Content Difficulty, Link Difficulty, and Domain Difficulty as distinct ..."
          ]
        },
        {
          "title": "Semrush's Privacy Policy",
          "url": "https://www.semrush.com/company/legal/privacy-policy/",
          "excerpts": [
            "This Privacy Policy explains how Semrush collects, uses, stores, discloses and otherwise processes the personal data we collect when you use and interact with ..."
          ]
        },
        {
          "title": "Semrush's Privacy Policy",
          "url": "https://es.semrush.com/company/legal/privacy-policy/",
          "excerpts": [
            "This Privacy Policy explains how Semrush collects, uses, stores, discloses and otherwise processes the personal data we collect when you use and interact with ..."
          ]
        },
        {
          "title": "How accurate is Keyword Difficulty in Ahrefs? Is it truly easy ...",
          "url": "https://www.reddit.com/r/SEO_Digital_Marketing/comments/1jvf3y1/how_accurate_is_keyword_difficulty_in_ahrefs_is/",
          "excerpts": [
            "I've come across keywords that appear to be high-quality and have a keyword difficulty of <10. Can the difficulty score be trusted?"
          ]
        },
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "Keyword difficulty calculation is based on a variety of factors such as the median number of referring domains pointing to the URLs that are ranking, the median ratio of dofollow/nofollow links pointing to these, the median authority score of the domains that are ranking, and the SERP-related qualities of the keyword itself.",
            "The keyword difficulty score is a percentage from 0 to 100, and the higher the percentage, the more difficult Semrush predicts it would be to rank for. Keyword ...",
            "* **0-14 = Very easy. ** These are the best opportunities to start ranking new web pages on Google if you want to rank as soon as possible with the least amount of effort.",
            "* **15-29 = Easy. ** These keywords have some competition but are still achievable, even if your domain is new. To be able to rank for these, you’ll need to produce quality content focused on the keyword’s intent.",
            "* **30-49 = Possible. ** For these, you’ll need quality, well-structured content that is properly optimized for your target keywords.",
            "* **50-69 = Difficult. ** To compete for these keywords, you’ll need some quality backlinks along with producing well-structured and optimized content.",
            "* **70-84 = Hard. ** Winning these keywords will require a lot of effort in terms of getting better quality backlinks to support your well-optimized and unique content.",
            "* **85-100 = Very hard.\n** To compete for these, you’ll need to put a lot of effort not only into producing high-quality content and link building but also into on-page SEO and content promotion",
            "What is KD%?",
            "Keyword difficulty (KD%) is a metric that measures the SEO effort it would take for your content to rank organically in the top 10 results on Google for a ..."
          ]
        },
        {
          "title": "Ahrefs vs. SEMRush Keyword Difficulty Score Compared",
          "url": "https://fatstacksblog.com/ahrefs-vs-semrush-keyword-difficulty-score/",
          "excerpts": [
            "The Ahrefs KD suggests the difficulty to get ranked in the top 10 spots. Not necessariy the top spot in Google search."
          ]
        },
        {
          "title": "Ahrefs vs Semrush vs Moz: Key Differences and Features",
          "url": "https://explodingtopics.com/blog/ahrefs-vs-semrush-vs-moz",
          "excerpts": [
            "Ahrefs excels in backlink analysis and keyword research. Semrush offers a comprehensive digital marketing suite, including SEO, PPC, social, and ..."
          ]
        },
        {
          "title": "What is keyword difficulty & how to use it for SEO [2024 Guide]",
          "url": "https://growthmindedmarketing.com/blog/what-is-seo-keyword-difficulty/",
          "excerpts": [
            "Ahrefs shows a keyword difficulty of 83 making it very hard. Semrush has 100% difficulty with very hard for the same keyword. Moz shows a ..."
          ]
        },
        {
          "title": "Keyword Difficulty: A Comparison of Top SEO Tools - Hop Online",
          "url": "https://www.hop.online/blog/keyword-difficulty-score-methodologies-moz-ahrefs-semrush-ubersuggest",
          "excerpts": [
            "Ahrefs uses a scale from 0 to 100 to determine keyword difficulty score. They also measure the average number of backlinks for the top 10 ranking URLs. If the average number is low, the tool tells you how easy it will be for the keyword to rank:",
            "SEMRush shows keyword difficulty index, and their metric is calculated in percentages from 0 to 100%. However, the official scale provided by SEMRush divides the scores into three groups, with the actual scale falling between 60 and 80 percent.",
            "MOZ’s keyword explorer is based on the page authority (PA) and domain authority (DA) of Google’s top 10 results. The metric also takes several other factors into account, like the number of internal pages vs. the number of home pages in SERP, as well as the use of query terms in the results."
          ]
        },
        {
          "title": "Free Keyword Difficulty Checker: Analyze by term in seconds",
          "url": "https://searchengineland.com/tools/keyword-difficulty-checker-tool",
          "excerpts": [
            "Keyword difficulty scores are usually calculated on a scale of 0 to 100, with higher scores indicating greater competition and lower scores ..."
          ]
        },
        {
          "title": "Unicode normalize - Pipeline Builder Expressions",
          "url": "https://palantir.com/docs/foundry/pb-functions-expression/unicodeNormalizeV1//",
          "excerpts": [
            "Perform unicode normalization as per Unicode Standard Annex #15. Expression categories: Data preparation, String Declared arguments Output type: String"
          ]
        },
        {
          "title": "StringNormalization",
          "url": "https://small.r7rs.org/wiki/StringNormalization/",
          "excerpts": [
            "Sep 7, 2010 — ... UAX #15, corresponding to two types of character equivalence. The first, and most important, is canonical equivalence. This is equivalence ..."
          ]
        },
        {
          "title": "When to use Unicode Normalization Forms NFC and NFD?",
          "url": "https://stackoverflow.com/questions/15985888/when-to-use-unicode-normalization-forms-nfc-and-nfd",
          "excerpts": [
            "NFC is the best form for general text, since it is more compatible with strings converted from legacy encodings. NFD and NFKD are most useful for internal ...See more"
          ]
        },
        {
          "title": "UAX #44: Unicode Character Database",
          "url": "https://www.unicode.org/reports/tr44/",
          "excerpts": [
            "Aug 27, 2024 — This annex provides the core documentation for the Unicode Character Database (UCD). It describes the layout and organization of the Unicode Character Database.",
            "SpecialCasing.txt, Uppercase_Mapping, Lowercase_Mapping ... Turkish, and Lithuanian are specified in an additional field in SpecialCasing.",
            "   * When a file contains the specification for multiple properties, the second field specifies the name of the property and the third field specifies the property value"
          ]
        },
        {
          "title": "Text Normalization in NLP: Techniques & Best Practices",
          "url": "https://www.getgalaxy.io/learn/glossary/text-normalization-for-nlp",
          "excerpts": [
            "Learn why text normalization is crucial for NLP, core techniques like lowercasing and lemmatization, best practices, pitfalls, and Python code examples."
          ]
        },
        {
          "title": "Template:Punctuation marks in Unicode - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Template:Punctuation_marks_in_Unicode",
          "excerpts": [
            "By Unicode General Category 'P'. (. v · e. ) § Pd, dash. § Ps-Pe, start–end (open–close brackets). § Pi-Pf, initial–final quote. § Pc, connector. § Po ..."
          ]
        },
        {
          "title": "Transforms | ICU Documentation",
          "url": "https://unicode-org.github.io/icu/userguide/transforms/general/",
          "excerpts": [
            "For example, to remove accents from characters, use the following transform:\n\n```\nNFD; [:Nonspacing Mark:] Remove; NFC. ```\n\nThis transform separates accents from their base characters, removes the accents, and then puts the remaining text into an unacce",
            "Transforms can be chained together to perform a series of operations and each step of the process can use a UnicodeSet to restrict the characters that are affected.",
            "If the user wants a version without certain accents, then a transform can be used to remove the accents.",
            ". The following transliterates to Latin but removes all accents:\n\n> **`Greek-Latin; nfd; [:nonspacing marks:] remove; nfc`"
          ]
        },
        {
          "title": "Command to remove diacritics",
          "url": "https://tex.stackexchange.com/questions/708094/command-to-remove-diacritics",
          "excerpts": [
            "Jan 27, 2024 — You could try normalizing to NFD and then using character properties to identify diacritics ... Combining multiple diacritics from unicode input."
          ]
        },
        {
          "title": "How fast can we identifiy almost-duplicates in a list of strings?",
          "url": "https://cs.stackexchange.com/questions/27539/how-fast-can-we-identifiy-almost-duplicates-in-a-list-of-strings",
          "excerpts": [
            "Algorithms for computing the Levenshtein edit distance between a pair of strings can be found in the Wikipedia page on the edit distance. As ..."
          ]
        },
        {
          "title": "Why is there NFC in NFD; [:Nonspacing Mark:] Remove",
          "url": "https://stackoverflow.com/questions/54829071/why-is-there-nfc-in-nfd-nonspacing-mark-remove-nfc",
          "excerpts": [
            "This transform separates accents from their base characters, removes the accents, and then puts the remaining text into an unaccented form."
          ]
        },
        {
          "title": "UAX #44: Unicode Character Database",
          "url": "https://www.unicode.org/reports/tr44/tr44-31.html",
          "excerpts": [
            "It describes the layout and organization of the Unicode Character Database and how it specifies the formal definitions of the Unicode Character Properties.",
            "The data files define the Unicode character properties and mappings between Unicode characters (such as case mappings). This annex describes the UCD and ..."
          ]
        },
        {
          "title": "Morphological, syntactic and diacritics rules for automatic ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S1319157816300428",
          "excerpts": [
            "This paper presents a model of automatic Arabic diacritization based on hybrid approach that combines the linguistic rules and statistical processing. The use ..."
          ]
        },
        {
          "title": "The Diacritics SEO Technique - A Tactic Nobody is Using",
          "url": "https://cognitiveseo.com/blog/6773/the-diacritics-seo-technique-a-tactic-nobody-is-using/",
          "excerpts": [
            "The Diacritics SEO Technique is about a tactic that can increase your rankings highly. A simple diacritic research and onpage optimization could ..."
          ]
        },
        {
          "title": "Pre-Processing Tweets for Sentiment Analysis | by Mike Erb - Medium",
          "url": "https://medium.com/analytics-vidhya/pre-processing-tweets-for-sentiment-analysis-a74deda9993e",
          "excerpts": [
            "Twitter handles Prior the text pre-processing ... Using this method will leave all the punctuation that is part of a word or an emoji."
          ]
        },
        {
          "title": "String#downcase and CAPITAL LETTER I WITH DOT ABOVE",
          "url": "https://bugs.ruby-lang.org/issues/18590",
          "excerpts": [
            "SpecialCasing.txt is an official Unicode data file. The case charts are just a Web page. But the case charts may be easier to understand for non-experts ..."
          ]
        },
        {
          "title": "Unicode character property - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Unicode_character_property",
          "excerpts": [
            "Name and alias. A Unicode character is assigned a unique Name (na). The name is composed of uppercase letters A–Z, digits 0–9, hyphen-minus and space."
          ]
        },
        {
          "title": "List of Unicode Characters of Category “Nonspacing Mark” - Compart",
          "url": "https://www.compart.com/en/unicode/category/Mn",
          "excerpts": [
            "Missing: Mc Me"
          ]
        },
        {
          "title": "Appendix:Unicode/Combining Diacritical Marks",
          "url": "https://en.wiktionary.org/wiki/Appendix:Unicode/Combining_Diacritical_Marks",
          "excerpts": [
            "Missing: Mc Me"
          ]
        },
        {
          "title": "Automatic Diacritic Recovery with focus on the Quality of the training ...",
          "url": "https://ieeexplore.ieee.org/document/9428872",
          "excerpts": [
            "The results show that the completeness and correctness of diacritics has a significant effect on the performance of the algorithms; decision tree algorithm ..."
          ]
        },
        {
          "title": "Character Properties - Unicode",
          "url": "https://www.unicode.org/versions/Unicode16.0.0/core-spec/chapter-4/",
          "excerpts": [
            "Pf, Final_Punctuation, a final quotation mark. Po, Other_Punctuation, a punctuation mark of other type. P, Punctuation, Pc | Pd | Ps | Pe | Pi | Pf | Po. Sm ...",
            "the Unicode Normalization Algorithm, which rigorously defines canonical and compatibility equivalences, and which does not specify a preference for one normalization form over another."
          ]
        },
        {
          "title": "All-Three: Near-optimal and domain-independent algorithms for ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S2590005621000187",
          "excerpts": [
            "Relations between threshold similarity metrics and accuracy are an important part of the near-duplication detection process. Different threshold setting and ..."
          ]
        },
        {
          "title": "Twitter API: How do I match punctuation at the end of a hashtag?",
          "url": "https://stackoverflow.com/questions/42769427/twitter-api-how-do-i-match-punctuation-at-the-end-of-a-hashtag",
          "excerpts": [
            "Note that punctuation is not considered to be part of a #hashtag or @mention, so a track term containing punctuation will not match either # ..."
          ]
        },
        {
          "title": "Baeldung: Remove Accents from Text (Java)",
          "url": "https://www.baeldung.com/java-remove-accents-from-text",
          "excerpts": [
            " Unicode defines a text normalization procedure that helps do this. In this tutorial, we’ll see what Unicode text normalization is, how we can use it to remove diacritical marks, and the pitfalls to watch out",
            "Unicode normalization is the decomposition of characters using equivalence forms defined by the standard .",
            "Before jumping straight into code, let’s learn some Unicode basics. To represent a character with a diacritical or accent mark, Unicode can use different sequences of code points.",
            "To compare sequences of code points, Unicode defines two terms: canonical equivalence and compatibility .",
            " . First, we will separate base characters from accent and diacritical marks using the Normalizer class . Moreover, we will perform the compatibility decomposition represented as the Java enum NFKD . Additionally, we use compatibility decomposition because it decomposes more ligatures than the canonical method (for example, ligature “ﬁ”).",
            "Second, we will remove all characters matching the Unicode Mark category using the \\p{M} regex expression .",
            "static String removeAccents (String input) { return normalize(input).replaceAll( \"\\\\p{M}\" , \"\" );\n}"
          ]
        },
        {
          "title": "In which cases normalize('NFKC') method work?",
          "url": "https://stackoverflow.com/questions/69058397/in-which-cases-normalizenfkc-method-work",
          "excerpts": [
            "NFKC makes compatible and canonically equivalent normalizations in different ways. Canonically equivalent normalization by NFKC is produced the same way as NFC."
          ]
        },
        {
          "title": "[PDF] UAX #15: Unicode Normalization Forms",
          "url": "https://www.unicode.org/L2/L2011/11292-tr15-34.pdf",
          "excerpts": [
            "\nBecause they erase many\n\t\t\t\tformatting distinctions, they will prevent round-trip conversion to and from many legacy character sets,\n\t\t\t\tand unless supplanted by formatting markup, they may remove distinctions that are important to the\n\t\t\t\tsemantics",
            "This annex describes normalization forms for Unicode text. When implementations keep strings in a\n\t\t\t\tnormalized form, they can be assured that equivalent strings have a unique binary representat",
            "The Unicode Consortium has well-defined policies in place to govern changes that affect backward\n\t\t\t\tcompatibil",
            "\n\n\n\n\n\t\t\t\t   A Unicode Standard Annex (UAX) forms an integral part of the Unicode Standard, but is published\n\t\t\t\t   online as a",
            "\n\n\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t   Unicode ",
            "NORMALIZATION FORMS",
            "UAX15-C1. A process that produces Unicode text that purports to be in a Normalization Form shall do so in\n\t\t\t\taccordance with the specifications in Section 3.11, Normalization Forms in [Unico",
            "UAX15-C2. A process that tests Unicode text to determine whether it is in a Normalization Form shall do\n\t\t\t\tso in accordance with the specifications in Section 3.11, Normalization Forms in [Unico",
            "The NormalizationText.txt file consists of a series of fields. When Normalization Forms are applied to\n\t\t\t\t\t  the different fields in the test file, the results shall be as specified in the header of tha"
          ]
        },
        {
          "title": "Introduction to Unicode equivalence and normalization",
          "url": "https://medium.com/@wanxiao1994/introduction-to-unicode-equivalence-and-normalization-7069eaa764d1",
          "excerpts": [
            "For example, U+006E (n), followed by a U+0303 ( ̃ ), is canonically equivalent to U+00F1(ñ) in Unicode. These two sequences are exactly the same ..."
          ]
        },
        {
          "title": "lower() vs. casefold() in string matching and converting to ...",
          "url": "https://stackoverflow.com/questions/45745661/lower-vs-casefold-in-string-matching-and-converting-to-lowercase",
          "excerpts": [
            "casefold() is a text normalization function like lower() that is specifically designed to remove upper- or lower-case distinctions for the purposes of ..."
          ]
        },
        {
          "title": "Unicode case folding to upper case - utf 16",
          "url": "https://stackoverflow.com/questions/20181505/unicode-case-folding-to-upper-case",
          "excerpts": [
            "Now there are two variants of case mapping and case folding, simple and full. Unlike the simple transformation, The full one can change ...",
            "The case folding is defined as an operation that bears much more resemblance to lower-casing, rather than upper-casing."
          ]
        },
        {
          "title": "Why does Unicode implement the Turkish I the way it does?",
          "url": "https://stackoverflow.com/questions/48067545/why-does-unicode-implement-the-turkish-i-the-way-it-does",
          "excerpts": [
            "Turkish has dotted and dotless I as two separate characters, each with their own uppercase and lowercase forms. Uppercase Lowercase I U+0049 ı U ...See more"
          ]
        },
        {
          "title": "Case mapping - Globalization - Microsoft Learn",
          "url": "https://learn.microsoft.com/en-us/globalization/text/case-mapping",
          "excerpts": [
            "The ICU library takes advantage of this data to provide a set of case mapping, case detection, and case folding (mapping strings to a canonical ..."
          ]
        },
        {
          "title": "UTR #25: Character Foldings",
          "url": "http://www.unicode.org/L2/L2000/00261-tr25-0d1.html",
          "excerpts": [
            "Folding operation – a folding operation removes a distinction between related characters. For example, case folding removes the case distinction, by replacing ..."
          ]
        },
        {
          "title": "lower() on Turkish letter \"İ\" returns a 2-chars-long string",
          "url": "https://bugs.python.org/issue34723",
          "excerpts": [
            "Sep 18, 2018 — Well, at the end, Python uses the following data file from the Unicode standard: https://www.unicode.org/Public/9.0.0/ucd/SpecialCasing.txt ...See more",
            "Sep 18, 2018 — lower() on Turkish letter \"İ\" returns a 2-chars-long string ... SpecialCasing.txt Extract: \"\"\" # Preserve canonical equivalence for I with dot."
          ]
        },
        {
          "title": "Whitespace character",
          "url": "https://en.wikipedia.org/wiki/Whitespace_character",
          "excerpts": [
            "A whitespace character is a character data element that represents white space when text is rendered for display by a computer."
          ]
        },
        {
          "title": "How collation of punctuation and whitespace works",
          "url": "http://peter.eisentraut.org/blog/2023/04/12/how-collation-of-punctuation-and-whitespace-works",
          "excerpts": [
            "Apr 12, 2023 — There are four options defined in Unicode for handling variable collation elements: non-ignorable; blanked; shifted; shift-trimmed. Let's look ..."
          ]
        },
        {
          "title": "Properties for Proposals",
          "url": "https://www.unicode.org/pending/properties.html",
          "excerpts": [
            "The preferred format for listing the character properties is that found in the file https://www.unicode.org/Public/UCD/latest/ucd/UnicodeData.txt. The following ..."
          ]
        },
        {
          "title": "When \"Zoë\" !== \"Zoë\". Or why you need to normalize ...",
          "url": "https://www.reddit.com/r/programming/comments/b09c0j/when_zo%C3%AB_zo%C3%AB_or_why_you_need_to_normalize_unicode/",
          "excerpts": [
            "The recommendation when normalizing strings for comparison, especially if those strings are intended for use as identifiers, should be to normalize to NFKC, ...See more"
          ]
        },
        {
          "title": "Why to normalize Unicode strings",
          "url": "https://news.ycombinator.com/item?id=19379965",
          "excerpts": [
            "Mar 13, 2019 — \"Content authors SHOULD use Unicode Normalization Form C (NFC) wherever possible for content.\"[1]. It's a SHOULD rather than a MUST. Non-NFC ...See more",
            "Mar 13, 2019 — UAX#15 notes that: ... I do understand the need for the difference between NFC and NFKC, but in hindsight NFD and NFKD seem entirely unnecessary."
          ]
        },
        {
          "title": "[Feature]: Choose between NFKC and NFC normalization ...",
          "url": "https://github.com/ocrmypdf/OCRmyPDF/issues/1282",
          "excerpts": [
            "Mar 24, 2024 — If there were an option to choose between NFKC and NFC normalization forms, then the author could opt to render the text more faithfully. In my ..."
          ]
        },
        {
          "title": "Why is \"Unicode whitespace character\" a superset of ...",
          "url": "https://talk.commonmark.org/t/why-is-unicode-whitespace-character-a-superset-of-whitespace-character-related-error/3419",
          "excerpts": [
            "Apr 16, 2020 — In the spec's section 2.1, “Whitespace character” is defined as a space, tab, newline, line tab, form feed, or carriage return. In the same ..."
          ]
        },
        {
          "title": "UAX #29: Unicode Text Segmentation",
          "url": "http://www.unicode.org/reports/tr29/tr29-27.html",
          "excerpts": [
            "Jun 1, 2015 — Characters such as hyphens, apostrophes, quotation marks, and colon should be taken into account when using identifiers that are intended to ..."
          ]
        },
        {
          "title": "UTS #18: Unicode Regular Expressions",
          "url": "http://www.unicode.org/reports/tr18/tr18-12.html",
          "excerpts": [
            "The most basic overall character property is the General Category, which is a basic categorization of Unicode characters into: Letters, Punctuation, Symbols, ..."
          ]
        },
        {
          "title": "Unicode Case Folding (CaseFolding.txt)",
          "url": "https://www.unicode.org/Public/16.0.0/ucd/CaseFolding.txt",
          "excerpts": [
            "# NOTE: case folding does not preserve normalization formats!",
            "# All code points not listed in this file map to themselves."
          ]
        },
        {
          "title": "Normalizing Unicode according to the W3C in PHP",
          "url": "https://stackoverflow.com/questions/8766675/normalizing-unicode-according-to-the-w3c-in-php",
          "excerpts": [
            "Strictly speaking, the rules of the web character model are not just that one should normalise to NFC, but that both the form before and the ...See more"
          ]
        },
        {
          "title": "UAX #44: Unicode Character Database",
          "url": "http://www.unicode.org/reports/tr44/tr44-3.html",
          "excerpts": [
            "This annex provides the core documentation for the Unicode Character Database (UCD). It describes the layout and organization of the Unicode Character Database ..."
          ]
        },
        {
          "title": "Case Mappings | ICU Documentation",
          "url": "https://unicode-org.github.io/icu/userguide/transforms/casemappings.html",
          "excerpts": [
            "The CaseFolding.txt file in the Unicode Character Database is used for performing locale-independent case folding. This text file is generated from the case ..."
          ]
        },
        {
          "title": "Unicode equivalence - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Unicode_equivalence",
          "excerpts": [
            "For instance, some typographic ligatures like U+FB03 (ﬃ), Roman numerals like U+2168 (Ⅸ) and even subscripts and superscripts, e.g. U+2075 (⁵) have their own ..."
          ]
        },
        {
          "title": "Overview (Lucene 9.7.0 icu API)",
          "url": "https://lucene.apache.org/core/9_7_0/analysis/icu/index.html",
          "excerpts": [
            "Search Term Folding: Removes distinctions (such as accent marks) between similar characters for a loose or fuzzy search. Text Transformation: Transforms Unicode ..."
          ]
        },
        {
          "title": "Case-folding a string in LuaTeX - unicode",
          "url": "https://tex.stackexchange.com/questions/672649/case-folding-a-string-in-luatex",
          "excerpts": [
            "Jan 23, 2023 — I would like to perform Unicode case-folding in the Lua interpreter of LuaTeX running within the TeX Live ecosystem. Can you suggest whether ..."
          ]
        },
        {
          "title": "UTR#21: Case Mappings",
          "url": "https://www.unicode.org/L2/L1999/99190.htm",
          "excerpts": [
            "Remember to use special mappings (e.g. Turkish) for some locales. toTitlecase(String s). Map each character to its titlecase or lowercase. If the preceeding ..."
          ]
        },
        {
          "title": "Unicode Normalization and Charmod-Norm (W3C CharMod Normalization) – Source Document",
          "url": "https://www.w3.org/TR/charmod-norm/",
          "excerpts": [
            "Aug 11, 2021 — There are four Unicode Normalization Forms. Each form is named using a letter code: D (or NFD) stands for canonical Decomposition. C (or NFC ) ...See more URL: <https://www.rfc-editor.org/rfc/rfc2119>\n",
            "[UAX15]\n:   [Unicode Normalization Forms](https://www.unicode.org/reports/tr15/tr15-50.html). Ken Whistler. Unicode Consortium. 24 February 2020. Unicode Standard Annex #15. URL: <https://www.unicode.org/reports/tr15/tr15-50.html>",
            "[UAX29]\n:   [Unicode Standard Annex #29: Unicode Text Segmentation](https://www.unicode.org/reports/tr29/). Mark Davis. URL: <https://www.unicode.org/reports/tr29/>",
            "[RFC3986]\n:   [Uniform Resource Identifier (URI): Generic Syntax](https://www.rfc-editor.org/rfc/rfc3986). T. Berners-Lee; R. Fielding; L. Masinter. IETF. January 2005. Internet Standard. URL: <https://www.rfc-editor.org/rfc/rfc3986>",
            "[RFC8174]\n:   [Ambiguity of Uppercase vs Lowercase in RFC 2119 Key Words](https://www.rfc-editor.org/rfc/rfc8174). B. Leiba. IETF. May 2017. Best Current Practice. URL: <https://www.rfc-editor.org/rfc/rfc8174>",
            "[UAX11]\n:   [Unicode Standard Annex #11: East Asian Width](https://www.unicode.org/reports/tr11/). Ken Lunde 小林劍. URL: <https://www.unicode.org/reports/tr11/>",
            "There are four Unicode Normalization Forms. Each form is named using a letter code:\n\n* **D** (or NFD) stands for *canonical Decomposition*. * **C** (or NFC) stands for *Composition*, which is canonical decomposition followed b",
            "Roughly speaking, NFC is defined such that each combining character sequence (a base character followed by one or more combining characters) is replaced, as far as possible, by a canonically equivalent precomposed character.",
            "Specifications *SHOULD NOT* specify compatibility normalization forms (NFKC, NFKD).",
            "Content authors *SHOULD* use Unicode Normalization Form C (NFC) wherever possible for content. Note that NFC is not always appropriate to the content or even available to content authors in some languages."
          ]
        },
        {
          "title": "Unicode Case Folding Properties (Unicode 12.1.0)",
          "url": "https://www.unicode.org/Public/12.1.0/ucd/CaseFolding.txt",
          "excerpts": [
            "NOTE: case folding does not preserve normalization formats!",
            "The data supports both implementations that require simple case foldings\n# (where string lengths don't change), and implementations that allow full case folding\n# (where string lengths may gr",
            "All code points not listed in this file map to themselves.",
            "For information on case folding, including how to have case folding\n# preserve normalization formats, see Section 3.13 Default Case Algorithms in\n# The Unicode Stand",
            "This file is a supplement to the UnicodeData file."
          ]
        },
        {
          "title": "Character Model for the World Wide Web 1.0: Normalization",
          "url": "https://www.w3.org/TR/2005/WD-charmod-norm-20051027/",
          "excerpts": [
            "Oct 27, 2005 — Text in a Unicode encoding form is said to be in NFC if it doesn't contain any combining sequence that could be replaced and if any remaining ..."
          ]
        },
        {
          "title": "Best Practice: Use Unicode Normal Form C or KC",
          "url": "https://jazz.net/wiki/bin/view/LinkedData/UseOfUnicodeNormalForms",
          "excerpts": [
            "In summary, NFC removes the distinction between equivalent characters, while preserving the distinction between compatible characters or sequences; NFKC removes ..."
          ]
        },
        {
          "title": "CaseFolding.txt",
          "url": "http://www.kreativekorp.com/ucsur/UNIDATA/CaseFolding.txt",
          "excerpts": [
            "... full mapping below, then # case differences are eliminated. # # The data supports both implementations that require simple case foldings # (where string ..."
          ]
        },
        {
          "title": "Regex Tutorial - Unicode Characters and Properties",
          "url": "https://www.regular-expressions.info/unicode.html",
          "excerpts": [
            "The Unicode code point U+0300 (grave accent) is a combining mark. Any code point that is not a combining mark can be followed by any number of combining marks."
          ]
        },
        {
          "title": "Vietnamese without diacritics",
          "url": "https://languagelog.ldc.upenn.edu/nll/?p=46400",
          "excerpts": [
            "Mar 16, 2020 — Normally one can read simple (email-style) Vietnamese without diacritical markings with no ambiguity, although today's input methods will ..."
          ]
        },
        {
          "title": "What is the best way to remove accents (normalize) in a Python ...",
          "url": "https://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-normalize-in-a-python-unicode-string",
          "excerpts": [
            "I have a Unicode string in Python, and I would like to remove all the accents (diacritics). I found an elegant way to do this (in Java)."
          ]
        },
        {
          "title": "I realize this is subjective, and perhaps a bit too ...",
          "url": "https://www.reddit.com/r/linguistics/comments/1ee9rm/i_realize_this_is_subjective_and_perhaps_a_bit/",
          "excerpts": [
            "Tones have a high functional load in Vietnamese, so diacritics are often necessary for determining the meaning of a word, e.g. ⟨đây⟩/[ɗəj˧] ' ..."
          ]
        },
        {
          "title": "Near Duplicate Detection using MinHashing and Solr",
          "url": "http://sujitpal.blogspot.com/2014/11/near-duplicate-detection-using.html",
          "excerpts": [
            "Nov 3, 2014 — For near-duplicate detection, it is customary to consider the Jaccard similarity between shingles."
          ]
        },
        {
          "title": "String Similarity Algorithms Compared | by Appaloosa Store",
          "url": "https://medium.com/@appaloosastore/string-similarity-algorithms-compared-3f7b4d12f0ff",
          "excerpts": [
            "We needed a way to determine if two strings are similar. The process would be to compare names in the order of the store's application list."
          ]
        },
        {
          "title": "Data Deduplication Strategies: Reducing Storage and ...",
          "url": "https://talent500.com/blog/data-deduplication-strategies-reducing-storage-and-improving-query-performance/",
          "excerpts": [
            "Aug 1, 2024 — Here, we will learn few techniques for data deduplication and their impact on reducing storage needs and for improving the query performance."
          ]
        },
        {
          "title": "Deduplication Best Practices",
          "url": "https://support.insycle.com/hc/en-us/articles/6584810088855-Deduplication-Best-Practices",
          "excerpts": [
            "With the Merge Duplicates module, Insycle helps you merge duplicate contacts, companies, deals, and other objects flexibly and powerfully."
          ]
        },
        {
          "title": "UTR# 39: Unicode Security Mechanisms",
          "url": "http://www.unicode.org/reports/tr39/tr39-1.html",
          "excerpts": [
            "X and Y are mixed-script confusables if they are confusable according to the Mixed-Script table, and they are not single-script confusables."
          ]
        },
        {
          "title": "The Turkish İ Problem and Why You Should Care (2012)",
          "url": "https://news.ycombinator.com/item?id=43902869",
          "excerpts": [
            "There is a corresponding capital \"ẞ\" in Unicode, and Germany has officially adopted 'ẞ' as an alternative since, but in Unicode's SpecialCasing.txt the upper of ..."
          ]
        },
        {
          "title": "How to type character with diacritics using Unicode combining ...",
          "url": "https://www.reddit.com/r/Unicode/comments/jteghz/how_to_type_character_with_diacritics_using/",
          "excerpts": [
            "Missing: Mn Mc"
          ]
        },
        {
          "title": "UTR# 39: Unicode Security Mechanisms",
          "url": "http://www.unicode.org/reports/tr39/tr39-3.html",
          "excerpts": [
            "X and Y are whole-script confusables if they are mixed-script confusables, and each of them is a single script string. Example: \"scope\" in Latin and \"scope\" in ..."
          ]
        },
        {
          "title": "Selecting and Weighting N-Grams to Identify 1100 Languages",
          "url": "http://www.cs.cmu.edu/~ralf/papers/brown-tsd13.pdf",
          "excerpts": [
            "by RD Brown · Cited by 57 — This paper presents a language identification algorithm using cosine similarity against a filtered and weighted subset of the most frequent n-grams in training ..."
          ]
        },
        {
          "title": "ICU Diacritics Removal via ICU (Stack Overflow)",
          "url": "https://stackoverflow.com/questions/2992066/code-to-strip-diacritical-marks-using-icu",
          "excerpts": [
            "ICU lets you transliterate a string using a specific rule. My rule is `NFD; [:M:] Remove; NFC`: decompose, remove diacritics, recompose.",
            "The one given in [unicode-org.github.io/icu/userguide/transforms/general](https://unicode-org.github.io/icu/userguide/transforms/general/) is `NFD; [:Nonspacing Mark:] Remove; NFC`"
          ]
        },
        {
          "title": null,
          "url": "https://mkonrad.net/2016/01/05/removing-diacritics-underlines-and-other-marks-from-unicode-strings-in-python.html",
          "excerpts": [
            "NFD; [:M:] Remove; NFC",
            "`\n\nAfter converting a Python string to an ICU `UnicodeString` object, we can apply a transliteration\noperation that is defined as `\"NFD; [:M:] Remove; NFC`“. This operation means the Unicode string is at first decomposed ([NFD](https://en.wikipedia.org/wiki/Unicode_equivalence)), then the character class \"marks",
            " is removed (“[:M:] Remove”) and finally the string is re-composed again (NFC). At the end, the `UnicodeString` object is converted back to a Python `str`. After defining a function we can use it as follows and see that it works (underlines may not be displayed correctly in your browser):",
            "```\nfrom icu import UnicodeString, Transliterator, UTransDirection\nu = UnicodeString(s)\nt = Transliterator.createInstance(\"NFD; [:M:] Remove; NFC\", UTransDirection.FORWARD)\nt.transliterate(u)\nnormalized = str(u)\n\n```"
          ]
        },
        {
          "title": "Finding near-duplicates with Jaccard similarity and MinHash",
          "url": "https://blog.nelhage.com/post/fuzzy-dedup/",
          "excerpts": [
            "Finding near-duplicates with Jaccard similarity and MinHash",
            "l signature  🔗︎\nThe simplest choice is to simply to use all \\(k\\) MinHash values together as a grouping key, and consider two documents “approximate duplicates” iff all of their MinHash values match. I’m pretty sure is what the GPT-3 paper cited above means when they say “we fuzzily deduplicated documents […] using Spark’s MinHashLSH implementation with 10 hashes.” They split each document into features, computed 10 MinHash values for each document (using 10 different hashes 2 ), and then grouped documents by that 10-vector, and kept only one document per group.",
            "The strongest virtue of this approach is its simplicity and efficiency. Grouping documents by a single high-cardinality bytestring is an efficient operation and easy to scale horizontally, and is offered as a basic primitive in essentially any data-processing toolkit (it’s arguably the core primitive in MapReduce , taking the form of the “shuffle” between the map and reduce stages). How does this approach behave? For a single pair of documents, we expect each MinHash value to be equal with probability \\(J(A,B)\\), so we expect all 10 to match with \\(p=J(A,B)^k\\). For \\(k=10\\), here’s what that looks like:",
            " 1.”\nBy using a subset of our \\(k\\) MinHash hashes as a grouping key, we can increase the likelihood of collisions at lower similarity values, and then compare the full signatures within each bucket to weed out false collisions. For instance, we might group by the first 4 MinHash values, and then – within each colliding group – use all of our MinHash values to estimate the trule similariy. Using fewer hashes is helpful, but only so far; \\(J^r\\) will always be smaller than \\(J\\), and if we push \\(r\\) too small, the rate of spurious matches will become unacceptable.",
            "What are the odds that two documents end up hashed together in at least one bucket? * The odds that two documents collide using a single key is \\(J^r\\)",
            "\\)\n\nThus, the odds that they collide at-least-once ends up as:\n\\[ p = 1 - (1-J^r)^b \\]"
          ]
        },
        {
          "title": "GARM Brand Safety Floor Suitability Framework 17Jun22",
          "url": "https://4962377.fs1.hubspotusercontent-na1.net/hubfs/4962377/resource-library/GARM%20Brand%20Safety%20Floor%20Suitability%20Framework%2023%20Sept%20(3).pdf",
          "excerpts": [
            "Adult & Explicit Sexual Content • Illegal sale, distribution, and consumption of child pornography. • Explicit or gratuitous depiction of sexual acts, and/or ...",
            "CONTENT CATEGORY High Risk. Medium Risk. Low Risk. Adult & Explicit Sexual. Content. • Suggestive sexual situations requiring adult supervision/approval or ...",
            "This work, the GARM Brand Safety Floor + Suitability Framework was first published in. September 2020. In June 2021, we began work to update the framework to ..."
          ]
        },
        {
          "title": "GARM Brand Safety Floor + Suitability Framework",
          "url": "https://wfanet.org/knowledge/item/2022/06/17/GARM-Brand-Safety-Floor--Suitability-Framework-3",
          "excerpts": [
            "Jun 17, 2022 — This document is designed to provide GARM members with a common understanding of key definitions and categories."
          ]
        },
        {
          "title": "GARM Brand Safety & Suitability - Documentation | Hive",
          "url": "https://docs.thehive.ai/docs/brand-safety-and-suitability",
          "excerpts": [
            "Brand Suitability classifies the risk level in four tiers: low, medium, high, and floor. Floor risk is defined as content not suitable for any advertiser."
          ]
        },
        {
          "title": "Adult Nudity and Sexual Activity",
          "url": "https://transparency.meta.com/policies/community-standards/adult-nudity-sexual-activity/",
          "excerpts": [
            "For the following content, we limit the ability to view the content to adults, ages 18 and older: Photorealistic/digital imagery depicting near nudity such as ..."
          ]
        },
        {
          "title": "An update to our policies on nudity and sexual content",
          "url": "https://support.google.com/youtube/thread/178333446/an-update-to-our-policies-on-nudity-and-sexual-content?hl=en",
          "excerpts": [
            "Sep 7, 2022 — Sex and nudity in Educational Content: We will allow content that is intended for educational purposes as long as it is not sexually gratifying."
          ]
        },
        {
          "title": "Adult Nudity and Sexual Activity",
          "url": "https://transparency.meta.com/policies/ad-standards/objectionable-content/adult-nudity-and-sexual-activity",
          "excerpts": [
            "This policy provides specific additional protections beyond what is prohibited in the Community Standard on Adult Nudity and Sexual Activity."
          ]
        },
        {
          "title": "About Meta's Adult Nudity and Sexual Activity advertising ...",
          "url": "https://www.facebook.com/business/help/819870269165994",
          "excerpts": [
            "Advertisers can't run ads that contain adult nudity and sexual activity, such as nudity and depictions of people in explicit or sexually suggestive positions."
          ]
        },
        {
          "title": "Nudity & Sexual Content Policy - YouTube Help",
          "url": "https://support.google.com/youtube/answer/2802002?hl=en",
          "excerpts": [
            "Explicit content meant to be sexually gratifying is not allowed on YouTube. Posting pornography may result in content removal or channel termination."
          ]
        },
        {
          "title": "Children's Online Privacy Protection Rule (\"COPPA\")",
          "url": "https://www.ftc.gov/legal-library/browse/rules/childrens-online-privacy-protection-rule-coppa",
          "excerpts": [
            "COPPA imposes certain requirements on operators of websites or online services directed to children under 13 years of age."
          ]
        },
        {
          "title": "18 U.S. Code § 2252A - Certain activities relating to material ...",
          "url": "https://www.law.cornell.edu/uscode/text/18/2252A",
          "excerpts": [
            "18 U.S. Code § 2252A - Certain activities relating to material constituting or containing child pornography · (1). Whoever engages in a child exploitation ...",
            "\n(1)\n\nknowingly mails, or transports or ships using any means or facility of interstate or foreign commerce or in or affecting interstate or foreign commerce by any means, including by [computer]",
            ", any [child pornography]",
            "\n ... \n(c) read as follows: “It shall be an affirmative defense to a charge of violating paragraph (1), (2), (3), or (4) of subsection (a) that—\n\n“(1",
            "notice. (d) Affirmative Defense.— It shall be an affirmative defense to a charge of violating subsection (a)(5) that the defendant—\n\n(1"
          ]
        },
        {
          "title": "Art. 9 GDPR – Processing of special categories of personal ...",
          "url": "https://gdpr-info.eu/art-9-gdpr/",
          "excerpts": [
            "... data concerning health or data concerning a natural person's sex life or sexual orientation shall be prohibited. Paragraph 1 shall not apply if one of the ...",
            "9 GDPR Processing of special categories of personal data ... data concerning a natural person's sex life or sexual orientation shall be prohibited."
          ]
        },
        {
          "title": "COYO-700M: Large-scale Image-Text Pair Dataset",
          "url": "https://github.com/kakaobrain/coyo-dataset",
          "excerpts": [
            "COYO-700M is a large-scale dataset that contains 747M image-text pairs as well as many other meta-attributes to increase the usability to train various models."
          ]
        },
        {
          "title": "kakaobrain/coyo-700m · Datasets at Hugging Face",
          "url": "https://huggingface.co/datasets/kakaobrain/coyo-700m",
          "excerpts": [
            "The COYO dataset is recommended to be used for research purposes. Kakao Brain tried to construct a \"Safe\" dataset when building the COYO dataset. (See Data ..."
          ]
        },
        {
          "title": "A Safe and High-Quality Open-sourced English Webtext Dataset",
          "url": "https://arxiv.org/html/2402.19282v1",
          "excerpts": [
            "Moreover, Common Crawl contains a large amount of unsafe content, such as toxic and pornographic materials, which could lead to unfriendly ..."
          ]
        },
        {
          "title": "Get Started - Common Crawl",
          "url": "https://commoncrawl.org/get-started",
          "excerpts": [
            "Dive into Common Crawl: your guide to accessing vast web data. Start here to harness the web's potential effortlessly."
          ]
        },
        {
          "title": "Suppressing Sexual Content Generation from Diffusion Models ...",
          "url": "https://arxiv.org/html/2410.05309",
          "excerpts": [
            "We focus on eliminating the NSFW (not safe for work) content generation from T2I model while maintaining the high quality of generated images."
          ]
        },
        {
          "title": "FTC's COPPA Rule Update—What Publishers Need to Know",
          "url": "https://www.admonsters.com/ftcs-coppa-rule-update-what-publishers-need-to-know/",
          "excerpts": [
            "Jan 30, 2025 — The FTC's COPPA overhaul introduces stricter data privacy rules for kids, requiring opt-in consent for targeted ads and redefining personal information."
          ]
        },
        {
          "title": "Complying with COPPA: Frequently Asked Questions",
          "url": "https://www.ftc.gov/business-guidance/resources/complying-coppa-frequently-asked-questions",
          "excerpts": [
            "The primary goal of COPPA is to place parents in control over what information is collected from their young children online."
          ]
        },
        {
          "title": "2467. Keeney Memorandum -- Recent Amendments To ...",
          "url": "https://www.justice.gov/archives/jm/criminal-resource-manual-2467-keeney-memorandum-recent-amendments-federal-child-pornography-and",
          "excerpts": [
            "Section 2252A expands the definition of the prohibited material by using the much more inclusive term \"child pornography\" which is defined in amended section ..."
          ]
        },
        {
          "title": "What personal data is considered sensitive?",
          "url": "https://commission.europa.eu/law/law-topic/data-protection/rules-business-and-organisations/legal-grounds-processing-data/sensitive-data/what-personal-data-considered-sensitive_en",
          "excerpts": [
            "The EU considers the following personal data sensitive: ethnic origin, trade union membership, genetic data, health-related data and data related to sexual ..."
          ]
        },
        {
          "title": "IAB Content Taxonomy 3.0 Implementation Guide",
          "url": "https://iabtechlab.com/wp-content/uploads/2021/09/Implementation-Guide-Content-Taxonomy-3-0-pc-Sept2021.pdf",
          "excerpts": [
            "Content Taxonomy Overview\nThe IAB Tech Lab Content Taxonomy provides a “common language” that all parties—publishers, Server-\nSide Providers (SSPs), Demand-Side Providers (DSPs), verification vendors, and advertisers—can use and\nunderstand when describing the content of a page, app, or other user environment",
            "The Brand Safety Floor & Suitability concepts introduced in the 2.2 version of the Content Taxonomy are\nbased on the Brand Safety & Suitability Framework released in September 2020 by the Global Alliance\nfor Responsible Media (GARM) in collaboration with the American Association of Advertising Agencies’\n(4As) Advertiser Protection Bureau (APB). For the purposes of the Content Taxonomy v2.2, the\ndescriptions for each category at each risk level, including the Floor, are described in the framework",
            "The 11 Brand Safety categories identified in the framework are introduced in v2.2 of the Content\nTaxonomy as topic categories under the parent category “Sensitive Topics” (id “v9i3On” in the Content\nTaxonomy 2.2 spreadsheet). The 11 categories are:\n\n\t1. Adult & Explicit Sexual Content\n\t2. Arms & Ammunition\n\t3. Crime & Harmful acts to individuals and Society and Human Right Violations\n\t4. Death Injury, or Military Conflict\n\t5. Online piracy\n\t6.\nHate speech & acts of aggression\n\t7. Obscenity and Profanity\n\t8. Illegal Drugs/Tobacco/eCigarettes/ Vaping/Alcohol\n\t9. Spam or Harmful Content\n\t10. Terrorism\n\t11. Sensitive Social Issues",
            "The 11 Brand Safety categories identified in the framework are introduced in v2.2 of the Content\nTaxonomy as topic categories under the parent category “Sensitive Topics” (id “v9i3On” in the Content\nTaxonomy 2.2 spreadsheet). The 11 categories ar",
            "Brand safety:\nBuyers should familiarize themselves with the GARM/4A’s APB Brand Safety & Suitability Framework\nand the Tech Lab Content Taxonomy.",
            "\t4. Death Injury, or Military Conflict",
            "\t5. Online piracy",
            "\t6.\nHate speech & acts of aggression",
            "\t7. Obscenity and Profanity",
            "\t8. Illegal Drugs/Tobacco/eCigarettes/ Vaping/Alcohol",
            "B Technology Laboratory\n\f\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tContent Taxonomy 3.0 Implementation ",
            "\t10. Terrorism",
            "\t11. Sensitive Social Issues",
            "The risk levels in the Framework that identify the levels of suitability are treated as additional attributes\nof the content. They are encoded in an orthogonal vector accordingly, allowing “risk” to be associated\nwith a “topic” dynamically. The levels are:\n\n\t1. Floor\n\t2. High Risk\n\t3. Medium Risk\n\t4. Low",
            "e\n\n\ngoal of including these categories are twofold. First, to provide a mechanism to mark content that might\nnot be suitable for certain brands, but equally important, to allow content that might otherwise have\nbeen blanket marked as unsafe to be monetized by allowing brands with the right risk tolerance to buy\nsuch inventory."
          ]
        },
        {
          "title": "LAION-5B: A New Era of Open Large-Scale Multi-Modal Datasets",
          "url": "https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/",
          "excerpts": [
            "It is possible to extract a “safe” subset by filtering out samples based on the safety tags (using a customized trained NSFW classifier that we built).",
            "While this strongly reduces the chance for encountering potentially harmful content when viewing, we cannot entirely exclude the possibility for harmful content being still present in safe mode, so that the warning holds also there."
          ]
        },
        {
          "title": "avpassociation.com / 4271-2 (Age-verification policies and laws)",
          "url": "https://avpassociation.com/4271-2/",
          "excerpts": [
            "F.pdf#navpanes=0) – Makes commercial websites where more than one-third of their content is pornographic liable to being sued for damages by individuals unless age verification using (1) digitized ID card (not defined), or a commercial age verification system based on (2a) government-issued ID or (2b) a commercial reasonable method based on transaction data (e.g. mortgage, education, employment).",
            "#navpanes=0) – Makes commercial websites where more than one-third of their content is pornographic liable to being sued for damages by individuals unless age verification using (1) digitized ID card (not defined), or a commercial age verification system based on (2a) government-issued ID or (2b) a commercial reasonable method based on transaction data (e.g. mortgage, education, employment).",
            "xe?231+ful+CHAP0811) Makes commercial websites where more than one-third of their content is pornographic liable to being sued for damages by individuals unless age verification using (1) commercially available database or (2) a commercial reasonable method of age and identity verification",
            "aspx?d=1332277) Gives commercial websites where more than one-third of thjeir content is pornographic 30 days to remedy a failure to provide age verification before the Attorney-General can take legal action to impose a fine of $5k per day or $10k if done knowingly (the “PAVE Act”)",
            "7.05.ENRH.pdf) Requires an adult oriented website operator that displays material harmful to minors to use a reasonable age verification method to prevent a minor from accessing an adult oriented website.",
            "024/3/BillText/er/PDF) Requires websites where at least one-third of the content is pornographic to perform “reasonable method of age verification” to prevent minors from accessing the harmful material. Adult sites must offer at least one option of anonymized age verification."
          ]
        },
        {
          "title": "Enforcement Mechanisms for Adult Websites (28 C.F.R. 75.1 et seq.) - Nissenbaum Law Group",
          "url": "https://www.gdnlaw.com/practice-areas/internet-picture-removal/enforcement-mechanisms-adult-websites-28-c-f-r-75-1-et-seq/",
          "excerpts": [
            "28 C.F.R. 75.1 et seq.\nrequires that producers obtain specific types of identification from their performers to ensure that they are indeed over the age of 18.",
            "a document issued by the United States, a State government, or a political subdivision thereof, or a United States territory, that bears the photograph, the name of the individual identified, and the date of birth of that individual, and provides specific information sufficient for the issuing authority to confirm its validity, such as a passport, Permanent Resident Card (commonly known as a “Green Card”), or employment authorization document issued by the United States, a driver’s license or other form of identification issued by a State or the District of Columbia; or a foreign government-issued equivalent of any of the documents listed above when the person who is the subject of the picture identification card is a non-U.S. citizen located outside the United States at the time of original production and the producer maintaining the required records, whether a U.S. citizen or non-U.S. citizen, is located outside the United States on the original production date. The picture identification card must be valid as of the original production date.",
            ", regulati",
            "Producers of adult content must keep detailed records of the identification of the performers. They must adhere to strict protocols not only for how those records are stored, but also for making those records available for inspection by law enforcement.",
            "\n\n“Any producer … shall, for each performer portrayed in such visual depiction, create and maintain records containing… [t]he legal name and date of birth of each performer, obtained by the producer’s examination of a picture identification card prior to production of the depiction… [as well as any] name, other than the performer’s legal name, ever used by the performer, including the performer’s maiden name, alias, nickname, stage name, or professional name",
            "Records required to be created and maintained under this part shall be organized alphabetically, or numerically where appropriate, by the legal name of the performer (by last or family name, then first or given name), and shall be indexed or cross-referenced to each alias or other name used and to each title or identifying number of the book, magazine, film, videotape, digitally- or computer-manipulated image, digital image, picture, URL, or other matter. “Investigators authorized by the Attorney General… are authorized to enter without delay and at reasonable times any establishment of a producer where records… are maintained to inspect during regular working hours and at other reasonable times, and within reasonable limits and in a reasonable manner, for the purpose of determining compliance with the record-keeping requirement",
            "**28 C.F.R. 75.1 et seq.\nrequires that producers obtain specific types of identification from their performers to ensure that they are indeed over the age of 18. *"
          ]
        },
        {
          "title": "Adult Website Law – Beginner's Legal Guide for Operating an Adult Website",
          "url": "https://www.firstamendment.com/adult-website-law-beginners-legal-guide-for-operating-an-adult-website/",
          "excerpts": [
            "Title 18 U.S.C. § 2257 (and associated federal regulations) require that performers in sexually explicit media provide government-issued ID’s, and that all producers (including secondary producers such as website operators) maintain records associated with the performer",
            "The publication of sexually explicit media on a website generally requires a Section 2257 disclosure statement, which identifies the location of where the mandatory records are kept.",
            "A more serious issue arises with the age of persons depicted in sexually explicit material. Child pornography, exploitation, and sex trafficking offenses are some of the most serious crimes in the nation, at both the state and federal levels. Adult website operators must make every effort to ensure that underage materials are not published on their sites."
          ]
        },
        {
          "title": "Garm Brand Safety Floor Suitability Framework 23 Sept | PDF",
          "url": "https://www.scribd.com/document/664972235/Garm-Brand-Safety-Floor-Suitability-Framework-23-Sept",
          "excerpts": [
            "The framework provides common definitions for categorizing harmful and sensitive content. It establishes a Brand Safety Floor that defines content ...",
            "Sep 23, 2024 — It establishes a Brand Safety Floor that defines content inappropriate for advertising support. It also includes a Brand Suitability Framework ..."
          ]
        },
        {
          "title": "Implementation Guide for Brand Suitability with the Content ...",
          "url": "https://iabtechlab.com/wp-content/uploads/2020/12/Implementation_Guide_for_Brand_Suitability_with_IABTechLab_Content_Taxonomy_2-2.pdf",
          "excerpts": [
            "Adult & Explicit Sexual Content. 2. Arms & Ammunition. 3 ... Buyers should familiarize themselves with the GARM/4A's APB Brand Safety & Suitability Framework."
          ]
        },
        {
          "title": "How to use the moderation API",
          "url": "https://cookbook.openai.com/examples/how_to_use_moderation",
          "excerpts": [
            "Mar 5, 2024 — You can also check for one or more categories to tailor this to a specific use case: sexual; sexual/minors; harassment; harassment/threatening ..."
          ]
        },
        {
          "title": "Moderation - OpenAI API",
          "url": "https://platform.openai.com/docs/guides/moderation",
          "excerpts": [
            "... categories ... Content meant to arouse sexual excitement, such as the description of sexual activity, or that promotes sexual services (excluding sex education ..."
          ]
        },
        {
          "title": "Directive - 2011/93 - EN - EUR-Lex - European Union",
          "url": "https://eur-lex.europa.eu/eli/dir/2011/93/oj/eng",
          "excerpts": [
            "Directive 2011/93/EU of the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "[PDF] B DIRECTIVE C1 2011/93/EU OF THE EUROPEAN ... - EUR-Lex",
          "url": "https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:02011L0093-20111217",
          "excerpts": [
            "This Directive obliges Member States to provide for criminal penalties in their national legislation in respect of the provisions of Union law ..."
          ]
        },
        {
          "title": "FTC Finalizes Changes to Children's Privacy Rule Limiting ...",
          "url": "https://www.ftc.gov/news-events/news/press-releases/2025/01/ftc-finalizes-changes-childrens-privacy-rule-limiting-companies-ability-monetize-kids-data",
          "excerpts": [
            "Jan 16, 2025 — The final rule requires parents to opt in to third-party advertising and includes other changes to address the emerging ways that consumers' ..."
          ]
        },
        {
          "title": "Congress, Not States or the Supreme Court, Should Lead ...",
          "url": "https://itif.org/publications/2025/02/05/congress-should-lead-way-in-childrens-online-safety-access-adult-content/",
          "excerpts": [
            "Feb 5, 2025 — Congress should pass legislation to preempt the impending patchwork of state age verification laws and establish a standardized child-flag system."
          ]
        },
        {
          "title": "Directive 2011/93/EU of the European Parliament and of the ...",
          "url": "https://www.legislation.gov.uk/eudr/2011/93/contents",
          "excerpts": [
            "Directive2011/93/EUof the European Parliament and of the Council of 13 December 2011 on combating the sexual abuse and sexual exploitation of children and ..."
          ]
        },
        {
          "title": "Children's Online Privacy Protection Rule",
          "url": "https://www.federalregister.gov/documents/2025/04/22/2025-05904/childrens-online-privacy-protection-rule",
          "excerpts": [
            "Apr 22, 2025 — The Rule requires operators to keep personal information they collect from children secure and to maintain effective data retention and deletion ...",
            "Apr 22, 2025 — The amendments are intended to strengthen protection of personal information collected from children, and, where appropriate, to clarify and ..."
          ]
        },
        {
          "title": "USA: Legal, regulatory, and enforcement developments ...",
          "url": "https://www.ebglaw.com/media/publication/68_Shah-Reisz_OneTrust-Data-Guidance_Data-Protection-Leader_July-2025-dpl-report-reduced.pdf",
          "excerpts": [
            "6 days ago — States such as Georgia and Utah have added requirements for age verification on both personal and school-issued devices, further broadening the ..."
          ]
        },
        {
          "title": "Using PhotoDNA in Digital Forensics Investigations",
          "url": "https://www.adfsolutions.com/news/photodna-digital-forensics-investigations?srsltid=AfmBOoougPWMuTOMg3ktZ6K6Yi8r-crn0Hgd6rlkElMTUuTDlrjoytMD",
          "excerpts": [
            "Aug 13, 2020 — Learn how to use PhotoDNA to speed digital forensics investigations of visually similar pictures. Photo forensics for CSAM, CEM, ..."
          ]
        },
        {
          "title": "PhotoDNA",
          "url": "https://www.microsoft.com/en-us/photodna",
          "excerpts": [
            "PhotoDNA is used by organizations around the world and has assisted in the detection, disruption, and reporting of millions of child exploitation images."
          ]
        },
        {
          "title": "Experts share key guidance on AI-generated child abuse material",
          "url": "https://www.iwf.org.uk/news-media/news/professionals-working-with-children-given-vital-guidance-to-tackle-threat-of-ai-generated-child-sexual-abuse-material/",
          "excerpts": [
            "New aid created by the NCA and IWF raises awareness of the risks to children caused by the 'weaponised' technology."
          ]
        },
        {
          "title": "Discover our child safety toolkit",
          "url": "https://protectingchildren.google/tools-for-partners/",
          "excerpts": [
            "CSAI Match is designed for video, but through Google's Content Safety API, a collection of tools are available to industry and NGO partners, offering machine ..."
          ]
        },
        {
          "title": "[PDF] Child sexual abuse material generated by artificial intelligence",
          "url": "https://www.iwf.org.uk/media/ceel0u4z/ai-guidance-england-final.pdf",
          "excerpts": [
            "Developments in artificial intelligence (AI) come with a range of benefits, including supporting learning, creativity and innovation."
          ]
        },
        {
          "title": "Fighting child sexual abuse online",
          "url": "https://protectingchildren.google/",
          "excerpts": [
            "CSAI Match is used by NGOs and companies to help them identify matches against our database of known abusive content so they can responsibly action it in ..."
          ]
        },
        {
          "title": "Child sexual abuse material generated by artificial intelligence",
          "url": "https://www.ceopeducation.co.uk/professionals/guidance/ai-guidance-for-professionals/",
          "excerpts": [
            "Understanding and responding to AI-generated child sexual abuse imagery. An essential guide for professionals who work with children and young people."
          ]
        },
        {
          "title": "IAB Content Taxonomy 3.1",
          "url": "https://iabtechlab.com/standards/content-taxonomy/",
          "excerpts": [
            "mber 11, 2024\n\nThe Content Taxonomy provides a “common language” that can be used when describing content. Typical uses of the content taxonomy are contextual targeting and brand safety.",
            "Content Taxonomy 3.1",
            "The 3.1 version of the content taxonomy is now open for public comment until Jan 24, 2025. This latest version contains an update to the ‘genre’ category to include Thrille",
            "Last updated: December 11, 2024"
          ]
        },
        {
          "title": "US Code Title 18 - Crimes and Criminal Procedure, 18 USC 2252A",
          "url": "https://uscode.house.gov/view.xhtml?req=granuleid:USC-prelim-title18-section2252A&num=0&edition=prelim",
          "excerpts": [
            "18 USC 2252A: Certain activities relating to material constituting or containing child pornography",
            " (b)(1) Whoever violates, or attempts or conspires to violate, paragraph (1), (2), (3), (4), or (6) of subsection (a) shall be fined under this title and imprisoned not less than 5 years and not more than 20 years",
            "rs.\n(2) Whoever violates, or attempts or conspires to violate, subsection (a)(5) shall be fined under this title or imprisoned not more than 10 years, or both",
            "s. (3) Whoever violates, or attempts or conspires to violate, subsection (a)(7) shall be fined under this title or imprisoned not more than 15 years, or both.",
            " It shall be an affirmative defense to a charge of violating paragraph (1), (2), (3)(A), (4), or (5) of subsection (a) that-"
          ]
        },
        {
          "title": "NCMEC CyberTipline 2024 Report",
          "url": "https://www.missingkids.org/gethelpnow/cybertipline/cybertiplinedata",
          "excerpts": [
            "When CSAM is reported by around the world, NCMEC can provide crucial support to child victims by notifying relevant platforms to review and remove any explicit images of the child.",
            "NCMEC's CyberTipline was created in 1998 to receive reports of suspected child sexual exploitation from the public and electronic service providers (ESPs).",
            "In 2024, the CyberTipline received\n20.5 million reports of suspected child sexual exploitation.",
            " NCMEC labeled more than\n9.7 million files in 2024",
            " has labeled more than 62.5 million files in total. ",
            "As of December 31, 2024, NCMEC shared more than 9.8 million hashes with 55 ESPs and 17 non-traditional ESPs who have voluntarily chosen to access this hash-sharing initiative.",
            "NCMEC analysts review suspected CSAM submitted by companies and label images and videos with information about the type of content, the estimated age range of the children seen and other details that help law enforcement prioritize the reports for review.",
            "Removal Notices and Tracking",
            "Hash values are unique digital fingerprints assigned to pieces of data, such as images and videos. They are an important tool in the effort to stop the spread of CSAM."
          ]
        },
        {
          "title": "NCMEC CyberTipline and Reporting Guidance",
          "url": "https://www.missingkids.org/gethelpnow/cybertipline",
          "excerpts": [
            "NCMEC's CyberTipline is the nation's centralized reporting system for the online exploitation of children. [National Center for Missing and Exploited Children, CyberTipline, 1-800-843-5678](/content/dam/missingkids/logos/cybertipline_logo-2018.jpg)",
            "## Report It",
            "If you think you have seen a missing child, or suspect a child may be sexually exploited, contact the National Center for ",
            " Missing & Exploited Children 24 hours a day, 7 days a week. ## Report Child Sexual Exploitation",
            "Use the CyberTipline to report child sexual exploitation. [Make a CyberTipline Report »](https://report.cybertip.org)",
            "The banner is a tool to allow you to conveniently share a link to NCMEC's CyberTipline to create a report. To display this banner on your website:",
            ":\n\n* [Read the terms of use](/footer/privacypolicy.html \"/content/ncmec/en/footer/privacypolicy\") . Your use of any National Center for Missing & Exploited Children® banner signifies your agreement to these terms of use. * Enter the code snippet below into your site. #### [Code Snippet]()",
            "<iframe src=\"https://www.missingkids.org/gethelpnow/cybertipline/widget\" width=\"300\" height=\"500\"></iframe>",
            "NCMEC is a founding member of",
            "[! [partner, logo](/gethelpnow/cybertipline/_jcr_content/mainpar/container_133256226/null/image.coreimg.png/1724687473559/partners-inhope-a.png \"INHOPE\")]",
            "24\\-Hour Call Center: [1\\-800-843-5678](tel:+1-800-843-567"
          ]
        },
        {
          "title": "Appendix Exhibit 1 - HJC-WFA-GARM-000001893 ...",
          "url": "https://judiciary.house.gov/sites/evo-subsites/republicans-judiciary.house.gov/files/evo-media-document/GARMReportFinalAppendix.pdf",
          "excerpts": [
            "This work, the GARM Brand Safety Floor+ Suitability Framework wasfirst published in. September 2020. In June 2021, we began work to update ..."
          ]
        },
        {
          "title": "Contextual Intelligence Targeting and Brand Safety ...",
          "url": "https://www.oracle.com/a/ocom/docs/oracle-contextual-intelligence-segment-guide.pdf",
          "excerpts": [
            "The incorporation of categories from the IABs content taxonomy v3.0 gives the opportunity for brands to grow within platforms with segments that support rising ..."
          ]
        },
        {
          "title": "Upgrading the Moderation API with our new multimodal ... - OpenAI",
          "url": "https://openai.com/index/upgrading-the-moderation-api-with-our-new-multimodal-moderation-model/",
          "excerpts": [
            "... sexual ( sexual but not sexual/minors ). The remaining categories are currently text-only and we are working to expand multimodal support to ..."
          ]
        },
        {
          "title": "Violent or graphic content policies - YouTube Help",
          "url": "https://support.google.com/youtube/answer/2802008?hl=en",
          "excerpts": [
            "Violent or gory content intended to shock or disgust viewers, or content encouraging others to commit violent acts, are not allowed on YouTube."
          ]
        },
        {
          "title": "[PDF] Online Health and Safety for Children and Youth: Best Practices for ...",
          "url": "https://www.ntia.gov/sites/default/files/reports/kids-online-health-safety/2024-kohs-report.pdf",
          "excerpts": [
            "✓ Use data-driven methods to detect and prevent cyberbullying and other forms of online harassment and abuse."
          ]
        },
        {
          "title": "18 U.S. Code § 2257 - Record keeping requirements",
          "url": "https://www.law.cornell.edu/uscode/text/18/2257",
          "excerpts": [
            "Shall create and maintain individually identifiable records pertaining to every performer portrayed in such a visual depiction."
          ]
        },
        {
          "title": "16 CFR Part 312 -- Children's Online Privacy Protection ...",
          "url": "https://www.ecfr.gov/current/title-16/chapter-I/subchapter-C/part-312",
          "excerpts": [
            "This part implements the Children's Online Privacy Protection Act of 1998, (15 USC 6501, et seq.,) which prohibits unfair or deceptive acts or practices."
          ]
        },
        {
          "title": "What is special category data? | ICO",
          "url": "https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/lawful-basis/special-category-data/what-is-special-category-data/",
          "excerpts": [
            "Article 9(1) includes in the list of special categories of data: “biometric data for the purpose of uniquely identifying a natural person”. The UK GDPR defines ..."
          ]
        },
        {
          "title": "28 CFR Part 75 -- Child Protection Restoration and ...",
          "url": "https://www.ecfr.gov/current/title-28/chapter-I/part-75",
          "excerpts": [
            "Only one copy of each picture of a performer's picture identification card and identification document must be kept as long as each copy is categorized and ..."
          ]
        },
        {
          "title": "Criminal Division | 18 U.S.C §§ 2257- 2257A Certifications",
          "url": "https://www.justice.gov/criminal/criminal-ceos/18-usc-2257-2257a-certifications",
          "excerpts": [
            "Aug 11, 2023 — In order to protect children from sexual exploitation crimes, federal law imposes name- and age-verification, recordkeeping, and labeling ..."
          ]
        },
        {
          "title": "[1803.09010] Datasheets for Datasets",
          "url": "https://arxiv.org/abs/1803.09010",
          "excerpts": [
            "by T Gebru · 2018 · Cited by 3090 — We propose that every dataset be accompanied with a datasheet that documents its motivation, composition, collection process, recommended uses, and so on."
          ]
        },
        {
          "title": "Data Statements for Natural Language Processing - CIS UPenn",
          "url": "https://www.cis.upenn.edu/~mkearns/teaching/ScienceDataEthics/files/lecture/l22/reading1.pdf",
          "excerpts": [
            "by EM Bender · Cited by 1195 — In this paper, we propose data statements as a design solution and professional practice for natural language processing technolo-."
          ]
        },
        {
          "title": "[2210.08402] LAION-5B: An open large-scale dataset for training ...",
          "url": "https://ar5iv.labs.arxiv.org/html/2210.08402",
          "excerpts": [
            "We present LAION-5B - a dataset consisting of 5.85 billion CLIP-filtered image-text pairs, of which 2.32B contain English language."
          ]
        },
        {
          "title": "[PDF] Identifying and Eliminating CSAM in Generative ML Training Data ...",
          "url": "https://stacks.stanford.edu/file/druid:kh752sm9123/ml_training_data_csam_report-2023-12-23.pdf",
          "excerpts": [
            "The LAION project's use of CLIP filtering for “NSFW” detection is potentially useful, though it is unclear whether this approach outperforms ..."
          ]
        },
        {
          "title": "Datasheets for Datasets",
          "url": "https://www.microsoft.com/en-us/research/wp-content/uploads/2019/01/1803.09010.pdf",
          "excerpts": [
            "by T Gebru · Cited by 3090 — Datasheets for datasets document motivation, creation, composition, intended uses, distribution, maintenance, and other information, similar to electronics  ..."
          ]
        },
        {
          "title": "Data Statements for Natural Language Processing: Toward ...",
          "url": "https://aclanthology.org/Q18-1041/",
          "excerpts": [
            "by EM Bender · 2018 · Cited by 1195 — In this paper, we propose data statements as a design solution and professional practice for natural language processing technologists, in both research and ..."
          ]
        },
        {
          "title": "FindLaw: 18 U.S.C. § 2252A - U.S. Code - Unannotated Title 18. Crimes and Criminal Procedure § 2252A",
          "url": "https://codes.findlaw.com/us/title-18-crimes-and-criminal-procedure/18-usc-sect-2252a/",
          "excerpts": [
            "- 18 U.S.C. § 2252A - U.S. Code - Unannotated Title 18. Crimes and Criminal Procedure § 2252A. Certain activities relating to material constituting or containing child pornography - *last updated January 01, 2024*",
            "(A) any child pornography using any means or facility of interstate or foreign commerce or that has been mailed, or has been shipped or transported in or ... U.S. Title 18. Crimes and Criminal Procedure 18 USCA Section 2252A. Read the code on FindLaw",
            "tion is, or appears to be, of a minor engaging in sexually explicit conduct--"
          ]
        },
        {
          "title": "KIDS ONLINE HEALTH AND SAFETY TASK FORCE",
          "url": "https://www.samhsa.gov/sites/default/files/online-health-safety-children-youth-report.pdf",
          "excerpts": [
            "Design age-appropriate experiences for youth users",
            "Make privacy protections for youth the default.",
            "Disclose accurate and comprehensive safety-related information about apps",
            "Provide age-appropriate parental control tools that are easy to understand and use.",
            "Do not enable targeted advertising to minors based on their activities"
          ]
        },
        {
          "title": "An Intent Taxonomy for Questions Asked in Web Search",
          "url": "https://dl.acm.org/doi/10.1145/3406522.3446027",
          "excerpts": [
            "We present a new, multi-faceted taxonomy to classify questions asked in web search engines based on the question intent, types of entities mentioned, types of ..."
          ]
        },
        {
          "title": "Google Quality Raters: definitions, tasks and evaluation methods",
          "url": "https://www.seozoom.com/google-quality-raters/",
          "excerpts": [
            "The Google quality raters are human external evaluators who judge the quality of the results of the search engine."
          ]
        },
        {
          "title": "How to define SERP intent and 'source type' for better ...",
          "url": "https://searchengineland.com/serp-intent-source-type-analysis-388116",
          "excerpts": [
            "Understanding the source types that Google displays in the SERPs helps SEOs know how viable it is to effectively rank for certain queries."
          ]
        },
        {
          "title": "Broad and Ambiguous Search Queries | by Daniel Tunkelang",
          "url": "https://dtunkelang.medium.com/broad-and-ambiguous-search-queries-1bbbe417dcc",
          "excerpts": [
            "Broad queries are unambiguous but underspecified. For example, the broad query “shirts” includes shirts for men, women, and children; t-shirts, polo shirts, ..."
          ]
        },
        {
          "title": "ClariQ: SCAI Workshop data challenge on conversational ...",
          "url": "https://github.com/aliannejadi/ClariQ",
          "excerpts": [
            "We have crowdsourced a new dataset to study clarifying questions that is suitable for conversational settings."
          ]
        },
        {
          "title": "Google Search Quality Rater Guidelines Explained - Vazoola",
          "url": "https://www.vazoola.com/resources/googles-new-quality-raters-guideline",
          "excerpts": [
            "Using the Search Quality Rater Guidelines, they assess whether a page meets the user's intent, provides accurate information, and is trustworthy ..."
          ]
        },
        {
          "title": "How Bing delivers search results - Microsoft Support",
          "url": "https://support.microsoft.com/en-us/topic/how-bing-delivers-search-results-d18fc815-ac37-4723-bc67-9229ce3eb6a3",
          "excerpts": [
            "We respect user intent. When a user expresses a clear intent to access specific information, we provide relevant results even if they are less credible, while ( ..."
          ]
        },
        {
          "title": "Generating Clarifying Questions for Open-Domain ...",
          "url": "https://arxiv.org/pdf/2009.11352",
          "excerpts": [
            "by M Aliannejadi · 2020 · Cited by 86 — This document presents a detailed description of the challenge on clarifying ques- tions for dialogue systems (ClariQ) [pronounce as ..."
          ]
        },
        {
          "title": "coveooss/shopper-intent-prediction-nature-2020",
          "url": "https://github.com/coveooss/shopper-intent-prediction-nature-2020",
          "excerpts": [
            "Jan 19, 2024 — The dataset is available for research and educational purposes here. To obtain the dataset, you are required to fill out a form with ..."
          ]
        },
        {
          "title": "How SERP features respond to search intent modifiers",
          "url": "https://getstat.com/blog/how-serp-features-respond-to-search-intent-modifiers",
          "excerpts": [
            "How SERP features respond to search intent modifiers",
            " Modifiers help give good ol’ Google (and us) insight into what might be motivating a searcher. When someone plunks in a keyword like [ _graphics card_ ], it’s far more difficult to guess their end goal than if they’d typed [ _buy graphics card_ ].",
            "In our study, we looked at the following keyword modifiers, categorized by search intent, on US mobile devices:",
            "We then looked at the top 20 Google SERP results, stripped out the organic results, and zeroed in on how many times each SERP feature showed up.",
            "Shopping boxes, news, and images made up the largest percentage of SERP features.",
            "During the commercial intent stage of searching, folks start using modifiers to help surface more precise information.",
            "The searcher has zeroed in on the product that will solve their problem, and now needs to figure out what the best available option is.",
            "we looked at how different levels of search intent — informational, commercial, transactional, and local — affect the kind of SERP features that Google serves ..."
          ]
        },
        {
          "title": "AmbigQA: Answering Ambiguous Open-domain Questions",
          "url": "https://aclanthology.org/2020.emnlp-main.466/",
          "excerpts": [
            "To study this task, we construct AmbigNQ, a dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark.",
            "We find that over half of the questions in NQ-open are ambiguous, with diverse sources of ambiguity such as event and entity references.",
            "Ambiguity is inherent to open-domain question answering; especially when exploring new topics, it can be difficult to ask questions that have a single, unambiguous answer.",
            "In this paper, we introduce AmbigQA, a new open-domain question answering task which involves finding every plausible answer, and then rewriting the question for each one to resolve the ambiguity."
          ]
        },
        {
          "title": "AmbigQA: Answering Ambiguous Open-domain Questions",
          "url": "https://nlp.cs.washington.edu/ambigqa/",
          "excerpts": [
            "Ambiguity is inherent to open-domain question answering; especially when exploring\nnew topics, it can be difficult to ask questions that have a single, unambiguous answer. We introduce AmbigQA, a new open-domain question answering task\nwhich involves predicting a set of question-answer pairs,\nwhere every plausible answer is paired with a disambiguated rewrite of the original question.",
            "AmbigQA, a new open-domain question answering task\nwhich involves predicting a set of question-answer pairs,\nwhere every plausible answer is paired with a disambiguated rewrite of the original question.",
            "To study this task,\nwe construct AmbigNQ, a dataset covering\n14,042 questions from NQ-open, an existing open-domain QA benchmark.",
            "We find that over half of the questions in NQ-open are ambiguous.",
            "The types of ambiguity are diverse\nand sometimes subtle, many of which are only apparent\nafter examining evidence provided by a very large text corpus."
          ]
        },
        {
          "title": "AmbigQA: Answering Ambiguous Open-domain Questions",
          "url": "https://arxiv.org/abs/2004.10645",
          "excerpts": [
            "Ambiguity is inherent to open-domain question answering; especially when exploring new topics, it can be difficult to ask questions that have a single, unambiguous answer.",
            "In this paper, we introduce AmbigQA, a new open-domain question answering task which involves finding every plausible answer, and then rewriting the question for each one to resolve the ambiguity.",
            "We find that over half of the questions in NQ-open are ambiguous, with diverse sources of ambiguity such as event and entity references. We also ..."
          ]
        },
        {
          "title": "Google's Search Quality Raters Guidelines: A Guide for ...",
          "url": "https://www.searchenginejournal.com/google-eat/quality-raters-guidelines/",
          "excerpts": [
            "The Google Search Quality Raters Guidelines is an important document. It tells us where Google wants to go, and they're throwing a lot of resources at it."
          ]
        },
        {
          "title": "SERP Features: What They Are & Why They Matter",
          "url": "https://backlinko.com/hub/seo/serp-features",
          "excerpts": [
            "SERP features are unique elements that appear on Google's search engine results page (SERP) that go beyond the traditional “10 blue links”."
          ]
        },
        {
          "title": "Local Search Intent Explained: A Guide for ...",
          "url": "https://www.localfalcon.com/blog/what-is-local-search-intent-and-how-can-you-optimize-for-it",
          "excerpts": [
            "Sep 27, 2024 — Local search intent refers to the intent behind a user's search query that indicates a desire to find local information, products, or services."
          ]
        },
        {
          "title": "Using intent confidence scores to improve intent selection ...",
          "url": "https://docs.aws.amazon.com/lexv2/latest/dg/using-intent-confidence-scores.html",
          "excerpts": [
            "To determine the difference between two intents within an interpretation, you can compare their confidence scores."
          ]
        },
        {
          "title": "Why is softmax output not a good uncertainty measure for ...",
          "url": "https://stats.stackexchange.com/questions/309642/why-is-softmax-output-not-a-good-uncertainty-measure-for-deep-learning-models",
          "excerpts": [
            "Oct 24, 2017 — In classification, predictive probabilities obtained at the end of the pipeline (the softmax output) are often erroneously interpreted as model ..."
          ]
        },
        {
          "title": "How and When to Use a Calibrated Classification Model ...",
          "url": "https://www.machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/",
          "excerpts": [
            "Sep 25, 2019 — Platt Scaling is most effective when the distortion in the predicted probabilities is sigmoid-shaped. Isotonic Regression is a more powerful ..."
          ]
        },
        {
          "title": "How to use classification threshold to balance precision ...",
          "url": "https://www.evidentlyai.com/classification-metrics/classification-threshold",
          "excerpts": [
            "Jan 9, 2025 — This chapter explains the trade-off between precision and recall and how to set an optimal classification threshold to balance them."
          ]
        },
        {
          "title": "The Four Core Types of Searches—Plus Emerging Ones ... - Slack",
          "url": "https://slack.com/blog/productivity/the-four-core-types-of-searches-plus-emerging-ones-you-should-know",
          "excerpts": [
            "This article will cover the four primary search types, including navigational, informational, transactional, and commercial."
          ]
        },
        {
          "title": "Local Pack SEO: What Is It & How to Rank for It?",
          "url": "https://www.highervisibility.com/seo/learn/local-pack-seo/",
          "excerpts": [
            "May 9, 2025 — Learn what the local pack is and how to rank in the prime position on the search results for local queries—the map pack."
          ]
        },
        {
          "title": "Intent classification and slot filling: managing web pages with natural ...",
          "url": "https://medium.com/geekculture/intent-classification-and-slot-filling-managing-web-pages-with-natural-language-4d21d5cee4e3",
          "excerpts": [
            "Intent classification is the automated categorization of text queries based on customer goals. In essence, an intent classifier automatically ..."
          ]
        },
        {
          "title": "4 Types of Keywords in SEO (+ Examples) - Semrush",
          "url": "https://www.semrush.com/blog/types-of-keywords-commercial-informational-navigational-transactional/",
          "excerpts": [
            "Missing: tie- breaker"
          ]
        },
        {
          "title": "Query Classification - Intent Question (impossible/minor/primary)",
          "url": "https://www.reddit.com/r/TELUSinternational/comments/1f0fgiu/query_classification_intent_question/",
          "excerpts": [
            "Missing: tie- breaker"
          ]
        },
        {
          "title": "Using Confidence Scores - Amazon Lex V1",
          "url": "https://docs.aws.amazon.com/lex/latest/dg/confidence-scores.html",
          "excerpts": [
            "To determine the difference between two alternative intents, you can compare their confidence scores. For example, if one intent has a confidence score of 0.95 ..."
          ]
        },
        {
          "title": "Intent Classification | Reference documentation",
          "url": "https://developers.teneo.ai/documentation/7.5.0/reference/conceptual-overviews/intent-classification",
          "excerpts": [
            "Teneo Predict creates annotations for the most probable intent(s) and denotes these with a confidence score. Intent classification in Teneo is designed to ..."
          ]
        },
        {
          "title": "Platt scaling, isotonic regression, and beta calibration. - Abzu.ai",
          "url": "https://www.abzu.ai/data-science/calibration-introduction-part-2/",
          "excerpts": [
            "Calibrators are tools used to transform the scores generated by your models into (almost) real mathematical probabilities. · Platt scaling. · Isotonic regression."
          ]
        },
        {
          "title": "Improving model performance through human participation",
          "url": "https://www.kdnuggets.com/2021/04/improving-model-performance-through-human-participation.html",
          "excerpts": [
            "Apr 23, 2021 — A precision-recall-threshold curve is a great tool in choosing the threshold for human review and automated model decisions. Involving human ..."
          ]
        },
        {
          "title": "Adaptive Sparse Softmax: An Effective and Efficient ...",
          "url": "https://arxiv.org/html/2508.03175v1",
          "excerpts": [
            "Aug 5, 2025 — Experiments show that AS-Softmax consistently improves the performance of text classification and alleviates overfitting to a large extent. In ..."
          ]
        },
        {
          "title": "How People Search",
          "url": "https://www.searchenginejournal.com/seo/how-people-search/",
          "excerpts": [
            "Dominant Interpretations. The dominant interpretation is what most users mean when they search for a specific query. Google search raters are ...",
            "Queries With Multiple Meanings\nDue to the diversity of language, many queries have more than one meaning. For example, [apple] can either be a consumer electrical goods brand or a fruit. Google handles this issue by classifying the query by its interpretation. The interpretation of the query can then be used to define intent.",
            "Dominant Interpretations\nThe dominant interpretation is what most users mean when they search for a specific query. Google search raters are told explicitly that the dominant interpretation should be clear, even more so after further online research.",
            "Common Interpretations\nAny given query can have multiple common interpretations. Google’s example in its guidelines is [mercury] – which can mean either the planet or the element. In this instance, Google can’t provide a result that “Fully Meets” a user’s search intent, but instead, it produces results varying in both interpretation and intent (to cover all bases).",
            "Minor Interpretations\nA lot of queries will also have less common interpretations, and these can often be locale-dependent. It can also be possible for minor interpretations to become dominant interpretations should real-world events force enough public interest in the changed interpretation.",
            "Do – Know – Go\nDo, Know, Go is a concept that search queries can be segmented into three categories: Do, Know, and Go. These classifications then, to an extent, determine the type of results that Google delivers to its users.",
            "Do (Transactional Queries)\nWhen users perform a “do” query , they want to achieve a specific action, such as purchasing a specific product or booking a service. This is important to ecommerce websites, for example, where a user may be looking for a specific brand or item. Device action queries are also a form of a “do” query and are becoming more and more important, given how we interact with our smartphones and other technologies."
          ]
        },
        {
          "title": "What Are SERP Features? Types & How to Optimize for Them",
          "url": "https://www.semrush.com/blog/serp-features-guide/",
          "excerpts": [
            "What Are SERP Features? Types & How to Optimize for Them",
            "SERP features are distinct search results that stand out from traditional organic (unpaid) search results (the blue links) that aim to improve the user experience by providing quick answers and additional information directly on results pages. And they can take several forms.",
            "AI Overviews\nGoogle’s AI Overviews are short, AI-generated summaries pulled from top-ranking pages that appear at the top of SERPs—above every other type of result. This SERP feature can show for any type of query. But you’ll see it more often for “what is/are [keyword/topic]” keywords and other informational queries.",
            "\n3. Popular Products\nPopular products carousels show products related to a user’s search query when relevant and include images, prices, ratings, and links to the corresponding product pages"
          ]
        },
        {
          "title": "Search Quality Guidelines: How Raters Review Sites | E10K",
          "url": "https://www.elevation10k.com/blog/search-quality-rater-guidelines/",
          "excerpts": [
            "Some queries are ambiguous and could have different intents. A search for [Walmart], for example, could be a Visit-in-person or Website query."
          ]
        },
        {
          "title": "Google Search Quality Rater Guidelines - MarketMuse Blog",
          "url": "https://blog.marketmuse.com/google-search-quality-rater-guidelines-how-google-evaluates-your-site/",
          "excerpts": [
            "Dominant Interpretation: this is the interpretation that the vast majority of users meant when they typed their query. · Common Interpretation: ..."
          ]
        },
        {
          "title": "We Asked ChatGPT to Audit Google's Search Quality ...",
          "url": "https://rankfuse.com/blog/when-ai-audits-googles-own-search-quality-guidelines/",
          "excerpts": [
            "For those of you who are not familiar, Google has a 170-page “Search Quality Evaluator Guidelines” PDF. They started to publicly release ..."
          ]
        },
        {
          "title": "Google's Search Quality Evaluators Guidelines Cliff Notes + ...",
          "url": "https://hookagency.com/blog/search-quality/",
          "excerpts": [
            "A very helpful result for a dominant interpretation should be rated Highly Meets , because it is very helpful for many or most users. Some ..."
          ]
        },
        {
          "title": "Set your Classify confidence score | Zonos Docs",
          "url": "https://zonos.com/docs/supply-chain/classify/features/confidence-score",
          "excerpts": [
            "The confidence score in Classify is a numerical value between 0% and 100%, expressed as a decimal, meant to represent a classification's level of certainty . This score is determined using entropy, a method from information theory that measures uncertainty or randomness in the data."
          ]
        },
        {
          "title": "What Does Softmax Probability Tell Us about Classifiers ...",
          "url": "https://arxiv.org/abs/2406.09908",
          "excerpts": [
            "by W Tu · 2024 · Cited by 3 — We commence by demonstrating that conventional uncertainty metrics, notably the maximum Softmax prediction probability, possess inherent ..."
          ]
        },
        {
          "title": "SEO Zoom – Google Search Quality Rater Guidelines (summary)",
          "url": "https://www.seozoom.com/google-search-quality-rater-guidelines/",
          "excerpts": [
            "For this reason, a more rigorous check on the\nambiguities of the results is required, to avoid sub-optimal pages from still being classified with high scores simply because they contain keywords in line with the query.",
            "The evaluation of the quality of a web page takes into account various factors that determine the reliability, usefulness and relevance of the content.",
            "A practical example concerns the term\n“mercury” : a user could be looking for information on the chemical element, on the plant Mercurialis or on the planet in the solar system.",
            "quality rater can evaluate it with a lower score.",
            "s to quality raters to help them distinguish between\nresults that are truly useful and pages that, although technically relevant, do not fully satisfy the user’s needs."
          ]
        },
        {
          "title": "Google Search Quality Guidelines: What You Need to Know",
          "url": "https://www.thehoth.com/blog/google-search-quality-guidelines/",
          "excerpts": [
            "Nov 28, 2022 — Dominant interpretations are what most users would mean when typing a query. Common ones are what many users would expect to find from a query, ..."
          ]
        },
        {
          "title": "The 4 Types of Search Intent (And How To Optimize Your Content)",
          "url": "https://www.flow.ninja/blog/search-intent-types",
          "excerpts": [
            "Informational Intent This is when someone is seeking information or knowledge. · Navigational Intent This is when someone is trying to find a ..."
          ]
        },
        {
          "title": "Identifying ambiguous queries in web search",
          "url": "https://dl.acm.org/doi/10.1145/1242572.1242749",
          "excerpts": [
            "It is widely believed that some queries submitted to search engines are by nature ambiguous (e.g., java, apple). However, few studies have investigated the ..."
          ]
        },
        {
          "title": "[PDF] AmbigQA: Answering Ambiguous Open-domain Questions",
          "url": "https://aclanthology.org/2020.emnlp-main.466.pdf",
          "excerpts": [
            "Table 1: Breakdown of the types of ambiguity in 100 randomly sampled items from the AMBIGNQ development data. Each example may fall into multiple categories."
          ]
        },
        {
          "title": "README.md · sewon/ambig_qa at ...",
          "url": "https://huggingface.co/datasets/sewon/ambig_qa/blame/6e667596df70f17ba3c8e7be4b7361f6be8b60f8/README.md",
          "excerpts": [
            "AMBIGNQ, a dataset with 14,042 annotations on NQ-OPEN questions containing diverse types of ambiguity. We provide two distributions of our new dataset AmbigNQ: ..."
          ]
        },
        {
          "title": "A Baseline for Detecting Misclassified and Out-of- ...",
          "url": "https://arxiv.org/pdf/1610.02136",
          "excerpts": [
            "by D Hendrycks · 2016 · Cited by 4597 — Table 1: The softmax predicted class probability allows for discrimination between correctly and incorrectly classified test set examples. “ ..."
          ]
        },
        {
          "title": "A benchmark for out-of-distribution detection in medical ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S1386505624004258",
          "excerpts": [
            "by M Azizmalayeri · 2025 · Cited by 5 — Uses maximum softmax probability as a simple but effective baseline. MLS [54], Uses the maximum logit score instead of MSP. TempScale [57], Calibrates the ..."
          ]
        },
        {
          "title": "GEN: Pushing the Limits of Softmax-Based Out-of-Distribution ...",
          "url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_GEN_Pushing_the_Limits_of_Softmax-Based_Out-of-Distribution_Detection_CVPR_2023_paper.pdf",
          "excerpts": [
            "by X Liu · 2023 · Cited by 124 — [14] proposes the maximum predicted soft- max probability (MSP) and thereby establishes an initial baseline for such scores."
          ]
        },
        {
          "title": "Comprehensive Bench-marking of Entropy and Margin ...",
          "url": "https://arxiv.org/html/2311.16302",
          "excerpts": [
            "Other inputs include, but are not limited to, intent classifier and token recognition scores. In general, a hypothesis with the correct domain ..."
          ]
        },
        {
          "title": "SERP Features in 2023: 23 Examples & Best Ways to Optimize",
          "url": "https://purevisibility.com/serp-features-defined/",
          "excerpts": [
            "Learn about the Search Engine Results Page (SERP) on Google, view examples, best practices & ways you can optimize to get into SERP features."
          ]
        },
        {
          "title": "A guide to Google's 2023 SERPs features & how to appear for them",
          "url": "https://www.tdmp.co.uk/insights/guide-googles-2023-serps-features-how-appear-them",
          "excerpts": [
            "Here are some of the most common Google SERP features and our tips on how to optimise your content to appear in them."
          ]
        },
        {
          "title": "AI Overview Study: How User Intent Drives AIO ...",
          "url": "https://www.authoritas.com/blog/ai-overview-user-intent-research",
          "excerpts": [
            "2024 marked a transformative year for AI Overviews in search, but we anticipate 2025 will reveal their true impact on the search landscape."
          ]
        },
        {
          "title": "Quality Rater Guidelines 2023: Whats new?",
          "url": "https://www.kopp-online-marketing.com/quality-rater-guidelines-2023",
          "excerpts": [
            "Nov 16, 2023 — A less helpful result for a dominant, common or reasonable minor interpretation/user intent Slightly Meets (SM) OR very helpful for some users."
          ]
        },
        {
          "title": "Distribution of scores of the unknown class for Maximum ...",
          "url": "https://www.researchgate.net/figure/Distribution-of-scores-of-the-unknown-class-for-Maximum-Softmax-Probability-MSP-and-our_fig1_361768267",
          "excerpts": [
            "The scores of the unknown class for novel classes are low in MSP (a), meaning the closedset prediction classifies novel classes as old classes with high ..."
          ]
        },
        {
          "title": "Accuracy and Entropy Reduction in Incremental Intent ...",
          "url": "https://aclanthology.org/2021.nlp4convai-1.6.pdf",
          "excerpts": [
            "by L Hrycyk · 2021 · Cited by 4 — Incremental intent classification requires the assignment of intent labels to partial utter- ances. However, partial utterances do not."
          ]
        },
        {
          "title": "Multimodal Classification and Out-of-distribution Detection ...",
          "url": "https://arxiv.org/html/2412.12453v1",
          "excerpts": [
            "We establish baselines for three multimodal intent datasets and build an OOD benchmark. Extensive experiments on these datasets demonstrate that ..."
          ]
        },
        {
          "title": "AmbigQA: Answering Ambiguous Open-domain Questions",
          "url": "https://huggingface.co/datasets/sewon/ambig_qa",
          "excerpts": [
            "AmbigNQ, a dataset covering 14,042 questions from NQ-open, an existing open-domain QA benchmark.\nWe find that over half of the questions in NQ-open are ambiguous. The types of ambiguity are diverse and sometimes subtle, many of which are only apparent after examining evidence provided by a very large text corpus. AMBIGNQ, a dataset with\n14,042 annotations on NQ-OPEN questions containing diverse types of ambiguity. We provide two distributions of our new dataset AmbigNQ: a `full` version with all annotation metadata and a `light` version with only inputs and outputs."
          ]
        },
        {
          "title": "6.6 STL decomposition | Forecasting: Principles and ...",
          "url": "https://otexts.com/fpp2/stl.html",
          "excerpts": [
            "STL is an acronym for “Seasonal and Trend decomposition using Loess”.",
            "STL is a versatile and robust method for decomposing time series. STL is an acronym for “Seasonal and Trend decomposition using Loess”."
          ]
        },
        {
          "title": "Seasonal-Trend decomposition using LOESS (STL)",
          "url": "https://www.statsmodels.org/dev/examples/notebooks/generated/stl_decomposition.html",
          "excerpts": [
            "This note book illustrates the use of\n`STL` to decompose a time series into three components: trend, season(al) and residual. STL uses LOESS (locally estimated scatterplot smoothing) to extract smooths estimates of the three component",
            "The key inputs into `STL` are:\n\n* \n  `season` \\- The length of the seasonal smoother. Must be odd. * \n  `trend` \\- The length of the trend smoother, usually around 150% of `season` . Must be odd and larger than `season` . * \n  `low_pass` \\- The length of the low-pass estimation window, usually the smallest odd number larger than the periodicity of the data. First we import the required packages, prepare the graphics environment, and prepare the da",
            "The decomposition requires 1 input, the data series. If the data series does not have a frequency, then you must also specify `period` . The default value for `seasonal` is 7, and so should also be changed in most applications.",
            "The example in Cleveland, Cleveland, McRae, and Terpenning (1990) uses CO2 data, which is in the list below. This monthly data (January 1959 to December 1987) has a clear trend and seasonality across the sample.",
            "from statsmodels.tsa.seasonal import STL",
            "stl = STL ( co2 , seasonal = 13 )",
            "res = stl . fit ()",
            "fig = res . plot ()"
          ]
        },
        {
          "title": "statsmodels.tsa.forecasting.stl.STLForecast",
          "url": "https://www.statsmodels.org/dev/generated/statsmodels.tsa.forecasting.stl.STLForecast.html",
          "excerpts": [
            "Model-based forecasting using STL to remove seasonality. Forecasts are produced by first subtracting the seasonality estimated using STL."
          ]
        },
        {
          "title": "Seasonal Decomposition of a Time Series (STL) - Saturn Cloud",
          "url": "https://saturncloud.io/glossary/stl/",
          "excerpts": [
            "Seasonal Adjustment: The STL method can be used to adjust the seasonal component for additive, multiplicative, or seasonal adjustment with respect to a reference period , providing more accurate and meaningful seasonal measures."
          ]
        },
        {
          "title": "Demystifying STL: Understanding Seasonal ...",
          "url": "https://medium.com/@kis.andras.nandor/demystifying-stl-understanding-seasonal-decomposition-of-time-series-d3c50150ec12",
          "excerpts": [
            "Introduction to STL Decomposition  STL is a powerful tool that breaks down your time series data into three components: trend, seasonality, and noise (remainder) . This decomposition helps you understand underlying patterns and make more informed decisions.",
            "The seasonal parameter specifies the periodicity of the seasonality (12 for monthly data). # Applying STL decomposition stl = STL(data ..."
          ]
        },
        {
          "title": "Seasonal-Trend decomposition using LOESS—ArcGIS Insights",
          "url": "https://doc.arcgis.com/en/insights/latest/analyze/stl.htm",
          "excerpts": [
            "The STL method uses locally fitted regression models to decompose a time series into trend, seasonal, and remainder components."
          ]
        },
        {
          "title": "3.6 STL decomposition | Forecasting: Principles and ...",
          "url": "https://otexts.com/fpp3/stl.html",
          "excerpts": [
            "The STL method was developed by R. B. Cleveland et al. (1990), and later extended to handle multiple seasonal patterns by Bandara et al. (2022). STL ...",
            "STL is a versatile and robust method for decomposing time series. STL is an acronym for “Seasonal and Trend decomposition using Loess”."
          ]
        },
        {
          "title": "STR: A Seasonal-Trend Decomposition Procedure Based ...",
          "url": "https://www.monash.edu/business/ebs/research/publications/ebs/wp13-15.pdf",
          "excerpts": [
            "by A Dokumentov · 2015 · Cited by 86 — A different approach was followed by Cleveland et al. (1990) who developed STL (Seasonal-. Trend decomposition using Loess) which has become ..."
          ]
        },
        {
          "title": "[PDF] Seasonal Adjustment by X-13ARIMA-SEATS in R - CRAN",
          "url": "https://cran.r-project.org/package=seasonal/vignettes/seas.pdf",
          "excerpts": [
            "The canonical reference for X-13 is the official manual by the US Census. Bureau (2017), which describes all available options and outputs in detail, and which ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/X-13ARIMA-SEATS",
          "excerpts": [
            "X-13ARIMA-SEATS, successor to X-12-ARIMA and X-11, is a set of statistical methods for seasonal adjustment and other descriptive analysis of time series data"
          ]
        },
        {
          "title": "The X13 Procedure",
          "url": "https://support.sas.com/documentation/onlinedoc/ets/151/x13.pdf",
          "excerpts": [
            "The X13 procedure is an adaptation of the US Bureau of the Census X-13ARIMA-SEATS seasonal adjustment program (US Bureau of the Census 2013c).",
            "RegARIMA level change outlier component. A8TC ... table shows that three additive outliers and a level-shift have been included in the regression model."
          ]
        },
        {
          "title": "gretl and X-13ARIMA-SEATS",
          "url": "https://gretl.sourceforge.net/x12a/x13as.html",
          "excerpts": [
            "X-13ARIMA-SEATS is the program currently used by the US Census Bureau for seasonal adjustment. The home page for this program is at www.census.gov."
          ]
        },
        {
          "title": "X_13ARIMA_SEATS: X-13ARIMA-SEATS Seasonal Adjustment",
          "url": "https://www.rdocumentation.org/packages/feasts/versions/0.3.0/topics/X_13ARIMA_SEATS",
          "excerpts": [
            "X-13ARIMA-SEATS is a seasonal adjustment program developed and maintained by the U.S. Census Bureau."
          ]
        },
        {
          "title": "x13as - the X-13ARIMA-SEATS Seasonal Adjustment Program",
          "url": "https://manpages.ubuntu.com/manpages/jammy/man1/x13as.1.html",
          "excerpts": [
            "The reference manual of X-13ARIMA-SEATS is available at: https://www2.census.gov/software/x-13arima- seats/x13as/unix-linux/documentation/docx13as.pdf ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Seasonal Adjustment — X_13ARIMA_SEATS",
          "url": "https://feasts.tidyverts.org/reference/X_13ARIMA_SEATS.html",
          "excerpts": [
            "This decomposition method can extract seasonality from data with seasonal periods of 2 (biannual), 4 (quarterly), 6 (bimonthly), and 12 (monthly)."
          ]
        },
        {
          "title": "1.3.5.17. Detection of Outliers",
          "url": "https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm",
          "excerpts": [
            "These authors recommend that modified Z-scores with an absolute value of greater than 3.5 be labeled as potential outliers. Formal Outlier Tests, A number of ..."
          ]
        },
        {
          "title": "(IQR Formula) The Interquartile Range Method For Outliers",
          "url": "https://procogia.com/interquartile-range-method-for-reliable-data-analysis/",
          "excerpts": [
            "The IQR method offers a simple yet effective approach for outlier detection, identifying data points that deviate significantly from the majority. The steps ..."
          ]
        },
        {
          "title": "Outlier detection in R: Tukey Method or why you need “box and ...",
          "url": "https://medium.com/data-and-beyond/outlier-detection-in-r-tukey-method-or-why-you-need-box-and-whiskers-3c35d9ad8fb3",
          "excerpts": [
            "Tukey's rule is pretty straightforward. You take the IQR and multiply it by a factor — typically 1.5 (for a mild outlier) or e.g. 3 (for an extreme outlier) . These factors are like the bouncers of your data club; they decide who's too far out to be allowed in."
          ]
        },
        {
          "title": "What is a Modified Z-Score? (Definition & Example) - Statology",
          "url": "https://www.statology.org/modified-z-score/",
          "excerpts": [
            "Iglewicz and Hoaglin recommend that values with modified z-scores less than -3.5 or greater than 3.5 be labeled as potential outliers. The ..."
          ]
        },
        {
          "title": "Iglewicz and Hoaglin outlier test with modified z-scores",
          "url": "https://stats.stackexchange.com/questions/339932/iglewicz-and-hoaglin-outlier-test-with-modified-z-scores-what-should-i-do-if-t",
          "excerpts": [
            "The Iglewicz and Hoaglin outlier test which creates a modified z-score M i for every value in the list and check it against an threshold (normally 3.5 )."
          ]
        },
        {
          "title": "Z-Score and Modified Z-Score. Outlier Detection Techniques in Data…",
          "url": "https://medium.com/@fawwazmts/z-score-and-modified-z-score-f689296e4d3a",
          "excerpts": [
            "Using the modified z-score, an observation is considered a potential outlier if it falls more than 3.5 MAD from the median, i.e. | mzᵢ | > 3.5."
          ]
        },
        {
          "title": "5.5 Resolve Outliers | Practitioner's Guide to Data Science",
          "url": "https://scientistcafe.com/ids/outliers",
          "excerpts": [
            "Iglewicz and Hoaglin proposed to use the modified Z-score to determine the outlier (Iglewicz and Hoaglin 1993)：. \\[M_{i}=\\frac{0.6745(Y_{i}-\\bar{Y})}{MAD}\\]."
          ]
        },
        {
          "title": "A note on detecting statistical outliers in psychophysical data",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC6647454/",
          "excerpts": [
            "by PR Jones · 2019 · Cited by 160 — The two iqr-based methods, IQR and Tukey, exhibited high hit rates when the number of outliers was low (≤ 20%). However, as expected, hit ..."
          ]
        },
        {
          "title": "Why John Tukey set 1.5 IQR to detect outliers instead of 1 ...",
          "url": "https://math.stackexchange.com/questions/966331/why-john-tukey-set-1-5-iqr-to-detect-outliers-instead-of-1-or-2",
          "excerpts": [
            "Oct 10, 2014 — The phrasing ±1.5IQR seems to imply that something is an outlier if it's more than 1.5IQR away from the median, which is not correct."
          ]
        },
        {
          "title": "statsmodels.tsa.seasonal.STL - Documentation",
          "url": "https://www.statsmodels.org/dev/generated/statsmodels.tsa.seasonal.STL.html",
          "excerpts": [
            "\n                                                  \n                                                  \n                                                                      - \n                                                           ",
            "Start by aggregating to monthly, and filling any missing values",
            "The period (12) is automatically detected from the data’s frequency (‘M’)."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Reference Manual",
          "url": "https://www2.census.gov/software/x-13arima-seats/x13as/unix-linux/documentation/docx13ashtml.pdf",
          "excerpts": [
            "The X-13ARIMA-SEATS seasonal adjustment program is an enhanced version of the X-11 Variant of the Census. Method II seasonal adjustment program (Shiskin, ... X-13ARIMA-SEATS Reference Man",
            "The main input to X-13ARIMA-SEATS comes from a special input file called an input specification file. This\nfile contains a set of specifications or specs that give X-13ARIMA-SEATS various information about the data and\nthe desired seasonal adjustment options and output, the time series model to be used, if any, etc.",
            "X-13ARIMA-SEATS can produce point forecasts, forecast standard errors, and prediction intervals\nfrom the fitted regARIMA model.",
            "The focus in Chapters 2 through 6 is on giving an overview of the use and capabilities of the X-13ARIMA-SEATS\nprogram.",
            " Table 3.1\ndescribes the different specs that are currently available in the X-13ARIMA-SEATS program.",
            "ARIMA models, as discussed by Box and Jenkins (1976), are frequently used for seasonal time series."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Documentation and Guidelines",
          "url": "https://www.census.gov/data/software/x13as.References.html",
          "excerpts": [
            "X-13ARIMA-SEATS is a seasonal adjustment software program developed and maintained at the U.S. Census Bureau.",
            "Documentation for X-13ARIMA-SEATS and related programs",
            "Documentation, quick references, and other material useful to those who run X-13ARIMA-SEATS are given below:"
          ]
        },
        {
          "title": "STL Decomposition - Altair RapidMiner Documentation",
          "url": "https://docs.rapidminer.com/9.7/studio/operators/modeling/time_series/decomposition/stl_decomposition.html",
          "excerpts": [
            "To perform the STL decomposition, the seasonality (e.g. 12 for monthly data with a pattern reoccuring every year) of the data has to be known. Advantages of ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Seasonal Adjustment Program",
          "url": "https://www.census.gov/data/software/x13as.html",
          "excerpts": [
            "X-13ARIMA-SEATS is a seasonal adjustment software produced, distributed, and maintained by the Census Bureau.",
            "X-13ARIMA-SEATS Seasonal Adjustment Program",
            "X-13ARIMA-SEATS is seasonal adjustment software produced, distributed, and maintained by the Census Bureau. Features of X-13ARIMA-SEATS include:",
            "* Extensive time series modeling and model selection capabilities for linear regression models with ARIMA errors (regARIMA models);",
            "* The capability to generate ARIMA model-based seasonal adjustment using a version of the SEATS software originally developed by Victor Gómez and Agustín Maravall at the Bank of Spain, as well as nonparametric adjustments from the X-11 procedure;",
            "* Diagnostics of the quality and stability of the adjustments achieved under the options selected;",
            "* The ability to efficiently process many series at once.",
            "This site contains distributions of X-13ARIMA-SEATS for Windows® PC and Linux/Unix platforms, along with multiple utility programs to assist in running the program:"
          ]
        },
        {
          "title": "The X13 Procedure - OUTLIER Statement - SAS Help Center",
          "url": "https://documentation.sas.com/doc/en/pgmsascdc/9.4_3.3/etsug/etsug_x13_syntax14.htm",
          "excerpts": [
            "The OUTLIER statement specifies that the X13 procedure perform automatic detection of additive point outliers, temporary change outliers, level ..."
          ]
        },
        {
          "title": "Simple anomaly detection using MAD - Crispin Agar",
          "url": "https://crispinagar.github.io/blogs/mad-anomaly-detection.html",
          "excerpts": [
            "Apr 21, 2024 — Median Absolute Deviation (MAD) anomaly detection is a robust technique used to identify outliers or anomalous changes in a dataset."
          ]
        },
        {
          "title": "Does IQR method for outliers work for non-normal data?",
          "url": "https://stats.stackexchange.com/questions/580580/does-iqr-method-for-outliers-work-for-non-normal-data",
          "excerpts": [
            "Missing: Penn State"
          ]
        },
        {
          "title": "Seasonal threshold to reduce false positives for prediction ...",
          "url": "https://www.sciencedirect.com/science/article/abs/pii/S2352710224001074",
          "excerpts": [
            "by K Takahashi · 2024 · Cited by 13 — This research proposes using a seasonal threshold for prediction-based point outlier detection methods to accurately detect the outliers while maintaining the ..."
          ]
        },
        {
          "title": "STL and Seasonal Adjustment Methods - otexts et al.",
          "url": "https://otexts.com/fpppy/nbs/03-decomposition.html",
          "excerpts": [
            "stl = STL(us_retail_employment[ \"y\" ], period = 12 , seasonal = 13 , trend = 21 , robust = True ) res_stl = stl.fit() dcmp = pd.DataFrame({ \"ds\" : us_retail_employment[ \"ds\" ], \"data\" : us_retail_employment[ \"y\" ], \"trend\" : res_stl.trend, \"seasonal\" : res_stl.seasonal, \"remainder\" : res_stl.resid }).reset_index(drop = True ) fig, axes = plt.subplots(nrows = 4 , ncols = 1 , sharex = True , figsize = ( 8 , 6 )) sns.lineplot(data = dcmp, x = dcmp.index, y = \"data\" , ax = axes[ 0 ]) sns.lineplot(data = dcmp, x = dcmp.index, y = \"trend\" , ax = axes[ 1 ]) sns.lineplot(data = dcmp, x = dcmp.index, y = \"seasonal\" , ax = axes[ 2 ]) sns.lineplot(data = dcmp, x = dcmp.index, y = \"remainder\" , ax = axes[ 3 ]) axes[ 0 ].set_ylabel( \"Employed\" ) axes[ 1 ].set_ylabel( \"trend\" ) axes[ 2 ].set_ylabel( \"season_year\" ) axes[ 3 ].set_ylabel( \"remainder\" ) fig.suptitle( \"STL decomposition\" ) fig.subplots_adjust(top = 0.90 ) fig.text( 0.5 , 0.95 , \"Employed = trend + seasonal + random\" , ha = \"center\" ) plt.xlabel( \"\" ) plt.show()",
            "STL is an acronym for “Seasonal and Trend decomposition using Loess”, while loess is a method for estimating nonlinear relationships. The STL method was developed by Cleveland et al. ( 1990 ) , and later extended to handle multiple seasonal patterns by Bandara, Hyndman, and Bergmeir ( 2022 ) . STL has several advantages over classical decomposition, and the SEATS and X-11 methods:",
            "The seasonal component is allowed to change over time, and the rate of change can be controlled by the user. * The smoothness of the trend-cycle can also be controlled by the user. * It can be robust to outliers (i.e., the user can specify a robust decomposition), so that occasional unusual observations will not affect the estimates of the trend-cycle and seasonal components. They will, however, affect the remainder compon",
            "onality. The two main parameters to be chosen when using STL are the\nseason and the\ntrend . The\nseason is the length of the seasonal smoother, while the\ntrend is the length of the trend smoother. These parameters control how rapidly the trend-cycle and seasonal components can change.\nSmaller values allow for more rapid changes. Both trend and seasonal windows should be odd numbers. By default, the\nSTL() function in\nstatsmodels provides a convenient automated STL decomposition. This usually gives a good balance between overfitting the seasonality and allowing it to slowly change over time. But, as with any automated procedure, the default settings will need adjusting for some time series. In this case the default trend window setting produces a trend-cycle component that is too rigid. As a result, signal from the 2008 global financial crisis has leaked into the remainder component, as can be seen in the bottom panel of Figure  3.5 . Selecting a shorter trend window as in Figure  3.12 improves this."
          ]
        },
        {
          "title": "Seasonal Decomposition of Time Series by Loess (STL)",
          "url": "https://www.geeksforgeeks.org/data-analysis/seasonal-decomposition-of-time-series-by-loess-stl/",
          "excerpts": [
            "In this article, we will perform seasonal decomposition using Loess(STL) on a time-series dataset and remove the seasonality from the dataset."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Quick Reference for DOS",
          "url": "https://www2.census.gov/software/x-13arima-seats/x13as/windows/documentation/qrefx13ashtmlpc.pdf",
          "excerpts": [
            "-s : Store seasonal adjustment and regARIMA model diagnostics in a file. -t : Store timing information in the diagnostics file (if -s or -g not specified, will ..."
          ]
        },
        {
          "title": "X-13ARIMA-SEATS Reference Manual Accessible HTML ...",
          "url": "https://www.census.gov/library/working-papers/2017/adrm/docx13ashtml.html",
          "excerpts": [
            "Jan 18, 2017 — The X-13ARIMA-SEATS seasonal adjustment program is an enhanced version of the X-11 Variant of the Census Method II seasonal adjustment ..."
          ]
        },
        {
          "title": "A Basic Seasonal Adjustment Glossary",
          "url": "https://www.census.gov/data/software/x13as/references/glossary.html",
          "excerpts": [
            "Oct 8, 2021 — X-13ARIMA-SEATS (X-13A-S). Seasonal adjustment software developed by the U. S. Census Bureau in collaboration with the Bank of Spain that ..."
          ]
        },
        {
          "title": "5 Effective Uses of MAD for Outlier Detection and Analysis",
          "url": "https://www.numberanalytics.com/blog/5-uses-of-mad-for-outlier-detection",
          "excerpts": [
            "Mar 18, 2025 — Robustness to Outliers: MAD remains stable even when the dataset includes extreme values. Simplicity: The computation of MAD is straightforward, ..."
          ]
        },
        {
          "title": "Outlier Detection and Treatment: Z-score, IQR, and Robust ...",
          "url": "https://medium.com/@aakash013/outlier-detection-treatment-z-score-iqr-and-robust-methods-398c99450ff3",
          "excerpts": [
            "Robust Methods: Median Absolute Deviation (MAD). Median Absolute Deviation (MAD) is a robust statistical method that measures data variability."
          ]
        },
        {
          "title": "Identify outliers using robust median absolute deviation ...",
          "url": "https://hauselin.github.io/hausekeep/reference/outliersMAD.html",
          "excerpts": [
            "outliersMAD is used to identify outliers in vectors using Leys et al.'s (2003) median absolute deviation approach. outliersMAD(x, MADCutOff = 3.0, ..."
          ]
        },
        {
          "title": "STAT 200 Midterm Flashcards - Quizlet",
          "url": "https://quizlet.com/513803345/stat-200-midterm-flash-cards/",
          "excerpts": [
            "IQR formula. IQR = Q3 - Q1. IQR Outliers. Q1 - IQR(1.5) Q3 + IQR(1.5). In the simple linear regression equation y ^ = a + b x, what does the symbol y ^ ..."
          ]
        },
        {
          "title": "STAT 200 - Identifying Outliers: IQR Method",
          "url": "https://online.stat.psu.edu/stat200/lesson/3/3.2",
          "excerpts": [
            "Any values that fall outside of this fence are considered outliers.",
            "To build this fence we take 1.5 times the IQR and then subtract this value from Q1 and add ... 3\\.2 - Identifying Outliers: IQR Method | STAT 200 [Skip to main content](#main-content)"
          ]
        },
        {
          "title": "2.6 - Identifying outliers: IQR Method",
          "url": "https://online.stat.psu.edu/stat800/lesson/2/2.6",
          "excerpts": [
            "Any values that fall outside of this fence are considered outliers. To build this fence we take 1.5 times the IQR and then subtract this value from Q1 and add this value to Q3. This gives us the minimum and maximum fence posts that we compare each observation to. Any observations that are more than 1.5 IQR below Q1 or more than 1.5 IQR above Q3 are considered outliers."
          ]
        },
        {
          "title": "Data Imputation Demystified | Time Series Data",
          "url": "https://medium.com/@aaabulkhair/data-imputation-demystified-time-series-data-69bc9c798cb7",
          "excerpts": [
            "STL Decomposition for Time Series: This method breaks down the time series into trend, seasonality, and residuals, then imputes missing values ..."
          ]
        },
        {
          "title": "Missing Values",
          "url": "https://documentation.sas.com/doc/en/etsug/15.2/etsug_x13_details02.htm",
          "excerpts": [
            "Aug 11, 2020 — The X-13ARIMA-SEATS missing value method requires the use of a regARIMA model to replace the missing values. Thus, either an ARIMA or AUTOMDL ..."
          ]
        },
        {
          "title": "Interpolation Techniques Guide & Benefits (2025) - Analytics Vidhya",
          "url": "https://www.analyticsvidhya.com/blog/2021/06/power-of-interpolation-in-python-to-fill-missing-values/",
          "excerpts": [
            "Interpolation is mostly used while working with time-series ... Time-series(datetime) data is data that follows some special trend or seasonality."
          ]
        },
        {
          "title": "Data Provenance Vs. Data Lineage: What's The Difference?",
          "url": "https://www.montecarlodata.com/blog-data-provenance-vs-data-lineage-difference/",
          "excerpts": [
            "Missing: QA month-"
          ]
        },
        {
          "title": "A Business Guide to Data Provenance",
          "url": "https://cohere.com/blog/data-provenance",
          "excerpts": [
            "Mar 10, 2025 — While audit logs can show you who accessed what and when, provenance goes deeper. It captures how data transforms, why changes happen, and how ..."
          ]
        },
        {
          "title": "Validate data freshness with GX",
          "url": "https://docs.greatexpectations.io/docs/reference/learn/data_quality_use_cases/freshness",
          "excerpts": [
            "Checking for data freshness may also center on validating how old the data is. This Expectation can be used on a timestamp column to validate the minimum, or ..."
          ]
        },
        {
          "title": "time series - Right Way to Extrapolate Data - Cross Validated",
          "url": "https://stats.stackexchange.com/questions/327454/right-way-to-extrapolate-data",
          "excerpts": [
            "Feb 8, 2018 — Time series analysis listens to the data , challenges unusual values , detects nuances and separates the observations to signal (fitted values) ..."
          ]
        },
        {
          "title": "Annualize - Overview, Benefits, APR, EAC",
          "url": "https://corporatefinanceinstitute.com/resources/financial-modeling/annualize/",
          "excerpts": [
            "To annualize is to convert a short-term or partial period result into an annual basis. · The six-month growth rate of 0.90% converts to 1.81% per year."
          ]
        },
        {
          "title": "statistics - Trying to extrapolate info from a partial data set",
          "url": "https://datascience.stackexchange.com/questions/118801/trying-to-extrapolate-info-from-a-partial-data-set-statistical-inference",
          "excerpts": [
            "Feb 25, 2023 — Bayes' theorem is a way of conducting statistical inference based on conditional probability. It might be useful to frame your problem as statistical inference."
          ]
        },
        {
          "title": "r - Extrapolating time series",
          "url": "https://stackoverflow.com/questions/36848569/extrapolating-time-series",
          "excerpts": [
            "Looking 10 years into the future, create a date sequence for the next 10 years and store as a dataframe (required for the predict command)"
          ]
        },
        {
          "title": "Annualize: Definition, Formulas, and Examples - Investopedia",
          "url": "https://www.investopedia.com/terms/a/annualize.asp",
          "excerpts": [
            "Annualizing is simply transforming a short-term rate, return, or value into an annual one. For example, you could convert a daily, monthly, or quarterly figure ..."
          ]
        },
        {
          "title": "How do I compare a current partial month vs a previous partial month with Postgres",
          "url": "https://stackoverflow.com/questions/44727884/how-do-i-compare-a-current-partial-month-vs-a-previous-partial-month-with-postgr",
          "excerpts": [
            "I'm building some basic reports and I want to see if I'm on track to surpass last month's metrics without waiting for the month to end. Basically I want to compare June 1 (start of current month) through June 23 (current\\_date) against May 1 (start of previous month) through May 23 (current\\_date - 1 month). **My goal is to show a count of distinct users that did event1 and event2.",
            "SELECT \n  month,\n  week,\n  count(*) as total_engagement\nFROM (\n  SELECT\n    extract(month from created_at) as month,\n    extract('day' from date_trunc('week', created_at::date) -\n                   date_trunc('week', date_trunc('month', created_at::date))) / 7 + 1 as week\n  FROM public.event\n  WHERE type IN ('event1', 'event2')\n    AND created_at > now() - interval '1 month'\n  ) t\nGROUP BY 1,2\n"
          ]
        },
        {
          "title": "Creating a Partial Period Projection for a Metric",
          "url": "https://help.metricinsights.com/m/Creating_Basic_Metrics_and_Reports/l/104390-creating-a-partial-period-projection-for-a-metric",
          "excerpts": [
            "This article describes how to create a Partial Period Projection within Metric Insights. Partial Period Projections predict the results for the end of the current period based on both of the following:",
            "1. A basic “Linear Regression\":  Typically employed when the Metric’s values accrue in a linear fashion through the specified Measurement Interva",
            "r\n\n4. Calculation Formulas\n",
            "There are two supported methods available for computing a Partial Period Projection by deriving it using:",
            "There are two supported methods available for computing a Partial Period Projection by deriving it using:",
            "### 4.1. Linear Regression Projection Formula",
            "The following algorithm is used to compute the Linear Regression for a Partial-Period data point. This formula computes the residual amount that is projected to be accumulated for the metric during the remained for the period. **Formula Components:**",
            "* Measurement Days (MD):  The number of full days that have elapsed in the ‘Measurement Interval’ up to the date/time that the measurement was take",
            "* Total Period Days (TPD):  The total number of days in the measurement interval perio",
            "* Residual Projected Value (RPV) =  MV x ((TPD/MD) – 1",
            "### 4.2. Historical Trend Projection Formula",
            "The Projection calculation is based on the distribution of values for the metric in the reference period. This approach applies when the distribution of values within a period is non-linear. For example, there is a weekly pattern to sales in which certain days of the week generate higher sales.",
            "* Measurement Value (MV): The partial-period value collected for the metric",
            "* Measurement Value (MV): The partial-period value collected for the metric",
            "* Prior Period Total Value (PPMV):  The complete period measurement value that was recorded in the reference prior period; e.g., same month last yea",
            "* Prior Period To Date  Measured Value (PPTDMV):  The Partial-Period measurement value that was recorded in the reference prior period the same number of days into the period as the measurement is in the current peri",
            "* Residual projected value (RPV) =  MV x ((PPMV/PPTDMV) – 1",
            "* Projected Value for the Period (PV) = MV + RPV",
            "* Projected Value for the Period (PV) = MV + RPV"
          ]
        },
        {
          "title": "Real Statistics: Handling Missing Seasonal Time Series Data",
          "url": "https://real-statistics.com/time-series-analysis/stochastic-processes/handling-missing-time-series-data/handling-missing-seasonal-time-series-data/",
          "excerpts": [
            "H.\n\n**Deseasonalizing**\n-------------------\n\nIn this approach, the data is deseasonalized using the seasonality period. E.g. if the seasonality period is *per* = 4, then the time series y1, y2, …, y*n* is replaced by *z*1, …, *z**n*-4 where *zi* = y*i* + 4 – y*i*. If either y*i*+4 or y*i* is missing then *zi* is considered missing. Any such missing *zi* is now imputed as described previously using the imputation approach specified by *itype* (as described in [Handling Missing Time Series Data](https://real-statistics.com/time-series-analysis/stochastic-processes/handling-missing-time-series-data/)). The original time series y*i* is now restored by reseasonalizing using the imputed *zi* values. This approach requires that the first *per* elements of the original time series are not missing (in order to reseasonalize). If one of these values is missing, we use the split seasonality approach to impute any of the missing elements among the first *per* elements in y*i*. We illustrate this approach for the same time series shown in Figure 2. ",
            "**Figure 1 – Seasonality Imputation**",
            "This approach is straightforward. If there are say 4 seasons then the time series is treated as 4 separate time series, one for each season. Imputation for each of these separated time series is then performed based on the selected imputation approach from Figure 1 of [Handling Missing Time Series Data](https://real-statistics.com/time-series-analysis/stochastic-processes/handling-missing-time-series-data/).",
            "If a time series has a seasonal component, then we can combine one of the imputation approaches described in Figure 1 of [Handling Missing Time Series Data](https://real-statistics.com/time-series-analysis/stochastic-processes/handling-missing-time-series-data/) with either deseasonalizing or split seasonal imputation (as shown in Figure 1) based on the seasonality period (i.e. 4 for quarterly, 12 for monthly, etc.)."
          ]
        },
        {
          "title": "Missing data and outliers",
          "url": "https://otexts.com/fpp2/missing-outliers.html",
          "excerpts": [
            "For seasonal data, an STL decomposition is used to estimate the seasonal component, and the seasonally adjusted series are linear interpolated.",
            "Outliers are observations that are very different from the majority of the observations in the time series.",
            "In this case, we may wish to replace them with missing values, or with an estimate that is more consistent with the majority of the data.",
            " More sophisticated missing value interpolation is provided in the imputeTS package",
            "For non-seasonal data like this, simple linear interpolation is used to fill in the missing sections."
          ]
        },
        {
          "title": "Stratified Random Sampling In Evaluation - Eval Academy",
          "url": "https://www.evalacademy.com/articles/stratified-random-sampling-in-evaluation",
          "excerpts": [
            "Rather than randomly selecting from a pool of all members of a population (as in random sampling), stratified sampling divides the population of interest into distinct subgroups or strata based on designated characteristics . With the population stratified, a random sample is taken from each of the stratum."
          ]
        },
        {
          "title": "Math 408 - Lecture 20-21: Neyman Allocation and Stratified Sampling",
          "url": "http://www.its.caltech.edu/~zuev/teaching/2013Spring/Math408-Lecture-20-21.pdf",
          "excerpts": [
            "Neyman allocation is always better than proportional allocation. (since Neyman allocation is optimal).",
            "Neyman Allocation and its properties",
            "Neyman allocation scheme minimizes  \nvarian"
          ]
        },
        {
          "title": "6.2.1. Cochran's Sample Size Formula",
          "url": "https://www.myrelab.com/learn/sample-size",
          "excerpts": [
            "Cochran's formula computes sample size for infinite populations using: n0=z2⋅p⋅(1−p)e2, where e is precision, p is the attribute fraction, and z is a z-value.",
            "Then we consider a 95% confidence level (leading to an α α =0.05) and a ±5% precision. From the z-tables, the value for z is 1.96. Therefore, the ...See more"
          ]
        },
        {
          "title": "11.2.1 - Bootstrapping Methods",
          "url": "https://online.stat.psu.edu/stat500/book/export/html/619",
          "excerpts": [
            "Once we find the bootstrap sample, we can create a confidence interval. For a 90% confidence interval, for example, we would find the 5th percentile and the 95 ..."
          ]
        },
        {
          "title": "Change timezone in Google Search Console",
          "url": "https://webmasters.stackexchange.com/questions/125623/change-timezone-in-google-search-console",
          "excerpts": [
            "Search Console timestamps data according to Pacific Daylight Time. PDT is UTC-07:00. (\"Pacific Standard Time\" (PST) is UTC-08:00). However ..."
          ]
        },
        {
          "title": "What is Average position in Google Search Console?",
          "url": "https://www.dataflo.io/metricbase/average-position",
          "excerpts": [
            "The average position shows the average ranking of a set of keywords in Google search results. It is used to measure the performance of a website."
          ]
        },
        {
          "title": "Timezone used in Search Console reporting - Google Help",
          "url": "https://support.google.com/webmasters/thread/10467744/timezone-used-in-search-console-reporting?hl=en",
          "excerpts": [
            "The Google Ads dashboard reports data in the MCC account's local timezone and the Search Console reports data in the local timezone of California."
          ]
        },
        {
          "title": "Performance report Google Search Console: My guide",
          "url": "https://ralfvanveen.com/en/seo/my-guide-to-the-google-search-console-performance-report/",
          "excerpts": [
            "Apr 26, 2024 — The performance report in Google Search Console provides detailed information about a website's performance in Google's search results."
          ]
        },
        {
          "title": "Bland-Altman Plot: Assessing Agreement",
          "url": "https://datatab.net/tutorial/bland-altman-plot",
          "excerpts": [
            "Bland-Altman plots, also known as difference plots, are a powerful graphical tool for comparing two measurement techniques and assessing the agreement between ..."
          ]
        },
        {
          "title": "Understand metrics from the Google Search Console ...",
          "url": "https://knowledge.hubspot.com/content-strategy/understand-metrics-in-the-google-search-console-integration",
          "excerpts": [
            "Apr 2, 2024 — What do the Google Search Console metrics mean? · Total pages: the number of pages detected by Google Search Console. · Total impressions: the ..."
          ]
        },
        {
          "title": "What Does Average Position Mean in Google Search ...",
          "url": "https://seotesting.com/google-search-console/average-position/",
          "excerpts": [
            "The average position value is the average rank in the Search Engine Result Pages (SERPs) for the given time period selected in Google Search Console."
          ]
        },
        {
          "title": "Mastering Google Search Console: Performance Data Guide",
          "url": "https://www.seerinteractive.com/insights/google-search-console-performance-data-guide",
          "excerpts": [
            "Mar 10, 2020 — Simply put, metrics refer to numerical, quantitative search data. In Google Search Console, there are four core metrics: Impressions; Clicks ..."
          ]
        },
        {
          "title": "Google Search Console: Metrics and their definitions",
          "url": "https://support.reportgarden.com/en/articles/5217068-google-search-console-metrics-and-their-definitions",
          "excerpts": [
            "Metric Definition. Clicks. The number of clicks on your website URLs from a Google Search results page, not including clicks on paid Google Ads search results."
          ]
        },
        {
          "title": "How To Use and Understand Our Search Performance (Google ...",
          "url": "https://help.carrot.com/tutorial/search-performance-google-search-console/",
          "excerpts": [
            "Search Performance is pulling the number of Total Clicks from your Google Search Console data. Total Clicks means the number of times a user ..."
          ]
        },
        {
          "title": "How are you performing on Google? - Search Console Help",
          "url": "https://support.google.com/webmasters/answer/10268906?hl=en",
          "excerpts": [
            "Search Console has several different performance reports that show how often users saw information or links to your site on Search, News, or Discover."
          ]
        },
        {
          "title": "Track your rankings",
          "url": "https://www.semrush.com/kb/1191-track-your-rankings",
          "excerpts": [
            "Rank tracking is a process of monitoring keyword positions that a website ranks for in search engine results pages. In order to assess your current ..."
          ]
        },
        {
          "title": "Rank Tracking",
          "url": "https://www.sistrix.com/google/rank-tracking",
          "excerpts": [
            "Rank tracking in the SISTRIX Optimizer supports over 350 country and language combinations – for perfectly localised results."
          ]
        },
        {
          "title": "changyaochen/rbo: Implementation of Rank-biased Overlap",
          "url": "https://github.com/changyaochen/rbo",
          "excerpts": [
            "RBO compares two ranked lists, and returns a numeric value between zero and one to quantify their similarity. A RBO value of zero indicates the lists are ...",
            "A RBO value of zero indicates the lists are completely different, and a RBO of one means completely identical.",
            "This project contains a Python implementation of Rank-Biased Overlap (RBO) from: Webber, William, Alistair Moffat, and Justin Zobel."
          ]
        },
        {
          "title": "Kendall's Tau and Spearman's Rank Correlation Coefficient",
          "url": "https://www.statisticssolutions.com/free-resources/directory-of-statistical-analyses/kendalls-tau-and-spearmans-rank-correlation-coefficient/",
          "excerpts": [
            "Kendall's Tau and Spearman's rank correlation coefficient assess statistical associations based on the ranks of the data . Researchers rank data by separately ordering the variables and assigning numbers. Correlation coefficients take the values between minus one and plus one."
          ]
        },
        {
          "title": "Finite Rank-Biased Overlap (FRBO)",
          "url": "https://ceur-ws.org/Vol-3802/paper3.pdf",
          "excerpts": [
            "by F Betello · 2022 · Cited by 3 — Finding the minimum and maximum values of RBO is crucial for normalizing it when summing up to the top k items of the ranking."
          ]
        },
        {
          "title": "10 metrics to evaluate recommender and ranking systems",
          "url": "https://www.evidentlyai.com/ranking-metrics/evaluating-recommender-systems",
          "excerpts": [
            "This guide will cover a few common metrics for ranking and recommendation, from Precision and Recall to more complex NDCG, MAP, or Serendipity.See more"
          ]
        },
        {
          "title": "Search Quality Metrics: What They Mean And How ...",
          "url": "https://serpstat.com/blog/search-quality-metrics-what-they-mean-and-how-they-work/",
          "excerpts": [
            "The task of ranking is to return the most relevant object in response to a request. The higher the relevance, the higher the likelihood that the ...See more"
          ]
        },
        {
          "title": "How a SERP Tracking API Can Take the Pain Out of Rank ...",
          "url": "https://dev.to/kervi_11_/how-a-serp-tracking-api-can-take-the-pain-out-of-rank-monitoring-47j7",
          "excerpts": [
            "It eliminates the inefficiencies of manual rank tracking, provides accurate and real-time data, and effortlessly scales to meet your specific ..."
          ]
        },
        {
          "title": "Google Search Console KPIs: Metrics and Dimensions to ...",
          "url": "https://www.databloo.com/blog/google-search-console-kpis/",
          "excerpts": [
            "Jan 24, 2025 — KPIs in Google Search Console are metrics that give you an overview of how your website is performing in search engines. They allow you to ..."
          ]
        },
        {
          "title": "What are impressions, clicks, and position in Google ...",
          "url": "https://www.centori.io/post/what-are-impressions-clicks-and-position-in-google-search-console",
          "excerpts": [
            "Sep 29, 2023 — The average ranking of your website URLs for the query or queries. For example, if your site's URL appeared at position 3 for one query and ..."
          ]
        },
        {
          "title": "Compare a Service's latency to the previous week",
          "url": "https://docs.datadoghq.com/tracing/guide/week_over_week_p50_comparison/",
          "excerpts": [
            "Datadog can show you the latency of your application over time and how it compares to similar moments in previous time frames such as last week or month."
          ]
        },
        {
          "title": "Understanding Core Web Vitals and Google search results",
          "url": "https://developers.google.com/search/docs/appearance/core-web-vitals",
          "excerpts": [
            "Core Web Vitals is a set of metrics that measure real-world user experience for loading performance, interactivity, and visual stability of the page.See more"
          ]
        },
        {
          "title": "Kendall rank correlation coefficient - Wikipedia",
          "url": "https://en.wikipedia.org/wiki/Kendall_rank_correlation_coefficient",
          "excerpts": [
            "If the agreement between the two rankings is perfect (i.e., the two rankings are the same) the coefficient has value 1. · If the disagreement between the two ...",
            "It is a measure of rank correlation: the similarity of the orderings of the data when ranked by each of the quantities."
          ]
        },
        {
          "title": "Correlation: Pearson, Spearman, and Kendall's tau | UVA Library",
          "url": "http://library.virginia.edu/data/articles/correlation-pearson-spearman-and-kendalls-tau",
          "excerpts": [
            "Points closer to the 1:1 line indicate stronger agreement while points farther away indicate greater deviations. ... Here, we reviewed Pearson, ..."
          ]
        },
        {
          "title": "What is rank tracking?",
          "url": "https://www.semrush.com/blog/what-is-rank-tracking/",
          "excerpts": [
            "Rank tracking is the process of monitoring where your webpages rank in search engine results for specific keywords."
          ]
        },
        {
          "title": "Position Tracking: Keyword Rank Tracker Tool",
          "url": "https://www.semrush.com/position-tracking/",
          "excerpts": [
            "Semrush helps you find competitors that are targeting and ranking for the same keywords as you. You can also find competitors for each location you track."
          ]
        },
        {
          "title": "SEO Performance Metrics and Tracking",
          "url": "https://www.sistrix.com/ask-sistrix/seo-strategy/overview-seo-results-and-tracking-them/",
          "excerpts": [
            "Sep 25, 2020 — Third-party rank tracking or search visibility tools – There are hundreds of tools out there which track performance of websites within search ..."
          ]
        },
        {
          "title": "STAT Search Analytics - Overview",
          "url": "https://moz.com/products/stat",
          "excerpts": [
            "Granular search data to help you scale, pivot, and optimize. · Daily tracking · Competitor intelligence · Priced for scale · Local & mobile SERPs · Expert support."
          ]
        },
        {
          "title": "Building A Rank Tracker using Python & Google Search API",
          "url": "https://www.scrapingdog.com/blog/building-rank-tracker-using-python-and-google-serp-api/",
          "excerpts": [
            "In this tutorial, we will create our rank-tracking tool with Scrapingdog's SERP API and Python. Logic and Requirements"
          ]
        },
        {
          "title": "7 Best Rank Tracking APIs for Accurate Keyword ...",
          "url": "https://www.link-assistant.com/news/best-rank-tracking-apis.html",
          "excerpts": [
            "1. SerpAPI · 2. DataForSEO · 3. Zenserp · 4. ScaleSERP · 5. SerpWow · 6. ScrapingDog · 7. SEO PowerSuite's Rank Tracker (Non-API Alternative)."
          ]
        },
        {
          "title": "How to track & analyze search intent",
          "url": "https://getstat.com/blog/track-search-intent",
          "excerpts": [
            "In this post, we'll show you how to track and analyze search intent for your own unique keyword set."
          ]
        },
        {
          "title": "Search Console Metrics - What are impressions, position, and clicks?",
          "url": "https://support.google.com/webmasters/answer/7042828?hl=en",
          "excerpts": [
            "In Search Console, the metric is shown as average position, which averages the position value for all impressions",
            "Introduction",
            "Search Console provides data showing how often users saw or interacted with links to or content from your site, in Google Search, News, and Discover. This data is available in the various performance reports . The performance reports show the following metrics:",
            "(average) Position : A relative ranking of the position of your link on Google, where 1 is the topmost position, 2 is the next position, and so on.",
            "Click-through rate : The calculation of (clicks ÷ impressions).",
            "Impressions : How often someone saw a link to your site on Google. Depending on the result type, the link might need to be scrolled or expanded into view.",
            "Clicks : How often someone clicked a link from Google to your site."
          ]
        },
        {
          "title": "Rmeasure: A Position-Based Performance Metric for Web Search Engines",
          "url": "https://ieeexplore.ieee.org/abstract/document/11006723/",
          "excerpts": [
            "easure}} : A Position-Based Performance Metric for Web Search Engine",
            "Web search evaluation faces a fundamental challenge when comparing different search engines: how do we assess ranking quality when search results don’t completely overlap?",
            "Rmeasure uniquely integrates statistical variation and psychophysical modeling to evaluate the consistency of web search rankings across repeated queries, even when the result sets are only partially overlapping.",
            "The key contributions of this research are as follows:\n\n1. Identification and analysis of fundamental limitations in conventional IR metrics for evaluating search engine performance, with particular emphasis on the need for rank stability assessment. 2.\nIntegration of Weber-Fechner Law principles to explain and model ranking fluctuations resulting from query repetition effects. 3. Development of a novel rank correlation measure that independently evaluates both overlapping and non-overlapping search results to provide a more granular assessment of ranking stability. 4. Comprehensive empirical evaluation of ranking consistency across major commercial search engines, revealing platform-specific patterns and providing actionable insights for search engine optimization and user experience enhance",
            "This study introduced a novel rank correlation measure to assess search engine consistency, addressing the limitations of traditional information retrieval metrics. By analyzing rank stability in repeated queries, the proposed framework distinguishes between overlapping and non-overlapping results, providing a comprehensive evaluation of ranking fluctuations.",
            "comprehensive}$\n values for both Bing and Google search engines across Googlewhack queries and High-volume Biographical Queries. These values offer insights into the overall stability patterns of search engine rankings under different query complexities and search volumes",
            ") accounts for the average precision between ranked lists and reflects early-position sensitivity [[15]](javascript:void()). *Rank-Biased Overlap (RBO)* supports incomplete and indefinite lists using a probabilistic decay model and has gained popularity for handling non-overlapping ranks effective"
          ]
        },
        {
          "title": "Overlap Among Major Web Search Engines",
          "url": "https://scispace.com/pdf/overlap-among-major-web-search-engines-1vbp8wlqav.pdf",
          "excerpts": [
            "The goal of the research was to: measure the overlap across three major web search engines on the first results page overlap (i.e. share the same results) and."
          ]
        },
        {
          "title": "A Comparison of Source Distribution and Result Overlap in ...",
          "url": "https://arxiv.org/pdf/2207.07330",
          "excerpts": [
            "by N Yagci · 2022 · Cited by 17 — The overlap between Google and Bing is always under 32%, while Metager has a higher overlap with Bing than DuckDuckGo, going up to 78%."
          ]
        },
        {
          "title": "A study of results overlap and uniqueness among major ...",
          "url": "https://faculty.ist.psu.edu/jjansen/academic/pubs/jansen_overlap_ipm2006.pdf",
          "excerpts": [
            "by A Spink · 2005 · Cited by 204 — The goal of our research was to measure the overlap across major Web search engines. ... run against each query to determine the overlap of search ...",
            "This paper reports results from large and current study of Web search engine overlap using four major Web search engines—Ask. Jeeves, Google, ..."
          ]
        },
        {
          "title": "Testing RBO services",
          "url": "https://docs.rocketsoftware.com/bundle/wde_restfuluser_531/page/dys1653316930459.html",
          "excerpts": [
            "Web DE provides a testing tool that you can use to test your RBOs without leaving the development environment. Test the RBO services you create to verify ..."
          ]
        },
        {
          "title": "Difference between Spearman's rank correlation and Kendall Tau ...",
          "url": "https://www.reddit.com/r/AskStatistics/comments/1db7rcl/difference_between_spearmans_rank_correlation_and/",
          "excerpts": [
            "In sample terms, the Spearman is the Pearson correlation between the rankes of the data while the Kendall looks at pairs of points and ..."
          ]
        },
        {
          "title": "Understanding Bland Altman analysis - PMC",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC4470095/",
          "excerpts": [
            "by D Giavarina · 2015 · Cited by 4618 — The B&A plot analysis is a simple way to evaluate a bias between the mean differences, and to estimate an agreement interval, within which 95% of the ...See more"
          ]
        },
        {
          "title": "Bland-Altman methods for comparing methods of ...",
          "url": "https://www.sciencedirect.com/science/article/pii/S2590113320300298",
          "excerpts": [
            "by MA Mansournia · 2021 · Cited by 114 — Introduced in 1983, Bland-Altman methods is now considered the standard approach for assessment of agreement between two methods of measurement.See more"
          ]
        },
        {
          "title": "Applying the Golden Rule of Sampling for Query Estimation",
          "url": "https://sigmodrecord.org/publications/sigmodRecord/0106/pdfs/Using%20the%20Golden%20Rule%20of%20Sampling%20for%20Query%20Estimation.pdf",
          "excerpts": [
            "by YL Wu · 2001 · Cited by 56 — We demonstrate that in most cases, under the same space requirement, the golden esti- mator gives more accurate estimation for the result size of range queries."
          ]
        },
        {
          "title": "[PDF] A New Framework for Query Evaluation on Uncertain Graphs",
          "url": "https://ronghuali.github.io/paper/tkdesampler.pdf",
          "excerpts": [
            "To reduce the variance of NMC, we propose two efficient estimators, called RSS-I and RSS-II estimators, based on the idea of recursive stratified sampling (RSS) ..."
          ]
        },
        {
          "title": "Efficient and accurate query evaluation on uncertain graphs via ...",
          "url": "https://ieeexplore.ieee.org/document/6816709/",
          "excerpts": [
            "More specifically, we first propose two classes of basic stratified sampling estimators, named BSS-I and BSS-II, which partition the entire population into 2r ..."
          ]
        },
        {
          "title": "The Treatment of Ties in Rank-Biased Overlap",
          "url": "https://arxiv.org/abs/2406.07121",
          "excerpts": [
            "Rank-Biased Overlap (RBO) is a similarity measure for indefinite rankings: it is top-weighted, and can be computed when only a prefix of the rankings is known or when they have only some items in common.",
            "In this paper we propose a generalized formulation for RBO to handle ties, thanks to which we complete the original definitions by showing how to perform prefix evaluation.",
            "Overall, these three variants provide researchers with flexibility when comparing rankings with RBO, by clearly determining what ties mean, and how they should be treated.",
            "It is widely used for instance to analyze differences between search engines by comparing the rankings of documents they retrieve for the same queries."
          ]
        },
        {
          "title": "Rank-biased measures for evaluating retrieval effectiveness",
          "url": "https://jmmackenzie.io/pdf/mmmp24-sigirap.pdf",
          "excerpts": [
            "rank-biased alignment, or RBA",
            "\t\t\t  Figure 5 gives an example RBA calculation for two non-conjoint\n𝐵 an"
          ]
        },
        {
          "title": "A similarity measure for indefinite rankings",
          "url": "https://dl.acm.org/doi/10.1145/1852102.1852106",
          "excerpts": [
            "In this article, we propose a new measure having these qualities, namely rank-biased overlap (RBO). ... Lester, N., Moffat, A., Webber, W., and Zobel, J. 2005.",
            "RBO has a parameter which determines the strength of the weighting to top ranks. We extend RBO to handle tied ranks and rankings of different lengths. Finally, ..."
          ]
        },
        {
          "title": "A Similarity Measure for Indefinite Rankings",
          "url": "http://blog.mobile.codalism.com/research/papers/wmz10_tois.pdf",
          "excerpts": [
            "by W WEBBER · 2010 · Cited by 1054 — Rank-biased overlap (RBO) is a new measure for comparing incomplete, top-weighted, and indefinite rankings, handling non-conjointness and weighting high ranks."
          ]
        },
        {
          "title": "The Treatment of Ties in Rank-Biased Overlap",
          "url": "https://dl.acm.org/doi/10.1145/3626772.3657700",
          "excerpts": [
            "Jul 11, 2024 — In this paper we propose a generalized formulation for RBO to handle ties, thanks to which we complete the original definitions by showing how to perform ...",
            "The Treatment of Ties in Rank-Biased Overlap"
          ]
        },
        {
          "title": "18.3 - Kendall Tau-b Correlation Coefficient | STAT 509",
          "url": "https://online.stat.psu.edu/stat509/lesson/18/18.3",
          "excerpts": [
            "The Kendall tau-b correlation coefficient, τ b , is a nonparametric measure of association based on the number of concordances and discordances in paired ..."
          ]
        },
        {
          "title": "On Inference for Kendall's τ within a Longitudinal Data Setting - PMC",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC3611981/",
          "excerpts": [
            "In this paper, we develop a novel approach to provide inference about Kendall's τ within a longitudinal study setting under both complete and missing data."
          ]
        },
        {
          "title": "(PDF) Rank-Stability and Rank-Similarity of Link-Based Web ...",
          "url": "https://www.researchgate.net/publication/226174141_Rank-Stability_and_Rank-Similarity_of_Link-Based_Web_Ranking_Algorithms_in_Authority-Connected_Graphs",
          "excerpts": [
            "This paper studies the rank-stability and rank-similarity of three link-based ranking algorithms—PageRank, HITS and SALSA—in authority connected graphs. For ..."
          ]
        },
        {
          "title": "A Review of Stability in Topic Modeling: Metrics for Assessing and ...",
          "url": "https://dl.acm.org/doi/full/10.1145/3623269",
          "excerpts": [
            "A rank correlation similarity approach penalizes similar terms with different positions and increases the penalty as position difference ..."
          ]
        },
        {
          "title": "A New Coefficient of Rankings Similarity in Decision-Making Problems",
          "url": "https://pmc.ncbi.nlm.nih.gov/articles/PMC7302865/",
          "excerpts": [
            "In this paper, we identify the shortcomings of currently used coefficients to measure the similarity of two rankings in decision-making problems. Afterward, we ..."
          ]
        },
        {
          "title": "Need help in understanding Google Search Console time zone.",
          "url": "https://www.reddit.com/r/SEO/comments/hd4utl/need_help_in_understanding_google_search_console/",
          "excerpts": [
            "Timezones would only have relevance where a specific timestamp is used (ie, 'Last updated at: 2:30') which would be in Pacific Time, not local ..."
          ]
        },
        {
          "title": "Probability Proportional to Size (PPS) Sampling - Wiley Online Library",
          "url": "https://onlinelibrary.wiley.com/doi/abs/10.1002/9781118445112.stat03346.pub2",
          "excerpts": [
            "Probability proportional to size (PPS) sampling is a method of sampling from a finite population in which a size measure is available for each population unit ..."
          ]
        },
        {
          "title": "Sample Size in Statistics (How to Find it): Excel, Cochran's ...",
          "url": "https://www.statisticshowto.com/probability-and-statistics/find-sample-size/",
          "excerpts": [
            "Now let's say we want 95% confidence, and at least 5 percent—plus or minus—precision. A 95 % confidence level gives us Z values of 1.96, per the normal tables, ...See more",
            "The Cochran formula allows you to calculate an ideal sample size given a desired level of precision, desired confidence level, and the estimated proportion."
          ]
        },
        {
          "title": "Cochran's Sample Size Calculator & Formula",
          "url": "https://dissertationdataanalysishelp.com/cochrans-sample-size-calculator/",
          "excerpts": [
            "Apr 1, 2025 — Select a confidence level – Common choices are 90% (z score = 1.645), 95% (z score = 1.96), or 99% (z score = 2.58). · Enter the margin of error ...See more"
          ]
        },
        {
          "title": "Bootstrapping Medians",
          "url": "https://www.uvm.edu/~statdhtx/StatPages/Randomization%20Tests/BootstMedians/bootstrapping_medians.html",
          "excerpts": [
            "Bootstrapped t Method. Just as we did with the mean, we can calculate a bootstrapped t estimate of the confidence limits for the median."
          ]
        },
        {
          "title": "R Handbook: Confidence Intervals for Medians",
          "url": "https://rcompanion.org/handbook/E_04.html",
          "excerpts": [
            "The boot.ci function produces four types of confidence intervals for the median. Note also that the displaying the result Mboot gives a standard error for the ..."
          ]
        },
        {
          "title": "What Counts as an Impression in Google Search Console ...",
          "url": "https://www.hbfreelance.com/what-counts-as-an-impression-in-google-search-console-performance-report/",
          "excerpts": [
            "May 4, 2025 — In Google Search Console, an impression is recorded when a link to your website appears in the search results a user views."
          ]
        },
        {
          "title": "Google Search Console Impressions - Metric Definition",
          "url": "https://databox.com/metric-library/metrics/google-search-console/impressions",
          "excerpts": [
            "Impressions metric represents the number of times a webpage of your site has appeared in search results, regardless of whether or not it was clicked by a user.See more"
          ]
        },
        {
          "title": "What timezone is Google Search Console published in?",
          "url": "https://support.google.com/webmasters/thread/308804464/what-timezone-is-google-search-console-published-in?hl=en",
          "excerpts": [
            "According to Google Performance Report documentation,. The Performance report tracks daily data according to local time ... Pacific Time Zone ..."
          ]
        },
        {
          "title": "Using Search Console and Google Analytics Data for SEO",
          "url": "https://developers.google.com/search/docs/monitor-debug/google-analytics-search-console",
          "excerpts": [
            "You can choose your timezone in Google Analytics, but you can't customize that in Search Console, where the default time zone is PST. This is particularly ..."
          ]
        },
        {
          "title": "Consolidating your website traffic on canonical URLs",
          "url": "https://developers.google.com/search/blog/2019/02/consolidating-your-website-traffic-on",
          "excerpts": [
            "Feb 6, 2019 — In Search Console, the Performance report currently credits all page metrics to the exact URL that the user is referred to by Google Search."
          ]
        },
        {
          "title": "Measuring Search Engine Consistency Using Rank Stability",
          "url": "https://www.researchgate.net/publication/391884532_Beyond_Precision_and_Recall_Measuring_Search_Engine_Consistency_Using_Rank_Stability",
          "excerpts": [
            "The proposed approach distinguishes between overlapping and non-overlapping documents, providing a detailed measure of ranking stability."
          ]
        },
        {
          "title": "How to Calculate Tau-b (τb) Using Alliance Data in R | Steven V. Miller",
          "url": "http://svmiller.com/blog/2021/11/calculate-tau-b-alliances-in-r/",
          "excerpts": [
            "Kendall's Tau-b is one of three rank correlation coefficients, which vary for how they handle ties. Kendall's Tau-b, in particular, is a correlation coefficient that deals with tied ranks by assuming a value of zero indicates an absence of association ."
          ]
        },
        {
          "title": "[PDF] Steps in applying Probability Proportional to Size (PPS)",
          "url": "https://cdn.who.int/media/docs/default-source/hq-tuberculosis/global-task-force-on-tb-impact-measurement/meetings/2008-03/p20_probability_proportional_to_size.pdf?sfvrsn",
          "excerpts": [
            "PPS involves two stages: first, larger clusters have higher sampling probability. Second, same number of individuals are sampled per cluster, ensuring equal ..."
          ]
        },
        {
          "title": "[PDF] Overlap in Web Search Results: A Study of Five Search Engines",
          "url": "https://digitalcommons.unl.edu/cgi/viewcontent.cgi?article=1228&context=libphilprac",
          "excerpts": [
            "Missing: Run- stability paper"
          ]
        },
        {
          "title": "Chapter 8 Sampling with probabilities proportional to size",
          "url": "https://dickbrus.github.io/SpatialSamplingwithR/pps.html",
          "excerpts": [
            "In this chapter the individual population units (elementary sampling units) are selected with probabilities proportional to size."
          ]
        },
        {
          "title": "What are Impressions in Google Search Console?",
          "url": "https://seotesting.com/google-search-console/impressions/",
          "excerpts": [
            "Impressions help you see how often your content appears in search. A high number of impressions with few clicks may mean your meta data needs improvement."
          ]
        },
        {
          "title": "Impressions in Google Search Console : r/TechSEO",
          "url": "https://www.reddit.com/r/TechSEO/comments/1590xgb/impressions_in_google_search_console/",
          "excerpts": [
            "Google Search Console (GSC) counts an impression every time a link to your website appears in the search results viewed by a user."
          ]
        },
        {
          "title": "A Practical Sampling Strategy for Efficient Retrieval Evaluation",
          "url": "http://www.ccs.neu.edu/~vip/study/sampling_files/submitted_1.pdf",
          "excerpts": [
            "by JAAV Pavlu · Cited by 27 — The sample is the set of documents selected for judging together with all information required for evaluation: in our case that means (1) the documents ids, (2) ..."
          ]
        },
        {
          "title": "Probability Proportional to Size (PPS) Sampling",
          "url": "https://methods.sagepub.com/ency/edvol/encyclopedia-of-survey-research-methods/chpt/probability-proportional-size-pps-sampling",
          "excerpts": [
            "Probability proportional to size (PPS) sampling includes a number of sample selection methods in which the probability of selection for a ..."
          ]
        },
        {
          "title": "RFC 4180 - Common Format and MIME Type for Comma- ...",
          "url": "https://datatracker.ietf.org/doc/html/rfc4180",
          "excerpts": [
            "This RFC documents the format of comma separated values (CSV) files and formally registers the \"text/csv\" MIME type for CSV in accordance with RFC 2048."
          ]
        },
        {
          "title": "Comma-separated values",
          "url": "https://en.wikipedia.org/wiki/Comma-separated_values",
          "excerpts": [
            "The 2005 technical standard RFC 4180 formalizes the CSV file format and defines the MIME type \"text/csv\" for the handling of text-based fields. However, the ...",
            "The CSV file format was formalized in the 2005 technical standard RFC 4180 ... MS-DOS-style lines that end with (CR/LF) characters (optional for the last line)."
          ]
        },
        {
          "title": "CSV files - Amperity Docs",
          "url": "https://docs.amperity.com/reference/format_csv.html",
          "excerpts": [
            "When a field is enclosed by double quotes, a double quote that appears inside a field must be escaped using a double quote. When an escape character is not specified, Amperity will assume that the escape character is double quotes. This follows the RFC as closely as possible: ",
            "If double quotes are used to enclose fields, then a double quote appearing inside a field must be escaped by preceding it with another double quote."
          ]
        },
        {
          "title": "Rfc 4180 definitely lays out rules for how to escape double quotes ...",
          "url": "https://news.ycombinator.com/item?id=15442983",
          "excerpts": [
            "Rfc 4180 definitely lays out rules for how to escape double quotes, commas, and newlines. ... CSV\" systems use backslash to escape quotes. § 3 says that the ...",
            "§ 2.7 requires fortran-style doubling of double-quote marks, like COBOL and SQL, and ignores that many \"CSV\" systems use backslash to escape quotes. § 3 says ..."
          ]
        },
        {
          "title": "What's the difference between UTF-8 and UTF-8 with BOM?",
          "url": "https://stackoverflow.com/questions/2223882/whats-the-difference-between-utf-8-and-utf-8-with-bom",
          "excerpts": [
            "UTF-8 without BOM has no BOM, which doesn't make it any better than UTF-8 with BOM, except when the consumer of the file needs to know (or ..."
          ]
        },
        {
          "title": "Should UTF-8 CSV files contain a BOM (byte order mark)?",
          "url": "https://softwareengineering.stackexchange.com/questions/372692/should-utf-8-csv-files-contain-a-bom-byte-order-mark",
          "excerpts": [
            "It's unnecessary (UTF-8 has no byte order) unlike UTF-16/32 and not recommended in the Unicode standard."
          ]
        },
        {
          "title": "Excel save behaviour of CSV file with UTF8 encoding vs ...",
          "url": "https://superuser.com/questions/1204233/excel-save-behaviour-of-csv-file-with-utf8-encoding-vs-utf8-bom-encoding",
          "excerpts": [
            "My issue is that with a UTF8 encoded CSV file, when you click save in Excel it gives you a popup option to keep the original formatting."
          ]
        },
        {
          "title": "How to Sort Unicode Strings Alphabetically in Python",
          "url": "https://realpython.com/python-sort-unicode-strings/",
          "excerpts": [
            "In this tutorial, you'll learn how to correctly sort Unicode strings in Python while avoiding common pitfalls. You'll explore powerful third-party libraries ..."
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.ietf.org/rfc/rfc4180.txt",
          "excerpts": [
            "  3. There maybe an optional header line appearing as the first line\n       of the file with the same format as normal record lines. This\n       header will contain names corresponding to the fields in the file\n       and should contain the same number of fields as the records in\n       the rest of the file (the presence or absence of the header line\n       should be indicated via the optional \"header\" parameter of this\n       MIME type). For example:\n\n       field_name,field_name,field_name CRLF\n       aaa,bbb,ccc CRLF\n       zzz,yyy,xxx CRLF",
            "4. Within the header and each record, there may be one or more\n       fields, separated by commas. Each line should contain the same\n       number of fields throughout the file. Spaces are considered part\n       of a field and should not be ignored. The last field in the\n       record must not be followed by a comma. For example:\n\n       aaa,bbb,ccc",
            "c\n\n   5. Each field may or may not be enclosed in double quotes (however\n       some programs, such as Microsoft Excel, do not use double quotes\n       at all). If fields are not enclosed with double quotes, then\n       double quotes may not appear inside the fields.\nFor example:\n\n       \"aaa\",\"bbb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "x\n\n   6. Fields containing line breaks (CRLF), double quotes, and commas\n       should be enclosed in double-quotes. For example:\n\n       \"aaa\",\"b CRLF\n       bb\",\"ccc\" CRLF\n       zzz,yyy,xxx",
            "xxx\n\n   7. If double-quotes are used to enclose fields, then a double-quote\n       appearing inside a field must be escaped by preceding it with\n       another double quote. For example:\n\n       \"aaa\",\"b\"\"bb\",\"ccc\"",
            "The ABNF grammar [2] appears as follows:\n\n   file = [header CRLF] record *(CRLF record) [CRLF]\n\n   header = name *(COMMA name)\n\n   record = field *(COMMA field)\n\n   name = field\n\n   field = (escaped / non-escaped)\n\n   escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE\n\n   non-escaped = *TEXTDATA",
            "3. MIME Type Registration of text/csv\n\n   This section provides the media-type registration application (as per\n   RFC 2048 [1]."
          ]
        },
        {
          "title": "RFC 4180: Common Format and MIME Type for CSV Files",
          "url": "https://www.loc.gov/preservation/digital/formats/fdd/fdd000323.shtml",
          "excerpts": [
            "RFC 4180 stipulates the use of CRLF pairs to denote line breaks, where CR is %x0D (Hex 0D) and LF is %x0A (Hex 0A). Each line should contain the same number of fields. Fields that contain a special character (comma, CR, LF, or double quote), must be \"escaped\" by enclosing them in double quotes (Hex 22) . ",
            "An optional header line may appear as the first line\nof the file with the same format as normal record lines.",
            "CSV is a simple format for representing a rectangular array (matrix) of numeric and textual values. It an example of a \"flat file\" format. It is ..."
          ]
        },
        {
          "title": "How to properly escape a double quote in CSV?",
          "url": "https://stackoverflow.com/questions/17808511/how-to-properly-escape-a-double-quote-in-csv",
          "excerpts": [
            "If double-quotes are used to enclose fields, then a double-quote appearing inside a field must be escaped by preceding it with another double quote.",
            "RFC 4180",
            "You only need to add a single double quote to escape a double quote."
          ]
        },
        {
          "title": "RFC 4180 - Common Format and MIME Type for Comma- ...",
          "url": "https://datatracker.ietf.org/doc/rfc4180/",
          "excerpts": [
            "Each record is located on a separate line, delimited by a line break (CRLF) ... The \"header\" parameter indicates the presence or absence of the header line."
          ]
        },
        {
          "title": "RFC Errata Report » RFC Editor",
          "url": "https://www.rfc-editor.org/errata/rfc4180",
          "excerpts": [
            "Section 2 says: 6. Fields containing line breaks (CRLF), double quotes, and commas should be enclosed in double-quotes. It should say:"
          ]
        },
        {
          "title": "RFC 4180 file standards",
          "url": "https://docs.oracle.com/en/cloud/saas/marketing/audience-develop/docs/reference/rfc-file-standards.htm",
          "excerpts": [
            "The RFC 4180 CSV parser enables you to ingest single-line and multi-line data within your .csv files. Data record size limits. The RFC 4180 parser supports ..."
          ]
        },
        {
          "title": "OpenLineage: Home",
          "url": "https://openlineage.io/",
          "excerpts": [
            "OpenLineage contains an open standard for lineage data collection, a metadata repository reference implementation (Marquez), libraries for common languages ...",
            "OpenLineage is an open platform for collection and analysis of data lineage. It tracks metadata about datasets, jobs, and runs."
          ]
        },
        {
          "title": "Object Model",
          "url": "https://openlineage.io/docs/spec/object-model",
          "excerpts": [
            "OpenLineage cares how Datasets come into being, not just that relationships exist between them. Accordingly, its object model contains both Jobs and Datasets."
          ]
        },
        {
          "title": "How Data Lineage Works and Why It Matters - Sifflet",
          "url": "https://www.siffletdata.com/blog/data-lineage",
          "excerpts": [
            "Best Practices to Implement Data Lineage"
          ]
        },
        {
          "title": "Data Lineage Best Practices - Decube",
          "url": "https://www.decube.io/post/data-lineage-best-practices",
          "excerpts": [
            "Explore crucial data lineage best practices to boost data governance, ensure compliance, and uphold data quality across your organization's information ..."
          ]
        },
        {
          "title": "5 Data Engineering Tips for AI Engineers - Dagster",
          "url": "https://dagster.io/blog/ai-engineering-is-data-engineering",
          "excerpts": [
            "Makes pipelines consistent and idempotent through its asset-based APIs that track the state and lineage of data assets to ensure idempotency."
          ]
        },
        {
          "title": "scheduler",
          "url": "https://docs.prefect.io/v3/api-ref/python/prefect-server-services-scheduler",
          "excerpts": [
            "Note that scheduling is idempotent, so its ok for this scheduler to attempt to schedule the same deployments as the main scheduler. It's purpose is to ..."
          ]
        },
        {
          "title": "A Complete Guide to Testing Your Data Pipelines for ...",
          "url": "https://medium.com/@maroofashraf987/a-complete-guide-to-testing-your-data-pipelines-for-optimal-performance-e9eef1874d00",
          "excerpts": [
            "End-to-end testing simulates the full pipeline process, from data ingestion through transformation to the final output, ensuring everything works in harmony."
          ]
        },
        {
          "title": "Implementing Data Validation with Great Expectations in H...",
          "url": "https://tech.trivago.com/post/2023-04-25-implementing-data-validation-with-great-expectations-in-hybrid-environments",
          "excerpts": [
            "Great Expectations is a tool for validating data pipelines and data quality. It can perform a variety of data validation tasks, including checking for missing ..."
          ]
        },
        {
          "title": "About data tests property | dbt Developer Hub",
          "url": "https://docs.getdbt.com/reference/resource-properties/data-tests",
          "excerpts": [
            "Custom data test name. By default, dbt will synthesize a name for your generic data test by concatenating: test name ( not_null , unique , etc); model name ..."
          ]
        },
        {
          "title": "Add data tests to your DAG | dbt Developer Hub - dbt Docs",
          "url": "https://docs.getdbt.com/docs/build/data-tests",
          "excerpts": [
            "Out of the box, you can test whether a specified column in a model only contains non-null values, unique values, or values that have a corresponding value in ...",
            "Generic data tests (a.k.a. schema tests) are defined using test blocks. Like almost everything in dbt, data tests are SQL queries. In particular, they are ..."
          ]
        },
        {
          "title": "4.2. Validate Your pandas DataFrame with Pandera",
          "url": "https://khuyentran1401.github.io/reproducible-data-science/testing_data/pandera.html",
          "excerpts": [
            "Create multiple tests for the entire dataset using DataFrameSchema. Create multiple tests for each column using Column. Specify the type of test using Check."
          ]
        },
        {
          "title": "DataFrame Schemas - pandera documentation",
          "url": "https://pandera.readthedocs.io/en/stable/dataframe_schemas.html",
          "excerpts": [
            "The DataFrameSchema class enables the specification of a schema that verifies the columns and index of a pandas DataFrame object."
          ]
        },
        {
          "title": "Data Pipeline Architecture Explained: 6 Diagrams And Best ...",
          "url": "https://www.montecarlodata.com/blog-data-pipeline-architecture-explained/",
          "excerpts": [
            "Mar 21, 2023 — Data pipeline architecture is the process of designing how data is surfaced from its source system to the consumption layer."
          ]
        },
        {
          "title": "Best practices for data lineage | Secoda",
          "url": "https://www.secoda.co/learn/best-practices-for-data-lineage",
          "excerpts": [
            "1. Document data sources clearly · 2. Automate lineage tracking · 3. Use consistent naming · 4. Define data owners and stewards · 5. Visualize ..."
          ]
        },
        {
          "title": "Data Quality Checks: Best Practices & Examples - Pantomath",
          "url": "https://www.pantomath.com/data-pipeline-automation/data-quality-checks",
          "excerpts": [
            "This article provides practical, actionable methods and best practices for implementing data quality checks using SQL and orchestrating them with Apache ..."
          ]
        },
        {
          "title": "Data Synthesis Strategies - pandera documentation",
          "url": "https://pandera.readthedocs.io/en/stable/data_synthesis_strategies.html",
          "excerpts": [
            "The example method is available for all schemas and schema components, and is primarily meant to be used interactively. It could be used in a script to generate ..."
          ]
        },
        {
          "title": "Scheduling & Triggers - Apache Airflow",
          "url": "https://airflow.apache.org/docs/apache-airflow/1.10.10/scheduler.html",
          "excerpts": [
            "A key capability of Airflow is that these DAG Runs are atomic, idempotent items, and the scheduler, by default, will examine the lifetime of the DAG (from start ..."
          ]
        },
        {
          "title": "What Is Idempotent - Dagster",
          "url": "https://dagster.io/glossary/data-idempotency",
          "excerpts": [
            "An idempotent operation produces the same result each time it is performed, ensuring data consistency and reliability in data engineering."
          ]
        },
        {
          "title": "The Importance of Idempotent Data Pipelines for Resilience",
          "url": "https://www.prefect.io/blog/the-importance-of-idempotent-data-pipelines-for-resilience",
          "excerpts": [
            "Nov 14, 2024 — Idempotency makes retries particularly powerful. With smart retries, pipelines can handle temporary issues without causing data duplication ..."
          ]
        },
        {
          "title": "Apache Airflow Useful Practices: Idempotent DAG",
          "url": "https://medium.com/@chanon.krittapholchai/apache-airflow-useful-practices-idempotent-dag-6d52b1594704",
          "excerpts": [
            "Idempotent Data pipeline is the pipeline that always return the same result, no matter when or how many times it runs."
          ]
        },
        {
          "title": "Configuring run retries - Dagster Docs",
          "url": "https://docs.dagster.io/deployment/execution/run-retries",
          "excerpts": [
            "Missing: scheduling idempotency lineage"
          ]
        },
        {
          "title": "Data Pipeline Architecture Patterns",
          "url": "https://www.alation.com/blog/data-pipeline-architecture-patterns/",
          "excerpts": [
            "Adopt a medallion architecture",
            "The **medallion architecture** organizes data into three lay\nBronze**: Raw, unfiltered data (e.g., logs, API exports)\nSilver**: Cleaned and standardized data, ready for analysis\nGold**: Curated, business-ready datasets optimized for dashboards\n",
            "This layered approach supports robust data lineage, incremental improvements, and domain-specific analytics. It's well-suited for cloud-native stacks—for instance, combining Amazon S3 for storage with Snowflake or BigQuery for downstream analytics.",
            "Tools such as Apache Kafka, Amazon Kinesis, and Google Pub/Sub allow teams to capture high-velocity data streams with low latency.",
            "Streaming ingestion allows data to be processed in real time, rather than waiting on batch jobs.",
            " architecture reduces friction by querying data where it resides—no transformation or movement required. Platforms like **Amazon Redshift Spectrum** and **Google BigQuery Omni** support this via federated queries.",
            "In addition to selecting the right patterns, foundational practices ensure your architecture stays reliable, secure, and audit-ready.",
            "m/glossary/data-lineage/): Automatically track how data flows through systems—essential for troubleshooting, auditing, and impact analysis.",
            "Embed data quality checks**: Automate validation, anomaly detection, and freshness monitoring throughout the pipeline, not just at the destinatio",
            "Enforce security by design**: Apply encryption, access control, audit trails, and data masking using zero-trust principles—especially critical for sensitive domains like finance or healt"
          ]
        },
        {
          "title": "Best practices for building scalable, reliable, and secure data pipelines",
          "url": "https://xenoss.io/blog/data-pipeline-best-practices",
          "excerpts": [
            "Best practices for building scalable, reliable, and secure data pipelines",
            "Posted May 30, 2025 11 min read",
            "Ensuring reproducibility. Build reproducible pipelines to ensure disaster recovery and prevent data duplication when replaying the pipeline",
            "Tools that enable data pipeline modularity** : Apache Airflow, Dagster, Prefect, dbt (Data Build Tool), Kedro, Luigi, Flyte, Mage, ZenML, Metafl",
            "Data quality assurance\n\nData engineering teams should validate data across all quality dimensions (completeness, accuracy, validity, consistency, integrity) to prevent poor-quality data from offering distorted insight and hindering decision-making.",
            "Documentation\n\nDocument all ETL steps to make sure that all stakeholders on your data engineering teams can navigate and manage mission-critical pipelines (e.g., a fraud detection system a bank uses to flag suspicious transactions).",
            "Data security best practices\n\nDepending on the types of data a data product is managing, the stringency of security policies will vary. The implementations below are a good starting point for reducing the impact of potential breaches.",
            "### Data security best practices\n\nDepending on the types of data a data product is managing, the stringency of security policies will vary. The implementations below are a good starting point for reducing the impact of potential breaches."
          ]
        },
        {
          "title": "Three best practices for building successful data pipelines",
          "url": "https://www.oreilly.com/content/three-best-practices-for-building-successful-data-pipelines/",
          "excerpts": [
            "Ensuring reproducibility by providing a reliable audit trail",
            "To ensure the reproducibility of your data analysis, there are three dependencies that need to be locked down: analysis code, data sources, and algorithmic randomness.",
            "The benefits, however, go beyond scientific reproducibility; making the analysis fully documented provides a reliable audit trail, which is critical for data-driven decision-making."
          ]
        },
        {
          "title": "ZenML Orchestration Showdown: Dagster vs Prefect vs Airflow",
          "url": "https://www.zenml.io/blog/orchestration-showdown-dagster-vs-prefect-vs-airflow",
          "excerpts": [
            "Dagster's focus on modularity makes it particularly powerful for complex data engineering tasks.",
            "agster.io/) offers a life cycle-oriented approach that provides unparalleled flexibility, particularly during development and test",
            "Asset-Centric Approach:** Adopts an asset-centric model, where assets are first-class citizen",
            "Prefect is a standout choice if you’re looking for a flexible, secure, and highly adaptable orchestration tool.",
            " with its dynamic execution model, which determines the DAG at runtime and offloads computation and optimization to other systems like Dask."
          ]
        },
        {
          "title": "Airflow vs Dagster vs Prefect: A Detailed Comparison - RisingWave",
          "url": "https://risingwave.com/blog/airflow-vs-dagster-vs-prefect-a-detailed-comparison/",
          "excerpts": [
            "Explore the comparison of Airflow, Dagster, and Prefect in managing data workflows efficiently.",
            "Airflow vs Dagster vs Prefect: A Detailed Comparison",
            "### Airflow vs Dagster vs Prefect",
            "#### Features of Airflow",
            "#### Features of Dagster",
            "#### Features of Prefect",
            "Use Cases and Recommendations",
            "Best Use Cases for Airflow",
            "Best Use Cases for Dagster",
            "Best Use Cases for Prefect"
          ]
        },
        {
          "title": "Marquez Project | Marquez Project",
          "url": "https://marquezproject.ai/",
          "excerpts": [
            "Marquez enables consuming, storing, and visualizing OpenLineage metadata from across an organization, serving use cases including data governance."
          ]
        },
        {
          "title": "Getting Started",
          "url": "https://openlineage.io/getting-started/",
          "excerpts": [
            "We'll show how to collect run-level metadata as OpenLineage events using Marquez as the HTTP backend, then explore lineage metadata via the Marquez UI."
          ]
        },
        {
          "title": "OpenLineage Airflow integration",
          "url": "https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/guides/structure.html",
          "excerpts": [
            "OpenLineage integrates with Airflow to collect DAG lineage metadata so that inter-DAG dependencies are easily maintained and viewable via a lineage graph."
          ]
        },
        {
          "title": "Getting Started with Apache Airflow® and ...",
          "url": "https://openlineage.io/docs/guides/airflow-quickstart/",
          "excerpts": [
            "In this tutorial, you'll configure Apache Airflow to send OpenLineage events to Marquez and explore a realistic troubleshooting scenario."
          ]
        },
        {
          "title": "Lineage",
          "url": "https://docs.datahub.com/docs/api/tutorials/lineage",
          "excerpts": [
            "DataHub's Python SDK allows you to programmatically define and retrieve lineage between metadata entities. With the DataHub Lineage SDK, you can:"
          ]
        },
        {
          "title": "Constraint.scala - awslabs/deequ",
          "url": "https://github.com/awslabs/deequ/blob/master/src/main/scala/com/amazon/deequ/constraints/Constraint.scala",
          "excerpts": [
            "Deequ is a library built on top of Apache Spark for defining \"unit tests for data\", which measure data quality in large datasets."
          ]
        },
        {
          "title": "PyDeequ 0.0.4 documentation",
          "url": "https://pydeequ.readthedocs.io/en/latest/README.html",
          "excerpts": [
            "PyDeequ is a Python API for Deequ, a library built on top of Apache Spark for defining “unit tests for data”, which measure data quality in large datasets."
          ]
        },
        {
          "title": "Writing custom generic data tests | dbt Developer Hub",
          "url": "https://docs.getdbt.com/best-practices/writing-custom-generic-tests",
          "excerpts": [
            "6 days ago — To define your own generic tests, simply create a test block called <test_name>. All generic tests should accept one or both of the standard arguments."
          ]
        },
        {
          "title": "Data Validation with Pandera in Python | by Gabriel Furnieles",
          "url": "https://medium.com/data-science/data-validation-with-pandera-in-python-f07b0f845040",
          "excerpts": [
            "Pandera has two ways of defining validators: Schemas and Models. I will focus on the second one because of its similarity with Pydantic models ..."
          ]
        },
        {
          "title": "Bucket Lock | Cloud Storage",
          "url": "https://cloud.google.com/storage/docs/bucket-lock",
          "excerpts": [
            "When a bucket retention policy is set, objects in the bucket can only be deleted or replaced once their age is greater than the retention period. The policy ..."
          ]
        },
        {
          "title": "Overview of immutable storage for blob data",
          "url": "https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-storage-overview",
          "excerpts": [
            "May 1, 2024 — Microsoft recommends that you lock the policy in a reasonable amount of time, typically less than 24 hours. While the unlocked state provides ..."
          ]
        },
        {
          "title": "Use and lock retention policies | Cloud Storage",
          "url": "https://cloud.google.com/storage/docs/using-bucket-lock",
          "excerpts": [
            "This page describes how to use the Bucket Lock feature, including working with retention policies and permanently locking them on buckets."
          ]
        },
        {
          "title": "Configure immutability policies for blob versions",
          "url": "https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy-configure-version-scope",
          "excerpts": [
            "Nov 21, 2023 — An immutability policy may be scoped either to an individual blob version or to a container. This article describes how to configure a version-level ..."
          ]
        },
        {
          "title": "OpenTelemetry Logs: Benefits, Concepts, & Best Practices",
          "url": "https://www.groundcover.com/opentelemetry/opentelemetry-logs",
          "excerpts": [
            "Discover the key concepts, benefits, and best practices for OpenTelemetry logs. Learn how to manage diverse log types and achieve unified ...",
            "Jan 5, 2025 — How to collect log data using OpenTelemetry Collector · Step 1: Install Collector · Step 2: Configure the Collector · Step 3: Run the Collector."
          ]
        },
        {
          "title": "apache-airflow-providers-openlineage Documentation",
          "url": "https://airflow.apache.org/docs/apache-airflow-providers-openlineage/stable/index.html",
          "excerpts": [
            "This package is for the openlineage provider. All classes for this package are included in the airflow.providers.openlineage python package."
          ]
        },
        {
          "title": "File Based Lineage",
          "url": "https://docs.datahub.com/docs/generated/ingestion/sources/file-based-lineage",
          "excerpts": [
            "This plugin pulls lineage metadata from a yaml-formatted file. An example of one such file is located in the examples directory here. CLI based Ingestion​."
          ]
        },
        {
          "title": "Streamlining Log Management with OpenTelemetry - Best Practices ...",
          "url": "https://greptime.com/blogs/2025-01-08-opentelemetry-log-management",
          "excerpts": [
            "This blog explains how to capture logs with OpenTelemetry using the Log Data Model. It covers two main approaches, the Log SDK for simple setups and the ..."
          ]
        },
        {
          "title": "Configure Retention Policies with Bucket Lock",
          "url": "https://trendmicro.com/cloudoneconformity/knowledge-base/gcp/CloudStorage/retention-policies-with-bucket-lock.html",
          "excerpts": [
            "Oct 28, 2021 — Ensure that all the retention policies attached to your Google Cloud log sink buckets are configured with the Bucket Lock feature."
          ]
        },
        {
          "title": "Configure immutability policies for containers - Azure Storage",
          "url": "https://learn.microsoft.com/en-us/azure/storage/blobs/immutable-policy-configure-container-scope",
          "excerpts": [
            "May 10, 2024 — By configuring immutability policies for blob data, you can protect your data from overwrites and deletes. Immutability policies include time-based retention ..."
          ]
        },
        {
          "title": "OpenLineage",
          "url": "https://openlineage.io/docs/",
          "excerpts": [
            "OpenLineage is an open framework for data lineage collection and analysis. At its core is an extensible specification that systems can use to interoperate with lineage metadata.",
            "OpenLineage defines the metadata for running jobs and their corresponding events. A configurable backend allows the user to choose what protocol to send the events to.",
            "The OpenLineage repository contains integrations with several systems."
          ]
        },
        {
          "title": "Google Cloud Dataplex - Open Lineage / processOpenLineageRunEvent API",
          "url": "https://cloud.google.com/dataplex/docs/reference/data-lineage/rest/v1/projects.locations/processOpenLineageRunEvent",
          "excerpts": [
            "Creates new lineage events together with their parents: process and run. Updates the process and run if they already exist. Mapped from Open Lineage specification: <https://github.com/OpenLineage/OpenLineage/blob/main/spec/OpenLineage.json>.",
            "### HTTP request\n\n`POST https://datalineage.googleapis.com/v1/{parent}:processOpenLineageRunEvent`",
            "The request body contains an instance of `Struct`.",
            "the response body contains data with the following structure:\n\n| JSON representation |\n| --- |\n| ``` {   \"process\": string,   \"run\": string,   \"lineageEvents\": [     string   ] } ``` |",
            "| `requestId` | `string`  Optional. A unique identifier for this request. Restricted to 36 ASCII characters. A random UUID is recommended. This request is idempotent only if a `requestId` is provided. |",
            "### Authorization scopes\n\nRequires the following OAuth scope:\n\n* `https://www.googleapis.com/auth/cloud-platform`"
          ]
        },
        {
          "title": "Checkpoint - Great Expectations",
          "url": "https://docs.greatexpectations.io/docs/0.18/reference/learn/terms/checkpoint/",
          "excerpts": [
            "Checkpoint",
            "Running a Checkpoint produces Validation Results and will result in optional Actions being performed if they are configured to do so.",
            "Checkpoints are reusable and only need to be created once, although you can create multiple Checkpoints to cover multiple Validation use cases.",
            "Checkpoint configurations are very flexible. At one end of the spectrum, you can specify a complete configuration in a Checkpoint's YAML file, and simply call `my_checkpoint.run()` . At the other end, you can specify a minimal configuration in the YAML file and provide missing keys as kwar"
          ]
        },
        {
          "title": "Checkpoint - Great Expectations",
          "url": "https://docs.greatexpectations.io/docs/reference/api/checkpoint_class/",
          "excerpts": [
            "API](/docs/reference/)\n* Checkpoint\nVersion: 1.5.8\n\nCheckpoint\n==========\n\nSignature\n\n```\n  \nclass great_expectations.Checkpoint(  \n *,  \n name: str,  \n validation_definitions: List[great_expectations.core.validation_definition.ValidationDefinition],  \n actions: List[great_expectations.checkpoint.actions.ValidationAction] = None,  \n result_format: Union[great_expectations.core.result_format.ResultFormat,  \n dict,  \n Literal['BOOLEAN_ONLY',  \n 'BASIC',  \n 'SUMMARY',  \n 'COMPLETE']] = ResultFormat.SUMMARY,  \n id: Optional[str] = None  \n)  \n\n```\n\n:   A Checkpoint is the primary means for validating data in a production deployment of Great Expectations. Checkpoints provide a convenient abstraction for running a number of validation definitions and triggering a set of actions\n    to be taken after the validation step."
          ]
        },
        {
          "title": "OpenLineage Integrations with Great Expectations",
          "url": "https://openlineage.io/docs/integrations/great-expectations",
          "excerpts": [
            "Great Expectations integrates with OpenLineage through the action list in a checkpoint. An OpenLineage action can be specified, which is triggered when all expectations are run. Data from the checkpoint is sent to OpenLineage, which can then be viewed in Marquez or Datakin.",
            "Great Expectations is a robust data quality tool."
          ]
        },
        {
          "title": "everything you need to know · Prodigy · An annotation tool ...",
          "url": "https://prodi.gy/docs",
          "excerpts": [
            "Prodigy is a modern annotation tool for creating training and evaluation data for machine learning models."
          ]
        },
        {
          "title": "Programmatic Labeling & Labeling Functions",
          "url": "https://snorkel.ai/data-centric-ai/programmatic-labeling/",
          "excerpts": [
            "Programmatic labeling is an approach to data labeling that breaks through the primary bottleneck limiting AI today: creating high-quality training sets."
          ]
        },
        {
          "title": "Creating good labeling functions",
          "url": "https://docs.snorkel.ai/docs/25.4/user-guide/analysis/creating-good-labeling-functions/",
          "excerpts": [
            "This article will cover both high-level guidance as well as specific tips for writing good labeling functions (LFs)."
          ]
        },
        {
          "title": "Label and annotate data",
          "url": "https://labelstud.io/guide/labeling",
          "excerpts": [
            "Label and annotate data to create bounding boxes, label text spans, set up relations. Filter and sort project data for machine learning dataset creation."
          ]
        },
        {
          "title": "Data labeling with a human-in-the-loop",
          "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/data-label.html",
          "excerpts": [
            "You can label your data using Amazon SageMaker Ground Truth. Choose from one of the Ground Truth built-in task types or create your own custom labeling workflow ..."
          ]
        },
        {
          "title": "Security best practices in IAM - AWS Identity and Access Management",
          "url": "https://docs.aws.amazon.com/IAM/latest/UserGuide/best-practices.html",
          "excerpts": [
            "Use IAM Access Analyzer to generate least-privilege policies based on access activity. To grant only the permissions required to perform a task, you can ..."
          ]
        },
        {
          "title": "Configuring OpenID Connect in Amazon Web Services - GitHub Docs",
          "url": "https://docs.github.com/actions/security-for-github-actions/security-hardening-your-deployments/configuring-openid-connect-in-amazon-web-services",
          "excerpts": [
            "This guide explains how to configure AWS to trust GitHub's OIDC as a federated identity, and includes a workflow example for the aws-actions/configure-aws- ..."
          ]
        },
        {
          "title": "Label Studio Compare and Guide (from source_document)",
          "url": "https://labelstud.io/guide/label_studio_compare",
          "excerpts": [
            "Activity logs for auditing annotation activity by project.",
            "Annotation history. View annotation history from the labeling interface.",
            "Label Studio is available to everyone as open source software (Label Studio Community Edition). There are also two paid editions: Starter Cloud and Enterprise. See full feature comparison"
          ]
        },
        {
          "title": "Prodigy Documentation - Review",
          "url": "https://prodi.gy/docs/review",
          "excerpts": [
            "Prodigy is designed to make it easy to collect labelled data. However, the goal\nof Prodigy isn’t just about getting data labelled; it’s also about getting the\ndata right.",
            "That means that at some point, if you’re working with multiple\nannotators, you’ll want to review the annotations that they produce.",
            "The goal of this document is to help explain how you can review data in Prodigy\nvia the\nreview recipe and also to demonstrate some use-cases to help you\nget started quickly.",
            "If your annotators don’t agree on a particular example, it may be a bad to\nuse that example to train machine learning models. Reviewing these examples\nwill allow you to prevent that from happening.",
            "During a review you can choose to focus on the examples where annotators\ndisagree.",
            "Annotations in Prodigy\nTo understand how reviews work in Prodigy, it also helps to take a step back to\nreflect on what we need in order to perform a review.",
            "First, we need multiple\nannotators and we need to route examples to them.",
            "When multiple users annotate\nOnce the annotators save their annotations we can prepare a stream for review."
          ]
        },
        {
          "title": "Get started with Continuous Integration tests - dbt Guide",
          "url": "https://docs.getdbt.com/guides/set-up-ci",
          "excerpts": [
            "Get started with Continuous Integration tests",
            "In this guide, we're going to add a **CI environment** , where proposed changes can be validated in the context of the entire project without impacting production sys",
            "Create a new CI environment",
            "Run linting checks with SQLFluff",
            "rmat#lint) your project during CI, you can ensure that code styling standards are consistently enforced, without spending human time nitpicking comma placement.",
            "Create a `.gitlab-ci.yml` file in your **root directory** to define the triggers for when to execute the script be",
            "Key pieces:",
            "image: python:3.9",
            "rules:",
            " This workflow will run whenever code is pushed to any branch except `main`"
          ]
        },
        {
          "title": "Customizing CI/CD with custom pipelines",
          "url": "https://docs.getdbt.com/guides/custom-cicd-pipelines",
          "excerpts": [
            "Since pushes happen frequently in a project, we’ll keep this job super simple and fast by linting with SQLFluff",
            "Run a dbt job on merge",
            "This job will take a bit more to setup, but is a good example of how to call the dbt API from a CI/CD pipeline",
            "Get your dbt API key",
            "Create script to trigger dbt job via an API call",
            "For this job, we'll set it up using the `gitlab-ci.yml` file as in the prior step",
            "If your Git provider has a native integration with dbt , you can take advantage of setting up [Merge jobs](/docs/deploy/merge-jobs) in the UI"
          ]
        },
        {
          "title": "pandas.DataFrame.to_csv — pandas 2.3.1 documentation - PyData |",
          "url": "https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_csv.html",
          "excerpts": [
            "Write object to a comma-separated values (csv) file. Parameters: path_or_bufstr, path object, file-like object, or None, default None. String, path object ..."
          ]
        },
        {
          "title": "pandas.DataFrame.to_csv — pandas 0.23.1 documentation",
          "url": "https://pandas.pydata.org/pandas-docs/version/0.23/generated/pandas.DataFrame.to_csv.html",
          "excerpts": [
            "Write DataFrame to a comma-separated values (csv) file. Parameters: path_or_buf : string or file handle, default None. File path or object, if None is ..."
          ]
        },
        {
          "title": "pandas.DataFrame.to_csv — pandas 0.14.1 documentation",
          "url": "https://pandas.pydata.org/pandas-docs/version/0.14/generated/pandas.DataFrame.to_csv.html",
          "excerpts": [
            "to_csv¶. DataFrame.to_csv(*args, **kwargs)¶. Write DataFrame to a comma-separated values (csv) file. Parameters : path_or_buf : string or file handle, default ..."
          ]
        },
        {
          "title": "Does Python csv writer always use DOS end-of-line ...",
          "url": "https://stackoverflow.com/questions/9845681/does-python-csv-writer-always-use-dos-end-of-line-characters",
          "excerpts": [
            "As Niklas answered, the lineterminator argument lets you choose your line endings. Rather than hard coding it to '\\n' , make it platform ..."
          ]
        },
        {
          "title": "Writing To CSV Files Using the Python CSV library (Optional)",
          "url": "https://gsp.humboldt.edu/olm/Courses/GSP_318/02_X_3_1_WritingCSVFiles_WithCSVLibrary.html",
          "excerpts": [
            "The default is setup for UNIX machines which have different characters for terminating a line. Also, the default does not put quotes around strings which can ..."
          ]
        },
        {
          "title": "Writing quotes around strings to CSVs in Python - Treehouse",
          "url": "https://teamtreehouse.com/community/writing-quotes-around-strings-to-csvs-in-python",
          "excerpts": [
            "The key changes were adding the quoting=csv.QUOTE_STRINGS and lineterminator=\"\\n\" parameters to the CSV DictWriter. However, I am still ..."
          ]
        },
        {
          "title": "Guide to structured logging in Python",
          "url": "https://newrelic.com/blog/how-to-relic/python-structured-logging",
          "excerpts": [
            "May 16, 2025 — Learn how to implement structured logging in Python for observability and debugging. Follow this step-by-step guide to organize logs and ..."
          ]
        },
        {
          "title": "Best Practices for Analyzing Logs in Data Pipelines",
          "url": "https://blog.dreamfactory.com/best-practices-for-analyzing-logs-in-data-pipelines",
          "excerpts": [
            "Aug 1, 2025 — Use structured formats like JSON or key-value pairs to standardize logs. Leverage logging libraries to enforce these standards. Popular tools ..."
          ]
        },
        {
          "title": "Best Practices for Monitoring Data Pipeline Performance - Medium",
          "url": "https://medium.com/@amitkhullaar/best-practices-for-monitoring-data-pipeline-performance-51dac73f632f",
          "excerpts": [
            "1. Establish Clear Metrics · 2. Implement Real-Time Monitoring · 3. Set Clear Monitoring Objectives · 4. Implement Comprehensive Logging · 5."
          ]
        },
        {
          "title": "Data Pipeline Monitoring: Best Practices for Full Observability - Prefect",
          "url": "https://www.prefect.io/blog/data-pipeline-monitoring-best-practices",
          "excerpts": [
            "Avoid monolithic architecture · Make dependencies explicit · Define clear metrics and thresholds · Log and alert centrally · Use reliable monitoring ..."
          ]
        },
        {
          "title": "Data pipeline monitoring: Tools and best practices - RudderStack",
          "url": "https://www.rudderstack.com/blog/data-pipeline-monitoring/",
          "excerpts": [
            "Define event and schema tracking · Leverage logs and alerts · Set up automated validation · Establish a scalability strategy."
          ]
        },
        {
          "title": "Create and materialize partitioned assets",
          "url": "https://docs.dagster.io/etl-pipeline-tutorial/partition-asset",
          "excerpts": [
            "This ensures that our pipeline is idempotent, allowing us to re-execute the same partition without duplicating data. ... When materializing a partitioned asset ..."
          ]
        },
        {
          "title": "Tasks — Airflow 3.0.4 Documentation",
          "url": "https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/tasks.html",
          "excerpts": [
            "A Task is the basic unit of execution in Airflow. Tasks are arranged into DAGs, and then have upstream and downstream dependencies set between them."
          ]
        },
        {
          "title": "Data Pipeline Architecture: 5 Design Patterns with Examples",
          "url": "https://dagster.io/guides/data-pipeline/data-pipeline-architecture-5-design-patterns-with-examples",
          "excerpts": [
            "Feb 14, 2025 — Solutions like Dagster help automate and optimize these workflows. A well-designed orchestration strategy enables parallel processing, load ..."
          ]
        },
        {
          "title": "Partitioning assets",
          "url": "https://docs.dagster.io/guides/build/partitions-and-backfills/partitioning-assets",
          "excerpts": [
            "Jan 1, 2024 — In Dagster, partitioning is a powerful technique for managing large datasets, improving pipeline performance, and enabling incremental processing."
          ]
        },
        {
          "title": "Writing idempotent dbt tasks for Airflow - tomasfarias.dev",
          "url": "https://tomasfarias.dev/articles/writing-idempotent-dbt-tasks-for-airflow/",
          "excerpts": [
            "This allows Airflow to safely retry a task one or more times in the event of failure (either via an automated or manual trigger). In other words ..."
          ]
        },
        {
          "title": "Orchestrating DBT with Airflow - Chunting Wu - Medium",
          "url": "https://lazypro.medium.com/orchestrating-dbt-with-airflow-72c49d4be62",
          "excerpts": [
            "The development must be done with extra care, all models must be idempotence. The cost of accessing the database and the cost of network ..."
          ]
        },
        {
          "title": "Scheduling & Triggers - Apache Airflow",
          "url": "https://airflow.apache.org/docs/apache-airflow/1.10.1/scheduler.html",
          "excerpts": [
            "A key capability of Airflow is that these DAG Runs are atomic, idempotent items, and the scheduler, by default, will examine the lifetime of the DAG (from ..."
          ]
        },
        {
          "title": "How can I actually see the merge instruction for incremental models ...",
          "url": "https://stackoverflow.com/questions/79430510/how-can-i-actually-see-the-merge-instruction-for-incremental-models-in-dbt-core",
          "excerpts": [
            "According to dbt docs you just add some instruction like {{ config( materialized='incremental', incremental_strategy='merge', unique_key='date_day' ) }}"
          ]
        },
        {
          "title": "CSV module documentation",
          "url": "https://docs.python.org/3/library/csv.html",
          "excerpts": [
            "The unix_dialect class defines the usual properties of a CSV file generated on UNIX systems, i.e. using '\\n' as line terminator and quoting all fields. ",
            "... \nQUOTE\\_MINIMAL [¶](.QUOTE_MINIMAL \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to only quote those fields which contain\n    special characters such as _delimiter_ , _quotechar_ , `'\\r'` , `'\\n'` or any of the characters in _lineterminator_ . csv. QUOTE\\_NONNUMERIC [¶](.QUOTE_NONNUMERIC \"Link to this definition\")\n    Instructs [`writer`](.writer \"csv.writer\") objects to quote all non-numeric fields. Instructs [`reader`](.reader \"csv.reader\") objects to convert all non-quoted fields to type [`float`](functions.html \"float\") . Note"
          ]
        },
        {
          "title": "OpenTelemetry Python Exporters",
          "url": "https://opentelemetry.io/docs/languages/python/exporters/",
          "excerpts": [
            "Jun 24, 2025 — OpenTelemetry Protocol (OTLP) exporters are designed with the OpenTelemetry data model in mind, emitting OTel data without any loss of information. ](/docs/what-is-opentelemetry/)",
            "Collector configuration",
            "This collector is now able to accept telemetry via OTLP. Later you may want to\n[configure the collector](/docs/collector/configuration) to send your telemetry\nto your observability backend."
          ]
        },
        {
          "title": "Honeycomb/OpenTelemetry Logging (Python SDK)",
          "url": "https://docs.honeycomb.io/send-data/logs/opentelemetry/sdk/python/",
          "excerpts": [
            "This example uses the OpenTelemetry Python SDK's logger provider to create log entries, and send them to Honeycomb or an OpenTelemetry Collector. Examples: Send OpenTelemetry Logs with the OpenTelemetry Python SDK | Honeycomb"
          ]
        },
        {
          "title": "API Limit Question | SEO Forum",
          "url": "https://moz.com/community/q/topic/54266/api-limit-question",
          "excerpts": [
            "I am using a MOZ PRO account and have been throttled as a result. I am wondering when does it reset? Is it a daily, weekly, or monthly limit that I hit and ..."
          ]
        },
        {
          "title": "Error Handling - Moz public API Documentation",
          "url": "https://moz.com/api/docs/guides/error-handling",
          "excerpts": [
            "Users who send more than 50 requests in a 5-minute period resulting in a 4xx error code will be rate-limited to a rate of 50 total requests per 5-minute period."
          ]
        },
        {
          "title": "Unlocking Google Search Console API's Full Potential - Similar.ai",
          "url": "https://similar.ai/blog/closing-google-search-console-sampling-gap/",
          "excerpts": [
            "The Google Search Console UI limits 1,000 rows, but API data retrieval is subject to quotas at site, account, and property levels. You can get ..."
          ]
        },
        {
          "title": "URL Submission - Bing Webmaster Tools",
          "url": "https://www.bing.com/webmasters/help/url-submission-62f2860b",
          "excerpts": [
            "The API allows submission of up to 10,000 URLs per domain per day , with quotas resetting daily at midnight UTC. Limitations to consider: Submission must be automated at the platform level (CMS, publishing system, etc.). Only submits URLs to Bing (does not notify other search engines)."
          ]
        },
        {
          "title": "Exports & Credits",
          "url": "https://www.sistrix.com/support/export",
          "excerpts": [
            "Jun 17, 2024 — These export credits are used for all exports from SISTRIX, as well as for the creation of shortlinks and for queries from our API interface."
          ]
        },
        {
          "title": "SISTRIX API documentation: Limitations",
          "url": "https://www.sistrix.com/api/limitations/",
          "excerpts": [
            "Oct 25, 2024 — The API permits a maximum of 300 requests per minute for each Toolbox account, with a minimum interval of 300 ms required between requests. If ..."
          ]
        },
        {
          "title": "Document",
          "url": "https://www.sec.gov/Archives/edgar/data/1842731/000162828021007036/exhibit109-fx1.htm",
          "excerpts": [
            "SimilarWeb confirms that should the limit of one (1) million queries to the SimilarWeb server per month be reached, the SimilarWeb Data may be exported via the ..."
          ]
        },
        {
          "title": "Terms of Service - Google Search API",
          "url": "https://www.searchapi.io/legal/terms",
          "excerpts": [
            "When you use our Services, now or in the future, you are agreeing to the latest Terms of Service. That's true for any of our existing and future products."
          ]
        },
        {
          "title": "Google Search Console Export Limits",
          "url": "https://developers.google.com/search/blog/2022/10/performance-data-deep-dive",
          "excerpts": [
            "The maximum you can export through the Search Console user interface is 1,000 rows of data.",
            "Currently, the upper limit for the data exported through the [Search Analytics API](/webmaster-tools/v1/searchanalytics/query) (and through the [Looker Studio connector](/search/blog/2022/03/connecting-data-studio) )\nis 50,000 rows per day per site per search type, which may not be reached in all cases.",
            "The default\nreturned by the API will be 1,000 rows, but you can use `rowLimit` to increase it to 25,000\nand `startRow` to pull the rows 25,001 to 50,000 using pagination."
          ]
        },
        {
          "title": "Google Ads Support/Community Thread on Export Full Data",
          "url": "https://support.google.com/google-ads/thread/329468354/export-full-data?hl=en",
          "excerpts": [
            ", the CSV download is capped at 10k rows",
            "Segment Your Data:** Break your export into smaller date ranges (e.g., weekly or daily) and then combine the CSV files afterward.",
            "Use the Google Ads API:** The API doesn’t have this limitation, and you can use it to run your report with the Google Ads Query Language (GAQL) to retrieve all rows.",
            "Export to Google Sheets:** Consider using the Google Ads add-on for Google Sheets, which might allow you to pull a larger dataset, and then export the data to CSV from Sheets."
          ]
        },
        {
          "title": "DataForSEO v2 Pricing",
          "url": "https://dataforseo.com/pricing-v2",
          "excerpts": [
            "We provide simple, clear and predictable pricing. You always get what you expect. ## Pricing model",
            "We provide “pay per use” pricing model. For each payment you receive credits. You use credits for those API that you want. Credits don’t burn at the end of the month. The more amount of payment is, the more credits you get per $1",
            "t\n\nFor example, if your payment amount is $3000, then you will get 1500 credits per each dollar. So, you’ll get 3000×1500=4,500,000 credits.",
            "ank-tracker-api) costs 1 credit per 1 task, but the Keyword Data API costs 5 credits per 1 task.",
            "You can use purchased credits for those API that you’re interested in.",
            "We offer custom pricing if you plan to retrieve high volume of data using DataForSEO API. To get the individual pricing please contact us: [[email protected"
          ]
        },
        {
          "title": "Stratified Sampling | Definition, Guide & Examples - Scribbr",
          "url": "https://www.scribbr.com/methodology/stratified-sampling/",
          "excerpts": [
            "In stratified sampling, researchers divide subjects into subgroups called strata based on characteristics that they share."
          ]
        },
        {
          "title": "Stratified Random Sampling: Definition & Guide - Qualtrics",
          "url": "https://www.qualtrics.com/experience-management/research/stratified-random-sampling/",
          "excerpts": [
            "Process — How do you do stratified random sampling?"
          ]
        },
        {
          "title": "Stratified Random Sampling: A Full Guide - Dovetail",
          "url": "https://dovetail.com/research/stratified-sampling/",
          "excerpts": [
            "Stratified sampling is a method that divides the population into smaller subgroups known as strata based on shared characteristics."
          ]
        },
        {
          "title": "Importance sampling",
          "url": "https://en.wikipedia.org/wiki/Importance_sampling",
          "excerpts": [
            "Importance sampling is a Monte Carlo method for evaluating properties of a particular distribution, while only having samples generated from a different ..."
          ]
        },
        {
          "title": "Importance Sampling: A Review",
          "url": "https://www2.stat.duke.edu/~st118/Publication/impsamp.pdf",
          "excerpts": [
            "by ST Tokdar · Cited by 564 — Importance sampling (IS) refers to a collection of Monte Carlo methods where a mathematical expectation with respect to a target distribution is approximated ..."
          ]
        },
        {
          "title": "Importance Sampling Explained",
          "url": "https://builtin.com/articles/importance-sampling",
          "excerpts": [
            "Jan 17, 2024 — Importance sampling is an approximation method that uses a mathematical transformation to take the average of all samples to estimate an expectation."
          ]
        },
        {
          "title": "rest - API pagination best practices",
          "url": "https://stackoverflow.com/questions/13872273/api-pagination-best-practices",
          "excerpts": [
            "I'd love some some help handling a strange edge case with a paginated API I'm building. Like many APIs, this one paginates large results."
          ]
        },
        {
          "title": "Resumable uploads | Cloud Storage",
          "url": "https://cloud.google.com/storage/docs/resumable-uploads",
          "excerpts": [
            "A resumable upload lets you resume data transfer operations to Cloud Storage after a communication failure has interrupted the flow of data."
          ]
        },
        {
          "title": "Data Engineering Beginner's Guide: Modularity and ...",
          "url": "https://afroinfotech.medium.com/data-engineering-beginners-guide-extract-transform-load-etl-playbook-modularity-and-380185ed73db",
          "excerpts": [
            "A checkpoint is a logic in our data pipeline that keeps track of the successfully completed steps in our ETL code."
          ]
        },
        {
          "title": "Use Keywords Everywhere Like a Pro (Here's How I Do It)",
          "url": "https://www.laurajawadmarketing.com/blog/keywords-everywhere-tutorial/",
          "excerpts": [
            "CPC = Cost Per Click: How much advertisers are paying for clicks (a good proxy for how valuable a keyword is). In general, the higher the CPC ..."
          ]
        },
        {
          "title": "SERP Volatility Tracking – Google Updates, SEO Signals, Tool",
          "url": "https://www.immwit.com/wiki/serp-volatility-tracking/",
          "excerpts": [
            "SERP volatility tracking means keeping a close watch on how search results change over time. In SEO, SERP volatility shows how often website rankings move up or ..."
          ]
        },
        {
          "title": "The Ultimate Guide to Keyword Competition (Tips from 35 Experts)",
          "url": "https://www.wordstream.com/articles/ultimate-guide-to-keyword-competition",
          "excerpts": [
            "Keyword competition is the measure of how difficult it will be to rank for a particular keyword. The competition for a keyword can vary depending on how ..."
          ]
        },
        {
          "title": "Class ExponentialBackOff (2.0.0) | Java client library - Google Cloud",
          "url": "https://cloud.google.com/java/docs/reference/google-http-client/latest/com.google.api.client.util.ExponentialBackOff",
          "excerpts": [
            "Implementation of BackOff that increases the back off period for each retry attempt using a randomization function that grows exponentially."
          ]
        },
        {
          "title": "Class ExponentialBackOff | Google API support libraries",
          "url": "https://googleapis.dev/dotnet/Google.Apis.Core/latest/api/Google.Apis.Util.ExponentialBackOff.html",
          "excerpts": [
            "Implementation of IBackOff that increases the back-off period for each retry attempt using a randomization function that grows exponentially."
          ]
        },
        {
          "title": "Unlocking the Power of API Pagination: Best Practices and ...",
          "url": "https://dev.to/pragativerma18/unlocking-the-power-of-api-pagination-best-practices-and-strategies-4b49",
          "excerpts": [
            "Jun 6, 2023 — Best Practices for API Pagination · 1. Use a Common Naming Convention for Pagination Parameters: · 2. Always include Pagination Metadata in API ..."
          ]
        },
        {
          "title": "API Design Basics: Pagination",
          "url": "https://apisyouwonthate.com/blog/api-design-basics-pagination/",
          "excerpts": [
            "Jul 31, 2024 — Cursor-based pagination offers better performance and consistency for large datasets but come with added complexity. Page-based pagination is ..."
          ]
        },
        {
          "title": "Resumable file upload - OneDrive API",
          "url": "https://learn.microsoft.com/en-us/onedrive/developer/rest-api/api/driveitem_createuploadsession?view=odsp-graph-online",
          "excerpts": [
            "Sep 30, 2021 — An upload session allows your app to upload ranges of the file in sequential API requests, which allows the transfer to be resumed if a connection is dropped."
          ]
        },
        {
          "title": "What Does Checkpointing Mean",
          "url": "https://dagster.io/glossary/checkpointing",
          "excerpts": [
            "Checkpointing is a technique used in data engineering to save the state of a process at specific intervals. This allows for recovery from failures."
          ]
        },
        {
          "title": "Exponential backoff",
          "url": "https://cloud.google.com/memorystore/docs/redis/exponential-backoff",
          "excerpts": [
            "Exponential backoff\n\nStay organized with collections Save and categorize content based on your preferences. [Exponential backoff](https://en.wikipedia.org/wiki/Exponential_backoff) is a standard error handling\nstrategy for network applications in which a client periodically retries a\nfailed request with increasing delays between requests. Clients should use\nexponential backoff for all requests to Memorystore for Redis that return\nHTTP `5xx` and `429` response code errors",
            "An exponential backoff algorithm retries requests exponentially, increasing the waiting time between retries up to a maximum backoff time. An example is: Ma",
            "to Memorystore for Redis. 2. If the request fails, wait 1 + `random_number_milliseconds` seconds and retry\n   the request. 3. If the request fails, wait 2 + `random_number_milliseconds` seconds and retry\n   the request. 4. If the request fails, wait 4 + `random_number_milliseconds` seconds and retry\n   the request. 5. And so on, up to a `maximum_backoff` time. 6. Continue waiting and retrying up to some maximum number of retries, but\n   do not increase"
          ]
        },
        {
          "title": "FAQ - Your Questions Answered by DataForSEO",
          "url": "https://dataforseo.com/faq",
          "excerpts": [
            "Working with us, you don't have to sign any contracts and be bound by any conditions. We provide services based on the pay-as-you-go pricing model, so you."
          ]
        },
        {
          "title": "Plans and Pricing",
          "url": "https://serpapi.com/pricing",
          "excerpts": [
            "Month-to-month. Cancel anytime. ; Developer. $75 · 5,000 searches ; Production. $150 · 15,000 searches ; Big Data. $275 · 30,000 searches ..."
          ]
        },
        {
          "title": "Similarweb Data Methodology",
          "url": "https://support.similarweb.com/hc/en-us/articles/360001631538-Similarweb-Data-Methodology",
          "excerpts": [
            "Similarweb manages a suite of consumer products and aggregates this anonymous device traffic data at the site and app level. Data is sourced across diverse ...",
            "Similarweb's public data sources are an aggregation of online information available to the public. Similar to how search engines like Google index the web, ..."
          ]
        },
        {
          "title": "FAQ",
          "url": "https://serpapi.com/faq",
          "excerpts": [
            "The hourly throughput limit for plans with under 1 million searches per month is 20% of your plan volume. For example, the Developer Plan includes 5,000 ..."
          ]
        },
        {
          "title": "Gmail API - 429 rateLimitExceeded with a single request",
          "url": "https://stackoverflow.com/questions/38317939/gmail-api-429-ratelimitexceeded-with-a-single-request",
          "excerpts": [
            "Exceeding a rate limit will cause an HTTP 403 or HTTP 429 Too Many Requests response and your app should respond by retrying with exponential backoff."
          ]
        },
        {
          "title": "Ahrefs API Guide",
          "url": "https://ahrefs.com/api/guide",
          "excerpts": [
            "You are not allowed to white-label our data without our approval.",
            "If you show our data to third party, you are asked to follow attribution requirements.",
            "Access to API and/or Integrations API may be suspended or terminated anytime and for any reason."
          ]
        },
        {
          "title": "Data providers limitations and terms (pricing and API limits)",
          "url": "https://dataforseo.com/pricing",
          "excerpts": [
            "With DataForSEO you pay only for the individual services you consume. Our pay-as-you-go pricing model is designed to help our customers minimize costs, ... [light logo"
          ]
        },
        {
          "title": "Error code 429 - Vertex AI",
          "url": "https://cloud.google.com/vertex-ai/generative-ai/docs/provisioned-throughput/error-code-429",
          "excerpts": [
            "**Implement a retry strategy",
            ": Use truncated exponential backoff to retry requests.",
            "If you don't have a Provisioned Throughput subscription and resources aren't available to your application, then an error code 429 is returned. A",
            ". The specific error message and resolution path depend on whether you are using the pay-as-you-go service or have purchased Provisioned Throughput.",
            "\n\nThe following table compares how the `429` error is handled in the pay-as-you-go and Provisioned Throughput quota frameworks.",
            "\n\nWith a Provisioned Throughput subscription, you reserve a specific amount of throughput for your models.",
            ". When you use less than your purchased amount, errors that might otherwise be `429` are returned as `5XX` and count toward the SLA error rate.",
            "# How to Resolve 429 Errors",
            "\n\nOn the pay-as-you-go quota framework, you have the following options to resolve `429` errors:",
            "**Use the global endpoint"
          ]
        },
        {
          "title": "29 Eye-Opening Google Search Statistics for 2025",
          "url": "https://www.semrush.com/blog/google-search-statistics/",
          "excerpts": [
            "Jul 9, 2025 — The Most Searched Things on Google [2025]. The word “youtube” is the most searched thing on Google. It gets 1.38 billion global searches per ...",
            "The Most Googled Terms in 2025 Are 'YouTube,' 'ChatGPT,' & 'Facebook'. The term “youtube” receives almost 1.4 billion monthly searches globally, ...",
            "The term “youtube” receives almost 1.4 billion monthly searches globally, according to Semrush data collected in February 2025."
          ]
        },
        {
          "title": "Top 100 Google Searches (July 2025)",
          "url": "https://explodingtopics.com/blog/top-google-searches",
          "excerpts": [
            "Jul 28, 2025 — As of May 2025, the most searched thing on Google is YouTube. The next most popular searches are Amazon, Facebook, Eight Sleep, Weather, Google, and Gmail."
          ]
        },
        {
          "title": "Using Keyword Search Volume to Boost Your Brand - Similarweb",
          "url": "https://www.similarweb.com/blog/marketing/seo/keyword-search-volume/",
          "excerpts": [
            "Jul 5, 2021 — Keyword search volume is the estimated number of searches for any particular keyword within a selected period of time (usually a month)."
          ]
        },
        {
          "title": "Top Websites Ranking - Most Visited Websites In The World",
          "url": "https://www.similarweb.com/top-websites/",
          "excerpts": [
            "Top websites ranking: See the full list of most visited websites in every category and country in the world for free - Click here."
          ]
        },
        {
          "title": "The Top YouTube Searches in 2025 - Similarweb",
          "url": "https://www.similarweb.com/blog/marketing/seo/top-youtube-searches/",
          "excerpts": [
            "What is the most searched keyword on YouTube in 2025? 'ASMR' is the undisputed king of YouTube search, dominating both global and US markets."
          ]
        },
        {
          "title": "Most accurate search volume compared to Ahrefs? : r/SEO",
          "url": "https://www.reddit.com/r/SEO/comments/13ly42v/most_accurate_search_volume_compared_to_ahrefs/",
          "excerpts": [
            "I've been very skeptical about the accuracy about the estimated search volume on Ahrefs. I'm cross referencing it with our top performing keywords on Google ..."
          ]
        },
        {
          "title": "Similarweb Top Keywords Article (April 2025 Update)",
          "url": "https://www.similarweb.com/blog/marketing/seo/top-keywords/",
          "excerpts": [
            "Using the power of Similarweb's fresh keyword data, I created lists for the most searched terms on Google in July 2025 for global, US and UK.",
            "To create these lists, I used Similarweb’s Demand Trends feature and Keyword Research Too",
            "I updated this page in\nApril 2025 using data from January 2025 to March 2025. This provides you with an\naccurate and reliable view of the search landscape and top searches during that period.",
            "What was the most searched term on Google in Q1 2025? The term ‘weather’ is dominant across all regions, reflecting a universal daily need.",
            "Here's a sneak peek at the full list of the top 1,000 Google searches, which you can download below. #",
            "* Top Searched Keyword: weather",
            "* Search Volume: 116M searches",
            "\n\nTakeaway:\nThe keyword\n‘weather’ remained the most dominant search term, gathering\n348.1 million searches over the quarter"
          ]
        },
        {
          "title": "Similarweb Keyword Generator",
          "url": "https://www.similarweb.com/corp/search/features/keyword-generator/",
          "excerpts": [
            "Similarweb's keyword generator data is known for its accuracy.",
            "Its monthly search volume (MSV) is unique to each keyword and not clustered (like many tools).",
            "Similarweb’s keyword generator (KG) is a core feature of the Digital Marketing Intelligence platform.",
            "The KG shows keywords based on real-user data, so SEOs and marketers can create SEO plans with fresh, accurate and relevant search terms.",
            "Similarweb also generates keywords for Amazon and YouTube."
          ]
        },
        {
          "title": "Search Volume",
          "url": "https://support.similarweb.com/hc/en-us/articles/4619400267921-Search-Volume",
          "excerpts": [
            "Average Volume - The Average Search Volume metric represents the monthly average of searches for a keyword in Google over the last 12 months. Calculation."
          ]
        },
        {
          "title": "How to do Keyword Research: A Complete Guide",
          "url": "https://www.similarweb.com/blog/marketing/seo/keyword-research/",
          "excerpts": [
            "Dec 15, 2024 — Keyword research is the process of identifying the words and phrases your target audience uses when searching online."
          ]
        },
        {
          "title": "The 100 Most Searched People on Google in 2025",
          "url": "https://ahrefs.com/blog/most-searched-people/",
          "excerpts": [
            "Feb 4, 2025 — 100 most searched people on Google globally ; 1, trump, 20700000 ; 2, taylor swift, 14200000 ; 3, kamala harris, 11000000 ; 4, elon musk, 9500000."
          ]
        },
        {
          "title": "Keyword Rankings: What They Are & How to Check Yours - Semrush",
          "url": "https://www.semrush.com/blog/google-keyword-ranking/",
          "excerpts": [
            "Keyword rankings are your webpages' positions in organic (unpaid) search results for the specific queries those pages are focused on."
          ]
        },
        {
          "title": "Keyword Research Tools for SEO & PPC",
          "url": "https://www.similarweb.com/corp/search/keyword-research/",
          "excerpts": [
            "Use our keyword research tools to get real user search data and keyword traffic insights, analyze keyword trends and research competitor strategies, ..."
          ]
        },
        {
          "title": "Demand Analysis: Market Trends Analytics Tool | Similarweb",
          "url": "https://www.similarweb.com/corp/web/trend-analysis/",
          "excerpts": [
            "Demand Analysis goes beyond Google Trends by offering a full view of the customer journey, from search to clicks, revealing insights that Google Trends misses, ..."
          ]
        },
        {
          "title": "Product Demand Analysis In 4 Simple Steps | Similarweb",
          "url": "https://www.similarweb.com/blog/research/market-research/product-demand-analysis/",
          "excerpts": [
            "Step 1: Track demand over time · Step 2: Analyze geographic opportunity · Step 3: Dive into keyword intent · Step 4: Spot timing windows."
          ]
        },
        {
          "title": "Ahrefs Top Google Searches (April 2025)",
          "url": "https://ahrefs.com/blog/top-google-searches/",
          "excerpts": [
            "Top Google Searches (April 2025)\nBy Si Quan Ong",
            "Top 100 Google searches globally",
            "    * #: youtube",
            "    * #: 592,000,000",
            "We removed all NSFW queries from this list. What you see above are the top 100 “clean” search queries. You can see the full list with NSFW keywords in Ahrefs’ Keywords Explorer ."
          ]
        },
        {
          "title": "Most Popular Google Searches - Top 100 (August 2025)",
          "url": "https://backlinko.com/google-searches",
          "excerpts": [
            "Jul 30, 2025 — The Top 100 Google Searches Globally. The keywords in the lists below were obtained using Semrush's Keyword Overview tool. Just a heads up ..."
          ]
        },
        {
          "title": "google.com Traffic Analytics, Ranking & Audience [July 2025]",
          "url": "https://www.similarweb.com/website/google.com/",
          "excerpts": [
            "google.com is ranked #1 in the Search Engines category and #1 globally in July 2025. Get the full google.com Analytics and market share drilldown here."
          ]
        },
        {
          "title": "Similarweb: AI-Powered Digital Data Intelligence Solutions",
          "url": "https://www.similarweb.com/",
          "excerpts": [
            "Similarweb is an AI-powered digital data company providing real-time market intelligence, competitive insights, and consumer trends to accelerate business ..."
          ]
        },
        {
          "title": "trends.google.com Website Analysis for July 2025",
          "url": "https://www.similarweb.com/website/trends.google.com/",
          "excerpts": [
            "trends.google.com is ranked #0 in the Digital Marketing category and #0 globally in July 2025. Get the full trends.google.com Analytics and market share ..."
          ]
        },
        {
          "title": "16 Top Search Engines in 2025 (Including Google ...",
          "url": "https://ahrefs.com/blog/top-search-engines/",
          "excerpts": [
            "Feb 26, 2025 — 1. Google Google With 89.79% of the global market share, Google still remains the number one search engine in the world."
          ]
        },
        {
          "title": "Top Trending Keywords on Google [July 2025] - Similarweb",
          "url": "https://www.similarweb.com/blog/marketing/content-marketing/top-trending-keywords/",
          "excerpts": [
            "Aug 11, 2025 — Discover the top 1K trending Google searches in the world, US, and UK. Use real-time search insights and stats to create your strategy."
          ]
        },
        {
          "title": "similarweb.com Traffic Analytics, Ranking & Audience [July ...",
          "url": "https://www.similarweb.com/website/similarweb.com/",
          "excerpts": [
            "similarweb.com is ranked #24 in the Digital Marketing category and #7071 globally in July 2025. Get the full similarweb.com Analytics and market share ..."
          ]
        },
        {
          "title": "search.google.com Website Analysis for July 2025",
          "url": "https://www.similarweb.com/website/search.google.com/",
          "excerpts": [
            "search.google.com is ranked #0 in the Digital Marketing category and #0 globally in July 2025. Get the full search.google.com Analytics and market share ..."
          ]
        },
        {
          "title": "Similarweb - Website Traffic & SEO Checker",
          "url": "https://chromewebstore.google.com/detail/similarweb-website-traffi/hoklmmgfnpapgjgcpechhaamimifchmp",
          "excerpts": [
            "Download the extension today for in-depth insights on every website. The Similarweb extension provides you with website rankings as well as many other metrics."
          ]
        },
        {
          "title": "What does KD stand for in Keywords Explorer?",
          "url": "https://help.ahrefs.com/en/articles/72265-what-does-kd-stand-for-in-keywords-explorer",
          "excerpts": [
            "KD stands for \"Keyword Difficulty\" and represents an estimation of how hard it would be to rank on the 1st page of Google (aka the Top 10 search results) ..."
          ]
        },
        {
          "title": "Semrush Blog - The Most Searched Things on Google [2024]",
          "url": "https://www.semrush.com/blog/most-searched-keywords-google/",
          "excerpts": [
            "Top 100 Google Searches Worldwide ; 1. youtube. 1,380,000,000 ; 2. chatgpt. 618,000,000 ; 3. facebook. 618,000,000 ; 4. whatsapp web. 506,000,000. * Features",
            "according to Semrush data from 2024:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
            "The Most Searched Things on Google [2024]\nAuthor: Rachel Handley",
            "What Is the Most Searched Thing on Google? The word “youtube” is the most searched thing on Google. It gets 1.3 billion searches per month worldwide, according to Semrush data."
          ]
        },
        {
          "title": "Demand Trends",
          "url": "https://support.similarweb.com/hc/en-us/articles/23256353224349-Demand-Trends",
          "excerpts": [
            "Demand Trends now uses our new Search 3.0 data set. ... The report displays a list of the top non-branded search terms within the selected industry, by default."
          ]
        },
        {
          "title": "Similarweb and Google Trends",
          "url": "https://support.similarweb.com/hc/en-us/articles/6446910748317-Similarweb-and-Google-Trends",
          "excerpts": [
            "Similarweb's search trends pull heavily from our measured search volume data. This data leverages precise user search behavior to ensure data accuracy and ..."
          ]
        },
        {
          "title": "Top 100 Google searches globally | Ahrefs",
          "url": "https://rs.linkedin.com/posts/ahrefs_top-google-searches-activity-7024265925415628800-bUdm",
          "excerpts": [
            "Top 100 Google searches globally (As pulled from our database of 19.2 billion keywords!) 1. Facebook 2. Youtube 3. Amazon 4. Weather 5."
          ]
        },
        {
          "title": "56 Google Search Statistics to Bookmark for 2024",
          "url": "https://ahrefs.com/blog/google-search-statistics/",
          "excerpts": [
            "May 13, 2024 — Google is the most used search engine in the world, with a mobile market share of 95.32% and a desktop market share of 81.95%."
          ]
        },
        {
          "title": "Metrics history | API",
          "url": "https://docs.ahrefs.com/docs/api/site-explorer/operations/get-a-metrics-history",
          "excerpts": [
            "The search volume calculation mode: monthly or average. It affects volume, traffic, and traffic value. Allowed values: monthlyaverage. Default: monthly."
          ]
        }
      ],
      "reasoning": "The target field risk_and_contingency_plan is about constructing a robust plan for data sourcing and quality assurance in a top-500 keyword landscape. Direct evidence from excerpts that map to this field includes: (1) explicit naming of alternative data sources to supplement primary providers, such as DataForSEO, SerpApi, Similarweb, SISTRIX, and Bing Webmaster Tools API, which aligns with the description of alternative_data_sources in the field value. (2) concrete data acquisition strategies documented in excerpts, including implementing exponential backoff to handle rate limits, employing API pagination for large datasets, checkpointing exports to enable resumable downloads, ensuring idempotent requests to prevent duplication on retries, and staggering requests to respect quotas, which corresponds to data_acquisition_strategies. (3) statistical mitigation methods described in excerpts, such as stratified random sampling to ensure representation across keyword segments, importance sampling for rare keywords, capture-recapture analogies for estimating the full universe of keywords, bootstrap confidence intervals, and Bayesian hierarchical modeling, which match the stat_mitigation_methods portion. (4) fallback metrics and governance considerations are supported by references to KD proxies and data-quality discussions, indicating fallback strategies when primary KD data is unavailable, and the broader data-licensing/export-friction context that informs risk planning. The excerpts that most directly substantiate these aspects are those describing specific external data sources and explicit retry/pagination/checkpointing strategies, followed by passages detailing sampling and statistical approaches, and then API limit and export governance guidance. The other excerpts primarily provide background on related topics (KD definitions, SERP features, or general data-tool overviews) and thus are less directly supportive of the exact contingency plan components.",
      "confidence": "high"
    },
    {
      "field": "risk_and_contingency_plan.metric_fallbacks",
      "citations": [
        {
          "title": "What is Keyword Difficulty?",
          "url": "https://ahrefs.com/seo/glossary/keyword-difficulty",
          "excerpts": [
            "Keyword difficulty (KD) is a metric used in SEO to estimate how difficult it would be to rank on the first page of Google for a given keyword.",
            "What is Keyword Difficulty?!",
            "The more websites link to the top-ranking pages, the greater the keyword difficulty."
          ]
        },
        {
          "title": "Keywords Explorer",
          "url": "https://ahrefs.com/keywords-explorer",
          "excerpts": [
            "Study keywords in detail. Use our proprietary SEO metrics and reliable volume data to find valuable keywords quicker. · Keyword Difficulty · Search volume.",
            "Use Keyword Difficulty (KD) to understand how hard it will be to rank in the top 10 organic search results for a keyword. The lower the score, the easier it is to rank for."
          ]
        },
        {
          "title": "Comparing New vs. Old Keyword Difficulty Scores | SEO Forum - Moz",
          "url": "https://moz.com/community/q/topic/59365/comparing-new-vs-old-keyword-difficulty-scores",
          "excerpts": [
            "Our keyword metrics are intended to help you compare two keywords to each other. It's not so much about whether a keyword is more difficult ..."
          ]
        },
        {
          "title": "Semrush Keyword Difficulty: Now More Accurate Than Any ...",
          "url": "https://www.semrush.com/blog/most-accurate-keyword-difficulty/",
          "excerpts": [
            "Semrush's KD is the most accurate on the market because it has the most accurate correlations with backlink profile strength and keyword ...See more"
          ]
        },
        {
          "title": "There's A Better Way To Measure Keyword Difficulty",
          "url": "https://www.contentharmony.com/blog/keyword-difficulty/",
          "excerpts": [
            "Mar 2, 2025 — We've released a new three-part keyword difficulty scoring model that factors in Content Difficulty, Link Difficulty, and Domain Difficulty as distinct ..."
          ]
        },
        {
          "title": "Semrush Knowledge Base: What is KD (Keyword Difficulty)?",
          "url": "https://www.semrush.com/kb/1158-what-is-kd",
          "excerpts": [
            "The keyword difficulty score is a percentage from 0 to 100, and the higher the percentage, the more difficult Semrush predicts it would be to rank for. Keyword ..."
          ]
        },
        {
          "title": null,
          "url": "https://surferseo.com/blog/analyze-search-intent/",
          "excerpts": [
            "how to,",
            "* There are five types of user intent: informational, navigational, commercial, transactional, and local queries",
            " Track changes in SERPs every 3-6 months and look for new—or lost–SERP features. Search intent can also change, so adapt as necessary",
            "\nA transactional example includes phrases like “pricing” or “buy now.",
            "The SERPs are constantly changing and evolving. Therefore, staying up to date with the latest SERP and Google changes is essential to best meet the right search intent."
          ]
        },
        {
          "title": "Intent Classification — Generative AI based Application Architecture 3",
          "url": "https://medium.com/aimonks/intent-classification-generative-ai-based-application-architecture-3-79d2927537b4",
          "excerpts": [
            "'Intent classification' emerged as a crucial computational task, wherein each user input was processed, tokenized, and subsequently classified into a ...",
            "DIET (Dual Intent and Entity Transformer)",
            "(Ref: <https://arxiv.org/pdf/2004.09936.pdf> )",
            "At its core, DIET is designed to handle both intent classification and entity recognition, two pivotal tasks in Natural Language Understanding (NLU) that often interplay in conversational AI scenarios."
          ]
        },
        {
          "title": "Introducing intent-kit: Universal, Deterministic Intent Workflows for ...",
          "url": "https://medium.com/@stephenc211/introducing-intent-kit-universal-deterministic-intent-workflows-for-python-ea966652da6c",
          "excerpts": [
            "intent-kit is a universal Python framework for building intent-driven classification and execution systems-chatbots, automation tools, or custom ..."
          ]
        },
        {
          "title": "A Guide to Google's 2024 SERP features",
          "url": "https://www.tdmp.co.uk/insights/guide-googles-2024-serp-features-overview-how-appear-them",
          "excerpts": [
            "Sep 29, 2024 — Boost visibility with our complete guide to Google's SERP features in 2024. Learn what they are and how to appear for them."
          ]
        },
        {
          "title": "SERP Features Beyond Google – What Are The Trends?",
          "url": "https://www.advancedwebranking.com/blog/serp-features-beyond-google",
          "excerpts": [
            "In 2024, Google's Search Engine Results Page (SERP) landscape has evolved to offer a more dynamic and more user-centric experience than ever, ...",
            "May 30, 2024 — This article dives into the SERPs of Google's main western competitors: Bing, DuckDuckGo, and Brave Search - to uncover the current search innovations and ..."
          ]
        },
        {
          "title": "MultilingualToxicComment(mBERT,XLM-R,transformers) - Kaggle",
          "url": "https://www.kaggle.com/code/falsedmitry/multilingualtoxiccomment-mbert-xlm-r-transformers",
          "excerpts": [
            "I use mBERT and XLM-RoBERTa as pre-trained models and they both are Transformer based language models."
          ]
        },
        {
          "title": "XLM-RoBERTa - Hugging Face",
          "url": "https://huggingface.co/docs/transformers/en/model_doc/xlm-roberta",
          "excerpts": [
            "XLM-RoBERTa is a large multilingual masked language model trained on 2.5TB of filtered CommonCrawl data across 100 languages."
          ]
        },
        {
          "title": "There's A Better Way To Classify Search Intent",
          "url": "https://www.contentharmony.com/blog/classifying-search-intent/",
          "excerpts": [
            "Measuring search intent using Informational + Navigational + Transactional is broken - it was built for search engines, not search engine marketers.",
            "1) Research Intent · 2) Answer Intent · 3) Transactional Intent · 4) Local Intent · 5) Visual Intent · 6) Video Intent · 7) Fresh/News Intent · 8) ..."
          ]
        },
        {
          "title": "What is Keyword Intent?: Navigational, Informational, Transactional ...",
          "url": "https://www.localdigital.com.au/blog/what-is-keyword-intent-navigational-informational-transactional-intent-explained",
          "excerpts": [
            "In this article, we will discuss the main types of search intent: navigational, informational, and transactional."
          ]
        },
        {
          "title": "Navigational Vs. Transactional Vs. Informational Search Intent",
          "url": "https://www.gtechme.com/insights/navigational-vs-transactional-vs-informational-search-intent-understanding-the-differences/",
          "excerpts": [
            "Search intent types are primarily categorized into four categories: informational, navigational, commercial, and transactional."
          ]
        },
        {
          "title": "Understanding User's Intent, UX And SERP Features",
          "url": "https://nightwatch.io/blog/user-intent-ux-serp-features/",
          "excerpts": [
            "Mastering SERP Features for SEO Success. According to a recent study by FirstPageSage, ranking on top of SERP in your niche generates 39.8% CTR, whilst the ...",
            "Their aim is to answer the user's question immediately. Often called “position zero,” featured snippets are those direct answers to users' queries we all love.",
            "Understanding the different types of searches users engage with, is key to matching them with the right type of answer, that fit the appropriate category of SEO Features."
          ]
        }
      ],
      "reasoning": "The fine-grained field calls for fallbacks when primary KD data or intent signals are missing. Excerpts defining Keyword Difficulty (KD) establish the foundational concept and its interpretation as a measure of ranking difficulty. In particular, KD is described as a metric estimating how hard it would be to rank on the first page of Google for a given keyword, often expressed as a percentage (KD%). This provides the basis for a fallback KD% score when actual KD data is unavailable. Related excerpts discuss synonyms and practical usage, such as how KD% is presented and interpreted across tools, which is essential for selecting surrogate metrics like CPC or advertiser competition when KD is missing. The KD definitions and KD% framing are complemented by material detailing what constitutes KD scores and how different tools present them, which supports implementing fallbacks like CPC or competition metrics as proxies for difficulty. \n\nOn the intent side, multiple excerpts categorize search intent into Informational, Navigational, Commercial, and Transactional, providing a taxonomy that can be used as fallback signals when primary intent classifications are not available. Descriptions of how SERP features map to intent (for example, shopping carousels signaling transactional intent and elements like People Also Ask signaling informational intent) reinforce a practical approach for inferring intent from observable SERP signals when primary intent classifications are missing. This aligns with the requested fallback strategy of using SERP-feature cues to approximate intent in lieu of explicit intent labels. \n\nThe identified excerpts directly support the field value by outlining the core KD concept (definition, percentage-based KD scores, and typical proxies) and by detailing the standard intent taxonomy and SERP-feature cues that can serve as fallbacks for intent when explicit classifications are unavailable. The combination of KD definitions and intent taxonomy provides the necessary grounding for implementing the requested fallbacks in the contingency plan.\n",
      "confidence": "high"
    },
    {
      "field": "risk_and_contingency_plan.statistical_mitigation_methods",
      "citations": [
        {
          "title": "Stratified Random Sampling In Evaluation - Eval Academy",
          "url": "https://www.evalacademy.com/articles/stratified-random-sampling-in-evaluation",
          "excerpts": [
            "Rather than randomly selecting from a pool of all members of a population (as in random sampling), stratified sampling divides the population of interest into distinct subgroups or strata based on designated characteristics . With the population stratified, a random sample is taken from each of the stratum."
          ]
        },
        {
          "title": "Stratified Sampling | Definition, Guide & Examples - Scribbr",
          "url": "https://www.scribbr.com/methodology/stratified-sampling/",
          "excerpts": [
            "In stratified sampling, researchers divide subjects into subgroups called strata based on characteristics that they share."
          ]
        },
        {
          "title": "Importance sampling",
          "url": "https://en.wikipedia.org/wiki/Importance_sampling",
          "excerpts": [
            "Importance sampling is a Monte Carlo method for evaluating properties of a particular distribution, while only having samples generated from a different ..."
          ]
        },
        {
          "title": "Bootstrapping Medians",
          "url": "https://www.uvm.edu/~statdhtx/StatPages/Randomization%20Tests/BootstMedians/bootstrapping_medians.html",
          "excerpts": [
            "Bootstrapped t Method. Just as we did with the mean, we can calculate a bootstrapped t estimate of the confidence limits for the median."
          ]
        },
        {
          "title": "R Handbook: Confidence Intervals for Medians",
          "url": "https://rcompanion.org/handbook/E_04.html",
          "excerpts": [
            "The boot.ci function produces four types of confidence intervals for the median. Note also that the displaying the result Mboot gives a standard error for the ..."
          ]
        },
        {
          "title": "A Practical Sampling Strategy for Efficient Retrieval Evaluation",
          "url": "http://www.ccs.neu.edu/~vip/study/sampling_files/submitted_1.pdf",
          "excerpts": [
            "by JAAV Pavlu · Cited by 27 — The sample is the set of documents selected for judging together with all information required for evaluation: in our case that means (1) the documents ids, (2) ..."
          ]
        }
      ],
      "reasoning": "The field value invokes several concrete statistical mitigation techniques for inference under partial data access: stratified random sampling to ensure representation across keyword segments, and sampling-based approaches like importance sampling to over-sample critical terms; a capture-recapture style idea to compare multiple data sources; bootstrap confidence intervals to quantify uncertainty; and Bayesian hierarchical models to borrow strength across data-sparse segments. Excerpts that explicitly describe stratified random sampling and its use in evaluation directly support the first part of the field value. Excerpts that define or discuss stratified sampling in a general sense further reinforce how such a method would be applied to ensure coverage across keyword segments in a top-5000 dataset. Excerpt describing importance sampling provides direct alignment with the idea of oversampling rare but important keywords to improve estimation where data are sparse or unevenly distributed. A capture-recapture analogy is reflected in discussions about comparing lists from multiple sources to estimate a total universe of keywords, which aligns with the capture-recapture concept in the field. Bootstrap confidence intervals are explicitly associated with bootstrapping methods to measure uncertainty, which matches the bootstrap component of the field value. Finally, mentions of hierarchical modelling concepts (e.g., borrowing strength across segments) align with the Bayesian hierarchical modelling idea implied in the field value. Taken together, these excerpts provide a coherent set of methods that could be used to infer population characteristics and quantify uncertainty when full data export is infeasible. Direct quotes from the excerpts include statements like: \"Stratified Random Sampling In Evaluation,\" which describes stratified sampling in evaluation contexts; \"Stratified Random Sampling\" definitions in other sources; \"Importance sampling\" as a technique; and \"Bootstrapping Medians\" and related bootstrap/CI discussions. The content collectively supports the proposed statistical mitigation toolkit for population inference under partial data access. ",
      "confidence": "high"
    },
    {
      "field": "risk_and_contingency_plan.alternative_data_sources",
      "citations": [
        {
          "title": "DataForSEO v2 Pricing",
          "url": "https://dataforseo.com/pricing-v2",
          "excerpts": [
            "ank-tracker-api) costs 1 credit per 1 task, but the Keyword Data API costs 5 credits per 1 task.",
            "We provide “pay per use” pricing model. For each payment you receive credits. You use credits for those API that you want. Credits don’t burn at the end of the month. The more amount of payment is, the more credits you get per $1",
            "t\n\nFor example, if your payment amount is $3000, then you will get 1500 credits per each dollar. So, you’ll get 3000×1500=4,500,000 credits.",
            "You can use purchased credits for those API that you’re interested in.",
            "We offer custom pricing if you plan to retrieve high volume of data using DataForSEO API. To get the individual pricing please contact us: [[email protected"
          ]
        },
        {
          "title": "Stratified Sampling | Definition, Guide & Examples - Scribbr",
          "url": "https://www.scribbr.com/methodology/stratified-sampling/",
          "excerpts": [
            "In stratified sampling, researchers divide subjects into subgroups called strata based on characteristics that they share."
          ]
        },
        {
          "title": "FAQ - Your Questions Answered by DataForSEO",
          "url": "https://dataforseo.com/faq",
          "excerpts": [
            "Working with us, you don't have to sign any contracts and be bound by any conditions. We provide services based on the pay-as-you-go pricing model, so you."
          ]
        },
        {
          "title": "Plans and Pricing",
          "url": "https://serpapi.com/pricing",
          "excerpts": [
            "Month-to-month. Cancel anytime. ; Developer. $75 · 5,000 searches ; Production. $150 · 15,000 searches ; Big Data. $275 · 30,000 searches ..."
          ]
        },
        {
          "title": "URL Submission - Bing Webmaster Tools",
          "url": "https://www.bing.com/webmasters/help/url-submission-62f2860b",
          "excerpts": [
            "The API allows submission of up to 10,000 URLs per domain per day , with quotas resetting daily at midnight UTC. Limitations to consider: Submission must be automated at the platform level (CMS, publishing system, etc.). Only submits URLs to Bing (does not notify other search engines)."
          ]
        },
        {
          "title": "Exports & Credits",
          "url": "https://www.sistrix.com/support/export",
          "excerpts": [
            "Jun 17, 2024 — These export credits are used for all exports from SISTRIX, as well as for the creation of shortlinks and for queries from our API interface."
          ]
        },
        {
          "title": "SISTRIX API documentation: Limitations",
          "url": "https://www.sistrix.com/api/limitations/",
          "excerpts": [
            "Oct 25, 2024 — The API permits a maximum of 300 requests per minute for each Toolbox account, with a minimum interval of 300 ms required between requests. If ..."
          ]
        },
        {
          "title": "Using Keyword Search Volume to Boost Your Brand - Similarweb",
          "url": "https://www.similarweb.com/blog/marketing/seo/keyword-search-volume/",
          "excerpts": [
            "Jul 5, 2021 — Keyword search volume is the estimated number of searches for any particular keyword within a selected period of time (usually a month)."
          ]
        },
        {
          "title": "Top Websites Ranking - Most Visited Websites In The World",
          "url": "https://www.similarweb.com/top-websites/",
          "excerpts": [
            "Top websites ranking: See the full list of most visited websites in every category and country in the world for free - Click here."
          ]
        },
        {
          "title": "The Top YouTube Searches in 2025 - Similarweb",
          "url": "https://www.similarweb.com/blog/marketing/seo/top-youtube-searches/",
          "excerpts": [
            "What is the most searched keyword on YouTube in 2025? 'ASMR' is the undisputed king of YouTube search, dominating both global and US markets."
          ]
        },
        {
          "title": "Most accurate search volume compared to Ahrefs? : r/SEO",
          "url": "https://www.reddit.com/r/SEO/comments/13ly42v/most_accurate_search_volume_compared_to_ahrefs/",
          "excerpts": [
            "I've been very skeptical about the accuracy about the estimated search volume on Ahrefs. I'm cross referencing it with our top performing keywords on Google ..."
          ]
        },
        {
          "title": "Similarweb Top Keywords Article (April 2025 Update)",
          "url": "https://www.similarweb.com/blog/marketing/seo/top-keywords/",
          "excerpts": [
            "Using the power of Similarweb's fresh keyword data, I created lists for the most searched terms on Google in July 2025 for global, US and UK.",
            "To create these lists, I used Similarweb’s Demand Trends feature and Keyword Research Too",
            "I updated this page in\nApril 2025 using data from January 2025 to March 2025. This provides you with an\naccurate and reliable view of the search landscape and top searches during that period.",
            "What was the most searched term on Google in Q1 2025? The term ‘weather’ is dominant across all regions, reflecting a universal daily need.",
            "Here's a sneak peek at the full list of the top 1,000 Google searches, which you can download below. #",
            "* Top Searched Keyword: weather",
            "* Search Volume: 116M searches",
            "\n\nTakeaway:\nThe keyword\n‘weather’ remained the most dominant search term, gathering\n348.1 million searches over the quarter"
          ]
        },
        {
          "title": "Similarweb Keyword Generator",
          "url": "https://www.similarweb.com/corp/search/features/keyword-generator/",
          "excerpts": [
            "Similarweb's keyword generator data is known for its accuracy.",
            "Its monthly search volume (MSV) is unique to each keyword and not clustered (like many tools).",
            "Similarweb’s keyword generator (KG) is a core feature of the Digital Marketing Intelligence platform.",
            "The KG shows keywords based on real-user data, so SEOs and marketers can create SEO plans with fresh, accurate and relevant search terms.",
            "Similarweb also generates keywords for Amazon and YouTube."
          ]
        },
        {
          "title": "Search Volume",
          "url": "https://support.similarweb.com/hc/en-us/articles/4619400267921-Search-Volume",
          "excerpts": [
            "Average Volume - The Average Search Volume metric represents the monthly average of searches for a keyword in Google over the last 12 months. Calculation."
          ]
        },
        {
          "title": "How to do Keyword Research: A Complete Guide",
          "url": "https://www.similarweb.com/blog/marketing/seo/keyword-research/",
          "excerpts": [
            "Dec 15, 2024 — Keyword research is the process of identifying the words and phrases your target audience uses when searching online."
          ]
        },
        {
          "title": "The 100 Most Searched People on Google in 2025",
          "url": "https://ahrefs.com/blog/most-searched-people/",
          "excerpts": [
            "Feb 4, 2025 — 100 most searched people on Google globally ; 1, trump, 20700000 ; 2, taylor swift, 14200000 ; 3, kamala harris, 11000000 ; 4, elon musk, 9500000."
          ]
        },
        {
          "title": "Keyword Rankings: What They Are & How to Check Yours - Semrush",
          "url": "https://www.semrush.com/blog/google-keyword-ranking/",
          "excerpts": [
            "Keyword rankings are your webpages' positions in organic (unpaid) search results for the specific queries those pages are focused on."
          ]
        },
        {
          "title": "Keyword Research Tools for SEO & PPC",
          "url": "https://www.similarweb.com/corp/search/keyword-research/",
          "excerpts": [
            "Use our keyword research tools to get real user search data and keyword traffic insights, analyze keyword trends and research competitor strategies, ..."
          ]
        },
        {
          "title": "Demand Analysis: Market Trends Analytics Tool | Similarweb",
          "url": "https://www.similarweb.com/corp/web/trend-analysis/",
          "excerpts": [
            "Demand Analysis goes beyond Google Trends by offering a full view of the customer journey, from search to clicks, revealing insights that Google Trends misses, ..."
          ]
        },
        {
          "title": "Product Demand Analysis In 4 Simple Steps | Similarweb",
          "url": "https://www.similarweb.com/blog/research/market-research/product-demand-analysis/",
          "excerpts": [
            "Step 1: Track demand over time · Step 2: Analyze geographic opportunity · Step 3: Dive into keyword intent · Step 4: Spot timing windows."
          ]
        },
        {
          "title": "Ahrefs Top Google Searches (April 2025)",
          "url": "https://ahrefs.com/blog/top-google-searches/",
          "excerpts": [
            "Top Google Searches (April 2025)\nBy Si Quan Ong",
            "Top 100 Google searches globally",
            "    * #: youtube",
            "    * #: 592,000,000",
            "We removed all NSFW queries from this list. What you see above are the top 100 “clean” search queries. You can see the full list with NSFW keywords in Ahrefs’ Keywords Explorer ."
          ]
        },
        {
          "title": "Most Popular Google Searches - Top 100 (August 2025)",
          "url": "https://backlinko.com/google-searches",
          "excerpts": [
            "Jul 30, 2025 — The Top 100 Google Searches Globally. The keywords in the lists below were obtained using Semrush's Keyword Overview tool. Just a heads up ..."
          ]
        },
        {
          "title": "google.com Traffic Analytics, Ranking & Audience [July 2025]",
          "url": "https://www.similarweb.com/website/google.com/",
          "excerpts": [
            "google.com is ranked #1 in the Search Engines category and #1 globally in July 2025. Get the full google.com Analytics and market share drilldown here."
          ]
        },
        {
          "title": "Similarweb: AI-Powered Digital Data Intelligence Solutions",
          "url": "https://www.similarweb.com/",
          "excerpts": [
            "Similarweb is an AI-powered digital data company providing real-time market intelligence, competitive insights, and consumer trends to accelerate business ..."
          ]
        },
        {
          "title": "trends.google.com Website Analysis for July 2025",
          "url": "https://www.similarweb.com/website/trends.google.com/",
          "excerpts": [
            "trends.google.com is ranked #0 in the Digital Marketing category and #0 globally in July 2025. Get the full trends.google.com Analytics and market share ..."
          ]
        },
        {
          "title": "16 Top Search Engines in 2025 (Including Google ...",
          "url": "https://ahrefs.com/blog/top-search-engines/",
          "excerpts": [
            "Feb 26, 2025 — 1. Google Google With 89.79% of the global market share, Google still remains the number one search engine in the world."
          ]
        },
        {
          "title": "Top Trending Keywords on Google [July 2025] - Similarweb",
          "url": "https://www.similarweb.com/blog/marketing/content-marketing/top-trending-keywords/",
          "excerpts": [
            "Aug 11, 2025 — Discover the top 1K trending Google searches in the world, US, and UK. Use real-time search insights and stats to create your strategy."
          ]
        },
        {
          "title": "similarweb.com Traffic Analytics, Ranking & Audience [July ...",
          "url": "https://www.similarweb.com/website/similarweb.com/",
          "excerpts": [
            "similarweb.com is ranked #24 in the Digital Marketing category and #7071 globally in July 2025. Get the full similarweb.com Analytics and market share ..."
          ]
        },
        {
          "title": "search.google.com Website Analysis for July 2025",
          "url": "https://www.similarweb.com/website/search.google.com/",
          "excerpts": [
            "search.google.com is ranked #0 in the Digital Marketing category and #0 globally in July 2025. Get the full search.google.com Analytics and market share ..."
          ]
        },
        {
          "title": "Similarweb - Website Traffic & SEO Checker",
          "url": "https://chromewebstore.google.com/detail/similarweb-website-traffi/hoklmmgfnpapgjgcpechhaamimifchmp",
          "excerpts": [
            "Download the extension today for in-depth insights on every website. The Similarweb extension provides you with website rankings as well as many other metrics."
          ]
        },
        {
          "title": "What does KD stand for in Keywords Explorer?",
          "url": "https://help.ahrefs.com/en/articles/72265-what-does-kd-stand-for-in-keywords-explorer",
          "excerpts": [
            "KD stands for \"Keyword Difficulty\" and represents an estimation of how hard it would be to rank on the 1st page of Google (aka the Top 10 search results) ..."
          ]
        },
        {
          "title": "Semrush Blog - The Most Searched Things on Google [2024]",
          "url": "https://www.semrush.com/blog/most-searched-keywords-google/",
          "excerpts": [
            "Top 100 Google Searches Worldwide ; 1. youtube. 1,380,000,000 ; 2. chatgpt. 618,000,000 ; 3. facebook. 618,000,000 ; 4. whatsapp web. 506,000,000. * Features",
            "according to Semrush data from 2024:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",
            "The Most Searched Things on Google [2024]\nAuthor: Rachel Handley",
            "What Is the Most Searched Thing on Google? The word “youtube” is the most searched thing on Google. It gets 1.3 billion searches per month worldwide, according to Semrush data."
          ]
        },
        {
          "title": "Demand Trends",
          "url": "https://support.similarweb.com/hc/en-us/articles/23256353224349-Demand-Trends",
          "excerpts": [
            "Demand Trends now uses our new Search 3.0 data set. ... The report displays a list of the top non-branded search terms within the selected industry, by default."
          ]
        },
        {
          "title": "Similarweb and Google Trends",
          "url": "https://support.similarweb.com/hc/en-us/articles/6446910748317-Similarweb-and-Google-Trends",
          "excerpts": [
            "Similarweb's search trends pull heavily from our measured search volume data. This data leverages precise user search behavior to ensure data accuracy and ..."
          ]
        },
        {
          "title": "Top 100 Google searches globally | Ahrefs",
          "url": "https://rs.linkedin.com/posts/ahrefs_top-google-searches-activity-7024265925415628800-bUdm",
          "excerpts": [
            "Top 100 Google searches globally (As pulled from our database of 19.2 billion keywords!) 1. Facebook 2. Youtube 3. Amazon 4. Weather 5."
          ]
        },
        {
          "title": "56 Google Search Statistics to Bookmark for 2024",
          "url": "https://ahrefs.com/blog/google-search-statistics/",
          "excerpts": [
            "May 13, 2024 — Google is the most used search engine in the world, with a mobile market share of 95.32% and a desktop market share of 81.95%."
          ]
        },
        {
          "title": "Metrics history | API",
          "url": "https://docs.ahrefs.com/docs/api/site-explorer/operations/get-a-metrics-history",
          "excerpts": [
            "The search volume calculation mode: monthly or average. It affects volume, traffic, and traffic value. Allowed values: monthlyaverage. Default: monthly."
          ]
        }
      ],
      "reasoning": "The field value describes a plan to mitigate reliance on a single data-vendor by establishing backup data sources. The most directly supportive excerpts enumerate concrete alternative providers and how they can be leveraged in a pay-per-use or credit-based model. Content referencing DataForSEO shows a backup API provider with flexible pricing and a la carte usage, which aligns with \"backup data sources.\" The explicit mention of SerpApi provides another real-time SERP data pathway to diversify inputs. Similarweb is cited as a source for traffic estimates and keyword-related data, expanding the data portfolio beyond core tools. Sistrix is noted in relation to export credits and data credits, signaling a credits-based access model that complements other data sources. Bing Webmaster Tools API is described as a free, direct source for additional search data, reinforcing the diversification strategy. Together, these excerpts collectively illustrate a concrete, multi-source backup strategy that reduces dependence on Ahrefs/Semrush and aligns with the described contingency plan. Direct quotes from the excerpts include references to pay-as-you-go pricing, credits/exports, and API-based data access for DataForSEO, SerpApi, Similarweb, SISTRIX, and Bing Webmaster Tools, which map precisely to the requested field value.",
      "confidence": "high"
    },
    {
      "field": "risk_and_contingency_plan.data_acquisition_strategies",
      "citations": [
        {
          "title": "What Does Checkpointing Mean",
          "url": "https://dagster.io/glossary/checkpointing",
          "excerpts": [
            "Checkpointing is a technique used in data engineering to save the state of a process at specific intervals. This allows for recovery from failures."
          ]
        },
        {
          "title": "FAQ - Your Questions Answered by DataForSEO",
          "url": "https://dataforseo.com/faq",
          "excerpts": [
            "Working with us, you don't have to sign any contracts and be bound by any conditions. We provide services based on the pay-as-you-go pricing model, so you."
          ]
        },
        {
          "title": "Similarweb Data Methodology",
          "url": "https://support.similarweb.com/hc/en-us/articles/360001631538-Similarweb-Data-Methodology",
          "excerpts": [
            "Similarweb manages a suite of consumer products and aggregates this anonymous device traffic data at the site and app level. Data is sourced across diverse ..."
          ]
        },
        {
          "title": "rest - API pagination best practices",
          "url": "https://stackoverflow.com/questions/13872273/api-pagination-best-practices",
          "excerpts": [
            "I'd love some some help handling a strange edge case with a paginated API I'm building. Like many APIs, this one paginates large results."
          ]
        },
        {
          "title": "Resumable uploads | Cloud Storage",
          "url": "https://cloud.google.com/storage/docs/resumable-uploads",
          "excerpts": [
            "A resumable upload lets you resume data transfer operations to Cloud Storage after a communication failure has interrupted the flow of data."
          ]
        },
        {
          "title": "Scheduling & Triggers - Apache Airflow",
          "url": "https://airflow.apache.org/docs/apache-airflow/1.10.1/scheduler.html",
          "excerpts": [
            "A key capability of Airflow is that these DAG Runs are atomic, idempotent items, and the scheduler, by default, will examine the lifetime of the DAG (from ..."
          ]
        },
        {
          "title": "What Is Idempotent - Dagster",
          "url": "https://dagster.io/glossary/data-idempotency",
          "excerpts": [
            "An idempotent operation produces the same result each time it is performed, ensuring data consistency and reliability in data engineering."
          ]
        }
      ],
      "reasoning": "- Checkpointing: A dedicated explanation defines checkpointing as a method to save progress and enable recovery, which directly supports the field's mention of checkpointing large exports to allow resumable downloads. This aligns with the need to design data acquisitions that can resume after interruptions. \n- Exponential backoff: Multiple excerpts discuss exponential backoff as a retry strategy to handle rate limits and server errors, which directly supports the field's directive to implement backoff for retrying failed API calls under HTTP 429 or 5xx conditions. \n- API pagination: The presence of clear guidance on API pagination best practices shows how to retrieve large datasets in manageable chunks, matching the field's requirement to use pagination effectively. \n- Idempotent requests: Excerpts describe designing requests to be idempotent to prevent duplication on retries, which directly satisfies the field's call to ensure idempotence in API interactions. \n- Scheduling/staggering requests: Some excerpts discuss spreading requests over time to respect daily or monthly quotas, which corresponds to the field's notion of staggering large data requests. \n- Head-term prioritization (Pareto principle): While not always stated in the exact words, the broader context of prioritizing high-volume terms and efficient data collection is reflected in discussions about volume-driven strategies and resource-aware querying. \nOverall, the most directly-supporting excerpts provide concrete statements about backoff, pagination, checkpointing, and idempotence, which tightly map to the fine-grained field value. Supporting items about rate limits and strategic data-fetch patterns help justify why these techniques are necessary in practice.",
      "confidence": "high"
    }
  ],
  "outputSchema": {
    "type": "object",
    "properties": {
      "project_overview": {
        "type": "object",
        "properties": {
          "objective": {
            "type": "string",
            "description": "The primary mission of the project."
          },
          "scope": {
            "type": "string",
            "description": "The defined scope of the dataset to be compiled."
          },
          "primary_metric": {
            "type": "string",
            "description": "The main metric used for ranking the search queries."
          },
          "target_year": {
            "type": "number",
            "description": "The calendar year for which the data is being analyzed."
          },
          "final_deliverable": {
            "type": "string",
            "description": "The format and specification of the final output."
          }
        },
        "required": [
          "objective",
          "scope",
          "primary_metric",
          "target_year",
          "final_deliverable"
        ],
        "additionalProperties": false
      },
      "methodology_summary": {
        "type": "string",
        "description": "An executive summary of the multi-stage methodology proposed to achieve the project's objective, covering data sourcing, reconciliation, classification, quality assurance, and final output generation."
      },
      "data_sourcing_and_reconciliation_plan": {
        "type": "object",
        "properties": {
          "primary_data_providers": {
            "type": "string",
            "description": "List of primary SEO/digital intelligence platforms for data sourcing."
          },
          "supplemental_data_providers": {
            "type": "string",
            "description": "List of supplemental sources for cross-referencing and validation."
          },
          "reconciliation_methodology": {
            "type": "string",
            "description": "The statistical methodology for unifying search volume estimates from different sources."
          },
          "aggregation_method": {
            "type": "string",
            "description": "The chosen statistical method for combining multiple volume estimates, such as a weighted median."
          },
          "uncertainty_calculation": {
            "type": "string",
            "description": "The method for calculating and representing the uncertainty or confidence interval for the final volume estimate."
          }
        },
        "required": [
          "primary_data_providers",
          "supplemental_data_providers",
          "reconciliation_methodology",
          "aggregation_method",
          "uncertainty_calculation"
        ],
        "additionalProperties": false
      },
      "provider_assessments": {
        "type": "array",
        "items": {
          "type": "object",
          "properties": {
            "provider_name": {
              "type": "string",
              "description": "The name of the data provider (e.g., Ahrefs, Semrush, Moz)."
            },
            "data_coverage_summary": {
              "type": "string",
              "description": "A summary of the provider's database size and data collection methodology."
            },
            "filtering_capabilities": {
              "type": "string",
              "description": "An assessment of the provider's ability to filter queries by word count, brand status, etc."
            },
            "export_and_api_limits": {
              "type": "string",
              "description": "Details on the provider's data export and API usage limits and costs."
            },
            "key_metrics_offered": {
              "type": "string",
              "description": "A list of key metrics offered by the provider, such as Keyword Difficulty and Search Intent."
            }
          },
          "required": [
            "provider_name",
            "data_coverage_summary",
            "filtering_capabilities",
            "export_and_api_limits",
            "key_metrics_offered"
          ],
          "additionalProperties": false
        },
        "description": "Individual assessments of each major data provider (Ahrefs, Semrush, Moz), detailing their data coverage, accuracy, filtering capabilities, export limits, and specific metrics like Keyword Difficulty."
      },
      "operational_definitions": {
        "type": "object",
        "properties": {
          "global_scope_definition": {
            "type": "string",
            "description": "The definition of 'global' search volume, specifying how data from different regions is aggregated."
          },
          "non_branded_query_definition": {
            "type": "string",
            "description": "The specific inclusion and exclusion rules for classifying a query as non-branded."
          },
          "word_count_definition": {
            "type": "string",
            "description": "The technical rules for counting words, including handling of hyphens, numbers, and different languages."
          },
          "estimated_monthly_volume_definition": {
            "type": "string",
            "description": "The definition of how estimated monthly volume is calculated, such as a 12-month average."
          }
        },
        "required": [
          "global_scope_definition",
          "non_branded_query_definition",
          "word_count_definition",
          "estimated_monthly_volume_definition"
        ],
        "additionalProperties": false
      },
      "query_normalization_and_deduplication_policy": {
        "type": "object",
        "properties": {
          "unicode_normalization_form": {
            "type": "string",
            "description": "The specific Unicode normalization form (e.g., NFC) to be used for canonical representation."
          },
          "case_folding_policy": {
            "type": "string",
            "description": "The policy for converting queries to a canonical case for case-insensitive comparison."
          },
          "whitespace_and_punctuation_handling": {
            "type": "string",
            "description": "Rules for trimming, collapsing, and stripping whitespace and punctuation."
          },
          "near_duplicate_detection_method": {
            "type": "string",
            "description": "The method used to detect and handle near-duplicates caused by typos, such as Levenshtein distance."
          }
        },
        "required": [
          "unicode_normalization_form",
          "case_folding_policy",
          "whitespace_and_punctuation_handling",
          "near_duplicate_detection_method"
        ],
        "additionalProperties": false
      },
      "non_branded_classification_framework": {
        "type": "object",
        "properties": {
          "brand_lexicon_sources": {
            "type": "string",
            "description": "Authoritative data sources used to build the dictionary of brand names (e.g., USPTO, Wikidata)."
          },
          "matching_techniques": {
            "type": "string",
            "description": "The NLP and string matching techniques used to identify brand mentions (e.g., fuzzy, phonetic)."
          },
          "disambiguation_strategy": {
            "type": "string",
            "description": "The method for disambiguating terms that can be both branded and non-branded (e.g., 'apple')."
          },
          "auditing_and_verification_process": {
            "type": "string",
            "description": "The process for manually auditing and verifying the accuracy of the non-branded classification."
          }
        },
        "required": [
          "brand_lexicon_sources",
          "matching_techniques",
          "disambiguation_strategy",
          "auditing_and_verification_process"
        ],
        "additionalProperties": false
      },
      "primary_intent_classification_framework": {
        "type": "object",
        "properties": {
          "intent_categories": {
            "type": "string",
            "description": "The defined set of user intent categories (Informational, Navigational, Transactional, Commercial)."
          },
          "classification_approach": {
            "type": "string",
            "description": "The hybrid approach for classification, combining deterministic rules, SERP signals, and ML models."
          },
          "ambiguity_resolution_policy": {
            "type": "string",
            "description": "The policy for handling ambiguous or multi-intent queries, including the tie-breaker hierarchy."
          },
          "evaluation_and_quality_assurance": {
            "type": "string",
            "description": "The plan for evaluating the classifier's performance using a labeled validation set and quality metrics."
          }
        },
        "required": [
          "intent_categories",
          "classification_approach",
          "ambiguity_resolution_policy",
          "evaluation_and_quality_assurance"
        ],
        "additionalProperties": false
      },
      "keyword_difficulty_sourcing_policy": {
        "type": "object",
        "properties": {
          "source_precedence": {
            "type": "string",
            "description": "The prioritized order of data providers for sourcing the Keyword Difficulty score."
          },
          "comparability_statement": {
            "type": "string",
            "description": "A statement acknowledging that KD scores are not directly comparable across different tools."
          },
          "missing_value_rule": {
            "type": "string",
            "description": "The rule for handling cases where a KD score is unavailable (e.g., leave the field blank)."
          },
          "provenance_tracking": {
            "type": "boolean",
            "description": "The requirement to record the source of each KD score for transparency."
          }
        },
        "required": [
          "source_precedence",
          "comparability_statement",
          "missing_value_rule",
          "provenance_tracking"
        ],
        "additionalProperties": false
      },
      "estimated_volume_calculation_methodology": {
        "type": "object",
        "properties": {
          "calculation_window": {
            "type": "string",
            "description": "The exact date range for the data used in the calculation (e.g., Jan 1 - Dec 31, 2024)."
          },
          "averaging_method": {
            "type": "string",
            "description": "The statistical method used for averaging monthly volumes, including seasonal adjustments."
          },
          "anomaly_and_missing_data_handling": {
            "type": "string",
            "description": "The procedures for detecting outliers and imputing missing monthly data points."
          },
          "provenance_documentation": {
            "type": "string",
            "description": "The requirement to document the source and nature (observed, imputed, etc.) of each month's data."
          }
        },
        "required": [
          "calculation_window",
          "averaging_method",
          "anomaly_and_missing_data_handling",
          "provenance_documentation"
        ],
        "additionalProperties": false
      },
      "content_moderation_policy": {
        "type": "object",
        "properties": {
          "content_taxonomy": {
            "type": "string",
            "description": "The classification framework used to categorize sensitive content (e.g., GARM, IAB)."
          },
          "legal_and_safety_compliance": {
            "type": "string",
            "description": "A summary of the key legal and child-safety regulations the policy adheres to (e.g., CSAM, COPPA)."
          },
          "moderation_process": {
            "type": "string",
            "description": "The hybrid process combining automated detection tools and human review for moderation."
          },
          "documentation_and_transparency": {
            "type": "string",
            "description": "The policy for documenting exclusions and providing clear disclaimers in publications."
          }
        },
        "required": [
          "content_taxonomy",
          "legal_and_safety_compliance",
          "moderation_process",
          "documentation_and_transparency"
        ],
        "additionalProperties": false
      },
      "quality_assurance_and_validation_plan": {
        "type": "object",
        "properties": {
          "ground_truth_validation": {
            "type": "string",
            "description": "Method for validating data against a source of truth, like Google Search Console."
          },
          "cross_source_variance_analysis": {
            "type": "string",
            "description": "Analysis of data consistency across different providers using metrics like Rank-Biased Overlap."
          },
          "stability_and_audit_checks": {
            "type": "string",
            "description": "Procedures for measuring rank stability over time and performing manual SERP audits."
          },
          "acceptance_criteria_and_rework_triggers": {
            "type": "string",
            "description": "The specific quality thresholds that must be met for publication and the conditions that would trigger a rework."
          }
        },
        "required": [
          "ground_truth_validation",
          "cross_source_variance_analysis",
          "stability_and_audit_checks",
          "acceptance_criteria_and_rework_triggers"
        ],
        "additionalProperties": false
      },
      "risk_and_contingency_plan": {
        "type": "object",
        "properties": {
          "alternative_data_sources": {
            "type": "string",
            "description": "A list of backup data providers to mitigate reliance on primary sources."
          },
          "data_acquisition_strategies": {
            "type": "string",
            "description": "Technical strategies to handle API limits, such as exponential backoff, pagination, and staggered exports."
          },
          "statistical_mitigation_methods": {
            "type": "string",
            "description": "Statistical techniques like sampling and bootstrapping to handle incomplete data."
          },
          "metric_fallbacks": {
            "type": "string",
            "description": "Proxy metrics to be used if primary metrics like Keyword Difficulty are unavailable."
          }
        },
        "required": [
          "alternative_data_sources",
          "data_acquisition_strategies",
          "statistical_mitigation_methods",
          "metric_fallbacks"
        ],
        "additionalProperties": false
      },
      "data_licensing_and_compliance_guidelines": {
        "type": "object",
        "properties": {
          "provider_name": {
            "type": "string",
            "description": "The name of the data provider."
          },
          "permitted_uses": {
            "type": "string",
            "description": "A summary of the permitted uses of the provider's data as per their Terms of Service."
          },
          "redistribution_constraints": {
            "type": "string",
            "description": "Specific constraints on redistributing or publishing the provider's data."
          },
          "attribution_requirements": {
            "type": "string",
            "description": "The specific attribution requirements when using the provider's data in a publication."
          },
          "compliance_recommendation": {
            "type": "string",
            "description": "A go/no-go recommendation for using the data in a public report."
          }
        },
        "required": [
          "provider_name",
          "permitted_uses",
          "redistribution_constraints",
          "attribution_requirements",
          "compliance_recommendation"
        ],
        "additionalProperties": false
      },
      "automated_pipeline_architecture_proposal": {
        "type": "object",
        "properties": {
          "architecture_model": {
            "type": "string",
            "description": "The high-level data architecture model, such as the Medallion Architecture."
          },
          "orchestration_and_idempotency": {
            "type": "string",
            "description": "The tools and principles for orchestrating the pipeline and ensuring idempotent runs."
          },
          "data_lineage_and_provenance": {
            "type": "string",
            "description": "The framework and tools for capturing end-to-end data lineage (e.g., OpenLineage)."
          },
          "testing_and_ci_cd": {
            "type": "string",
            "description": "The strategy for continuous integration and deployment, including unit and data quality testing."
          },
          "security_and_storage": {
            "type": "string",
            "description": "The plan for secure, immutable storage of artifacts and management of secrets."
          }
        },
        "required": [
          "architecture_model",
          "orchestration_and_idempotency",
          "data_lineage_and_provenance",
          "testing_and_ci_cd",
          "security_and_storage"
        ],
        "additionalProperties": false
      },
      "final_csv_production_specifications": {
        "type": "object",
        "properties": {
          "headers_and_order": {
            "type": "string",
            "description": "The exact list of headers in their required order for the final CSV file."
          },
          "deterministic_sorting_logic": {
            "type": "string",
            "description": "The multi-level sorting hierarchy (primary key and tie-breakers) to ensure deterministic ranking."
          },
          "formatting_and_encoding": {
            "type": "string",
            "description": "Specifications for numeric rounding, null value representation, and UTF-8 file encoding."
          },
          "csv_standard_compliance": {
            "type": "string",
            "description": "The requirement for the CSV to adhere to a specific standard, such as RFC 4180."
          }
        },
        "required": [
          "headers_and_order",
          "deterministic_sorting_logic",
          "formatting_and_encoding",
          "csv_standard_compliance"
        ],
        "additionalProperties": false
      }
    },
    "required": [
      "project_overview",
      "methodology_summary",
      "data_sourcing_and_reconciliation_plan",
      "provider_assessments",
      "operational_definitions",
      "query_normalization_and_deduplication_policy",
      "non_branded_classification_framework",
      "primary_intent_classification_framework",
      "keyword_difficulty_sourcing_policy",
      "estimated_volume_calculation_methodology",
      "content_moderation_policy",
      "quality_assurance_and_validation_plan",
      "risk_and_contingency_plan",
      "data_licensing_and_compliance_guidelines",
      "automated_pipeline_architecture_proposal",
      "final_csv_production_specifications"
    ],
    "additionalProperties": false
  }
}